{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import ray\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from ml_collections import config_dict\n",
    "from ray import tune, air\n",
    "from ray.air import session, Checkpoint\n",
    "from ray.tune.schedulers import PopulationBasedTraining\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def get_config():\n",
    "    config = config_dict.ConfigDict()\n",
    "    # General parameters\n",
    "    config.dataset = 'Organoid'\n",
    "    config.model = 'VAE'\n",
    "    config.seed = 12345\n",
    "    config.output_dir = './logs/VanillaVAE/'\n",
    "    config.device = 'cuda'\n",
    "    config.epochs = 10000\n",
    "\n",
    "    # VAE architecture parameters\n",
    "    config.architecture = config_dict.ConfigDict()\n",
    "    config.architecture.in_features = 41\n",
    "    config.architecture.latent_dim = 2\n",
    "    config.architecture.hidden_dims = (32, 32, 32)\n",
    "    config.architecture.kld_weight = 0.0025\n",
    "    config.architecture.loss_type = 'beta'\n",
    "    config.architecture.activation = 'GELU'\n",
    "\n",
    "    # Tunable parameters\n",
    "    config.tunable = config_dict.ConfigDict()\n",
    "    config.tunable.learning_rate = 0.05\n",
    "    config.tunable.weight_decay = 0.0\n",
    "    config.tunable.batch_size = 4096\n",
    "    return config"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class BetaVAE(nn.Module):\n",
    "\n",
    "    def __init__(self, config: config_dict.ConfigDict) -> None:\n",
    "        super(BetaVAE, self).__init__()\n",
    "\n",
    "        self.config = config\n",
    "        self.kld_weight = torch.Tensor([config.architecture.kld_weight]).to(config.device)\n",
    "\n",
    "        self.act_class = getattr(nn, config.architecture.activation)\n",
    "\n",
    "        modules = []\n",
    "\n",
    "        # Build Encoder\n",
    "\n",
    "        encoder_dims = [config.architecture.in_features] + list(config.architecture.hidden_dims)\n",
    "\n",
    "        for i in range(len(config.architecture.hidden_dims)):\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(in_features=encoder_dims[i], out_features=encoder_dims[i + 1]),\n",
    "                    nn.BatchNorm1d(encoder_dims[i + 1]),\n",
    "                    self.act_class(),\n",
    "                )\n",
    "            )\n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "        self.fc_mu = nn.Linear(config.architecture.hidden_dims[-1], config.architecture.latent_dim)\n",
    "        self.fc_var = nn.Linear(config.architecture.hidden_dims[-1], config.architecture.latent_dim)\n",
    "\n",
    "        # Build Decoder\n",
    "        modules = []\n",
    "        decoder_dims = [config.architecture.latent_dim] + list(reversed(config.architecture.hidden_dims)) + [config.architecture.in_features]\n",
    "\n",
    "        for i in range(len(config.architecture.hidden_dims) + 1):\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(decoder_dims[i], decoder_dims[i + 1]),\n",
    "                    nn.BatchNorm1d(decoder_dims[i + 1]),\n",
    "                    self.act_class()\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.decoder = nn.Sequential(*modules)\n",
    "        self.final_layer = nn.Linear(config.architecture.in_features, config.architecture.in_features)\n",
    "\n",
    "    def encode(self, input: torch.Tensor) -> List[torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Encodes the input by passing through the encoder network\n",
    "        and returns the latent codes.\n",
    "        :param input: (Tensor) Input tensor to encoder [N x C]\n",
    "        :return: (Tensor) List of latent codes\n",
    "        \"\"\"\n",
    "        result = self.encoder(input)\n",
    "        result = torch.flatten(result, start_dim=1)\n",
    "\n",
    "        # Split the result into mu and var components\n",
    "        # of the latent Gaussian distribution\n",
    "        mu = self.fc_mu(result)\n",
    "        log_var = self.fc_var(result)\n",
    "\n",
    "        return [mu, log_var]\n",
    "\n",
    "    def decode(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Maps the given latent codes\n",
    "        onto the sample matrix space.\n",
    "        :param z: (Tensor) [B x D]\n",
    "        :return: (Tensor) [B x C]\n",
    "        \"\"\"\n",
    "        # Only batch - normalized layers\n",
    "        result = self.decoder(z)\n",
    "        # Use linear layer to map normalized decoder outputs back to input space\n",
    "        result = self.final_layer(result)\n",
    "        return result\n",
    "\n",
    "    def reparameterize(self, mu: torch.Tensor, logvar: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Reparameterization trick to sample from N(mu, var) from\n",
    "        N(0,1).\n",
    "        :param mu: (Tensor) Mean of the latent Gaussian [B x D]\n",
    "        :param logvar: (Tensor) Standard deviation of the latent Gaussian [B x D]\n",
    "        :return: (Tensor) [B x D]\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps * std + mu\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> List[torch.Tensor]:\n",
    "        mu, log_var = self.encode(input)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        return [self.decode(z), input, mu, log_var]\n",
    "\n",
    "    def loss_function(self,\n",
    "                      *args) -> dict:\n",
    "        r\"\"\"\n",
    "        Computes the VAE loss function.\n",
    "        KL(N(\\mu, \\sigma), N(0, 1)) = \\log \\frac{1}{\\sigma} + \\frac{\\sigma^2 + \\mu^2}{2} - \\frac{1}{2}\n",
    "        :param epoch: current epoch\n",
    "        :param args:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        recons = args[0]\n",
    "        input = args[1]\n",
    "        mu = args[2]\n",
    "        log_var = args[3]\n",
    "\n",
    "        recons_loss = F.mse_loss(recons, input)\n",
    "\n",
    "        kld_loss = torch.mean(-0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp(), dim=1), dim=0)\n",
    "\n",
    "        loss = recons_loss + self.kld_weight * kld_loss\n",
    "\n",
    "        return {'loss': loss, 'MSE': recons_loss.detach(), 'KLD': -kld_loss.detach()}\n",
    "\n",
    "    def generate(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Given an input sample matrix x, returns the reconstructed sample matrix\n",
    "        :param x: (Tensor) [B x C]\n",
    "        :return: (Tensor) [B x C]\n",
    "        \"\"\"\n",
    "\n",
    "        return self.forward(x)[0]\n",
    "\n",
    "    def latent(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.reparameterize(*self.encode(x))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from datasets import OrganoidDataset\n",
    "\n",
    "data = OrganoidDataset()\n",
    "\n",
    "X_train, y_train = data.train\n",
    "X_val, y_val = data.val\n",
    "config = get_config()\n",
    "X_train_batches = torch.split(X_train, split_size_or_sections=config.tunable.batch_size)\n",
    "X_val_batches = torch.split(X_val, split_size_or_sections=config.tunable.batch_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4096, 41])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_batches[0].shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "model = BetaVAE(config).to(config.device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "{'loss': tensor([6.0899], device='cuda:0', grad_fn=<AddBackward0>),\n 'MSE': tensor(6.0893, device='cuda:0'),\n 'KLD': tensor(-0.2448, device='cuda:0')}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loss_function(*model.forward(X_train_batches[0]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def train(model,optimizer,train_dataloader):\n",
    "    for X_batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        model.train()\n",
    "        outputs = model.forward(X_batch)\n",
    "        loss = model.loss_function(*outputs)\n",
    "\n",
    "        loss['loss'].backward()\n",
    "        optimizer.step()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def test(model,val_dataloader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        mse,kld,loss = list(),list(),list()\n",
    "        for X_batch in val_dataloader:\n",
    "            loss_dict = dict()\n",
    "            outputs = model.forward(X_batch)\n",
    "            losses = model.loss_function(*outputs)\n",
    "            for key in losses.keys():\n",
    "                loss_dict[key] = losses[key].item() * X_batch.shape[0]\n",
    "            mse.append(loss_dict['MSE'])\n",
    "            kld.append(loss_dict['KLD'])\n",
    "            loss.append(loss_dict['loss'])\n",
    "    data_len = sum(len(batch) for batch in val_dataloader)\n",
    "    return sum(mse)/data_len,sum(kld)/data_len, sum(loss)/data_len\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%        \n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "model = BetaVAE(config).to(config.device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(),\n",
    "                        lr=config.get(\"learning_rate\", 0.05),\n",
    "                        weight_decay=config.get(\"weight_decay\", 0.0),\n",
    "                        )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "train(model,optimizer,X_train_batches)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.47315053030962567, -6.747065047704933, 0.4900181938554461)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model,X_val_batches)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def vae_train(cfg):\n",
    "    config = cfg.get('default_config')\n",
    "    model = BetaVAE(config).to(config.device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(),\n",
    "                           lr=config.get(\"learning_rate\", 0.05),\n",
    "                           weight_decay=config.get(\"weight_decay\", 0.0),\n",
    "                           )\n",
    "\n",
    "    dataset = OrganoidDataset(data_dir='/data/PycharmProjects/cytof_benchmark/data/organoids')\n",
    "    X_train, y_train = dataset.train\n",
    "    X_val, y_val = dataset.val\n",
    "    X_train_batches = torch.split(X_train, split_size_or_sections=config.get(\"batch_size\", 16384))\n",
    "    X_val_batches = torch.split(X_val, split_size_or_sections=config.get(\"batch_size\", 16384))\n",
    "\n",
    "    step = 1\n",
    "    if session.get_checkpoint():\n",
    "        checkpoint_dict = session.get_checkpoint().to_dict()\n",
    "\n",
    "        model.load_state_dict(checkpoint_dict[\"model\"])\n",
    "        optimizer.load_state_dict(checkpoint_dict[\"optim\"])\n",
    "        # Note: Make sure to increment the loaded step by 1 to get the\n",
    "        # current step.\n",
    "        last_step = checkpoint_dict[\"step\"]\n",
    "        step = last_step + 1\n",
    "\n",
    "        # NOTE: It's important to set the optimizer learning rates\n",
    "        # again, since we want to explore the parameters passed in by PBT.\n",
    "        # Without this, we would continue using the exact same\n",
    "        # configuration as the trial whose checkpoint we are exploiting.\n",
    "        if \"learning_rate\" in cfg:\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group[\"lr\"] = cfg[\"learning_rate\"]\n",
    "        if \"weight_decay\" in cfg:\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group[\"weight_decay\"] = cfg[\"weight_decay\"]\n",
    "        print(cfg)\n",
    "    while True:\n",
    "        train(model,optimizer,X_train_batches)\n",
    "        MSE, KLD, loss = test(model,X_val_batches)\n",
    "\n",
    "        checkpoint = None\n",
    "        if step % cfg[\"checkpoint_interval\"] == 0:\n",
    "            checkpoint = Checkpoint.from_dict(\n",
    "                {\n",
    "                    \"model\": model.state_dict(),\n",
    "                    \"optim\": optimizer.state_dict(),\n",
    "                    \"step\": step,\n",
    "                }\n",
    "            )\n",
    "        session.report(\n",
    "            {\n",
    "                \"MSE\": MSE,\n",
    "                \"KLD\": KLD,\n",
    "                \"loss\": loss,\n",
    "                'lr':cfg.get(\"learning_rate\", 0.05),\n",
    "                'wd':cfg.get(\"weight_decay\", 0.0)\n",
    "            },\n",
    "            checkpoint=checkpoint,\n",
    "        )\n",
    "        step += 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 16:19:49,481\tINFO worker.py:1538 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/plain": "RayContext(dashboard_url='', python_version='3.10.6', ray_version='2.2.0', ray_commit='b6af0887ee5f2e460202133791ad941a41f15beb', address_info={'node_ip_address': '192.168.2.8', 'raylet_ip_address': '192.168.2.8', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2023-01-09_16-19-47_736769_6133/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2023-01-09_16-19-47_736769_6133/sockets/raylet', 'webui_url': '', 'session_dir': '/tmp/ray/session_2023-01-09_16-19-47_736769_6133', 'metrics_export_port': 65453, 'gcs_address': '192.168.2.8:61897', 'address': '192.168.2.8:61897', 'dashboard_agent_listen_port': 52365, 'node_id': 'ede873d0ef94fa99805e9781462666e5c4d7066fed59e3b068ba9234'})",
      "text/html": "<div>\n    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n            <g id=\"layer-1\">\n                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n            </g>\n        </svg>\n        <table>\n            <tr>\n                <td style=\"text-align: left\"><b>Python version:</b></td>\n                <td style=\"text-align: left\"><b>3.10.6</b></td>\n            </tr>\n            <tr>\n                <td style=\"text-align: left\"><b>Ray version:</b></td>\n                <td style=\"text-align: left\"><b> 2.2.0</b></td>\n            </tr>\n            \n        </table>\n    </div>\n</div>\n"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 16:30:33,504\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial vae_train_8645f_00004\n",
      "2023-01-09 16:30:33,527\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial vae_train_8645f_00001\n",
      "2023-01-09 16:30:33,598\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial vae_train_8645f_00007\n",
      "2023-01-09 16:30:36,621\tINFO pbt.py:646 -- [pbt]: no checkpoint for trial. Skip exploit for Trial vae_train_8645f_00002\n",
      "2023-01-09 16:30:46,722\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00007 (score = -0.443788) into trial 8645f_00002 (score = -0.453924)\n",
      "\n",
      "2023-01-09 16:30:46,723\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00002:\n",
      "learning_rate : 1e-05 --- (* 0.8) --> 8.000000000000001e-06\n",
      "weight_decay : 1e-09 --- (* 1.2) --> 1.2e-09\n",
      "batch_size : 16384 --- (* 0.8) --> 13107\n",
      "\n",
      "\u001B[2m\u001B[36m(vae_train pid=21785)\u001B[0m 2023-01-09 16:30:47,586\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00002_2_2023-01-09_16-30-21/checkpoint_tmpea6de9\n",
      "\u001B[2m\u001B[36m(vae_train pid=21785)\u001B[0m 2023-01-09 16:30:47,586\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 27, '_timesteps_total': None, '_time_total': 21.14049220085144, '_episodes_total': None}\n",
      "\u001B[2m\u001B[36m(vae_train pid=22933)\u001B[0m 2023-01-09 16:30:49,896\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00005_5_2023-01-09_16-30-21/checkpoint_tmp9b2dab\n",
      "\u001B[2m\u001B[36m(vae_train pid=22933)\u001B[0m 2023-01-09 16:30:49,896\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 26, '_timesteps_total': None, '_time_total': 24.25457739830017, '_episodes_total': None}\n",
      "2023-01-09 16:30:54,526\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00006 (score = -0.427840) into trial 8645f_00003 (score = -0.446760)\n",
      "\n",
      "2023-01-09 16:30:54,528\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00003:\n",
      "learning_rate : 1e-05 --- (* 1.2) --> 1.2e-05\n",
      "weight_decay : 1e-09 --- (* 0.8) --> 8.000000000000001e-10\n",
      "batch_size : 16384 --- (resample) --> 15629\n",
      "\n",
      "\u001B[2m\u001B[36m(vae_train pid=23105)\u001B[0m 2023-01-09 16:30:56,536\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00003_3_2023-01-09_16-30-21/checkpoint_tmpae4306\n",
      "\u001B[2m\u001B[36m(vae_train pid=23105)\u001B[0m 2023-01-09 16:30:56,536\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 55, '_timesteps_total': None, '_time_total': 31.296525955200195, '_episodes_total': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(vae_train pid=21785)\u001B[0m {'learning_rate': 8.000000000000001e-06, 'weight_decay': 1.2e-09, 'batch_size': 13107, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=21785)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=21785)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=21785)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=21785)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=21785)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=21785)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=21785)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=21785)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=21785)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=21785)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=21785)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=21785)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=21785)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=21785)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=21785)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=21785)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=21785)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=21785)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=21785)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=21785)\u001B[0m }\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 16:30:58,352\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00006 (score = -0.427840) into trial 8645f_00002 (score = -0.448313)\n",
      "\n",
      "2023-01-09 16:30:58,354\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00002:\n",
      "learning_rate : 1e-05 --- (resample) --> 1.1080714910059648e-05\n",
      "weight_decay : 1e-09 --- (* 1.2) --> 1.2e-09\n",
      "batch_size : 16384 --- (resample) --> 11851\n",
      "\n",
      "\u001B[2m\u001B[36m(vae_train pid=23280)\u001B[0m 2023-01-09 16:31:00,723\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00002_2_2023-01-09_16-30-21/checkpoint_tmpa03d74\n",
      "\u001B[2m\u001B[36m(vae_train pid=23280)\u001B[0m 2023-01-09 16:31:00,723\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 55, '_timesteps_total': None, '_time_total': 31.296525955200195, '_episodes_total': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(vae_train pid=22933)\u001B[0m {'learning_rate': 1e-05, 'weight_decay': 1e-09, 'batch_size': 16384, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=22933)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=22933)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=22933)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=22933)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=22933)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=22933)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=22933)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=22933)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=22933)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=22933)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=22933)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=22933)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=22933)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=22933)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=22933)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=22933)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=22933)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=22933)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=22933)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=22933)\u001B[0m }\n",
      "\u001B[2m\u001B[36m(vae_train pid=23105)\u001B[0m {'learning_rate': 1.2e-05, 'weight_decay': 8.000000000000001e-10, 'batch_size': 15629, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=23105)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=23105)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=23105)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=23105)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=23105)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=23105)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=23105)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=23105)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=23105)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=23105)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=23105)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=23105)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=23105)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=23105)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=23105)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=23105)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=23105)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=23105)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=23105)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=23105)\u001B[0m }\n",
      "\u001B[2m\u001B[36m(vae_train pid=23280)\u001B[0m {'learning_rate': 1.1080714910059648e-05, 'weight_decay': 1.2e-09, 'batch_size': 11851, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=23280)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=23280)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=23280)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=23280)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=23280)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=23280)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=23280)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=23280)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=23280)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=23280)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=23280)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=23280)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=23280)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=23280)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=23280)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=23280)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=23280)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=23280)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=23280)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=23280)\u001B[0m }\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 16:31:13,275\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00001 (score = -0.418113) into trial 8645f_00005 (score = -0.436861)\n",
      "\n",
      "2023-01-09 16:31:13,276\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00005:\n",
      "learning_rate : 1e-05 --- (* 1.2) --> 1.2e-05\n",
      "weight_decay : 1e-09 --- (* 0.8) --> 8.000000000000001e-10\n",
      "batch_size : 16384 --- (* 0.8) --> 13107\n",
      "\n",
      "\u001B[2m\u001B[36m(vae_train pid=23517)\u001B[0m 2023-01-09 16:31:16,127\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00005_5_2023-01-09_16-30-21/checkpoint_tmp5cf69b\n",
      "\u001B[2m\u001B[36m(vae_train pid=23517)\u001B[0m 2023-01-09 16:31:16,127\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 88, '_timesteps_total': None, '_time_total': 41.41149306297302, '_episodes_total': None}\n",
      "2023-01-09 16:31:24,210\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00003 (score = -0.419265) into trial 8645f_00004 (score = -0.433115)\n",
      "\n",
      "2023-01-09 16:31:24,211\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00004:\n",
      "learning_rate : 1.2e-05 --- (* 1.2) --> 1.44e-05\n",
      "weight_decay : 8.000000000000001e-10 --- (* 1.2) --> 9.600000000000002e-10\n",
      "batch_size : 15629 --- (* 1.2) --> 18754\n",
      "\n",
      "\u001B[2m\u001B[36m(vae_train pid=21777)\u001B[0m 2023-01-09 16:31:24,625\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00004_4_2023-01-09_16-30-21/checkpoint_tmp78dee1\n",
      "\u001B[2m\u001B[36m(vae_train pid=21777)\u001B[0m 2023-01-09 16:31:24,625\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 85, '_timesteps_total': None, '_time_total': 56.419676542282104, '_episodes_total': None}\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m 2023-01-09 16:31:24,794\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00001_1_2023-01-09_16-30-21/checkpoint_tmpadcd87\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m 2023-01-09 16:31:24,794\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 144, '_timesteps_total': None, '_time_total': 61.45433688163757, '_episodes_total': None}\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m 2023-01-09 16:31:24,928\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00007_7_2023-01-09_16-30-21/checkpoint_tmp667f3e\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m 2023-01-09 16:31:24,928\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 153, '_timesteps_total': None, '_time_total': 61.553058385849, '_episodes_total': None}\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m 2023-01-09 16:31:26,661\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00006_6_2023-01-09_16-30-21/checkpoint_tmp9fea9a\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m 2023-01-09 16:31:26,661\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 148, '_timesteps_total': None, '_time_total': 61.59453248977661, '_episodes_total': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(vae_train pid=23517)\u001B[0m {'learning_rate': 1.2e-05, 'weight_decay': 8.000000000000001e-10, 'batch_size': 13107, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=23517)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=23517)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=23517)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=23517)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=23517)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=23517)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=23517)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=23517)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=23517)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=23517)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=23517)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=23517)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=23517)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=23517)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=23517)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=23517)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=23517)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=23517)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=23517)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=23517)\u001B[0m }\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 16:31:32,343\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00006 (score = -0.416475) into trial 8645f_00000 (score = -0.421663)\n",
      "\n",
      "2023-01-09 16:31:32,344\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00000:\n",
      "learning_rate : 1e-05 --- (* 0.8) --> 8.000000000000001e-06\n",
      "weight_decay : 1e-09 --- (* 1.2) --> 1.2e-09\n",
      "batch_size : 16384 --- (* 1.2) --> 19660\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(vae_train pid=21777)\u001B[0m {'learning_rate': 1.44e-05, 'weight_decay': 9.600000000000002e-10, 'batch_size': 18754, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=21777)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=21777)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=21777)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=21777)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=21777)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=21777)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=21777)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=21777)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=21777)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=21777)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=21777)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=21777)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=21777)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=21777)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=21777)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=21777)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=21777)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=21777)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=21777)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=21777)\u001B[0m }\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(vae_train pid=23920)\u001B[0m 2023-01-09 16:31:34,560\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00000_0_2023-01-09_16-30-19/checkpoint_tmp330821\n",
      "\u001B[2m\u001B[36m(vae_train pid=23920)\u001B[0m 2023-01-09 16:31:34,561\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 148, '_timesteps_total': None, '_time_total': 61.59453248977661, '_episodes_total': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m {'learning_rate': 1e-05, 'weight_decay': 1e-09, 'batch_size': 16384, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m }\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m {'learning_rate': 1e-05, 'weight_decay': 1e-09, 'batch_size': 16384, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m }\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m {'learning_rate': 1e-05, 'weight_decay': 1e-09, 'batch_size': 16384, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m }\n",
      "\u001B[2m\u001B[36m(vae_train pid=23920)\u001B[0m {'learning_rate': 8.000000000000001e-06, 'weight_decay': 1.2e-09, 'batch_size': 19660, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=23920)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=23920)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=23920)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=23920)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=23920)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=23920)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=23920)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=23920)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=23920)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=23920)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=23920)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=23920)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=23920)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=23920)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=23920)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=23920)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=23920)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=23920)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=23920)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=23920)\u001B[0m }\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 16:31:55,282\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00006 (score = -0.405737) into trial 8645f_00004 (score = -0.418929)\n",
      "\n",
      "2023-01-09 16:31:55,284\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00004:\n",
      "learning_rate : 1e-05 --- (resample) --> 1.8651994327566872e-05\n",
      "weight_decay : 1e-09 --- (* 1.2) --> 1.2e-09\n",
      "batch_size : 16384 --- (resample) --> 4300\n",
      "\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m 2023-01-09 16:31:55,842\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00004_4_2023-01-09_16-30-21/checkpoint_tmp443be6\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m 2023-01-09 16:31:55,842\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 180, '_timesteps_total': None, '_time_total': 83.106032371521, '_episodes_total': None}\n",
      "2023-01-09 16:31:55,943\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00001 (score = -0.406278) into trial 8645f_00002 (score = -0.418877)\n",
      "\n",
      "2023-01-09 16:31:55,944\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00002:\n",
      "learning_rate : 1e-05 --- (* 1.2) --> 1.2e-05\n",
      "weight_decay : 1e-09 --- (resample) --> 2.8727178630719702e-08\n",
      "batch_size : 16384 --- (resample) --> 1028\n",
      "\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m 2023-01-09 16:31:55,947\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00001_1_2023-01-09_16-30-21/checkpoint_tmp4504f1\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m 2023-01-09 16:31:55,947\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 190, '_timesteps_total': None, '_time_total': 92.11603379249573, '_episodes_total': None}\n",
      "\u001B[2m\u001B[36m(vae_train pid=24139)\u001B[0m 2023-01-09 16:31:57,680\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00007_7_2023-01-09_16-30-21/checkpoint_tmpb0cd00\n",
      "\u001B[2m\u001B[36m(vae_train pid=24139)\u001B[0m 2023-01-09 16:31:57,681\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 200, '_timesteps_total': None, '_time_total': 92.40974402427673, '_episodes_total': None}\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m 2023-01-09 16:31:58,614\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00002_2_2023-01-09_16-30-21/checkpoint_tmp57fc55\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m 2023-01-09 16:31:58,614\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 190, '_timesteps_total': None, '_time_total': 92.11603379249573, '_episodes_total': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m {'learning_rate': 1.8651994327566872e-05, 'weight_decay': 1.2e-09, 'batch_size': 4300, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=21790)\u001B[0m }\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m {'learning_rate': 1e-05, 'weight_decay': 1e-09, 'batch_size': 16384, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=21787)\u001B[0m }\n",
      "\u001B[2m\u001B[36m(vae_train pid=24139)\u001B[0m {'learning_rate': 1e-05, 'weight_decay': 1e-09, 'batch_size': 16384, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=24139)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=24139)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=24139)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=24139)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=24139)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=24139)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=24139)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=24139)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=24139)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=24139)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=24139)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=24139)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=24139)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=24139)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=24139)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=24139)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=24139)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=24139)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=24139)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=24139)\u001B[0m }\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m {'learning_rate': 1.2e-05, 'weight_decay': 2.8727178630719702e-08, 'batch_size': 1028, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m }\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 16:32:12,863\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00006 (score = -0.405458) into trial 8645f_00003 (score = -0.418708)\n",
      "\n",
      "2023-01-09 16:32:12,864\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00003:\n",
      "learning_rate : 1e-05 --- (resample) --> 4.475124417286522e-05\n",
      "weight_decay : 1e-09 --- (* 1.2) --> 1.2e-09\n",
      "batch_size : 16384 --- (* 1.2) --> 19660\n",
      "\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m 2023-01-09 16:32:13,570\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00003_3_2023-01-09_16-30-21/checkpoint_tmpa91601\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m 2023-01-09 16:32:13,570\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 246, '_timesteps_total': None, '_time_total': 103.37041091918945, '_episodes_total': None}\n",
      "\u001B[2m\u001B[36m(vae_train pid=24502)\u001B[0m 2023-01-09 16:32:15,861\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00002_2_2023-01-09_16-30-21/checkpoint_tmpdf2333\n",
      "\u001B[2m\u001B[36m(vae_train pid=24502)\u001B[0m 2023-01-09 16:32:15,861\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 191, '_timesteps_total': None, '_time_total': 106.49547266960144, '_episodes_total': None}\n",
      "2023-01-09 16:32:19,751\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00006 (score = -0.405394) into trial 8645f_00005 (score = -0.413035)\n",
      "\n",
      "2023-01-09 16:32:19,752\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00005:\n",
      "learning_rate : 1e-05 --- (* 0.8) --> 8.000000000000001e-06\n",
      "weight_decay : 1e-09 --- (* 0.8) --> 8.000000000000001e-10\n",
      "batch_size : 16384 --- (* 0.8) --> 13107\n",
      "\n",
      "\u001B[2m\u001B[36m(vae_train pid=24675)\u001B[0m 2023-01-09 16:32:22,527\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00005_5_2023-01-09_16-30-21/checkpoint_tmpb9568f\n",
      "\u001B[2m\u001B[36m(vae_train pid=24675)\u001B[0m 2023-01-09 16:32:22,527\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 277, '_timesteps_total': None, '_time_total': 113.51411509513855, '_episodes_total': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m {'learning_rate': 4.475124417286522e-05, 'weight_decay': 1.2e-09, 'batch_size': 19660, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=24295)\u001B[0m }\n",
      "\u001B[2m\u001B[36m(vae_train pid=24502)\u001B[0m {'learning_rate': 1.2e-05, 'weight_decay': 2.8727178630719702e-08, 'batch_size': 1028, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=24502)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=24502)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=24502)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=24502)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=24502)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=24502)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=24502)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=24502)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=24502)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=24502)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=24502)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=24502)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=24502)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=24502)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=24502)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=24502)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=24502)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=24502)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=24502)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=24502)\u001B[0m }\n",
      "\u001B[2m\u001B[36m(vae_train pid=24675)\u001B[0m {'learning_rate': 8.000000000000001e-06, 'weight_decay': 8.000000000000001e-10, 'batch_size': 13107, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=24675)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=24675)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=24675)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=24675)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=24675)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=24675)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=24675)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=24675)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=24675)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=24675)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=24675)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=24675)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=24675)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=24675)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=24675)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=24675)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=24675)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=24675)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=24675)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=24675)\u001B[0m }\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 16:32:38,684\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00003 (score = -0.405319) into trial 8645f_00002 (score = -0.406138)\n",
      "\n",
      "2023-01-09 16:32:38,686\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00002:\n",
      "learning_rate : 4.475124417286522e-05 --- (resample) --> 0.0004580782322763293\n",
      "weight_decay : 1.2e-09 --- (* 1.2) --> 1.44e-09\n",
      "batch_size : 19660 --- (* 0.8) --> 15728\n",
      "\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m 2023-01-09 16:32:39,177\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00002_2_2023-01-09_16-30-21/checkpoint_tmp747317\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m 2023-01-09 16:32:39,177\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 272, '_timesteps_total': None, '_time_total': 124.14954018592834, '_episodes_total': None}\n",
      "2023-01-09 16:32:39,913\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00003 (score = -0.405319) into trial 8645f_00007 (score = -0.406109)\n",
      "\n",
      "2023-01-09 16:32:39,914\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00007:\n",
      "learning_rate : 4.475124417286522e-05 --- (* 0.8) --> 3.580099533829218e-05\n",
      "weight_decay : 1.2e-09 --- (* 1.2) --> 1.44e-09\n",
      "batch_size : 19660 --- (* 1.2) --> 23592\n",
      "\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m 2023-01-09 16:32:41,781\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00006_6_2023-01-09_16-30-21/checkpoint_tmp72a55a\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m 2023-01-09 16:32:41,781\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 326, '_timesteps_total': None, '_time_total': 133.78305411338806, '_episodes_total': None}\n",
      "\u001B[2m\u001B[36m(vae_train pid=25036)\u001B[0m 2023-01-09 16:32:42,540\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00007_7_2023-01-09_16-30-21/checkpoint_tmpef01dc\n",
      "\u001B[2m\u001B[36m(vae_train pid=25036)\u001B[0m 2023-01-09 16:32:42,540\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 272, '_timesteps_total': None, '_time_total': 124.14954018592834, '_episodes_total': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m {'learning_rate': 0.0004580782322763293, 'weight_decay': 1.44e-09, 'batch_size': 15728, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=23745)\u001B[0m }\n",
      "\u001B[2m\u001B[36m(vae_train pid=25036)\u001B[0m {'learning_rate': 3.580099533829218e-05, 'weight_decay': 1.44e-09, 'batch_size': 23592, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=25036)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=25036)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=25036)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=25036)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=25036)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=25036)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=25036)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=25036)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=25036)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=25036)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=25036)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=25036)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=25036)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=25036)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=25036)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=25036)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=25036)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=25036)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=25036)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=25036)\u001B[0m }\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m {'learning_rate': 1e-05, 'weight_decay': 1e-09, 'batch_size': 16384, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m }\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 16:32:57,825\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00003 (score = -0.405137) into trial 8645f_00001 (score = -0.405889)\n",
      "\n",
      "2023-01-09 16:32:57,826\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00001:\n",
      "learning_rate : 4.475124417286522e-05 --- (* 0.8) --> 3.580099533829218e-05\n",
      "weight_decay : 1.2e-09 --- (* 1.2) --> 1.44e-09\n",
      "batch_size : 19660 --- (* 1.2) --> 23592\n",
      "\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m 2023-01-09 16:33:00,982\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00001_1_2023-01-09_16-30-21/checkpoint_tmpd924da\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m 2023-01-09 16:33:00,982\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 334, '_timesteps_total': None, '_time_total': 144.46832084655762, '_episodes_total': None}\n",
      "2023-01-09 16:33:09,047\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00003 (score = -0.405112) into trial 8645f_00000 (score = -0.405360)\n",
      "\n",
      "2023-01-09 16:33:09,048\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00000:\n",
      "learning_rate : 4.475124417286522e-05 --- (resample) --> 1.4539688055496267e-05\n",
      "weight_decay : 1.2e-09 --- (* 0.8) --> 9.6e-10\n",
      "batch_size : 19660 --- (* 0.8) --> 15728\n",
      "\n",
      "\u001B[2m\u001B[36m(vae_train pid=25429)\u001B[0m 2023-01-09 16:33:11,781\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00000_0_2023-01-09_16-30-19/checkpoint_tmpa0e219\n",
      "\u001B[2m\u001B[36m(vae_train pid=25429)\u001B[0m 2023-01-09 16:33:11,781\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 356, '_timesteps_total': None, '_time_total': 154.48519682884216, '_episodes_total': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m {'learning_rate': 3.580099533829218e-05, 'weight_decay': 1.44e-09, 'batch_size': 23592, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m }\n",
      "\u001B[2m\u001B[36m(vae_train pid=25429)\u001B[0m {'learning_rate': 1.4539688055496267e-05, 'weight_decay': 9.6e-10, 'batch_size': 15728, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=25429)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=25429)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=25429)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=25429)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=25429)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=25429)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=25429)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=25429)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=25429)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=25429)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=25429)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=25429)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=25429)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=25429)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=25429)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=25429)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=25429)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=25429)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=25429)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=25429)\u001B[0m }\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 16:33:27,675\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00003 (score = -0.404993) into trial 8645f_00005 (score = -0.405281)\n",
      "\n",
      "2023-01-09 16:33:27,676\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00005:\n",
      "learning_rate : 4.475124417286522e-05 --- (* 1.2) --> 5.3701493007438265e-05\n",
      "weight_decay : 1.2e-09 --- (* 1.2) --> 1.44e-09\n",
      "batch_size : 19660 --- (resample) --> 5066\n",
      "\n",
      "2023-01-09 16:33:28,088\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00002 (score = -0.404320) into trial 8645f_00006 (score = -0.405264)\n",
      "\n",
      "2023-01-09 16:33:28,090\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00006:\n",
      "learning_rate : 0.0004580782322763293 --- (resample) --> 6.747574942575416e-05\n",
      "weight_decay : 1.44e-09 --- (* 1.2) --> 1.7279999999999998e-09\n",
      "batch_size : 15728 --- (* 1.2) --> 18873\n",
      "\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m 2023-01-09 16:33:28,270\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00006_6_2023-01-09_16-30-21/checkpoint_tmpb6f277\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m 2023-01-09 16:33:28,270\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 356, '_timesteps_total': None, '_time_total': 165.14728689193726, '_episodes_total': None}\n",
      "\u001B[2m\u001B[36m(vae_train pid=25632)\u001B[0m 2023-01-09 16:33:30,507\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00005_5_2023-01-09_16-30-21/checkpoint_tmpd0ee07\n",
      "\u001B[2m\u001B[36m(vae_train pid=25632)\u001B[0m 2023-01-09 16:33:30,507\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 412, '_timesteps_total': None, '_time_total': 174.7458004951477, '_episodes_total': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m {'learning_rate': 6.747574942575416e-05, 'weight_decay': 1.7279999999999998e-09, 'batch_size': 18873, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m }\n",
      "\u001B[2m\u001B[36m(vae_train pid=25632)\u001B[0m {'learning_rate': 5.3701493007438265e-05, 'weight_decay': 1.44e-09, 'batch_size': 5066, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=25632)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=25632)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=25632)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=25632)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=25632)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=25632)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=25632)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=25632)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=25632)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=25632)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=25632)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=25632)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=25632)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=25632)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=25632)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=25632)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=25632)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=25632)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=25632)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=25632)\u001B[0m }\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 16:33:46,055\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00002 (score = -0.404110) into trial 8645f_00007 (score = -0.405079)\n",
      "\n",
      "2023-01-09 16:33:46,056\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00007:\n",
      "learning_rate : 0.0004580782322763293 --- (resample) --> 0.0007715937047435311\n",
      "weight_decay : 1.44e-09 --- (* 0.8) --> 1.1520000000000002e-09\n",
      "batch_size : 15728 --- (* 1.2) --> 18873\n",
      "\n",
      "2023-01-09 16:33:47,933\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00002 (score = -0.404110) into trial 8645f_00004 (score = -0.405079)\n",
      "\n",
      "2023-01-09 16:33:47,934\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00004:\n",
      "learning_rate : 0.0004580782322763293 --- (* 0.8) --> 0.00036646258582106344\n",
      "weight_decay : 1.44e-09 --- (* 0.8) --> 1.1520000000000002e-09\n",
      "batch_size : 15728 --- (* 0.8) --> 12582\n",
      "\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m 2023-01-09 16:33:48,695\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00007_7_2023-01-09_16-30-21/checkpoint_tmp741e68\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m 2023-01-09 16:33:48,695\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 405, '_timesteps_total': None, '_time_total': 185.6255488395691, '_episodes_total': None}\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m 2023-01-09 16:33:48,953\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00006_6_2023-01-09_16-30-21/checkpoint_tmp4062e2\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m 2023-01-09 16:33:48,953\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 384, '_timesteps_total': None, '_time_total': 185.53882932662964, '_episodes_total': None}\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m 2023-01-09 16:33:50,612\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00004_4_2023-01-09_16-30-21/checkpoint_tmpd2626b\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m 2023-01-09 16:33:50,612\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 405, '_timesteps_total': None, '_time_total': 185.6255488395691, '_episodes_total': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m {'learning_rate': 6.747574942575416e-05, 'weight_decay': 1.7279999999999998e-09, 'batch_size': 18873, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=24881)\u001B[0m }\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m {'learning_rate': 0.0007715937047435311, 'weight_decay': 1.1520000000000002e-09, 'batch_size': 18873, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m }\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m {'learning_rate': 0.00036646258582106344, 'weight_decay': 1.1520000000000002e-09, 'batch_size': 12582, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m }\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 16:34:05,953\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00002 (score = -0.403938) into trial 8645f_00000 (score = -0.405026)\n",
      "\n",
      "2023-01-09 16:34:05,954\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00000:\n",
      "learning_rate : 0.0004580782322763293 --- (resample) --> 1.2113857231201255e-05\n",
      "weight_decay : 1.44e-09 --- (* 0.8) --> 1.1520000000000002e-09\n",
      "batch_size : 15728 --- (* 0.8) --> 12582\n",
      "\n",
      "2023-01-09 16:34:06,208\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00004 (score = -0.404120) into trial 8645f_00001 (score = -0.404950)\n",
      "\n",
      "2023-01-09 16:34:06,209\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00001:\n",
      "learning_rate : 0.00036646258582106344 --- (resample) --> 5.775855836524057e-05\n",
      "weight_decay : 1.1520000000000002e-09 --- (* 0.8) --> 9.216000000000002e-10\n",
      "batch_size : 12582 --- (* 0.8) --> 10065\n",
      "\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m 2023-01-09 16:34:06,642\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00001_1_2023-01-09_16-30-21/checkpoint_tmp3f5579\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m 2023-01-09 16:34:06,642\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 406, '_timesteps_total': None, '_time_total': 199.80069518089294, '_episodes_total': None}\n",
      "\u001B[2m\u001B[36m(vae_train pid=26196)\u001B[0m 2023-01-09 16:34:08,915\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00000_0_2023-01-09_16-30-19/checkpoint_tmp408537\n",
      "\u001B[2m\u001B[36m(vae_train pid=26196)\u001B[0m 2023-01-09 16:34:08,916\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 461, '_timesteps_total': None, '_time_total': 206.07250714302063, '_episodes_total': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m {'learning_rate': 5.775855836524057e-05, 'weight_decay': 9.216000000000002e-10, 'batch_size': 10065, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=25244)\u001B[0m }\n",
      "\u001B[2m\u001B[36m(vae_train pid=26196)\u001B[0m {'learning_rate': 1.2113857231201255e-05, 'weight_decay': 1.1520000000000002e-09, 'batch_size': 12582, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=26196)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=26196)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=26196)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=26196)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=26196)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=26196)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=26196)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=26196)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=26196)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=26196)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=26196)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=26196)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=26196)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=26196)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=26196)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=26196)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=26196)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=26196)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=26196)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=26196)\u001B[0m }\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 16:34:24,650\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00002 (score = -0.403752) into trial 8645f_00005 (score = -0.404815)\n",
      "\n",
      "2023-01-09 16:34:24,651\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00005:\n",
      "learning_rate : 0.0004580782322763293 --- (* 0.8) --> 0.00036646258582106344\n",
      "weight_decay : 1.44e-09 --- (* 0.8) --> 1.1520000000000002e-09\n",
      "batch_size : 15728 --- (resample) --> 10360\n",
      "\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m 2023-01-09 16:34:25,414\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00004_4_2023-01-09_16-30-21/checkpoint_tmpf6e62d\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m 2023-01-09 16:34:25,414\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 460, '_timesteps_total': None, '_time_total': 220.28631234169006, '_episodes_total': None}\n",
      "2023-01-09 16:34:26,016\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00007 (score = -0.403798) into trial 8645f_00003 (score = -0.404822)\n",
      "\n",
      "2023-01-09 16:34:26,018\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00003:\n",
      "learning_rate : 0.0007715937047435311 --- (* 1.2) --> 0.0009259124456922373\n",
      "weight_decay : 1.1520000000000002e-09 --- (* 0.8) --> 9.216000000000002e-10\n",
      "batch_size : 18873 --- (resample) --> 12334\n",
      "\n",
      "\u001B[2m\u001B[36m(vae_train pid=26400)\u001B[0m 2023-01-09 16:34:27,569\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00005_5_2023-01-09_16-30-21/checkpoint_tmp518bd2\n",
      "\u001B[2m\u001B[36m(vae_train pid=26400)\u001B[0m 2023-01-09 16:34:27,569\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 520, '_timesteps_total': None, '_time_total': 226.3972294330597, '_episodes_total': None}\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m 2023-01-09 16:34:28,988\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00003_3_2023-01-09_16-30-21/checkpoint_tmp4971ef\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m 2023-01-09 16:34:28,988\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 463, '_timesteps_total': None, '_time_total': 219.83208060264587, '_episodes_total': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m {'learning_rate': 0.00036646258582106344, 'weight_decay': 1.1520000000000002e-09, 'batch_size': 12582, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=25994)\u001B[0m }\n",
      "\u001B[2m\u001B[36m(vae_train pid=26400)\u001B[0m {'learning_rate': 0.00036646258582106344, 'weight_decay': 1.1520000000000002e-09, 'batch_size': 10360, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=26400)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=26400)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=26400)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=26400)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=26400)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=26400)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=26400)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=26400)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=26400)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=26400)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=26400)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=26400)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=26400)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=26400)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=26400)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=26400)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=26400)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=26400)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=26400)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=26400)\u001B[0m }\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m {'learning_rate': 0.0009259124456922373, 'weight_decay': 9.216000000000002e-10, 'batch_size': 12334, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m }\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 16:34:47,657\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00002 (score = -0.403570) into trial 8645f_00001 (score = -0.404154)\n",
      "\n",
      "2023-01-09 16:34:47,658\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00001:\n",
      "learning_rate : 0.0004580782322763293 --- (* 0.8) --> 0.00036646258582106344\n",
      "weight_decay : 1.44e-09 --- (* 0.8) --> 1.1520000000000002e-09\n",
      "batch_size : 15728 --- (* 1.2) --> 18873\n",
      "\n",
      "2023-01-09 16:34:50,055\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00002 (score = -0.403570) into trial 8645f_00006 (score = -0.404274)\n",
      "\n",
      "2023-01-09 16:34:50,056\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00006:\n",
      "learning_rate : 0.0004580782322763293 --- (* 1.2) --> 0.0005496938787315952\n",
      "weight_decay : 1.44e-09 --- (* 0.8) --> 1.1520000000000002e-09\n",
      "batch_size : 15728 --- (* 1.2) --> 18873\n",
      "\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m 2023-01-09 16:34:50,564\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00001_1_2023-01-09_16-30-21/checkpoint_tmp0b6a3a\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m 2023-01-09 16:34:50,564\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 579, '_timesteps_total': None, '_time_total': 246.61029887199402, '_episodes_total': None}\n",
      "\u001B[2m\u001B[36m(vae_train pid=26927)\u001B[0m 2023-01-09 16:34:52,529\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00006_6_2023-01-09_16-30-21/checkpoint_tmp838bb0\n",
      "\u001B[2m\u001B[36m(vae_train pid=26927)\u001B[0m 2023-01-09 16:34:52,529\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 579, '_timesteps_total': None, '_time_total': 246.61029887199402, '_episodes_total': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m {'learning_rate': 0.00036646258582106344, 'weight_decay': 1.1520000000000002e-09, 'batch_size': 18873, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m }\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 16:35:03,783\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00007 (score = -0.403423) into trial 8645f_00000 (score = -0.404022)\n",
      "\n",
      "2023-01-09 16:35:03,784\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00000:\n",
      "learning_rate : 0.0007715937047435311 --- (resample) --> 0.00019743421754652658\n",
      "weight_decay : 1.1520000000000002e-09 --- (* 0.8) --> 9.216000000000002e-10\n",
      "batch_size : 18873 --- (* 0.8) --> 15098\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(vae_train pid=26927)\u001B[0m {'learning_rate': 0.0005496938787315952, 'weight_decay': 1.1520000000000002e-09, 'batch_size': 18873, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=26927)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=26927)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=26927)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=26927)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=26927)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=26927)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=26927)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=26927)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=26927)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=26927)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=26927)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=26927)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=26927)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=26927)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=26927)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=26927)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=26927)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=26927)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=26927)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=26927)\u001B[0m }\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m 2023-01-09 16:35:04,015\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00000_0_2023-01-09_16-30-19/checkpoint_tmp9ed5da\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m 2023-01-09 16:35:04,015\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 547, '_timesteps_total': None, '_time_total': 250.63149523735046, '_episodes_total': None}\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m 2023-01-09 16:35:04,089\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00003_3_2023-01-09_16-30-21/checkpoint_tmp4b504b\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m 2023-01-09 16:35:04,089\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 512, '_timesteps_total': None, '_time_total': 254.6242859363556, '_episodes_total': None}\n",
      "2023-01-09 16:35:06,032\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00007 (score = -0.403316) into trial 8645f_00004 (score = -0.403755)\n",
      "\n",
      "2023-01-09 16:35:06,033\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00004:\n",
      "learning_rate : 0.0007715937047435311 --- (* 1.2) --> 0.0009259124456922373\n",
      "weight_decay : 1.1520000000000002e-09 --- (* 0.8) --> 9.216000000000002e-10\n",
      "batch_size : 18873 --- (* 1.2) --> 22647\n",
      "\n",
      "\u001B[2m\u001B[36m(vae_train pid=27122)\u001B[0m 2023-01-09 16:35:06,429\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00007_7_2023-01-09_16-30-21/checkpoint_tmpd4576c\n",
      "\u001B[2m\u001B[36m(vae_train pid=27122)\u001B[0m 2023-01-09 16:35:06,429\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 569, '_timesteps_total': None, '_time_total': 260.7116310596466, '_episodes_total': None}\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m 2023-01-09 16:35:09,055\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00004_4_2023-01-09_16-30-21/checkpoint_tmp18b7ef\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m 2023-01-09 16:35:09,055\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 569, '_timesteps_total': None, '_time_total': 260.7116310596466, '_episodes_total': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m {'learning_rate': 0.00019743421754652658, 'weight_decay': 9.216000000000002e-10, 'batch_size': 15098, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=25831)\u001B[0m }\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m {'learning_rate': 0.0009259124456922373, 'weight_decay': 9.216000000000002e-10, 'batch_size': 12334, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=26555)\u001B[0m }\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 16:35:14,415\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00002 (score = -0.403359) into trial 8645f_00003 (score = -0.403577)\n",
      "\n",
      "2023-01-09 16:35:14,416\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00003:\n",
      "learning_rate : 0.0004580782322763293 --- (* 0.8) --> 0.00036646258582106344\n",
      "weight_decay : 1.44e-09 --- (* 1.2) --> 1.7279999999999998e-09\n",
      "batch_size : 15728 --- (* 1.2) --> 18873\n",
      "\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m 2023-01-09 16:35:16,449\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00003_3_2023-01-09_16-30-21/checkpoint_tmp2d7f88\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m 2023-01-09 16:35:16,449\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 661, '_timesteps_total': None, '_time_total': 277.13913917541504, '_episodes_total': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(vae_train pid=27122)\u001B[0m {'learning_rate': 0.0007715937047435311, 'weight_decay': 1.1520000000000002e-09, 'batch_size': 18873, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=27122)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=27122)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=27122)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=27122)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=27122)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=27122)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=27122)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=27122)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=27122)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=27122)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=27122)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=27122)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=27122)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=27122)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=27122)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=27122)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=27122)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=27122)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=27122)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=27122)\u001B[0m }\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m {'learning_rate': 0.0009259124456922373, 'weight_decay': 9.216000000000002e-10, 'batch_size': 22647, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m }\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m {'learning_rate': 0.00036646258582106344, 'weight_decay': 1.7279999999999998e-09, 'batch_size': 18873, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m }\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 16:35:32,707\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00007 (score = -0.403249) into trial 8645f_00005 (score = -0.403437)\n",
      "\n",
      "2023-01-09 16:35:32,708\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00005:\n",
      "learning_rate : 0.0007715937047435311 --- (* 0.8) --> 0.0006172749637948249\n",
      "weight_decay : 1.1520000000000002e-09 --- (resample) --> 1.2834440744246343e-08\n",
      "batch_size : 18873 --- (resample) --> 15927\n",
      "\n",
      "2023-01-09 16:35:33,118\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00002 (score = -0.403236) into trial 8645f_00001 (score = -0.403423)\n",
      "\n",
      "2023-01-09 16:35:33,119\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00001:\n",
      "learning_rate : 0.0004580782322763293 --- (resample) --> 5.874907362665687e-05\n",
      "weight_decay : 1.44e-09 --- (* 0.8) --> 1.1520000000000002e-09\n",
      "batch_size : 15728 --- (resample) --> 6597\n",
      "\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m 2023-01-09 16:35:33,240\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00005_5_2023-01-09_16-30-21/checkpoint_tmpf6ccba\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m 2023-01-09 16:35:33,240\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 600, '_timesteps_total': None, '_time_total': 282.48777318000793, '_episodes_total': None}\n",
      "2023-01-09 16:35:34,489\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00007 (score = -0.403249) into trial 8645f_00000 (score = -0.403426)\n",
      "\n",
      "2023-01-09 16:35:34,490\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00000:\n",
      "learning_rate : 0.0007715937047435311 --- (* 0.8) --> 0.0006172749637948249\n",
      "weight_decay : 1.1520000000000002e-09 --- (resample) --> 9.995757897820504e-07\n",
      "batch_size : 18873 --- (* 1.2) --> 22647\n",
      "\n",
      "\u001B[2m\u001B[36m(vae_train pid=27664)\u001B[0m 2023-01-09 16:35:35,633\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00001_1_2023-01-09_16-30-21/checkpoint_tmpb6c600\n",
      "\u001B[2m\u001B[36m(vae_train pid=27664)\u001B[0m 2023-01-09 16:35:35,633\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 724, '_timesteps_total': None, '_time_total': 297.59527611732483, '_episodes_total': None}\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m 2023-01-09 16:35:37,080\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00000_0_2023-01-09_16-30-19/checkpoint_tmpecc48b\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m 2023-01-09 16:35:37,080\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 600, '_timesteps_total': None, '_time_total': 282.48777318000793, '_episodes_total': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m {'learning_rate': 0.0006172749637948249, 'weight_decay': 1.2834440744246343e-08, 'batch_size': 15927, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m }\n",
      "\u001B[2m\u001B[36m(vae_train pid=27664)\u001B[0m {'learning_rate': 5.874907362665687e-05, 'weight_decay': 1.1520000000000002e-09, 'batch_size': 6597, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=27664)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=27664)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=27664)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=27664)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=27664)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=27664)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=27664)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=27664)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=27664)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=27664)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=27664)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=27664)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=27664)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=27664)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=27664)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=27664)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=27664)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=27664)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=27664)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=27664)\u001B[0m }\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m {'learning_rate': 0.0006172749637948249, 'weight_decay': 9.995757897820504e-07, 'batch_size': 22647, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m }\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 16:35:50,020\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00002 (score = -0.403113) into trial 8645f_00001 (score = -0.403307)\n",
      "\n",
      "2023-01-09 16:35:50,020\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00001:\n",
      "learning_rate : 0.0004580782322763293 --- (* 1.2) --> 0.0005496938787315952\n",
      "weight_decay : 1.44e-09 --- (* 1.2) --> 1.7279999999999998e-09\n",
      "batch_size : 15728 --- (* 0.8) --> 12582\n",
      "\n",
      "2023-01-09 16:35:50,614\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00007 (score = -0.403084) into trial 8645f_00000 (score = -0.403420)\n",
      "\n",
      "2023-01-09 16:35:50,614\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00000:\n",
      "learning_rate : 0.0007715937047435311 --- (* 1.2) --> 0.0009259124456922373\n",
      "weight_decay : 1.1520000000000002e-09 --- (* 1.2) --> 1.3824000000000001e-09\n",
      "batch_size : 18873 --- (resample) --> 3760\n",
      "\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m 2023-01-09 16:35:51,049\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00000_0_2023-01-09_16-30-19/checkpoint_tmp44804e\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m 2023-01-09 16:35:51,049\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 654, '_timesteps_total': None, '_time_total': 302.8643219470978, '_episodes_total': None}\n",
      "\u001B[2m\u001B[36m(vae_train pid=28021)\u001B[0m 2023-01-09 16:35:52,849\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00001_1_2023-01-09_16-30-21/checkpoint_tmp1f3e4f\n",
      "\u001B[2m\u001B[36m(vae_train pid=28021)\u001B[0m 2023-01-09 16:35:52,850\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 754, '_timesteps_total': None, '_time_total': 307.70660424232483, '_episodes_total': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m {'learning_rate': 0.0009259124456922373, 'weight_decay': 1.3824000000000001e-09, 'batch_size': 3760, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m }\n",
      "\u001B[2m\u001B[36m(vae_train pid=28021)\u001B[0m {'learning_rate': 0.0005496938787315952, 'weight_decay': 1.7279999999999998e-09, 'batch_size': 12582, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=28021)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=28021)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=28021)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=28021)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=28021)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=28021)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=28021)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=28021)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=28021)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=28021)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=28021)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=28021)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=28021)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=28021)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=28021)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=28021)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=28021)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=28021)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=28021)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=28021)\u001B[0m }\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 16:36:07,383\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00007 (score = -0.402962) into trial 8645f_00001 (score = -0.403141)\n",
      "\n",
      "2023-01-09 16:36:07,384\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00001:\n",
      "learning_rate : 0.0007715937047435311 --- (* 1.2) --> 0.0009259124456922373\n",
      "weight_decay : 1.1520000000000002e-09 --- (* 0.8) --> 9.216000000000002e-10\n",
      "batch_size : 18873 --- (* 1.2) --> 22647\n",
      "\n",
      "2023-01-09 16:36:09,242\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00004 (score = -0.402948) into trial 8645f_00003 (score = -0.403157)\n",
      "\n",
      "2023-01-09 16:36:09,243\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00003:\n",
      "learning_rate : 0.0009259124456922373 --- (* 0.8) --> 0.0007407299565537899\n",
      "weight_decay : 9.216000000000002e-10 --- (* 0.8) --> 7.372800000000002e-10\n",
      "batch_size : 22647 --- (* 1.2) --> 27176\n",
      "\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m 2023-01-09 16:36:09,673\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00003_3_2023-01-09_16-30-21/checkpoint_tmpf6bf7c\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m 2023-01-09 16:36:09,674\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 687, '_timesteps_total': None, '_time_total': 317.22208762168884, '_episodes_total': None}\n",
      "\u001B[2m\u001B[36m(vae_train pid=28221)\u001B[0m 2023-01-09 16:36:09,851\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00001_1_2023-01-09_16-30-21/checkpoint_tmp8e5177\n",
      "\u001B[2m\u001B[36m(vae_train pid=28221)\u001B[0m 2023-01-09 16:36:09,851\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 684, '_timesteps_total': None, '_time_total': 313.02489614486694, '_episodes_total': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m {'learning_rate': 0.0007407299565537899, 'weight_decay': 7.372800000000002e-10, 'batch_size': 27176, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=27457)\u001B[0m }\n",
      "\u001B[2m\u001B[36m(vae_train pid=28221)\u001B[0m {'learning_rate': 0.0009259124456922373, 'weight_decay': 9.216000000000002e-10, 'batch_size': 22647, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=28221)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=28221)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=28221)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=28221)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=28221)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=28221)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=28221)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=28221)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=28221)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=28221)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=28221)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=28221)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=28221)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=28221)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=28221)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=28221)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=28221)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=28221)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=28221)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=28221)\u001B[0m }\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 16:36:24,952\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00007 (score = -0.402813) into trial 8645f_00001 (score = -0.402993)\n",
      "\n",
      "2023-01-09 16:36:24,953\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00001:\n",
      "learning_rate : 0.0007715937047435311 --- (* 0.8) --> 0.0006172749637948249\n",
      "weight_decay : 1.1520000000000002e-09 --- (resample) --> 9.331146036476077e-10\n",
      "batch_size : 18873 --- (* 0.8) --> 15098\n",
      "\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m 2023-01-09 16:36:25,942\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00001_1_2023-01-09_16-30-21/checkpoint_tmp5a3624\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m 2023-01-09 16:36:25,942\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 741, '_timesteps_total': None, '_time_total': 333.42836689949036, '_episodes_total': None}\n",
      "2023-01-09 16:36:26,520\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00007 (score = -0.402813) into trial 8645f_00006 (score = -0.402956)\n",
      "\n",
      "2023-01-09 16:36:26,521\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00006:\n",
      "learning_rate : 0.0007715937047435311 --- (* 1.2) --> 0.0009259124456922373\n",
      "weight_decay : 1.1520000000000002e-09 --- (* 1.2) --> 1.3824000000000001e-09\n",
      "batch_size : 18873 --- (resample) --> 1077\n",
      "\n",
      "\u001B[2m\u001B[36m(vae_train pid=28422)\u001B[0m 2023-01-09 16:36:27,605\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00004_4_2023-01-09_16-30-21/checkpoint_tmp43d7b3\n",
      "\u001B[2m\u001B[36m(vae_train pid=28422)\u001B[0m 2023-01-09 16:36:27,605\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 744, '_timesteps_total': None, '_time_total': 337.43125653266907, '_episodes_total': None}\n",
      "\u001B[2m\u001B[36m(vae_train pid=28577)\u001B[0m 2023-01-09 16:36:28,436\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00006_6_2023-01-09_16-30-21/checkpoint_tmpa7c9f0\n",
      "\u001B[2m\u001B[36m(vae_train pid=28577)\u001B[0m 2023-01-09 16:36:28,436\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 741, '_timesteps_total': None, '_time_total': 333.42836689949036, '_episodes_total': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m {'learning_rate': 0.0006172749637948249, 'weight_decay': 9.331146036476077e-10, 'batch_size': 15098, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=27283)\u001B[0m }\n",
      "\u001B[2m\u001B[36m(vae_train pid=28422)\u001B[0m {'learning_rate': 0.0009259124456922373, 'weight_decay': 9.216000000000002e-10, 'batch_size': 22647, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=28422)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=28422)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=28422)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=28422)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=28422)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=28422)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=28422)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=28422)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=28422)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=28422)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=28422)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=28422)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=28422)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=28422)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=28422)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=28422)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=28422)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=28422)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=28422)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=28422)\u001B[0m }\n",
      "\u001B[2m\u001B[36m(vae_train pid=28577)\u001B[0m {'learning_rate': 0.0009259124456922373, 'weight_decay': 1.3824000000000001e-09, 'batch_size': 1077, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=28577)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=28577)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=28577)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=28577)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=28577)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=28577)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=28577)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=28577)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=28577)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=28577)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=28577)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=28577)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=28577)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=28577)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=28577)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=28577)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=28577)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=28577)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=28577)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=28577)\u001B[0m }\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 16:36:42,216\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00007 (score = -0.402677) into trial 8645f_00006 (score = -0.402862)\n",
      "\n",
      "2023-01-09 16:36:42,217\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00006:\n",
      "learning_rate : 0.0007715937047435311 --- (* 1.2) --> 0.0009259124456922373\n",
      "weight_decay : 1.1520000000000002e-09 --- (* 0.8) --> 9.216000000000002e-10\n",
      "batch_size : 18873 --- (* 1.2) --> 22647\n",
      "\n",
      "\u001B[2m\u001B[36m(vae_train pid=28777)\u001B[0m 2023-01-09 16:36:44,992\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00006_6_2023-01-09_16-30-21/checkpoint_tmpc3c7c4\n",
      "\u001B[2m\u001B[36m(vae_train pid=28777)\u001B[0m 2023-01-09 16:36:44,992\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 788, '_timesteps_total': None, '_time_total': 353.99608302116394, '_episodes_total': None}\n",
      "2023-01-09 16:36:53,940\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00007 (score = -0.402594) into trial 8645f_00002 (score = -0.402746)\n",
      "\n",
      "2023-01-09 16:36:53,941\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00002:\n",
      "learning_rate : 0.0007715937047435311 --- (resample) --> 0.00010520605004148732\n",
      "weight_decay : 1.1520000000000002e-09 --- (resample) --> 1.8626012347603393e-09\n",
      "batch_size : 18873 --- (resample) --> 4279\n",
      "\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m 2023-01-09 16:36:54,922\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00005_5_2023-01-09_16-30-21/checkpoint_tmp83a3c3\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m 2023-01-09 16:36:54,922\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 821, '_timesteps_total': None, '_time_total': 363.98400831222534, '_episodes_total': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(vae_train pid=28777)\u001B[0m {'learning_rate': 0.0009259124456922373, 'weight_decay': 9.216000000000002e-10, 'batch_size': 22647, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=28777)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=28777)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=28777)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=28777)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=28777)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=28777)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=28777)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=28777)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=28777)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=28777)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=28777)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=28777)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=28777)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=28777)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=28777)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=28777)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=28777)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=28777)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=28777)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=28777)\u001B[0m }\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(vae_train pid=28961)\u001B[0m 2023-01-09 16:36:56,788\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00002_2_2023-01-09_16-30-21/checkpoint_tmp86c997\n",
      "\u001B[2m\u001B[36m(vae_train pid=28961)\u001B[0m 2023-01-09 16:36:56,788\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 812, '_timesteps_total': None, '_time_total': 364.3037488460541, '_episodes_total': None}\n",
      "2023-01-09 16:36:57,726\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00004 (score = -0.402633) into trial 8645f_00006 (score = -0.402741)\n",
      "\n",
      "2023-01-09 16:36:57,727\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00006:\n",
      "learning_rate : 0.0009259124456922373 --- (* 1.2) --> 0.0011110949348306848\n",
      "weight_decay : 9.216000000000002e-10 --- (* 1.2) --> 1.1059200000000003e-09\n",
      "batch_size : 22647 --- (* 0.8) --> 18117\n",
      "\n",
      "\u001B[2m\u001B[36m(vae_train pid=29135)\u001B[0m 2023-01-09 16:37:00,785\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00006_6_2023-01-09_16-30-21/checkpoint_tmp874c02\n",
      "\u001B[2m\u001B[36m(vae_train pid=29135)\u001B[0m 2023-01-09 16:37:00,785\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 774, '_timesteps_total': None, '_time_total': 358.90772557258606, '_episodes_total': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m {'learning_rate': 0.0006172749637948249, 'weight_decay': 1.2834440744246343e-08, 'batch_size': 15927, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=26765)\u001B[0m }\n",
      "\u001B[2m\u001B[36m(vae_train pid=28961)\u001B[0m {'learning_rate': 0.00010520605004148732, 'weight_decay': 1.8626012347603393e-09, 'batch_size': 4279, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=28961)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=28961)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=28961)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=28961)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=28961)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=28961)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=28961)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=28961)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=28961)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=28961)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=28961)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=28961)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=28961)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=28961)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=28961)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=28961)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=28961)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=28961)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=28961)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=28961)\u001B[0m }\n",
      "\u001B[2m\u001B[36m(vae_train pid=29135)\u001B[0m {'learning_rate': 0.0011110949348306848, 'weight_decay': 1.1059200000000003e-09, 'batch_size': 18117, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=29135)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=29135)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=29135)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=29135)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=29135)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=29135)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=29135)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=29135)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=29135)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=29135)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=29135)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=29135)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=29135)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=29135)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=29135)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=29135)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=29135)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=29135)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=29135)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=29135)\u001B[0m }\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 16:37:15,446\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00004 (score = -0.402426) into trial 8645f_00006 (score = -0.402657)\n",
      "\n",
      "2023-01-09 16:37:15,447\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00006:\n",
      "learning_rate : 0.0009259124456922373 --- (* 1.2) --> 0.0011110949348306848\n",
      "weight_decay : 9.216000000000002e-10 --- (* 1.2) --> 1.1059200000000003e-09\n",
      "batch_size : 22647 --- (* 1.2) --> 27176\n",
      "\n",
      "\u001B[2m\u001B[36m(vae_train pid=29333)\u001B[0m 2023-01-09 16:37:18,371\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00006_6_2023-01-09_16-30-21/checkpoint_tmp25425a\n",
      "\u001B[2m\u001B[36m(vae_train pid=29333)\u001B[0m 2023-01-09 16:37:18,372\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 843, '_timesteps_total': None, '_time_total': 379.47130155563354, '_episodes_total': None}\n",
      "2023-01-09 16:37:21,676\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00007 (score = -0.402348) into trial 8645f_00002 (score = -0.402654)\n",
      "\n",
      "2023-01-09 16:37:21,677\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00002:\n",
      "learning_rate : 0.0007715937047435311 --- (* 0.8) --> 0.0006172749637948249\n",
      "weight_decay : 1.1520000000000002e-09 --- (* 1.2) --> 1.3824000000000001e-09\n",
      "batch_size : 18873 --- (resample) --> 12512\n",
      "\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m 2023-01-09 16:37:22,557\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00000_0_2023-01-09_16-30-19/checkpoint_tmp4da7df\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m 2023-01-09 16:37:22,557\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 863, '_timesteps_total': None, '_time_total': 394.08881640434265, '_episodes_total': None}\n",
      "\u001B[2m\u001B[36m(vae_train pid=29509)\u001B[0m 2023-01-09 16:37:24,587\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00002_2_2023-01-09_16-30-21/checkpoint_tmpb9d122\n",
      "\u001B[2m\u001B[36m(vae_train pid=29509)\u001B[0m 2023-01-09 16:37:24,587\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 895, '_timesteps_total': None, '_time_total': 394.63296580314636, '_episodes_total': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(vae_train pid=29333)\u001B[0m {'learning_rate': 0.0011110949348306848, 'weight_decay': 1.1059200000000003e-09, 'batch_size': 27176, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=29333)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=29333)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=29333)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=29333)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=29333)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=29333)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=29333)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=29333)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=29333)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=29333)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=29333)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=29333)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=29333)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=29333)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=29333)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=29333)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=29333)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=29333)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=29333)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=29333)\u001B[0m }\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m {'learning_rate': 0.0009259124456922373, 'weight_decay': 1.3824000000000001e-09, 'batch_size': 3760, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=27820)\u001B[0m }\n",
      "\u001B[2m\u001B[36m(vae_train pid=29509)\u001B[0m {'learning_rate': 0.0006172749637948249, 'weight_decay': 1.3824000000000001e-09, 'batch_size': 12512, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=29509)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=29509)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=29509)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=29509)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=29509)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=29509)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=29509)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=29509)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=29509)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=29509)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=29509)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=29509)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=29509)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=29509)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=29509)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=29509)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=29509)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=29509)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=29509)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=29509)\u001B[0m }\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 16:37:41,723\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00007 (score = -0.402185) into trial 8645f_00006 (score = -0.402400)\n",
      "\n",
      "2023-01-09 16:37:41,724\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00006:\n",
      "learning_rate : 0.0007715937047435311 --- (* 0.8) --> 0.0006172749637948249\n",
      "weight_decay : 1.1520000000000002e-09 --- (* 1.2) --> 1.3824000000000001e-09\n",
      "batch_size : 18873 --- (* 1.2) --> 22647\n",
      "\n",
      "\u001B[2m\u001B[36m(vae_train pid=29719)\u001B[0m 2023-01-09 16:37:45,102\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00006_6_2023-01-09_16-30-21/checkpoint_tmp61a73b\n",
      "\u001B[2m\u001B[36m(vae_train pid=29719)\u001B[0m 2023-01-09 16:37:45,102\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 960, '_timesteps_total': None, '_time_total': 415.0144076347351, '_episodes_total': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(vae_train pid=29719)\u001B[0m {'learning_rate': 0.0006172749637948249, 'weight_decay': 1.3824000000000001e-09, 'batch_size': 22647, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=29719)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=29719)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=29719)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=29719)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=29719)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=29719)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=29719)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=29719)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=29719)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=29719)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=29719)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=29719)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=29719)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=29719)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=29719)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=29719)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=29719)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=29719)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=29719)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=29719)\u001B[0m }\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 16:38:06,399\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00004 (score = -0.401997) into trial 8645f_00005 (score = -0.402266)\n",
      "\n",
      "2023-01-09 16:38:06,400\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00005:\n",
      "learning_rate : 0.0009259124456922373 --- (* 0.8) --> 0.0007407299565537899\n",
      "weight_decay : 9.216000000000002e-10 --- (* 0.8) --> 7.372800000000002e-10\n",
      "batch_size : 22647 --- (* 1.2) --> 27176\n",
      "\n",
      "\u001B[2m\u001B[36m(vae_train pid=29933)\u001B[0m 2023-01-09 16:38:08,643\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00005_5_2023-01-09_16-30-21/checkpoint_tmp81c945\n",
      "\u001B[2m\u001B[36m(vae_train pid=29933)\u001B[0m 2023-01-09 16:38:08,643\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 981, '_timesteps_total': None, '_time_total': 430.6233332157135, '_episodes_total': None}\n",
      "2023-01-09 16:38:08,761\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00000 (score = -0.402120) into trial 8645f_00002 (score = -0.402177)\n",
      "\n",
      "2023-01-09 16:38:08,762\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00002:\n",
      "learning_rate : 0.0009259124456922373 --- (* 1.2) --> 0.0011110949348306848\n",
      "weight_decay : 1.3824000000000001e-09 --- (* 1.2) --> 1.6588800000000002e-09\n",
      "batch_size : 3760 --- (* 0.8) --> 3008\n",
      "\n",
      "\u001B[2m\u001B[36m(vae_train pid=30096)\u001B[0m 2023-01-09 16:38:10,509\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00002_2_2023-01-09_16-30-21/checkpoint_tmpbb342a\n",
      "\u001B[2m\u001B[36m(vae_train pid=30096)\u001B[0m 2023-01-09 16:38:10,509\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 942, '_timesteps_total': None, '_time_total': 434.68488001823425, '_episodes_total': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(vae_train pid=29933)\u001B[0m {'learning_rate': 0.0007407299565537899, 'weight_decay': 7.372800000000002e-10, 'batch_size': 27176, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=29933)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=29933)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=29933)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=29933)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=29933)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=29933)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=29933)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=29933)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=29933)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=29933)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=29933)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=29933)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=29933)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=29933)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=29933)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=29933)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=29933)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=29933)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=29933)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=29933)\u001B[0m }\n",
      "\u001B[2m\u001B[36m(vae_train pid=30096)\u001B[0m {'learning_rate': 0.0011110949348306848, 'weight_decay': 1.6588800000000002e-09, 'batch_size': 3008, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=30096)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=30096)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=30096)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=30096)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=30096)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=30096)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=30096)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=30096)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=30096)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=30096)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=30096)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=30096)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=30096)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=30096)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=30096)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=30096)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=30096)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=30096)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=30096)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=30096)\u001B[0m }\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 16:38:20,843\tINFO pbt.py:804 -- \n",
      "\n",
      "[PopulationBasedTraining] [Exploit] Cloning trial 8645f_00005 (score = -0.401923) into trial 8645f_00002 (score = -0.402200)\n",
      "\n",
      "2023-01-09 16:38:20,844\tINFO pbt.py:831 -- \n",
      "\n",
      "[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8645f_00002:\n",
      "learning_rate : 0.0007407299565537899 --- (* 0.8) --> 0.000592583965243032\n",
      "weight_decay : 7.372800000000002e-10 --- (* 0.8) --> 5.898240000000002e-10\n",
      "batch_size : 27176 --- (* 0.8) --> 21740\n",
      "\n",
      "\u001B[2m\u001B[36m(vae_train pid=30273)\u001B[0m 2023-01-09 16:38:22,572\tINFO trainable.py:790 -- Restored on 192.168.2.8 from checkpoint: /home/egor/ray_results/vae_training/vae_train_8645f_00002_2_2023-01-09_16-30-21/checkpoint_tmp0a65fe\n",
      "\u001B[2m\u001B[36m(vae_train pid=30273)\u001B[0m 2023-01-09 16:38:22,572\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 982, '_timesteps_total': None, '_time_total': 441.551726102829, '_episodes_total': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(vae_train pid=30273)\u001B[0m {'learning_rate': 0.000592583965243032, 'weight_decay': 5.898240000000002e-10, 'batch_size': 21740, 'checkpoint_interval': 10, 'default_config': architecture:\n",
      "\u001B[2m\u001B[36m(vae_train pid=30273)\u001B[0m   activation: GELU\n",
      "\u001B[2m\u001B[36m(vae_train pid=30273)\u001B[0m   hidden_dims: !!python/tuple\n",
      "\u001B[2m\u001B[36m(vae_train pid=30273)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=30273)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=30273)\u001B[0m   - 32\n",
      "\u001B[2m\u001B[36m(vae_train pid=30273)\u001B[0m   in_features: 41\n",
      "\u001B[2m\u001B[36m(vae_train pid=30273)\u001B[0m   kld_weight: 0.0025\n",
      "\u001B[2m\u001B[36m(vae_train pid=30273)\u001B[0m   latent_dim: 2\n",
      "\u001B[2m\u001B[36m(vae_train pid=30273)\u001B[0m   loss_type: beta\n",
      "\u001B[2m\u001B[36m(vae_train pid=30273)\u001B[0m dataset: Organoid\n",
      "\u001B[2m\u001B[36m(vae_train pid=30273)\u001B[0m device: cuda\n",
      "\u001B[2m\u001B[36m(vae_train pid=30273)\u001B[0m epochs: 10000\n",
      "\u001B[2m\u001B[36m(vae_train pid=30273)\u001B[0m model: VAE\n",
      "\u001B[2m\u001B[36m(vae_train pid=30273)\u001B[0m output_dir: ./logs/VanillaVAE/\n",
      "\u001B[2m\u001B[36m(vae_train pid=30273)\u001B[0m seed: 12345\n",
      "\u001B[2m\u001B[36m(vae_train pid=30273)\u001B[0m tunable:\n",
      "\u001B[2m\u001B[36m(vae_train pid=30273)\u001B[0m   batch_size: 4096\n",
      "\u001B[2m\u001B[36m(vae_train pid=30273)\u001B[0m   learning_rate: 0.05\n",
      "\u001B[2m\u001B[36m(vae_train pid=30273)\u001B[0m   weight_decay: 0.0\n",
      "\u001B[2m\u001B[36m(vae_train pid=30273)\u001B[0m }\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 16:38:37,560\tINFO tune.py:762 -- Total run time: 498.18 seconds (498.02 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "perturbation_interval = 10\n",
    "scheduler = PopulationBasedTraining(\n",
    "    time_attr=\"time_total_s\",\n",
    "    perturbation_interval=perturbation_interval,\n",
    "    hyperparam_mutations={\n",
    "        # Distribution for resampling\n",
    "        \"learning_rate\": tune.loguniform(1e-5, 1e-2),\n",
    "        \"weight_decay\": tune.loguniform(1e-10, 1e-6),\n",
    "        \"batch_size\":tune.randint(1024,16*1024)\n",
    "    },\n",
    ")\n",
    "\n",
    "smoke_test = True  # For testing purposes: set this to False to run the full experiment\n",
    "tuner = tune.Tuner(\n",
    "    tune.with_resources(vae_train, {\"cpu\": 16, \"gpu\": 0.25}),\n",
    "    run_config=air.RunConfig(\n",
    "        name=\"vae_training\",\n",
    "        stop={\"training_iteration\": 1000},\n",
    "        verbose=1,\n",
    "    ),\n",
    "    tune_config=tune.TuneConfig(\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        num_samples= 8,\n",
    "        scheduler=scheduler,\n",
    "    ),\n",
    "    param_space={\n",
    "        # Define how initial values of the learning rates should be chosen.\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"weight_decay\": 1e-9,\n",
    "        \"batch_size\": 16384,\n",
    "        \"checkpoint_interval\": perturbation_interval,\n",
    "        \"default_config\":get_config()\n",
    "    },\n",
    ")\n",
    "results_grid = tuner.fit()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "result_dfs = [result.metrics_dataframe for result in results_grid]\n",
    "best_result = results_grid.get_best_result(metric=\"MSE\", mode=\"min\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "Result(metrics={'MSE': 0.38341038301239194, 'KLD': -7.383336454875566, 'loss': 0.4018687200058487, 'lr': 0.0007407299565537899, 'wd': 7.372800000000002e-10, 'done': True, 'trial_id': '8645f_00005', 'experiment_tag': '5@perturbed[batch_size=27176,learning_rate=0.0007,weight_decay=0.0000]'}, error=None, log_dir=PosixPath('/home/egor/ray_results/vae_training/vae_train_8645f_00005_5_2023-01-09_16-30-21'))"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "Result(metrics={'MSE': 0.38343411134568844, 'KLD': -7.373263793958652, 'loss': 0.40186727006538747, 'lr': 0.000592583965243032, 'wd': 5.898240000000002e-10, 'done': True, 'trial_id': '8645f_00002', 'experiment_tag': '2@perturbed[batch_size=21740,learning_rate=0.0006,weight_decay=0.0000]'}, error=None, log_dir=PosixPath('/home/egor/ray_results/vae_training/vae_train_8645f_00002_2_2023-01-09_16-30-21'))"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_grid.get_best_result(metric=\"loss\", mode=\"min\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 700x400 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7, 4))\n",
    "for i, df in enumerate(result_dfs):\n",
    "    plt.plot(df[\"MSE\"], label=i)\n",
    "plt.legend()\n",
    "plt.title(\"MSE During Training\")\n",
    "plt.xlabel(\"Training Iterations\")\n",
    "plt.ylabel(\"MSE Score\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.632389\n",
      "1       0.529680\n",
      "2       0.516023\n",
      "3       0.524322\n",
      "4       0.509985\n",
      "          ...   \n",
      "1050    0.383522\n",
      "1051    0.383486\n",
      "1052    0.383518\n",
      "1053    0.383490\n",
      "1054    0.383502\n",
      "Name: MSE, Length: 1055, dtype: float64\n",
      "0      0.810567\n",
      "1      0.527594\n",
      "2      0.491037\n",
      "3      0.495580\n",
      "4      0.481445\n",
      "         ...   \n",
      "911    0.383687\n",
      "912    0.383694\n",
      "913    0.383708\n",
      "914    0.383675\n",
      "915    0.383702\n",
      "Name: MSE, Length: 916, dtype: float64\n",
      "0      0.760956\n",
      "1      0.540004\n",
      "2      0.520835\n",
      "3      0.487017\n",
      "4      0.514038\n",
      "         ...   \n",
      "959    0.383420\n",
      "960    0.383434\n",
      "961    0.383415\n",
      "962    0.383421\n",
      "963    0.383434\n",
      "Name: MSE, Length: 964, dtype: float64\n",
      "0       0.665623\n",
      "1       0.540386\n",
      "2       0.493463\n",
      "3       0.482290\n",
      "4       0.477600\n",
      "          ...   \n",
      "1035    0.383593\n",
      "1036    0.383597\n",
      "1037    0.383573\n",
      "1038    0.383559\n",
      "1039    0.383581\n",
      "Name: MSE, Length: 1040, dtype: float64\n",
      "0       0.633644\n",
      "1       0.539807\n",
      "2       0.503135\n",
      "3       0.489704\n",
      "4       0.484369\n",
      "          ...   \n",
      "1065    0.383454\n",
      "1066    0.383478\n",
      "1067    0.383454\n",
      "1068    0.383500\n",
      "1069    0.383488\n",
      "Name: MSE, Length: 1070, dtype: float64\n",
      "0       0.561614\n",
      "1       0.524286\n",
      "2       0.504293\n",
      "3       0.481471\n",
      "4       0.476820\n",
      "          ...   \n",
      "1002    0.383433\n",
      "1003    0.383431\n",
      "1004    0.383409\n",
      "1005    0.383402\n",
      "1006    0.383410\n",
      "Name: MSE, Length: 1007, dtype: float64\n",
      "0      0.656691\n",
      "1      0.545583\n",
      "2      0.529895\n",
      "3      0.492027\n",
      "4      0.477522\n",
      "         ...   \n",
      "876    0.383575\n",
      "877    0.383596\n",
      "878    0.383578\n",
      "879    0.383615\n",
      "880    0.383558\n",
      "Name: MSE, Length: 881, dtype: float64\n",
      "0       0.723410\n",
      "1       0.563175\n",
      "2       0.492250\n",
      "3       0.482474\n",
      "4       0.493379\n",
      "          ...   \n",
      "1011    0.383572\n",
      "1012    0.383566\n",
      "1013    0.383568\n",
      "1014    0.383578\n",
      "1015    0.383579\n",
      "Name: MSE, Length: 1016, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for i, df in enumerate(result_dfs):\n",
    "    print(df[\"MSE\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "model_dict = best_result.checkpoint.to_dict()['model']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "model = BetaVAE(config).to(config.device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(model_dict)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.3834534478688556, -7.3850293643225635, 0.4019160213057462)"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model,X_val_batches)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "torch.save(best_result.checkpoint.to_dict(),'/data/PycharmProjects/cytof_benchmark/logs/ray_tune/Beta_VAE_big.pth')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "0.38341038301239194"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_result.metrics['MSE']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from ray import tune, air\n",
    "ray.init()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-12 15:42:55,418\tINFO experiment_analysis.py:795 -- No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n"
     ]
    }
   ],
   "source": [
    "analysis = ray.tune.ExperimentAnalysis(experiment_checkpoint_path='/home/egor/ray_results/vae_training')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "trial = analysis.get_best_trial(metric=\"MSE\", mode=\"min\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "2754"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial.last_result['training_iteration']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/home/egor/ray_results/vae_training/vae_train_a20ab_00014_14_batch_size=10451,learning_rate=0.0000_2023-01-11_15-02-51/checkpoint_tmp8d8afe/.tune_metadata', 'rb') as f:\n",
    "    metadata = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "2700"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['iteration']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-12 16:23:10,615\tWARNING trial_runner.py:415 -- The maximum number of pending trials has been automatically set to the number of available cluster CPUs, which is high (140 CPUs/pending trials). If you're running an experiment with a large number of trials, this could lead to scheduling overhead. In this case, consider setting the `TUNE_MAX_PENDING_TRIALS_PG` environment variable to the desired maximum number of concurrent trials.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-12 16:23:10,622\tWARNING pbt.py:1046 -- Trial was initialized with a config, which was overwritten. Did you start the PBT replay with a `config` parameter?\n",
      "2023-01-12 16:23:12,367\tERROR trial_runner.py:1088 -- Trial vae_train_05f23_00000: Error processing event.\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001B[36mray::ImplicitFunc.train()\u001B[39m (pid=23611, ip=192.168.2.8, repr=vae_train)\n",
      "  File \"/data/PycharmProjects/cytof_benchmark/venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 367, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/data/PycharmProjects/cytof_benchmark/venv/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 335, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/data/PycharmProjects/cytof_benchmark/venv/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 652, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/tmp/ipykernel_7212/3480078133.py\", line 207, in vae_train\n",
      "  File \"/tmp/ipykernel_7212/3480078133.py\", line 50, in __init__\n",
      "AttributeError: 'str' object has no attribute 'architecture'\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<div class=\"trialProgress\">\n  <h3>Trial Progress</h3>\n  <table>\n<thead>\n<tr><th>Trial name           </th><th>date               </th><th>experiment_id                   </th><th>hostname          </th><th>node_ip    </th><th style=\"text-align: right;\">  pid</th><th style=\"text-align: right;\">  timestamp</th><th>trial_id   </th></tr>\n</thead>\n<tbody>\n<tr><td>vae_train_05f23_00000</td><td>2023-01-12_16-23-12</td><td>d944b07108304d35aba7cc6ee6caed81</td><td>egor-Lambda-Vector</td><td>192.168.2.8</td><td style=\"text-align: right;\">23611</td><td style=\"text-align: right;\"> 1673536992</td><td>05f23_00000</td></tr>\n</tbody>\n</table>\n</div>\n<style>\n.trialProgress {\n  display: flex;\n  flex-direction: column;\n  color: var(--jp-ui-font-color1);\n}\n.trialProgress h3 {\n  font-weight: bold;\n}\n.trialProgress td {\n  white-space: nowrap;\n}\n</style>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-12 16:23:12,477\tERROR tune.py:758 -- Trials did not complete: [vae_train_05f23_00000]\n",
      "2023-01-12 16:23:12,477\tINFO tune.py:762 -- Total run time: 1.87 seconds (1.75 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import PopulationBasedTrainingReplay\n",
    "# Get a random replay policy from the experiment we just ran\n",
    "sample_pbt_trial_log = '/home/egor/ray_results/vae_training/pbt_policy_a20ab_00014.txt'\n",
    "replay = PopulationBasedTrainingReplay(sample_pbt_trial_log)\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    vae_train,\n",
    "    tune_config=tune.TuneConfig(scheduler=replay),\n",
    "    run_config=air.RunConfig(stop={\"training_iteration\": trial.last_result['training_iteration']}),\n",
    "    param_space={\n",
    "            \"default_config\": get_config()\n",
    "        },\n",
    ")\n",
    "results_grid = tuner.fit()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import ray\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from ml_collections import config_dict\n",
    "from ray import tune, air\n",
    "from ray.air import session, Checkpoint\n",
    "from ray.tune.schedulers import PopulationBasedTraining\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from datasets import OrganoidDataset\n",
    "\n",
    "\n",
    "def get_config():\n",
    "    config = config_dict.ConfigDict()\n",
    "    # General parameters\n",
    "    config.dataset = 'Organoid'\n",
    "    config.model = 'VAE'\n",
    "    config.seed = 12345\n",
    "    config.output_dir = './logs/VanillaVAE/'\n",
    "    config.device = 'cuda'\n",
    "    config.epochs = 10000\n",
    "\n",
    "    # VAE architecture parameters\n",
    "    config.architecture = config_dict.ConfigDict()\n",
    "    config.architecture.in_features = 41\n",
    "    config.architecture.latent_dim = 2\n",
    "    config.architecture.hidden_dims = [256, 256, 256, 256, 256]\n",
    "    config.architecture.kld_weight = 0.0025\n",
    "    config.architecture.loss_type = 'beta'\n",
    "    config.architecture.activation = 'LeakyReLU'\n",
    "\n",
    "    # Tunable default parameters\n",
    "    config.tunable = config_dict.ConfigDict()\n",
    "    config.tunable.learning_rate = 0.05\n",
    "    config.tunable.weight_decay = 0.0\n",
    "    config.tunable.batch_size = 4096\n",
    "    return config\n",
    "\n",
    "\n",
    "class BetaVAE(nn.Module):\n",
    "\n",
    "    def __init__(self, config: config_dict.ConfigDict) -> None:\n",
    "        super(BetaVAE, self).__init__()\n",
    "\n",
    "        self.config = config\n",
    "        self.kld_weight = torch.Tensor([config.architecture.kld_weight]).to(config.device)\n",
    "\n",
    "        self.act_class = getattr(nn, config.architecture.activation)\n",
    "\n",
    "        modules = []\n",
    "\n",
    "        # Build Encoder\n",
    "\n",
    "        encoder_dims = [config.architecture.in_features] + list(config.architecture.hidden_dims)\n",
    "\n",
    "        for i in range(len(config.architecture.hidden_dims)):\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(in_features=encoder_dims[i], out_features=encoder_dims[i + 1]),\n",
    "                    nn.BatchNorm1d(encoder_dims[i + 1]),\n",
    "                    self.act_class(),\n",
    "                )\n",
    "            )\n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "        self.fc_mu = nn.Linear(config.architecture.hidden_dims[-1], config.architecture.latent_dim)\n",
    "        self.fc_var = nn.Linear(config.architecture.hidden_dims[-1], config.architecture.latent_dim)\n",
    "\n",
    "        # Build Decoder\n",
    "        modules = []\n",
    "        decoder_dims = \\\n",
    "            [config.architecture.latent_dim] + \\\n",
    "            list(reversed(config.architecture.hidden_dims)) + \\\n",
    "            [config.architecture.in_features]\n",
    "\n",
    "        for i in range(len(config.architecture.hidden_dims) + 1):\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(decoder_dims[i], decoder_dims[i + 1]),\n",
    "                    nn.BatchNorm1d(decoder_dims[i + 1]),\n",
    "                    self.act_class()\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.decoder = nn.Sequential(*modules)\n",
    "        self.final_layer = nn.Linear(config.architecture.in_features, config.architecture.in_features)\n",
    "\n",
    "    def encode(self, input: torch.Tensor) -> List[torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Encodes the input by passing through the encoder network\n",
    "        and returns the latent codes.\n",
    "        :param input: (Tensor) Input tensor to encoder [N x C]\n",
    "        :return: (Tensor) List of latent codes\n",
    "        \"\"\"\n",
    "        result = self.encoder(input)\n",
    "        result = torch.flatten(result, start_dim=1)\n",
    "\n",
    "        # Split the result into mu and var components\n",
    "        # of the latent Gaussian distribution\n",
    "        mu = self.fc_mu(result)\n",
    "        log_var = self.fc_var(result)\n",
    "\n",
    "        return [mu, log_var]\n",
    "\n",
    "    def decode(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Maps the given latent codes\n",
    "        onto the sample matrix space.\n",
    "        :param z: (Tensor) [B x D]\n",
    "        :return: (Tensor) [B x C]\n",
    "        \"\"\"\n",
    "        # Only batch - normalized layers\n",
    "        result = self.decoder(z)\n",
    "        # Use linear layer to map normalized decoder outputs back to input space\n",
    "        result = self.final_layer(result)\n",
    "        return result\n",
    "\n",
    "    def reparameterize(self, mu: torch.Tensor, logvar: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Reparameterization trick to sample from N(mu, var) from\n",
    "        N(0,1).\n",
    "        :param mu: (Tensor) Mean of the latent Gaussian [B x D]\n",
    "        :param logvar: (Tensor) Standard deviation of the latent Gaussian [B x D]\n",
    "        :return: (Tensor) [B x D]\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps * std + mu\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> List[torch.Tensor]:\n",
    "        mu, log_var = self.encode(input)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        return [self.decode(z), input, mu, log_var]\n",
    "\n",
    "    def loss_function(self,\n",
    "                      *args) -> dict:\n",
    "        r\"\"\"\n",
    "        Computes the VAE loss function.\n",
    "        KL(N(\\mu, \\sigma), N(0, 1)) = \\log \\frac{1}{\\sigma} + \\frac{\\sigma^2 + \\mu^2}{2} - \\frac{1}{2}\n",
    "        :param epoch: current epoch\n",
    "        :param args:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        recons = args[0]\n",
    "        input = args[1]\n",
    "        mu = args[2]\n",
    "        log_var = args[3]\n",
    "\n",
    "        recons_loss = F.mse_loss(recons, input)\n",
    "\n",
    "        kld_loss = torch.mean(-0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp(), dim=1), dim=0)\n",
    "\n",
    "        loss = recons_loss + self.kld_weight * kld_loss\n",
    "\n",
    "        return {'loss': loss, 'MSE': recons_loss.detach(), 'KLD': -kld_loss.detach()}\n",
    "\n",
    "    def generate(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Given an input sample matrix x, returns the reconstructed sample matrix\n",
    "        :param x: (Tensor) [B x C]\n",
    "        :return: (Tensor) [B x C]\n",
    "        \"\"\"\n",
    "\n",
    "        return self.forward(x)[0]\n",
    "\n",
    "    def latent(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.reparameterize(*self.encode(x))\n",
    "\n",
    "\n",
    "def train(model, optimizer, train_dataloader):\n",
    "    for X_batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        model.train()\n",
    "        outputs = model.forward(X_batch)\n",
    "        loss = model.loss_function(*outputs)\n",
    "\n",
    "        loss['loss'].backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def test(model, val_dataloader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        mse, kld, loss = list(), list(), list()\n",
    "        for X_batch in val_dataloader:\n",
    "            loss_dict = dict()\n",
    "            outputs = model.forward(X_batch)\n",
    "            losses = model.loss_function(*outputs)\n",
    "            for key in losses.keys():\n",
    "                loss_dict[key] = losses[key].to('cpu').numpy().item() * X_batch.shape[0]\n",
    "            mse.append(loss_dict['MSE'])\n",
    "            kld.append(loss_dict['KLD'])\n",
    "            loss.append(loss_dict['loss'])\n",
    "    data_len = sum(len(batch) for batch in val_dataloader)\n",
    "\n",
    "    return \\\n",
    "        np.nan_to_num(sum(mse) / data_len, nan=10), \\\n",
    "        np.nan_to_num(sum(kld) / data_len, nan=10), \\\n",
    "        np.nan_to_num(sum(loss) / data_len, nan=10)\n",
    "\n",
    "\n",
    "def vae_train(cfg):\n",
    "    config = cfg.get('default_config')\n",
    "    model = BetaVAE(config).to(config.device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(),\n",
    "                           lr=cfg.get(\"learning_rate\"),\n",
    "                           )\n",
    "\n",
    "    dataset = OrganoidDataset(data_dir='/data/organoids')\n",
    "    X_train, y_train = dataset.train\n",
    "    X_val, y_val = dataset.val\n",
    "    X_train_batches = torch.split(X_train, split_size_or_sections=cfg.get(\"batch_size\"))\n",
    "    X_val_batches = torch.split(X_val, split_size_or_sections=cfg.get(\"batch_size\"))\n",
    "\n",
    "    # Remove last batch if it has less than half batch size samples to reduce variance\n",
    "    if X_train_batches[-1].shape[0] < cfg.get(\"batch_size\") // 2:\n",
    "        X_train_batches = X_train_batches[:-1]\n",
    "\n",
    "    step = 1\n",
    "    if session.get_checkpoint():\n",
    "        checkpoint_dict = session.get_checkpoint().to_dict()\n",
    "\n",
    "        model.load_state_dict(checkpoint_dict[\"model\"])\n",
    "        optimizer.load_state_dict(checkpoint_dict[\"optim\"])\n",
    "        # Note: Make sure to increment the loaded step by 1 to get the\n",
    "        # current step.\n",
    "        last_step = checkpoint_dict[\"step\"]\n",
    "        step = last_step + 1\n",
    "\n",
    "        # NOTE: It's important to set the optimizer learning rates\n",
    "        # again, since we want to explore the parameters passed in by PBT.\n",
    "        # Without this, we would continue using the exact same\n",
    "        # configuration as the trial whose checkpoint we are exploiting.\n",
    "        if \"learning_rate\" in cfg:\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group[\"lr\"] = cfg[\"learning_rate\"]\n",
    "    while True:\n",
    "        train(model, optimizer, X_train_batches)\n",
    "        MSE, KLD, loss = test(model, X_val_batches)\n",
    "\n",
    "        checkpoint = None\n",
    "        if step % cfg[\"checkpoint_interval\"] == 0:\n",
    "            checkpoint = Checkpoint.from_dict(\n",
    "                {\n",
    "                    \"model\": model.state_dict(),\n",
    "                    \"optim\": optimizer.state_dict(),\n",
    "                    \"step\": step,\n",
    "                }\n",
    "            )\n",
    "        session.report(\n",
    "            {\n",
    "                \"MSE\": MSE,\n",
    "                \"KLD\": KLD,\n",
    "                \"loss\": loss,\n",
    "                'lr': cfg.get(\"learning_rate\"),\n",
    "                \"step\": step,\n",
    "            },\n",
    "            checkpoint=checkpoint,\n",
    "        )\n",
    "        step += 1"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
