{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import sys\n",
    "if \"..\" not in sys.path:\n",
    "    sys.path.insert(0, \"..\")\n",
    "\n",
    "from datasets import OrganoidDataset\n",
    "import torch\n",
    "\n",
    "data = OrganoidDataset(data_dir='/home/egor/PycharmProjects/deep_dr/data/organoids')\n",
    "\n",
    "X_train, y_train = data.train\n",
    "X_val, y_val = data.val\n",
    "\n",
    "X_train_batches = torch.split(torch.Tensor(X_train), split_size_or_sections=1024)\n",
    "X_val_batches = torch.split(torch.Tensor(X_val), split_size_or_sections=1024)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from models.vqvae import *\n",
    "from configs.vqvae import get_config"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1024, 41])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = X_train_batches[0]\n",
    "x.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "batch_size: 32768\ndataset: Organoid\nembed_dim: 16\nhidden_features: 32\nin_features: 41\nkld_scale: 0.0005\nmodel: VQVAE\nn_layers: 3\nnb_entries: 256\noutput_dir: ./logs/VQVAE/\nseed: 12345\nstraight_through: false\ntemperature: 1"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = get_config()\n",
    "config"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "Encoder(\n  (layers): Sequential(\n    (0): Linear(in_features=41, out_features=32, bias=True)\n    (1): ResidualStack(\n      (stack): Sequential(\n        (0): ReZero(\n          (layers): Sequential(\n            (0): Linear(in_features=32, out_features=32, bias=True)\n            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n        )\n        (1): ReZero(\n          (layers): Sequential(\n            (0): Linear(in_features=32, out_features=32, bias=True)\n            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n        )\n        (2): ReZero(\n          (layers): Sequential(\n            (0): Linear(in_features=32, out_features=32, bias=True)\n            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n        )\n      )\n    )\n  )\n)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = Encoder(config)\n",
    "emb"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1024, 32])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_embedded = emb(x)\n",
    "x_embedded.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([256, 16])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed = torch.randn(config.nb_entries, config.embed_dim, dtype=torch.float32)\n",
    "embed.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "CodeLayer(\n  (linear_in): Linear(in_features=32, out_features=256, bias=True)\n)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coder = CodeLayer(config)\n",
    "coder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1024, 16])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_coded = coder(x_embedded)\n",
    "x_coded[0].shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "Decoder(\n  (layers): Sequential(\n    (0): Linear(in_features=16, out_features=32, bias=True)\n    (1): ResidualStack(\n      (stack): Sequential(\n        (0): ReZero(\n          (layers): Sequential(\n            (0): Linear(in_features=32, out_features=32, bias=True)\n            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n        )\n        (1): ReZero(\n          (layers): Sequential(\n            (0): Linear(in_features=32, out_features=32, bias=True)\n            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n        )\n        (2): ReZero(\n          (layers): Sequential(\n            (0): Linear(in_features=32, out_features=32, bias=True)\n            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n        )\n      )\n    )\n    (2): Linear(in_features=32, out_features=41, bias=True)\n  )\n)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = Decoder(config)\n",
    "decoder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1024, 41])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder(x_coded[0]).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "def get_parameter_count(net: torch.nn.Module) -> int:\n",
    "    return sum(p.numel() for p in net.parameters() if p.requires_grad)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:8, loss: 0.5556803345680237, MSE: 0.553026556968689, KLD:5.307550430297852\n",
      "Epoch:9, loss: 0.5563061833381653, MSE: 0.5536498427391052, KLD:5.31266975402832\n",
      "Epoch:10, loss: 0.5511208176612854, MSE: 0.5484678745269775, KLD:5.305926322937012\n",
      "Epoch:11, loss: 0.5503928661346436, MSE: 0.5477404594421387, KLD:5.3047871589660645\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [49], line 26\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m X_batch \u001B[38;5;129;01min\u001B[39;00m X_val_batches:\n\u001B[1;32m     25\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 26\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     27\u001B[0m     loss \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mloss_function(\u001B[38;5;241m*\u001B[39moutputs)\n\u001B[1;32m     28\u001B[0m     loss[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloss\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[0;32m~/PycharmProjects/deep_dr/testing/../models/vqvae.py:117\u001B[0m, in \u001B[0;36mVQVAE.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m    116\u001B[0m     encoder_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder(x)\n\u001B[0;32m--> 117\u001B[0m     code_q, code_d, emb_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcodebook\u001B[49m\u001B[43m(\u001B[49m\u001B[43mencoder_output\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    118\u001B[0m     decoder_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoder(code_q)\n\u001B[1;32m    120\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m decoder_output, x, code_d, encoder_output, emb_id\n",
      "File \u001B[0;32m~/PycharmProjects/deep_dr/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/PycharmProjects/deep_dr/venv/lib/python3.10/site-packages/torch/amp/autocast_mode.py:14\u001B[0m, in \u001B[0;36mautocast_decorator.<locals>.decorate_autocast\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_autocast\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m autocast_instance:\n\u001B[0;32m---> 14\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/deep_dr/testing/../models/vqvae.py:92\u001B[0m, in \u001B[0;36mCodeLayer.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     88\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlinear_in(x\u001B[38;5;241m.\u001B[39mfloat())\n\u001B[1;32m     90\u001B[0m hard \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstraight_through \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m---> 92\u001B[0m soft_one_hot \u001B[38;5;241m=\u001B[39m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgumbel_softmax\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtau\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtemperature\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhard\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhard\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     93\u001B[0m quantize \u001B[38;5;241m=\u001B[39m soft_one_hot \u001B[38;5;241m@\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membed\n\u001B[1;32m     95\u001B[0m \u001B[38;5;66;03m# + kl divergence to the prior loss\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/deep_dr/venv/lib/python3.10/site-packages/torch/nn/functional.py:1893\u001B[0m, in \u001B[0;36mgumbel_softmax\u001B[0;34m(logits, tau, hard, eps, dim)\u001B[0m\n\u001B[1;32m   1889\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m eps \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m1e-10\u001B[39m:\n\u001B[1;32m   1890\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`eps` parameter is deprecated and has no effect.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1892\u001B[0m gumbels \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m-> 1893\u001B[0m     \u001B[38;5;241m-\u001B[39m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mempty_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlogits\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemory_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlegacy_contiguous_format\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexponential_\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mlog()\n\u001B[1;32m   1894\u001B[0m )  \u001B[38;5;66;03m# ~Gumbel(0,1)\u001B[39;00m\n\u001B[1;32m   1895\u001B[0m gumbels \u001B[38;5;241m=\u001B[39m (logits \u001B[38;5;241m+\u001B[39m gumbels) \u001B[38;5;241m/\u001B[39m tau  \u001B[38;5;66;03m# ~Gumbel(logits,tau)\u001B[39;00m\n\u001B[1;32m   1896\u001B[0m y_soft \u001B[38;5;241m=\u001B[39m gumbels\u001B[38;5;241m.\u001B[39msoftmax(dim)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "config = get_config()\n",
    "config.n_layers = 10\n",
    "config.hidden_features = 32\n",
    "config.embed_dim = 16\n",
    "model = VQVAE(config=config)\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "\n",
    "model.apply(init_weights)\n",
    "print(f\"Model parameters: {get_parameter_count(model)}\")\n",
    "\n",
    "epochs = 200\n",
    "optimizer = optim.AdamW(model.parameters(),\n",
    "                       lr=0.01,\n",
    "                       )\n",
    "\n",
    "scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "for epoch in range(epochs):\n",
    "    for X_batch in X_val_batches:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model.forward(X_batch)\n",
    "        loss = model.loss_function(*outputs)\n",
    "        loss['loss'].backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch:{epoch}, loss: {loss['loss']}, MSE: {loss['MSE']}, KLD:{loss['KLD']}\")\n",
    "    scheduler.step()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
