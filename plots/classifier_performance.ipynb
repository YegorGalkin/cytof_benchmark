{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['/data/PycharmProjects/cytof_benchmark/results/latent_data/dim5/HyperSphericalVAE/CafDataset/test.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim5/HyperSphericalVAE/CafDataset/val.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim5/HyperSphericalVAE/CafDataset/train.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim5/HyperSphericalVAE/ChallengeDataset/test.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim5/HyperSphericalVAE/ChallengeDataset/val.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim5/HyperSphericalVAE/ChallengeDataset/train.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim5/HyperSphericalVAE/OrganoidDataset/test.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim5/HyperSphericalVAE/OrganoidDataset/val.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim5/HyperSphericalVAE/OrganoidDataset/train.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim5/DBetaVAE/CafDataset/test.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim5/DBetaVAE/CafDataset/val.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim5/DBetaVAE/CafDataset/train.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim5/DBetaVAE/ChallengeDataset/test.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim5/DBetaVAE/ChallengeDataset/val.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim5/DBetaVAE/ChallengeDataset/train.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim5/DBetaVAE/OrganoidDataset/test.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim5/DBetaVAE/OrganoidDataset/val.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim5/DBetaVAE/OrganoidDataset/train.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim5/WAE_MMD/CafDataset/test.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim5/WAE_MMD/CafDataset/val.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim5/WAE_MMD/CafDataset/train.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim5/WAE_MMD/ChallengeDataset/test.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim5/WAE_MMD/ChallengeDataset/val.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim5/WAE_MMD/ChallengeDataset/train.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim5/WAE_MMD/OrganoidDataset/test.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim5/WAE_MMD/OrganoidDataset/val.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim5/WAE_MMD/OrganoidDataset/train.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim5/BetaVAE/CafDataset/test.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim5/BetaVAE/CafDataset/val.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim5/BetaVAE/CafDataset/train.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim5/BetaVAE/ChallengeDataset/test.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim5/BetaVAE/ChallengeDataset/val.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim5/BetaVAE/ChallengeDataset/train.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim5/BetaVAE/OrganoidDataset/test.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim5/BetaVAE/OrganoidDataset/val.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim5/BetaVAE/OrganoidDataset/train.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim2/HyperSphericalVAE/CafDataset/test.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim2/HyperSphericalVAE/CafDataset/val.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim2/HyperSphericalVAE/CafDataset/train.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim2/HyperSphericalVAE/ChallengeDataset/test.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim2/HyperSphericalVAE/ChallengeDataset/val.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim2/HyperSphericalVAE/ChallengeDataset/train.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim2/HyperSphericalVAE/OrganoidDataset/test.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim2/HyperSphericalVAE/OrganoidDataset/val.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim2/HyperSphericalVAE/OrganoidDataset/train.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim2/DBetaVAE/CafDataset/test.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim2/DBetaVAE/CafDataset/val.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim2/DBetaVAE/CafDataset/train.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim2/DBetaVAE/ChallengeDataset/test.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim2/DBetaVAE/ChallengeDataset/val.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim2/DBetaVAE/ChallengeDataset/train.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim2/DBetaVAE/OrganoidDataset/test.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim2/DBetaVAE/OrganoidDataset/val.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim2/DBetaVAE/OrganoidDataset/train.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim2/WAE_MMD/CafDataset/test.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim2/WAE_MMD/CafDataset/val.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim2/WAE_MMD/CafDataset/train.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim2/WAE_MMD/ChallengeDataset/test.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim2/WAE_MMD/ChallengeDataset/val.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim2/WAE_MMD/ChallengeDataset/train.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim2/WAE_MMD/OrganoidDataset/test.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim2/WAE_MMD/OrganoidDataset/val.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim2/WAE_MMD/OrganoidDataset/train.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim2/BetaVAE/CafDataset/test.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim2/BetaVAE/CafDataset/val.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim2/BetaVAE/CafDataset/train.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim2/BetaVAE/ChallengeDataset/test.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim2/BetaVAE/ChallengeDataset/val.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim2/BetaVAE/ChallengeDataset/train.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim2/BetaVAE/OrganoidDataset/test.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim2/BetaVAE/OrganoidDataset/val.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim2/BetaVAE/OrganoidDataset/train.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim3/HyperSphericalVAE/CafDataset/test.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim3/HyperSphericalVAE/CafDataset/val.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim3/HyperSphericalVAE/CafDataset/train.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim3/HyperSphericalVAE/ChallengeDataset/test.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim3/HyperSphericalVAE/ChallengeDataset/val.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim3/HyperSphericalVAE/ChallengeDataset/train.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim3/HyperSphericalVAE/OrganoidDataset/test.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim3/HyperSphericalVAE/OrganoidDataset/val.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim3/HyperSphericalVAE/OrganoidDataset/train.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim3/DBetaVAE/CafDataset/test.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim3/DBetaVAE/CafDataset/val.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim3/DBetaVAE/CafDataset/train.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim3/DBetaVAE/ChallengeDataset/test.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim3/DBetaVAE/ChallengeDataset/val.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim3/DBetaVAE/ChallengeDataset/train.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim3/DBetaVAE/OrganoidDataset/test.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim3/DBetaVAE/OrganoidDataset/val.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim3/DBetaVAE/OrganoidDataset/train.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim3/WAE_MMD/CafDataset/test.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim3/WAE_MMD/CafDataset/val.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim3/WAE_MMD/CafDataset/train.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim3/WAE_MMD/ChallengeDataset/test.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim3/WAE_MMD/ChallengeDataset/val.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim3/WAE_MMD/ChallengeDataset/train.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim3/WAE_MMD/OrganoidDataset/test.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim3/WAE_MMD/OrganoidDataset/val.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim3/WAE_MMD/OrganoidDataset/train.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim3/BetaVAE/CafDataset/test.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim3/BetaVAE/CafDataset/val.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim3/BetaVAE/CafDataset/train.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim3/BetaVAE/ChallengeDataset/test.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim3/BetaVAE/ChallengeDataset/val.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim3/BetaVAE/ChallengeDataset/train.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim3/BetaVAE/OrganoidDataset/test.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim3/BetaVAE/OrganoidDataset/val.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim3/BetaVAE/OrganoidDataset/train.csv']"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "bench_dir = \"/data/PycharmProjects/cytof_benchmark/results/latent_data/\"\n",
    "latent_files = glob.glob(bench_dir + \"*/*/*/*.csv\")\n",
    "latent_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "split   dim              model           dataset  \\\n0      dim2            BetaVAE        CafDataset   \n1      dim2            BetaVAE  ChallengeDataset   \n2      dim2            BetaVAE   OrganoidDataset   \n3      dim2           DBetaVAE        CafDataset   \n4      dim2           DBetaVAE  ChallengeDataset   \n5      dim2           DBetaVAE   OrganoidDataset   \n6      dim2  HyperSphericalVAE        CafDataset   \n7      dim2  HyperSphericalVAE  ChallengeDataset   \n8      dim2  HyperSphericalVAE   OrganoidDataset   \n9      dim2            WAE_MMD        CafDataset   \n10     dim2            WAE_MMD  ChallengeDataset   \n11     dim2            WAE_MMD   OrganoidDataset   \n12     dim3            BetaVAE        CafDataset   \n13     dim3            BetaVAE  ChallengeDataset   \n14     dim3            BetaVAE   OrganoidDataset   \n15     dim3           DBetaVAE        CafDataset   \n16     dim3           DBetaVAE  ChallengeDataset   \n17     dim3           DBetaVAE   OrganoidDataset   \n18     dim3  HyperSphericalVAE        CafDataset   \n19     dim3  HyperSphericalVAE  ChallengeDataset   \n20     dim3  HyperSphericalVAE   OrganoidDataset   \n21     dim3            WAE_MMD        CafDataset   \n22     dim3            WAE_MMD  ChallengeDataset   \n23     dim3            WAE_MMD   OrganoidDataset   \n24     dim5            BetaVAE        CafDataset   \n25     dim5            BetaVAE  ChallengeDataset   \n26     dim5            BetaVAE   OrganoidDataset   \n27     dim5           DBetaVAE        CafDataset   \n28     dim5           DBetaVAE  ChallengeDataset   \n29     dim5           DBetaVAE   OrganoidDataset   \n30     dim5  HyperSphericalVAE        CafDataset   \n31     dim5  HyperSphericalVAE  ChallengeDataset   \n32     dim5  HyperSphericalVAE   OrganoidDataset   \n33     dim5            WAE_MMD        CafDataset   \n34     dim5            WAE_MMD  ChallengeDataset   \n35     dim5            WAE_MMD   OrganoidDataset   \n\nsplit                                               test  \\\n0      /data/PycharmProjects/cytof_benchmark/results/...   \n1      /data/PycharmProjects/cytof_benchmark/results/...   \n2      /data/PycharmProjects/cytof_benchmark/results/...   \n3      /data/PycharmProjects/cytof_benchmark/results/...   \n4      /data/PycharmProjects/cytof_benchmark/results/...   \n5      /data/PycharmProjects/cytof_benchmark/results/...   \n6      /data/PycharmProjects/cytof_benchmark/results/...   \n7      /data/PycharmProjects/cytof_benchmark/results/...   \n8      /data/PycharmProjects/cytof_benchmark/results/...   \n9      /data/PycharmProjects/cytof_benchmark/results/...   \n10     /data/PycharmProjects/cytof_benchmark/results/...   \n11     /data/PycharmProjects/cytof_benchmark/results/...   \n12     /data/PycharmProjects/cytof_benchmark/results/...   \n13     /data/PycharmProjects/cytof_benchmark/results/...   \n14     /data/PycharmProjects/cytof_benchmark/results/...   \n15     /data/PycharmProjects/cytof_benchmark/results/...   \n16     /data/PycharmProjects/cytof_benchmark/results/...   \n17     /data/PycharmProjects/cytof_benchmark/results/...   \n18     /data/PycharmProjects/cytof_benchmark/results/...   \n19     /data/PycharmProjects/cytof_benchmark/results/...   \n20     /data/PycharmProjects/cytof_benchmark/results/...   \n21     /data/PycharmProjects/cytof_benchmark/results/...   \n22     /data/PycharmProjects/cytof_benchmark/results/...   \n23     /data/PycharmProjects/cytof_benchmark/results/...   \n24     /data/PycharmProjects/cytof_benchmark/results/...   \n25     /data/PycharmProjects/cytof_benchmark/results/...   \n26     /data/PycharmProjects/cytof_benchmark/results/...   \n27     /data/PycharmProjects/cytof_benchmark/results/...   \n28     /data/PycharmProjects/cytof_benchmark/results/...   \n29     /data/PycharmProjects/cytof_benchmark/results/...   \n30     /data/PycharmProjects/cytof_benchmark/results/...   \n31     /data/PycharmProjects/cytof_benchmark/results/...   \n32     /data/PycharmProjects/cytof_benchmark/results/...   \n33     /data/PycharmProjects/cytof_benchmark/results/...   \n34     /data/PycharmProjects/cytof_benchmark/results/...   \n35     /data/PycharmProjects/cytof_benchmark/results/...   \n\nsplit                                              train  \\\n0      /data/PycharmProjects/cytof_benchmark/results/...   \n1      /data/PycharmProjects/cytof_benchmark/results/...   \n2      /data/PycharmProjects/cytof_benchmark/results/...   \n3      /data/PycharmProjects/cytof_benchmark/results/...   \n4      /data/PycharmProjects/cytof_benchmark/results/...   \n5      /data/PycharmProjects/cytof_benchmark/results/...   \n6      /data/PycharmProjects/cytof_benchmark/results/...   \n7      /data/PycharmProjects/cytof_benchmark/results/...   \n8      /data/PycharmProjects/cytof_benchmark/results/...   \n9      /data/PycharmProjects/cytof_benchmark/results/...   \n10     /data/PycharmProjects/cytof_benchmark/results/...   \n11     /data/PycharmProjects/cytof_benchmark/results/...   \n12     /data/PycharmProjects/cytof_benchmark/results/...   \n13     /data/PycharmProjects/cytof_benchmark/results/...   \n14     /data/PycharmProjects/cytof_benchmark/results/...   \n15     /data/PycharmProjects/cytof_benchmark/results/...   \n16     /data/PycharmProjects/cytof_benchmark/results/...   \n17     /data/PycharmProjects/cytof_benchmark/results/...   \n18     /data/PycharmProjects/cytof_benchmark/results/...   \n19     /data/PycharmProjects/cytof_benchmark/results/...   \n20     /data/PycharmProjects/cytof_benchmark/results/...   \n21     /data/PycharmProjects/cytof_benchmark/results/...   \n22     /data/PycharmProjects/cytof_benchmark/results/...   \n23     /data/PycharmProjects/cytof_benchmark/results/...   \n24     /data/PycharmProjects/cytof_benchmark/results/...   \n25     /data/PycharmProjects/cytof_benchmark/results/...   \n26     /data/PycharmProjects/cytof_benchmark/results/...   \n27     /data/PycharmProjects/cytof_benchmark/results/...   \n28     /data/PycharmProjects/cytof_benchmark/results/...   \n29     /data/PycharmProjects/cytof_benchmark/results/...   \n30     /data/PycharmProjects/cytof_benchmark/results/...   \n31     /data/PycharmProjects/cytof_benchmark/results/...   \n32     /data/PycharmProjects/cytof_benchmark/results/...   \n33     /data/PycharmProjects/cytof_benchmark/results/...   \n34     /data/PycharmProjects/cytof_benchmark/results/...   \n35     /data/PycharmProjects/cytof_benchmark/results/...   \n\nsplit                                                val  \n0      /data/PycharmProjects/cytof_benchmark/results/...  \n1      /data/PycharmProjects/cytof_benchmark/results/...  \n2      /data/PycharmProjects/cytof_benchmark/results/...  \n3      /data/PycharmProjects/cytof_benchmark/results/...  \n4      /data/PycharmProjects/cytof_benchmark/results/...  \n5      /data/PycharmProjects/cytof_benchmark/results/...  \n6      /data/PycharmProjects/cytof_benchmark/results/...  \n7      /data/PycharmProjects/cytof_benchmark/results/...  \n8      /data/PycharmProjects/cytof_benchmark/results/...  \n9      /data/PycharmProjects/cytof_benchmark/results/...  \n10     /data/PycharmProjects/cytof_benchmark/results/...  \n11     /data/PycharmProjects/cytof_benchmark/results/...  \n12     /data/PycharmProjects/cytof_benchmark/results/...  \n13     /data/PycharmProjects/cytof_benchmark/results/...  \n14     /data/PycharmProjects/cytof_benchmark/results/...  \n15     /data/PycharmProjects/cytof_benchmark/results/...  \n16     /data/PycharmProjects/cytof_benchmark/results/...  \n17     /data/PycharmProjects/cytof_benchmark/results/...  \n18     /data/PycharmProjects/cytof_benchmark/results/...  \n19     /data/PycharmProjects/cytof_benchmark/results/...  \n20     /data/PycharmProjects/cytof_benchmark/results/...  \n21     /data/PycharmProjects/cytof_benchmark/results/...  \n22     /data/PycharmProjects/cytof_benchmark/results/...  \n23     /data/PycharmProjects/cytof_benchmark/results/...  \n24     /data/PycharmProjects/cytof_benchmark/results/...  \n25     /data/PycharmProjects/cytof_benchmark/results/...  \n26     /data/PycharmProjects/cytof_benchmark/results/...  \n27     /data/PycharmProjects/cytof_benchmark/results/...  \n28     /data/PycharmProjects/cytof_benchmark/results/...  \n29     /data/PycharmProjects/cytof_benchmark/results/...  \n30     /data/PycharmProjects/cytof_benchmark/results/...  \n31     /data/PycharmProjects/cytof_benchmark/results/...  \n32     /data/PycharmProjects/cytof_benchmark/results/...  \n33     /data/PycharmProjects/cytof_benchmark/results/...  \n34     /data/PycharmProjects/cytof_benchmark/results/...  \n35     /data/PycharmProjects/cytof_benchmark/results/...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>split</th>\n      <th>dim</th>\n      <th>model</th>\n      <th>dataset</th>\n      <th>test</th>\n      <th>train</th>\n      <th>val</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dim2</td>\n      <td>BetaVAE</td>\n      <td>CafDataset</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dim2</td>\n      <td>BetaVAE</td>\n      <td>ChallengeDataset</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>dim2</td>\n      <td>BetaVAE</td>\n      <td>OrganoidDataset</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>dim2</td>\n      <td>DBetaVAE</td>\n      <td>CafDataset</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>dim2</td>\n      <td>DBetaVAE</td>\n      <td>ChallengeDataset</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>dim2</td>\n      <td>DBetaVAE</td>\n      <td>OrganoidDataset</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>dim2</td>\n      <td>HyperSphericalVAE</td>\n      <td>CafDataset</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>dim2</td>\n      <td>HyperSphericalVAE</td>\n      <td>ChallengeDataset</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>dim2</td>\n      <td>HyperSphericalVAE</td>\n      <td>OrganoidDataset</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>dim2</td>\n      <td>WAE_MMD</td>\n      <td>CafDataset</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>dim2</td>\n      <td>WAE_MMD</td>\n      <td>ChallengeDataset</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>dim2</td>\n      <td>WAE_MMD</td>\n      <td>OrganoidDataset</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>dim3</td>\n      <td>BetaVAE</td>\n      <td>CafDataset</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>dim3</td>\n      <td>BetaVAE</td>\n      <td>ChallengeDataset</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>dim3</td>\n      <td>BetaVAE</td>\n      <td>OrganoidDataset</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>dim3</td>\n      <td>DBetaVAE</td>\n      <td>CafDataset</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>dim3</td>\n      <td>DBetaVAE</td>\n      <td>ChallengeDataset</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>dim3</td>\n      <td>DBetaVAE</td>\n      <td>OrganoidDataset</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>dim3</td>\n      <td>HyperSphericalVAE</td>\n      <td>CafDataset</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>dim3</td>\n      <td>HyperSphericalVAE</td>\n      <td>ChallengeDataset</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>dim3</td>\n      <td>HyperSphericalVAE</td>\n      <td>OrganoidDataset</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>dim3</td>\n      <td>WAE_MMD</td>\n      <td>CafDataset</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>dim3</td>\n      <td>WAE_MMD</td>\n      <td>ChallengeDataset</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>dim3</td>\n      <td>WAE_MMD</td>\n      <td>OrganoidDataset</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>dim5</td>\n      <td>BetaVAE</td>\n      <td>CafDataset</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>dim5</td>\n      <td>BetaVAE</td>\n      <td>ChallengeDataset</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>dim5</td>\n      <td>BetaVAE</td>\n      <td>OrganoidDataset</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>dim5</td>\n      <td>DBetaVAE</td>\n      <td>CafDataset</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>dim5</td>\n      <td>DBetaVAE</td>\n      <td>ChallengeDataset</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>dim5</td>\n      <td>DBetaVAE</td>\n      <td>OrganoidDataset</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>dim5</td>\n      <td>HyperSphericalVAE</td>\n      <td>CafDataset</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>dim5</td>\n      <td>HyperSphericalVAE</td>\n      <td>ChallengeDataset</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>dim5</td>\n      <td>HyperSphericalVAE</td>\n      <td>OrganoidDataset</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>dim5</td>\n      <td>WAE_MMD</td>\n      <td>CafDataset</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>dim5</td>\n      <td>WAE_MMD</td>\n      <td>ChallengeDataset</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>dim5</td>\n      <td>WAE_MMD</td>\n      <td>OrganoidDataset</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "latent_list = list()\n",
    "for latent_file in latent_files:\n",
    "    split = latent_file.split('/')[-1].removesuffix('.csv')\n",
    "    dataset_name = latent_file.split('/')[-2]\n",
    "    model_name = latent_file.split('/')[-3]\n",
    "    dim = latent_file.split('/')[-4]\n",
    "    latent_list.append((dim,model_name,dataset_name,split,latent_file))\n",
    "\n",
    "latent_data =  pd.pivot(\n",
    "    pd.DataFrame(latent_list,columns=['dim','model','dataset','split','file']),\n",
    "    index=['dim','model','dataset'],\n",
    "    columns='split',\n",
    "    values='file'\n",
    ").reset_index()\n",
    "latent_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "['dim2',\n 'BetaVAE',\n 'CafDataset',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim2/BetaVAE/CafDataset/test.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim2/BetaVAE/CafDataset/train.csv',\n '/data/PycharmProjects/cytof_benchmark/results/latent_data/dim2/BetaVAE/CafDataset/val.csv']"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(list(latent_data.iterrows())[0][1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import sys\n",
    "if \"..\" not in sys.path:\n",
    "    sys.path.insert(0, \"..\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "dataset_dirs = {\n",
    "    'OrganoidDataset':'/data/PycharmProjects/cytof_benchmark/data/organoids',\n",
    "    'CafDataset':'/data/PycharmProjects/cytof_benchmark/data/caf',\n",
    "    'ChallengeDataset':'/data/PycharmProjects/cytof_benchmark/data/breast_cancer_challenge',\n",
    "}\n",
    "\n",
    "variables = {\n",
    "    'OrganoidDataset':['cell_type','day'],\n",
    "    'CafDataset':['Patient','Culture','Treatment','Cell_type','Batch'],\n",
    "    'ChallengeDataset':['treatment','cell_line'],\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "split   dim              model          dataset  \\\n20     dim3  HyperSphericalVAE  OrganoidDataset   \n\nsplit                                               test  \\\n20     /data/PycharmProjects/cytof_benchmark/results/...   \n\nsplit                                              train  \\\n20     /data/PycharmProjects/cytof_benchmark/results/...   \n\nsplit                                                val  \n20     /data/PycharmProjects/cytof_benchmark/results/...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>split</th>\n      <th>dim</th>\n      <th>model</th>\n      <th>dataset</th>\n      <th>test</th>\n      <th>train</th>\n      <th>val</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>20</th>\n      <td>dim3</td>\n      <td>HyperSphericalVAE</td>\n      <td>OrganoidDataset</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n      <td>/data/PycharmProjects/cytof_benchmark/results/...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_data.iloc[20:21,:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017394 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.853404\n",
      "[LightGBM] [Info] Start training from score -2.123202\n",
      "[LightGBM] [Info] Start training from score -2.391862\n",
      "[LightGBM] [Info] Start training from score -2.719639\n",
      "[LightGBM] [Info] Start training from score -2.078311\n",
      "[LightGBM] [Info] Start training from score -2.161447\n",
      "[LightGBM] [Info] Start training from score -2.497610\n",
      "[LightGBM] [Info] Start training from score -2.232530\n",
      "[LightGBM] [Info] Start training from score -2.689447\n",
      "[LightGBM] [Info] Start training from score -2.680407\n",
      "[1]\tvalid_0's multi_logloss: 1.90161\n",
      "[2]\tvalid_0's multi_logloss: 1.72186\n",
      "[3]\tvalid_0's multi_logloss: 1.59654\n",
      "[4]\tvalid_0's multi_logloss: 1.50166\n",
      "[5]\tvalid_0's multi_logloss: 1.42664\n",
      "[6]\tvalid_0's multi_logloss: 1.36697\n",
      "[7]\tvalid_0's multi_logloss: 1.3177\n",
      "[8]\tvalid_0's multi_logloss: 1.2766\n",
      "[9]\tvalid_0's multi_logloss: 1.24267\n",
      "[10]\tvalid_0's multi_logloss: 1.21405\n",
      "[11]\tvalid_0's multi_logloss: 1.18943\n",
      "[12]\tvalid_0's multi_logloss: 1.16919\n",
      "[13]\tvalid_0's multi_logloss: 1.15126\n",
      "[14]\tvalid_0's multi_logloss: 1.13606\n",
      "[15]\tvalid_0's multi_logloss: 1.12241\n",
      "[16]\tvalid_0's multi_logloss: 1.11098\n",
      "[17]\tvalid_0's multi_logloss: 1.10042\n",
      "[18]\tvalid_0's multi_logloss: 1.09068\n",
      "[19]\tvalid_0's multi_logloss: 1.08269\n",
      "[20]\tvalid_0's multi_logloss: 1.07545\n",
      "[21]\tvalid_0's multi_logloss: 1.06846\n",
      "[22]\tvalid_0's multi_logloss: 1.0626\n",
      "[23]\tvalid_0's multi_logloss: 1.05744\n",
      "[24]\tvalid_0's multi_logloss: 1.05218\n",
      "[25]\tvalid_0's multi_logloss: 1.04756\n",
      "[26]\tvalid_0's multi_logloss: 1.04313\n",
      "[27]\tvalid_0's multi_logloss: 1.03946\n",
      "[28]\tvalid_0's multi_logloss: 1.03602\n",
      "[29]\tvalid_0's multi_logloss: 1.03284\n",
      "[30]\tvalid_0's multi_logloss: 1.02935\n",
      "[31]\tvalid_0's multi_logloss: 1.02658\n",
      "[32]\tvalid_0's multi_logloss: 1.02376\n",
      "[33]\tvalid_0's multi_logloss: 1.0211\n",
      "[34]\tvalid_0's multi_logloss: 1.01873\n",
      "[35]\tvalid_0's multi_logloss: 1.01643\n",
      "[36]\tvalid_0's multi_logloss: 1.01444\n",
      "[37]\tvalid_0's multi_logloss: 1.01226\n",
      "[38]\tvalid_0's multi_logloss: 1.01022\n",
      "[39]\tvalid_0's multi_logloss: 1.00832\n",
      "[40]\tvalid_0's multi_logloss: 1.00659\n",
      "[41]\tvalid_0's multi_logloss: 1.0046\n",
      "[42]\tvalid_0's multi_logloss: 1.00313\n",
      "[43]\tvalid_0's multi_logloss: 1.00145\n",
      "[44]\tvalid_0's multi_logloss: 0.999935\n",
      "[45]\tvalid_0's multi_logloss: 0.998537\n",
      "[46]\tvalid_0's multi_logloss: 0.997197\n",
      "[47]\tvalid_0's multi_logloss: 0.995928\n",
      "[48]\tvalid_0's multi_logloss: 0.994563\n",
      "[49]\tvalid_0's multi_logloss: 0.993411\n",
      "[50]\tvalid_0's multi_logloss: 0.992187\n",
      "[51]\tvalid_0's multi_logloss: 0.991186\n",
      "[52]\tvalid_0's multi_logloss: 0.989729\n",
      "[53]\tvalid_0's multi_logloss: 0.988704\n",
      "[54]\tvalid_0's multi_logloss: 0.987865\n",
      "[55]\tvalid_0's multi_logloss: 0.986648\n",
      "[56]\tvalid_0's multi_logloss: 0.985544\n",
      "[57]\tvalid_0's multi_logloss: 0.984696\n",
      "[58]\tvalid_0's multi_logloss: 0.983679\n",
      "[59]\tvalid_0's multi_logloss: 0.982556\n",
      "[60]\tvalid_0's multi_logloss: 0.981539\n",
      "[61]\tvalid_0's multi_logloss: 0.980512\n",
      "[62]\tvalid_0's multi_logloss: 0.979511\n",
      "[63]\tvalid_0's multi_logloss: 0.978546\n",
      "[64]\tvalid_0's multi_logloss: 0.977461\n",
      "[65]\tvalid_0's multi_logloss: 0.976626\n",
      "[66]\tvalid_0's multi_logloss: 0.975537\n",
      "[67]\tvalid_0's multi_logloss: 0.974628\n",
      "[68]\tvalid_0's multi_logloss: 0.973974\n",
      "[69]\tvalid_0's multi_logloss: 0.973228\n",
      "[70]\tvalid_0's multi_logloss: 0.972285\n",
      "[71]\tvalid_0's multi_logloss: 0.97159\n",
      "[72]\tvalid_0's multi_logloss: 0.970878\n",
      "[73]\tvalid_0's multi_logloss: 0.970174\n",
      "[74]\tvalid_0's multi_logloss: 0.969432\n",
      "[75]\tvalid_0's multi_logloss: 0.968904\n",
      "[76]\tvalid_0's multi_logloss: 0.968005\n",
      "[77]\tvalid_0's multi_logloss: 0.967354\n",
      "[78]\tvalid_0's multi_logloss: 0.966631\n",
      "[79]\tvalid_0's multi_logloss: 0.966017\n",
      "[80]\tvalid_0's multi_logloss: 0.965287\n",
      "[81]\tvalid_0's multi_logloss: 0.964694\n",
      "[82]\tvalid_0's multi_logloss: 0.964006\n",
      "[83]\tvalid_0's multi_logloss: 0.963446\n",
      "[84]\tvalid_0's multi_logloss: 0.962924\n",
      "[85]\tvalid_0's multi_logloss: 0.962366\n",
      "[86]\tvalid_0's multi_logloss: 0.961887\n",
      "[87]\tvalid_0's multi_logloss: 0.961244\n",
      "[88]\tvalid_0's multi_logloss: 0.960731\n",
      "[89]\tvalid_0's multi_logloss: 0.960252\n",
      "[90]\tvalid_0's multi_logloss: 0.959697\n",
      "[91]\tvalid_0's multi_logloss: 0.95924\n",
      "[92]\tvalid_0's multi_logloss: 0.958695\n",
      "[93]\tvalid_0's multi_logloss: 0.958281\n",
      "[94]\tvalid_0's multi_logloss: 0.957839\n",
      "[95]\tvalid_0's multi_logloss: 0.957261\n",
      "[96]\tvalid_0's multi_logloss: 0.956677\n",
      "[97]\tvalid_0's multi_logloss: 0.956255\n",
      "[98]\tvalid_0's multi_logloss: 0.95569\n",
      "[99]\tvalid_0's multi_logloss: 0.955268\n",
      "[100]\tvalid_0's multi_logloss: 0.954755\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022921 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.047228\n",
      "[LightGBM] [Info] Start training from score -1.516216\n",
      "[LightGBM] [Info] Start training from score -0.845018\n",
      "[1]\tvalid_0's multi_logloss: 1.01029\n",
      "[2]\tvalid_0's multi_logloss: 0.966946\n",
      "[3]\tvalid_0's multi_logloss: 0.931018\n",
      "[4]\tvalid_0's multi_logloss: 0.90076\n",
      "[5]\tvalid_0's multi_logloss: 0.87474\n",
      "[6]\tvalid_0's multi_logloss: 0.852508\n",
      "[7]\tvalid_0's multi_logloss: 0.833375\n",
      "[8]\tvalid_0's multi_logloss: 0.816645\n",
      "[9]\tvalid_0's multi_logloss: 0.802024\n",
      "[10]\tvalid_0's multi_logloss: 0.789186\n",
      "[11]\tvalid_0's multi_logloss: 0.77779\n",
      "[12]\tvalid_0's multi_logloss: 0.767607\n",
      "[13]\tvalid_0's multi_logloss: 0.758463\n",
      "[14]\tvalid_0's multi_logloss: 0.750268\n",
      "[15]\tvalid_0's multi_logloss: 0.742927\n",
      "[16]\tvalid_0's multi_logloss: 0.736327\n",
      "[17]\tvalid_0's multi_logloss: 0.730289\n",
      "[18]\tvalid_0's multi_logloss: 0.724815\n",
      "[19]\tvalid_0's multi_logloss: 0.719774\n",
      "[20]\tvalid_0's multi_logloss: 0.715102\n",
      "[21]\tvalid_0's multi_logloss: 0.710754\n",
      "[22]\tvalid_0's multi_logloss: 0.70685\n",
      "[23]\tvalid_0's multi_logloss: 0.703295\n",
      "[24]\tvalid_0's multi_logloss: 0.699927\n",
      "[25]\tvalid_0's multi_logloss: 0.696853\n",
      "[26]\tvalid_0's multi_logloss: 0.694017\n",
      "[27]\tvalid_0's multi_logloss: 0.691404\n",
      "[28]\tvalid_0's multi_logloss: 0.688985\n",
      "[29]\tvalid_0's multi_logloss: 0.686797\n",
      "[30]\tvalid_0's multi_logloss: 0.684682\n",
      "[31]\tvalid_0's multi_logloss: 0.68276\n",
      "[32]\tvalid_0's multi_logloss: 0.680943\n",
      "[33]\tvalid_0's multi_logloss: 0.679271\n",
      "[34]\tvalid_0's multi_logloss: 0.677704\n",
      "[35]\tvalid_0's multi_logloss: 0.676252\n",
      "[36]\tvalid_0's multi_logloss: 0.674854\n",
      "[37]\tvalid_0's multi_logloss: 0.673582\n",
      "[38]\tvalid_0's multi_logloss: 0.672394\n",
      "[39]\tvalid_0's multi_logloss: 0.671274\n",
      "[40]\tvalid_0's multi_logloss: 0.670233\n",
      "[41]\tvalid_0's multi_logloss: 0.669215\n",
      "[42]\tvalid_0's multi_logloss: 0.668269\n",
      "[43]\tvalid_0's multi_logloss: 0.667396\n",
      "[44]\tvalid_0's multi_logloss: 0.666627\n",
      "[45]\tvalid_0's multi_logloss: 0.665831\n",
      "[46]\tvalid_0's multi_logloss: 0.665105\n",
      "[47]\tvalid_0's multi_logloss: 0.664446\n",
      "[48]\tvalid_0's multi_logloss: 0.663844\n",
      "[49]\tvalid_0's multi_logloss: 0.663297\n",
      "[50]\tvalid_0's multi_logloss: 0.662782\n",
      "[51]\tvalid_0's multi_logloss: 0.662262\n",
      "[52]\tvalid_0's multi_logloss: 0.661773\n",
      "[53]\tvalid_0's multi_logloss: 0.661322\n",
      "[54]\tvalid_0's multi_logloss: 0.660887\n",
      "[55]\tvalid_0's multi_logloss: 0.660478\n",
      "[56]\tvalid_0's multi_logloss: 0.66011\n",
      "[57]\tvalid_0's multi_logloss: 0.659733\n",
      "[58]\tvalid_0's multi_logloss: 0.659369\n",
      "[59]\tvalid_0's multi_logloss: 0.659052\n",
      "[60]\tvalid_0's multi_logloss: 0.658751\n",
      "[61]\tvalid_0's multi_logloss: 0.658442\n",
      "[62]\tvalid_0's multi_logloss: 0.65819\n",
      "[63]\tvalid_0's multi_logloss: 0.657863\n",
      "[64]\tvalid_0's multi_logloss: 0.657613\n",
      "[65]\tvalid_0's multi_logloss: 0.657382\n",
      "[66]\tvalid_0's multi_logloss: 0.65716\n",
      "[67]\tvalid_0's multi_logloss: 0.656912\n",
      "[68]\tvalid_0's multi_logloss: 0.656691\n",
      "[69]\tvalid_0's multi_logloss: 0.656471\n",
      "[70]\tvalid_0's multi_logloss: 0.656263\n",
      "[71]\tvalid_0's multi_logloss: 0.656096\n",
      "[72]\tvalid_0's multi_logloss: 0.655916\n",
      "[73]\tvalid_0's multi_logloss: 0.655767\n",
      "[74]\tvalid_0's multi_logloss: 0.655605\n",
      "[75]\tvalid_0's multi_logloss: 0.655464\n",
      "[76]\tvalid_0's multi_logloss: 0.655307\n",
      "[77]\tvalid_0's multi_logloss: 0.655202\n",
      "[78]\tvalid_0's multi_logloss: 0.655078\n",
      "[79]\tvalid_0's multi_logloss: 0.654918\n",
      "[80]\tvalid_0's multi_logloss: 0.654786\n",
      "[81]\tvalid_0's multi_logloss: 0.654648\n",
      "[82]\tvalid_0's multi_logloss: 0.654506\n",
      "[83]\tvalid_0's multi_logloss: 0.654363\n",
      "[84]\tvalid_0's multi_logloss: 0.65424\n",
      "[85]\tvalid_0's multi_logloss: 0.654143\n",
      "[86]\tvalid_0's multi_logloss: 0.653985\n",
      "[87]\tvalid_0's multi_logloss: 0.653878\n",
      "[88]\tvalid_0's multi_logloss: 0.65376\n",
      "[89]\tvalid_0's multi_logloss: 0.65367\n",
      "[90]\tvalid_0's multi_logloss: 0.653584\n",
      "[91]\tvalid_0's multi_logloss: 0.653451\n",
      "[92]\tvalid_0's multi_logloss: 0.653344\n",
      "[93]\tvalid_0's multi_logloss: 0.653268\n",
      "[94]\tvalid_0's multi_logloss: 0.653192\n",
      "[95]\tvalid_0's multi_logloss: 0.653121\n",
      "[96]\tvalid_0's multi_logloss: 0.653063\n",
      "[97]\tvalid_0's multi_logloss: 0.652997\n",
      "[98]\tvalid_0's multi_logloss: 0.652891\n",
      "[99]\tvalid_0's multi_logloss: 0.652803\n",
      "[100]\tvalid_0's multi_logloss: 0.652716\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017267 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -3.244539\n",
      "[LightGBM] [Info] Start training from score -3.224920\n",
      "[LightGBM] [Info] Start training from score -3.369880\n",
      "[LightGBM] [Info] Start training from score -3.326941\n",
      "[LightGBM] [Info] Start training from score -3.378266\n",
      "[LightGBM] [Info] Start training from score -2.568017\n",
      "[LightGBM] [Info] Start training from score -1.914747\n",
      "[LightGBM] [Info] Start training from score -3.469579\n",
      "[LightGBM] [Info] Start training from score -1.919436\n",
      "[LightGBM] [Info] Start training from score -2.291576\n",
      "[LightGBM] [Info] Start training from score -2.007538\n",
      "[LightGBM] [Info] Start training from score -3.402200\n",
      "[LightGBM] [Info] Start training from score -3.212376\n",
      "[LightGBM] [Info] Start training from score -2.244521\n",
      "[1]\tvalid_0's multi_logloss: 2.39482\n",
      "[2]\tvalid_0's multi_logloss: 2.35392\n",
      "[3]\tvalid_0's multi_logloss: 2.32187\n",
      "[4]\tvalid_0's multi_logloss: 2.29657\n",
      "[5]\tvalid_0's multi_logloss: 2.27531\n",
      "[6]\tvalid_0's multi_logloss: 2.25785\n",
      "[7]\tvalid_0's multi_logloss: 2.2427\n",
      "[8]\tvalid_0's multi_logloss: 2.22958\n",
      "[9]\tvalid_0's multi_logloss: 2.21811\n",
      "[10]\tvalid_0's multi_logloss: 2.20821\n",
      "[11]\tvalid_0's multi_logloss: 2.19902\n",
      "[12]\tvalid_0's multi_logloss: 2.19128\n",
      "[13]\tvalid_0's multi_logloss: 2.18438\n",
      "[14]\tvalid_0's multi_logloss: 2.17829\n",
      "[15]\tvalid_0's multi_logloss: 2.17243\n",
      "[16]\tvalid_0's multi_logloss: 2.1673\n",
      "[17]\tvalid_0's multi_logloss: 2.16272\n",
      "[18]\tvalid_0's multi_logloss: 2.15834\n",
      "[19]\tvalid_0's multi_logloss: 2.15435\n",
      "[20]\tvalid_0's multi_logloss: 2.15076\n",
      "[21]\tvalid_0's multi_logloss: 2.14743\n",
      "[22]\tvalid_0's multi_logloss: 2.14443\n",
      "[23]\tvalid_0's multi_logloss: 2.14156\n",
      "[24]\tvalid_0's multi_logloss: 2.13919\n",
      "[25]\tvalid_0's multi_logloss: 2.13672\n",
      "[26]\tvalid_0's multi_logloss: 2.13454\n",
      "[27]\tvalid_0's multi_logloss: 2.13227\n",
      "[28]\tvalid_0's multi_logloss: 2.13027\n",
      "[29]\tvalid_0's multi_logloss: 2.12848\n",
      "[30]\tvalid_0's multi_logloss: 2.12676\n",
      "[31]\tvalid_0's multi_logloss: 2.12515\n",
      "[32]\tvalid_0's multi_logloss: 2.1234\n",
      "[33]\tvalid_0's multi_logloss: 2.12201\n",
      "[34]\tvalid_0's multi_logloss: 2.12075\n",
      "[35]\tvalid_0's multi_logloss: 2.11943\n",
      "[36]\tvalid_0's multi_logloss: 2.11821\n",
      "[37]\tvalid_0's multi_logloss: 2.1171\n",
      "[38]\tvalid_0's multi_logloss: 2.11596\n",
      "[39]\tvalid_0's multi_logloss: 2.11486\n",
      "[40]\tvalid_0's multi_logloss: 2.11366\n",
      "[41]\tvalid_0's multi_logloss: 2.11272\n",
      "[42]\tvalid_0's multi_logloss: 2.11187\n",
      "[43]\tvalid_0's multi_logloss: 2.11096\n",
      "[44]\tvalid_0's multi_logloss: 2.10999\n",
      "[45]\tvalid_0's multi_logloss: 2.109\n",
      "[46]\tvalid_0's multi_logloss: 2.10816\n",
      "[47]\tvalid_0's multi_logloss: 2.10737\n",
      "[48]\tvalid_0's multi_logloss: 2.10658\n",
      "[49]\tvalid_0's multi_logloss: 2.10579\n",
      "[50]\tvalid_0's multi_logloss: 2.10514\n",
      "[51]\tvalid_0's multi_logloss: 2.10448\n",
      "[52]\tvalid_0's multi_logloss: 2.10389\n",
      "[53]\tvalid_0's multi_logloss: 2.10326\n",
      "[54]\tvalid_0's multi_logloss: 2.10243\n",
      "[55]\tvalid_0's multi_logloss: 2.1018\n",
      "[56]\tvalid_0's multi_logloss: 2.10117\n",
      "[57]\tvalid_0's multi_logloss: 2.1006\n",
      "[58]\tvalid_0's multi_logloss: 2.09999\n",
      "[59]\tvalid_0's multi_logloss: 2.09935\n",
      "[60]\tvalid_0's multi_logloss: 2.09882\n",
      "[61]\tvalid_0's multi_logloss: 2.09825\n",
      "[62]\tvalid_0's multi_logloss: 2.09774\n",
      "[63]\tvalid_0's multi_logloss: 2.09722\n",
      "[64]\tvalid_0's multi_logloss: 2.09674\n",
      "[65]\tvalid_0's multi_logloss: 2.09619\n",
      "[66]\tvalid_0's multi_logloss: 2.09574\n",
      "[67]\tvalid_0's multi_logloss: 2.09518\n",
      "[68]\tvalid_0's multi_logloss: 2.09463\n",
      "[69]\tvalid_0's multi_logloss: 2.09414\n",
      "[70]\tvalid_0's multi_logloss: 2.09362\n",
      "[71]\tvalid_0's multi_logloss: 2.09326\n",
      "[72]\tvalid_0's multi_logloss: 2.09275\n",
      "[73]\tvalid_0's multi_logloss: 2.09233\n",
      "[74]\tvalid_0's multi_logloss: 2.09182\n",
      "[75]\tvalid_0's multi_logloss: 2.0914\n",
      "[76]\tvalid_0's multi_logloss: 2.09104\n",
      "[77]\tvalid_0's multi_logloss: 2.09062\n",
      "[78]\tvalid_0's multi_logloss: 2.09026\n",
      "[79]\tvalid_0's multi_logloss: 2.08988\n",
      "[80]\tvalid_0's multi_logloss: 2.08949\n",
      "[81]\tvalid_0's multi_logloss: 2.0891\n",
      "[82]\tvalid_0's multi_logloss: 2.0886\n",
      "[83]\tvalid_0's multi_logloss: 2.08823\n",
      "[84]\tvalid_0's multi_logloss: 2.0878\n",
      "[85]\tvalid_0's multi_logloss: 2.08732\n",
      "[86]\tvalid_0's multi_logloss: 2.08701\n",
      "[87]\tvalid_0's multi_logloss: 2.08664\n",
      "[88]\tvalid_0's multi_logloss: 2.08633\n",
      "[89]\tvalid_0's multi_logloss: 2.08604\n",
      "[90]\tvalid_0's multi_logloss: 2.08574\n",
      "[91]\tvalid_0's multi_logloss: 2.08539\n",
      "[92]\tvalid_0's multi_logloss: 2.08509\n",
      "[93]\tvalid_0's multi_logloss: 2.08476\n",
      "[94]\tvalid_0's multi_logloss: 2.08448\n",
      "[95]\tvalid_0's multi_logloss: 2.08416\n",
      "[96]\tvalid_0's multi_logloss: 2.08385\n",
      "[97]\tvalid_0's multi_logloss: 2.08362\n",
      "[98]\tvalid_0's multi_logloss: 2.08331\n",
      "[99]\tvalid_0's multi_logloss: 2.08306\n",
      "[100]\tvalid_0's multi_logloss: 2.08276\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022904 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -0.501622\n",
      "[LightGBM] [Info] Start training from score -0.930257\n",
      "[1]\tvalid_0's multi_logloss: 0.576149\n",
      "[2]\tvalid_0's multi_logloss: 0.499999\n",
      "[3]\tvalid_0's multi_logloss: 0.437158\n",
      "[4]\tvalid_0's multi_logloss: 0.384362\n",
      "[5]\tvalid_0's multi_logloss: 0.339404\n",
      "[6]\tvalid_0's multi_logloss: 0.300721\n",
      "[7]\tvalid_0's multi_logloss: 0.267271\n",
      "[8]\tvalid_0's multi_logloss: 0.238139\n",
      "[9]\tvalid_0's multi_logloss: 0.212626\n",
      "[10]\tvalid_0's multi_logloss: 0.190189\n",
      "[11]\tvalid_0's multi_logloss: 0.170371\n",
      "[12]\tvalid_0's multi_logloss: 0.152812\n",
      "[13]\tvalid_0's multi_logloss: 0.137217\n",
      "[14]\tvalid_0's multi_logloss: 0.123341\n",
      "[15]\tvalid_0's multi_logloss: 0.110973\n",
      "[16]\tvalid_0's multi_logloss: 0.099919\n",
      "[17]\tvalid_0's multi_logloss: 0.0900456\n",
      "[18]\tvalid_0's multi_logloss: 0.0812137\n",
      "[19]\tvalid_0's multi_logloss: 0.0733002\n",
      "[20]\tvalid_0's multi_logloss: 0.0661937\n",
      "[21]\tvalid_0's multi_logloss: 0.0598129\n",
      "[22]\tvalid_0's multi_logloss: 0.0540534\n",
      "[23]\tvalid_0's multi_logloss: 0.0488927\n",
      "[24]\tvalid_0's multi_logloss: 0.044256\n",
      "[25]\tvalid_0's multi_logloss: 0.0400733\n",
      "[26]\tvalid_0's multi_logloss: 0.0363122\n",
      "[27]\tvalid_0's multi_logloss: 0.0329068\n",
      "[28]\tvalid_0's multi_logloss: 0.0298307\n",
      "[29]\tvalid_0's multi_logloss: 0.0270717\n",
      "[30]\tvalid_0's multi_logloss: 0.0245824\n",
      "[31]\tvalid_0's multi_logloss: 0.0223349\n",
      "[32]\tvalid_0's multi_logloss: 0.0203068\n",
      "[33]\tvalid_0's multi_logloss: 0.0184792\n",
      "[34]\tvalid_0's multi_logloss: 0.0168226\n",
      "[35]\tvalid_0's multi_logloss: 0.015323\n",
      "[36]\tvalid_0's multi_logloss: 0.0139724\n",
      "[37]\tvalid_0's multi_logloss: 0.0127506\n",
      "[38]\tvalid_0's multi_logloss: 0.0116497\n",
      "[39]\tvalid_0's multi_logloss: 0.0106534\n",
      "[40]\tvalid_0's multi_logloss: 0.00975742\n",
      "[41]\tvalid_0's multi_logloss: 0.00894758\n",
      "[42]\tvalid_0's multi_logloss: 0.0082128\n",
      "[43]\tvalid_0's multi_logloss: 0.00755216\n",
      "[44]\tvalid_0's multi_logloss: 0.00695707\n",
      "[45]\tvalid_0's multi_logloss: 0.00641726\n",
      "[46]\tvalid_0's multi_logloss: 0.00591318\n",
      "[47]\tvalid_0's multi_logloss: 0.00547206\n",
      "[48]\tvalid_0's multi_logloss: 0.00507318\n",
      "[49]\tvalid_0's multi_logloss: 0.00471183\n",
      "[50]\tvalid_0's multi_logloss: 0.00438557\n",
      "[51]\tvalid_0's multi_logloss: 0.00409339\n",
      "[52]\tvalid_0's multi_logloss: 0.00382764\n",
      "[53]\tvalid_0's multi_logloss: 0.00358784\n",
      "[54]\tvalid_0's multi_logloss: 0.0033722\n",
      "[55]\tvalid_0's multi_logloss: 0.00317651\n",
      "[56]\tvalid_0's multi_logloss: 0.00300124\n",
      "[57]\tvalid_0's multi_logloss: 0.00283872\n",
      "[58]\tvalid_0's multi_logloss: 0.00269558\n",
      "[59]\tvalid_0's multi_logloss: 0.00256616\n",
      "[60]\tvalid_0's multi_logloss: 0.0024475\n",
      "[61]\tvalid_0's multi_logloss: 0.00234086\n",
      "[62]\tvalid_0's multi_logloss: 0.0022456\n",
      "[63]\tvalid_0's multi_logloss: 0.0021586\n",
      "[64]\tvalid_0's multi_logloss: 0.00208062\n",
      "[65]\tvalid_0's multi_logloss: 0.00203065\n",
      "[66]\tvalid_0's multi_logloss: 0.00196596\n",
      "[67]\tvalid_0's multi_logloss: 0.00190837\n",
      "[68]\tvalid_0's multi_logloss: 0.00185624\n",
      "[69]\tvalid_0's multi_logloss: 0.00180927\n",
      "[70]\tvalid_0's multi_logloss: 0.00176701\n",
      "[71]\tvalid_0's multi_logloss: 0.00172906\n",
      "[72]\tvalid_0's multi_logloss: 0.00169517\n",
      "[73]\tvalid_0's multi_logloss: 0.00164524\n",
      "[74]\tvalid_0's multi_logloss: 0.00161751\n",
      "[75]\tvalid_0's multi_logloss: 0.00159257\n",
      "[76]\tvalid_0's multi_logloss: 0.00157041\n",
      "[77]\tvalid_0's multi_logloss: 0.00154983\n",
      "[78]\tvalid_0's multi_logloss: 0.00153145\n",
      "[79]\tvalid_0's multi_logloss: 0.00154569\n",
      "[80]\tvalid_0's multi_logloss: 0.00150071\n",
      "[81]\tvalid_0's multi_logloss: 0.0014872\n",
      "[82]\tvalid_0's multi_logloss: 0.00147511\n",
      "[83]\tvalid_0's multi_logloss: 0.00146285\n",
      "[84]\tvalid_0's multi_logloss: 0.00145271\n",
      "[85]\tvalid_0's multi_logloss: 0.00144459\n",
      "[86]\tvalid_0's multi_logloss: 0.00143629\n",
      "[87]\tvalid_0's multi_logloss: 0.00142761\n",
      "[88]\tvalid_0's multi_logloss: 0.00142211\n",
      "[89]\tvalid_0's multi_logloss: 0.00141585\n",
      "[90]\tvalid_0's multi_logloss: 0.00141041\n",
      "[91]\tvalid_0's multi_logloss: 0.00140508\n",
      "[92]\tvalid_0's multi_logloss: 0.00140021\n",
      "[93]\tvalid_0's multi_logloss: 0.00139569\n",
      "[94]\tvalid_0's multi_logloss: 0.00146956\n",
      "[95]\tvalid_0's multi_logloss: 0.00139495\n",
      "[96]\tvalid_0's multi_logloss: 0.00139091\n",
      "[97]\tvalid_0's multi_logloss: 0.00138741\n",
      "[98]\tvalid_0's multi_logloss: 0.00138354\n",
      "[99]\tvalid_0's multi_logloss: 0.00138039\n",
      "[100]\tvalid_0's multi_logloss: 0.00137752\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -0.141837\n",
      "[LightGBM] [Info] Start training from score -2.023158\n",
      "[1]\tvalid_0's multi_logloss: 0.351085\n",
      "[2]\tvalid_0's multi_logloss: 0.326752\n",
      "[3]\tvalid_0's multi_logloss: 0.3082\n",
      "[4]\tvalid_0's multi_logloss: 0.293362\n",
      "[5]\tvalid_0's multi_logloss: 0.28133\n",
      "[6]\tvalid_0's multi_logloss: 0.271287\n",
      "[7]\tvalid_0's multi_logloss: 0.262325\n",
      "[8]\tvalid_0's multi_logloss: 0.255183\n",
      "[9]\tvalid_0's multi_logloss: 0.248541\n",
      "[10]\tvalid_0's multi_logloss: 0.242998\n",
      "[11]\tvalid_0's multi_logloss: 0.237912\n",
      "[12]\tvalid_0's multi_logloss: 0.233471\n",
      "[13]\tvalid_0's multi_logloss: 0.229461\n",
      "[14]\tvalid_0's multi_logloss: 0.225981\n",
      "[15]\tvalid_0's multi_logloss: 0.222655\n",
      "[16]\tvalid_0's multi_logloss: 0.220009\n",
      "[17]\tvalid_0's multi_logloss: 0.217328\n",
      "[18]\tvalid_0's multi_logloss: 0.215249\n",
      "[19]\tvalid_0's multi_logloss: 0.213065\n",
      "[20]\tvalid_0's multi_logloss: 0.211194\n",
      "[21]\tvalid_0's multi_logloss: 0.209587\n",
      "[22]\tvalid_0's multi_logloss: 0.208012\n",
      "[23]\tvalid_0's multi_logloss: 0.206736\n",
      "[24]\tvalid_0's multi_logloss: 0.205277\n",
      "[25]\tvalid_0's multi_logloss: 0.203769\n",
      "[26]\tvalid_0's multi_logloss: 0.202599\n",
      "[27]\tvalid_0's multi_logloss: 0.201533\n",
      "[28]\tvalid_0's multi_logloss: 0.200378\n",
      "[29]\tvalid_0's multi_logloss: 0.199306\n",
      "[30]\tvalid_0's multi_logloss: 0.198386\n",
      "[31]\tvalid_0's multi_logloss: 0.197639\n",
      "[32]\tvalid_0's multi_logloss: 0.196588\n",
      "[33]\tvalid_0's multi_logloss: 0.195797\n",
      "[34]\tvalid_0's multi_logloss: 0.195011\n",
      "[35]\tvalid_0's multi_logloss: 0.194372\n",
      "[36]\tvalid_0's multi_logloss: 0.193939\n",
      "[37]\tvalid_0's multi_logloss: 0.193438\n",
      "[38]\tvalid_0's multi_logloss: 0.192981\n",
      "[39]\tvalid_0's multi_logloss: 0.192247\n",
      "[40]\tvalid_0's multi_logloss: 0.191664\n",
      "[41]\tvalid_0's multi_logloss: 0.191117\n",
      "[42]\tvalid_0's multi_logloss: 0.190723\n",
      "[43]\tvalid_0's multi_logloss: 0.190251\n",
      "[44]\tvalid_0's multi_logloss: 0.189833\n",
      "[45]\tvalid_0's multi_logloss: 0.189413\n",
      "[46]\tvalid_0's multi_logloss: 0.188828\n",
      "[47]\tvalid_0's multi_logloss: 0.188413\n",
      "[48]\tvalid_0's multi_logloss: 0.188098\n",
      "[49]\tvalid_0's multi_logloss: 0.187668\n",
      "[50]\tvalid_0's multi_logloss: 0.187426\n",
      "[51]\tvalid_0's multi_logloss: 0.186982\n",
      "[52]\tvalid_0's multi_logloss: 0.186644\n",
      "[53]\tvalid_0's multi_logloss: 0.186436\n",
      "[54]\tvalid_0's multi_logloss: 0.186055\n",
      "[55]\tvalid_0's multi_logloss: 0.185794\n",
      "[56]\tvalid_0's multi_logloss: 0.185505\n",
      "[57]\tvalid_0's multi_logloss: 0.185251\n",
      "[58]\tvalid_0's multi_logloss: 0.185108\n",
      "[59]\tvalid_0's multi_logloss: 0.184799\n",
      "[60]\tvalid_0's multi_logloss: 0.184614\n",
      "[61]\tvalid_0's multi_logloss: 0.184275\n",
      "[62]\tvalid_0's multi_logloss: 0.183883\n",
      "[63]\tvalid_0's multi_logloss: 0.183856\n",
      "[64]\tvalid_0's multi_logloss: 0.183617\n",
      "[65]\tvalid_0's multi_logloss: 0.18333\n",
      "[66]\tvalid_0's multi_logloss: 0.183023\n",
      "[67]\tvalid_0's multi_logloss: 0.18289\n",
      "[68]\tvalid_0's multi_logloss: 0.182779\n",
      "[69]\tvalid_0's multi_logloss: 0.182521\n",
      "[70]\tvalid_0's multi_logloss: 0.182224\n",
      "[71]\tvalid_0's multi_logloss: 0.182055\n",
      "[72]\tvalid_0's multi_logloss: 0.181953\n",
      "[73]\tvalid_0's multi_logloss: 0.181682\n",
      "[74]\tvalid_0's multi_logloss: 0.18153\n",
      "[75]\tvalid_0's multi_logloss: 0.181276\n",
      "[76]\tvalid_0's multi_logloss: 0.181248\n",
      "[77]\tvalid_0's multi_logloss: 0.181142\n",
      "[78]\tvalid_0's multi_logloss: 0.180951\n",
      "[79]\tvalid_0's multi_logloss: 0.180889\n",
      "[80]\tvalid_0's multi_logloss: 0.180776\n",
      "[81]\tvalid_0's multi_logloss: 0.180548\n",
      "[82]\tvalid_0's multi_logloss: 0.180475\n",
      "[83]\tvalid_0's multi_logloss: 0.180368\n",
      "[84]\tvalid_0's multi_logloss: 0.180096\n",
      "[85]\tvalid_0's multi_logloss: 0.179967\n",
      "[86]\tvalid_0's multi_logloss: 0.179822\n",
      "[87]\tvalid_0's multi_logloss: 0.179572\n",
      "[88]\tvalid_0's multi_logloss: 0.179503\n",
      "[89]\tvalid_0's multi_logloss: 0.179256\n",
      "[90]\tvalid_0's multi_logloss: 0.179202\n",
      "[91]\tvalid_0's multi_logloss: 0.179023\n",
      "[92]\tvalid_0's multi_logloss: 0.178913\n",
      "[93]\tvalid_0's multi_logloss: 0.178628\n",
      "[94]\tvalid_0's multi_logloss: 0.178572\n",
      "[95]\tvalid_0's multi_logloss: 0.178391\n",
      "[96]\tvalid_0's multi_logloss: 0.178331\n",
      "[97]\tvalid_0's multi_logloss: 0.178131\n",
      "[98]\tvalid_0's multi_logloss: 0.177925\n",
      "[99]\tvalid_0's multi_logloss: 0.177774\n",
      "[100]\tvalid_0's multi_logloss: 0.177654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [04:36, 276.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007582 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 7715638, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.249550\n",
      "[LightGBM] [Info] Start training from score -3.165534\n",
      "[LightGBM] [Info] Start training from score -1.726403\n",
      "[LightGBM] [Info] Start training from score -1.902421\n",
      "[LightGBM] [Info] Start training from score -1.667720\n",
      "[LightGBM] [Info] Start training from score -1.861961\n",
      "[1]\tvalid_0's multi_logloss: 1.6754\n",
      "[2]\tvalid_0's multi_logloss: 1.66695\n",
      "[3]\tvalid_0's multi_logloss: 1.66015\n",
      "[4]\tvalid_0's multi_logloss: 1.65463\n",
      "[5]\tvalid_0's multi_logloss: 1.65002\n",
      "[6]\tvalid_0's multi_logloss: 1.64624\n",
      "[7]\tvalid_0's multi_logloss: 1.64302\n",
      "[8]\tvalid_0's multi_logloss: 1.64037\n",
      "[9]\tvalid_0's multi_logloss: 1.63794\n",
      "[10]\tvalid_0's multi_logloss: 1.63598\n",
      "[11]\tvalid_0's multi_logloss: 1.6341\n",
      "[12]\tvalid_0's multi_logloss: 1.63255\n",
      "[13]\tvalid_0's multi_logloss: 1.63115\n",
      "[14]\tvalid_0's multi_logloss: 1.62995\n",
      "[15]\tvalid_0's multi_logloss: 1.62883\n",
      "[16]\tvalid_0's multi_logloss: 1.62788\n",
      "[17]\tvalid_0's multi_logloss: 1.62696\n",
      "[18]\tvalid_0's multi_logloss: 1.62621\n",
      "[19]\tvalid_0's multi_logloss: 1.62539\n",
      "[20]\tvalid_0's multi_logloss: 1.62468\n",
      "[21]\tvalid_0's multi_logloss: 1.624\n",
      "[22]\tvalid_0's multi_logloss: 1.62346\n",
      "[23]\tvalid_0's multi_logloss: 1.62279\n",
      "[24]\tvalid_0's multi_logloss: 1.62229\n",
      "[25]\tvalid_0's multi_logloss: 1.62171\n",
      "[26]\tvalid_0's multi_logloss: 1.62134\n",
      "[27]\tvalid_0's multi_logloss: 1.62087\n",
      "[28]\tvalid_0's multi_logloss: 1.62039\n",
      "[29]\tvalid_0's multi_logloss: 1.61998\n",
      "[30]\tvalid_0's multi_logloss: 1.61964\n",
      "[31]\tvalid_0's multi_logloss: 1.61926\n",
      "[32]\tvalid_0's multi_logloss: 1.61895\n",
      "[33]\tvalid_0's multi_logloss: 1.61867\n",
      "[34]\tvalid_0's multi_logloss: 1.61834\n",
      "[35]\tvalid_0's multi_logloss: 1.6181\n",
      "[36]\tvalid_0's multi_logloss: 1.61778\n",
      "[37]\tvalid_0's multi_logloss: 1.61756\n",
      "[38]\tvalid_0's multi_logloss: 1.61729\n",
      "[39]\tvalid_0's multi_logloss: 1.61703\n",
      "[40]\tvalid_0's multi_logloss: 1.61684\n",
      "[41]\tvalid_0's multi_logloss: 1.61657\n",
      "[42]\tvalid_0's multi_logloss: 1.61638\n",
      "[43]\tvalid_0's multi_logloss: 1.61616\n",
      "[44]\tvalid_0's multi_logloss: 1.61599\n",
      "[45]\tvalid_0's multi_logloss: 1.61578\n",
      "[46]\tvalid_0's multi_logloss: 1.6156\n",
      "[47]\tvalid_0's multi_logloss: 1.61533\n",
      "[48]\tvalid_0's multi_logloss: 1.61508\n",
      "[49]\tvalid_0's multi_logloss: 1.61492\n",
      "[50]\tvalid_0's multi_logloss: 1.61481\n",
      "[51]\tvalid_0's multi_logloss: 1.61463\n",
      "[52]\tvalid_0's multi_logloss: 1.61446\n",
      "[53]\tvalid_0's multi_logloss: 1.61431\n",
      "[54]\tvalid_0's multi_logloss: 1.61416\n",
      "[55]\tvalid_0's multi_logloss: 1.61404\n",
      "[56]\tvalid_0's multi_logloss: 1.61395\n",
      "[57]\tvalid_0's multi_logloss: 1.6138\n",
      "[58]\tvalid_0's multi_logloss: 1.61368\n",
      "[59]\tvalid_0's multi_logloss: 1.61353\n",
      "[60]\tvalid_0's multi_logloss: 1.61341\n",
      "[61]\tvalid_0's multi_logloss: 1.61328\n",
      "[62]\tvalid_0's multi_logloss: 1.61318\n",
      "[63]\tvalid_0's multi_logloss: 1.61308\n",
      "[64]\tvalid_0's multi_logloss: 1.61296\n",
      "[65]\tvalid_0's multi_logloss: 1.61285\n",
      "[66]\tvalid_0's multi_logloss: 1.61275\n",
      "[67]\tvalid_0's multi_logloss: 1.61261\n",
      "[68]\tvalid_0's multi_logloss: 1.61253\n",
      "[69]\tvalid_0's multi_logloss: 1.61244\n",
      "[70]\tvalid_0's multi_logloss: 1.61229\n",
      "[71]\tvalid_0's multi_logloss: 1.61218\n",
      "[72]\tvalid_0's multi_logloss: 1.61205\n",
      "[73]\tvalid_0's multi_logloss: 1.61195\n",
      "[74]\tvalid_0's multi_logloss: 1.6119\n",
      "[75]\tvalid_0's multi_logloss: 1.61181\n",
      "[76]\tvalid_0's multi_logloss: 1.61172\n",
      "[77]\tvalid_0's multi_logloss: 1.61161\n",
      "[78]\tvalid_0's multi_logloss: 1.61152\n",
      "[79]\tvalid_0's multi_logloss: 1.61144\n",
      "[80]\tvalid_0's multi_logloss: 1.61136\n",
      "[81]\tvalid_0's multi_logloss: 1.61129\n",
      "[82]\tvalid_0's multi_logloss: 1.61116\n",
      "[83]\tvalid_0's multi_logloss: 1.61109\n",
      "[84]\tvalid_0's multi_logloss: 1.61104\n",
      "[85]\tvalid_0's multi_logloss: 1.61094\n",
      "[86]\tvalid_0's multi_logloss: 1.61085\n",
      "[87]\tvalid_0's multi_logloss: 1.61079\n",
      "[88]\tvalid_0's multi_logloss: 1.61073\n",
      "[89]\tvalid_0's multi_logloss: 1.61065\n",
      "[90]\tvalid_0's multi_logloss: 1.61056\n",
      "[91]\tvalid_0's multi_logloss: 1.61049\n",
      "[92]\tvalid_0's multi_logloss: 1.61045\n",
      "[93]\tvalid_0's multi_logloss: 1.61038\n",
      "[94]\tvalid_0's multi_logloss: 1.61032\n",
      "[95]\tvalid_0's multi_logloss: 1.61026\n",
      "[96]\tvalid_0's multi_logloss: 1.61019\n",
      "[97]\tvalid_0's multi_logloss: 1.61012\n",
      "[98]\tvalid_0's multi_logloss: 1.61007\n",
      "[99]\tvalid_0's multi_logloss: 1.61\n",
      "[100]\tvalid_0's multi_logloss: 1.60994\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 7715638, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -3.388563\n",
      "[LightGBM] [Info] Start training from score -3.286043\n",
      "[LightGBM] [Info] Start training from score -3.265766\n",
      "[LightGBM] [Info] Start training from score -3.814547\n",
      "[LightGBM] [Info] Start training from score -3.310265\n",
      "[LightGBM] [Info] Start training from score -3.206426\n",
      "[LightGBM] [Info] Start training from score -4.264605\n",
      "[LightGBM] [Info] Start training from score -3.385622\n",
      "[LightGBM] [Info] Start training from score -3.678169\n",
      "[LightGBM] [Info] Start training from score -3.401590\n",
      "[LightGBM] [Info] Start training from score -4.879144\n",
      "[LightGBM] [Info] Start training from score -3.027581\n",
      "[LightGBM] [Info] Start training from score -2.985319\n",
      "[LightGBM] [Info] Start training from score -3.251856\n",
      "[LightGBM] [Info] Start training from score -3.294527\n",
      "[LightGBM] [Info] Start training from score -3.372086\n",
      "[LightGBM] [Info] Start training from score -2.973489\n",
      "[LightGBM] [Info] Start training from score -2.489644\n",
      "[LightGBM] [Info] Start training from score -3.403357\n",
      "[LightGBM] [Info] Start training from score -4.161407\n",
      "[LightGBM] [Info] Start training from score -4.219942\n",
      "[LightGBM] [Info] Start training from score -3.454308\n",
      "[LightGBM] [Info] Start training from score -3.414970\n",
      "[LightGBM] [Info] Start training from score -3.160243\n",
      "[LightGBM] [Info] Start training from score -3.113230\n",
      "[LightGBM] [Info] Start training from score -3.209175\n",
      "[LightGBM] [Info] Start training from score -3.282600\n",
      "[LightGBM] [Info] Start training from score -3.180636\n",
      "[1]\tvalid_0's multi_logloss: 2.66345\n",
      "[2]\tvalid_0's multi_logloss: 2.5151\n",
      "[3]\tvalid_0's multi_logloss: 2.40038\n",
      "[4]\tvalid_0's multi_logloss: 2.31757\n",
      "[5]\tvalid_0's multi_logloss: 2.25473\n",
      "[6]\tvalid_0's multi_logloss: 2.22037\n",
      "[7]\tvalid_0's multi_logloss: 2.18535\n",
      "[8]\tvalid_0's multi_logloss: 2.14453\n",
      "[9]\tvalid_0's multi_logloss: 2.11696\n",
      "[10]\tvalid_0's multi_logloss: 2.07782\n",
      "[11]\tvalid_0's multi_logloss: 2.05727\n",
      "[12]\tvalid_0's multi_logloss: 2.03984\n",
      "[13]\tvalid_0's multi_logloss: 2.02506\n",
      "[14]\tvalid_0's multi_logloss: 2.01211\n",
      "[15]\tvalid_0's multi_logloss: 1.99962\n",
      "[16]\tvalid_0's multi_logloss: 1.9982\n",
      "[17]\tvalid_0's multi_logloss: 1.98329\n",
      "[18]\tvalid_0's multi_logloss: 1.98941\n",
      "[19]\tvalid_0's multi_logloss: 1.96522\n",
      "[20]\tvalid_0's multi_logloss: 1.96478\n",
      "[21]\tvalid_0's multi_logloss: 1.95349\n",
      "[22]\tvalid_0's multi_logloss: 1.95772\n",
      "[23]\tvalid_0's multi_logloss: 1.95323\n",
      "[24]\tvalid_0's multi_logloss: 1.94916\n",
      "[25]\tvalid_0's multi_logloss: 1.94541\n",
      "[26]\tvalid_0's multi_logloss: 1.94197\n",
      "[27]\tvalid_0's multi_logloss: 1.93896\n",
      "[28]\tvalid_0's multi_logloss: 1.93615\n",
      "[29]\tvalid_0's multi_logloss: 1.93298\n",
      "[30]\tvalid_0's multi_logloss: 1.92219\n",
      "[31]\tvalid_0's multi_logloss: 1.92119\n",
      "[32]\tvalid_0's multi_logloss: 1.91777\n",
      "[33]\tvalid_0's multi_logloss: 1.91619\n",
      "[34]\tvalid_0's multi_logloss: 1.9157\n",
      "[35]\tvalid_0's multi_logloss: 1.91478\n",
      "[36]\tvalid_0's multi_logloss: 1.91223\n",
      "[37]\tvalid_0's multi_logloss: 1.91151\n",
      "[38]\tvalid_0's multi_logloss: 1.90738\n",
      "[39]\tvalid_0's multi_logloss: 1.90592\n",
      "[40]\tvalid_0's multi_logloss: 1.90694\n",
      "[41]\tvalid_0's multi_logloss: 1.91938\n",
      "[42]\tvalid_0's multi_logloss: 1.9134\n",
      "[43]\tvalid_0's multi_logloss: 1.91553\n",
      "[44]\tvalid_0's multi_logloss: 1.91208\n",
      "[45]\tvalid_0's multi_logloss: 1.90473\n",
      "[46]\tvalid_0's multi_logloss: 1.90358\n",
      "[47]\tvalid_0's multi_logloss: 1.90508\n",
      "[48]\tvalid_0's multi_logloss: 1.902\n",
      "[49]\tvalid_0's multi_logloss: 1.90008\n",
      "[50]\tvalid_0's multi_logloss: 1.89999\n",
      "[51]\tvalid_0's multi_logloss: 1.90865\n",
      "[52]\tvalid_0's multi_logloss: 1.89469\n",
      "[53]\tvalid_0's multi_logloss: 1.89499\n",
      "[54]\tvalid_0's multi_logloss: 1.89525\n",
      "[55]\tvalid_0's multi_logloss: 1.89606\n",
      "[56]\tvalid_0's multi_logloss: 1.89494\n",
      "[57]\tvalid_0's multi_logloss: 1.89499\n",
      "[58]\tvalid_0's multi_logloss: 1.89405\n",
      "[59]\tvalid_0's multi_logloss: 1.89258\n",
      "[60]\tvalid_0's multi_logloss: 1.89441\n",
      "[61]\tvalid_0's multi_logloss: 1.8914\n",
      "[62]\tvalid_0's multi_logloss: 1.89345\n",
      "[63]\tvalid_0's multi_logloss: 1.89319\n",
      "[64]\tvalid_0's multi_logloss: 1.89442\n",
      "[65]\tvalid_0's multi_logloss: 1.89306\n",
      "[66]\tvalid_0's multi_logloss: 1.89379\n",
      "[67]\tvalid_0's multi_logloss: 1.89452\n",
      "[68]\tvalid_0's multi_logloss: 1.89493\n",
      "[69]\tvalid_0's multi_logloss: 1.89517\n",
      "[70]\tvalid_0's multi_logloss: 1.8946\n",
      "[71]\tvalid_0's multi_logloss: 1.89719\n",
      "[72]\tvalid_0's multi_logloss: 1.89851\n",
      "[73]\tvalid_0's multi_logloss: 1.8966\n",
      "[74]\tvalid_0's multi_logloss: 1.89864\n",
      "[75]\tvalid_0's multi_logloss: 1.8965\n",
      "[76]\tvalid_0's multi_logloss: 1.90108\n",
      "[77]\tvalid_0's multi_logloss: 1.9017\n",
      "[78]\tvalid_0's multi_logloss: 1.90833\n",
      "[79]\tvalid_0's multi_logloss: 1.91959\n",
      "[80]\tvalid_0's multi_logloss: 1.92332\n",
      "[81]\tvalid_0's multi_logloss: 1.92561\n",
      "[82]\tvalid_0's multi_logloss: 1.92491\n",
      "[83]\tvalid_0's multi_logloss: 1.92561\n",
      "[84]\tvalid_0's multi_logloss: 1.92642\n",
      "[85]\tvalid_0's multi_logloss: 1.92564\n",
      "[86]\tvalid_0's multi_logloss: 1.92858\n",
      "[87]\tvalid_0's multi_logloss: 1.93191\n",
      "[88]\tvalid_0's multi_logloss: 1.93852\n",
      "[89]\tvalid_0's multi_logloss: 1.94447\n",
      "[90]\tvalid_0's multi_logloss: 1.9523\n",
      "[91]\tvalid_0's multi_logloss: 1.9596\n",
      "[92]\tvalid_0's multi_logloss: 1.95263\n",
      "[93]\tvalid_0's multi_logloss: 1.95613\n",
      "[94]\tvalid_0's multi_logloss: 1.99063\n",
      "[95]\tvalid_0's multi_logloss: 2.00232\n",
      "[96]\tvalid_0's multi_logloss: 2.01132\n",
      "[97]\tvalid_0's multi_logloss: 2.00203\n",
      "[98]\tvalid_0's multi_logloss: 2.00683\n",
      "[99]\tvalid_0's multi_logloss: 2.00067\n",
      "[100]\tvalid_0's multi_logloss: 2.03223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [07:03, 200.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001127 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 820733, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -0.683185\n",
      "[LightGBM] [Info] Start training from score -2.382997\n",
      "[LightGBM] [Info] Start training from score -2.734975\n",
      "[LightGBM] [Info] Start training from score -3.826068\n",
      "[LightGBM] [Info] Start training from score -1.583719\n",
      "[LightGBM] [Info] Start training from score -2.199855\n",
      "[1]\tvalid_0's multi_logloss: 1.15125\n",
      "[2]\tvalid_0's multi_logloss: 1.03653\n",
      "[3]\tvalid_0's multi_logloss: 0.949619\n",
      "[4]\tvalid_0's multi_logloss: 0.880804\n",
      "[5]\tvalid_0's multi_logloss: 0.825627\n",
      "[6]\tvalid_0's multi_logloss: 0.780892\n",
      "[7]\tvalid_0's multi_logloss: 0.743461\n",
      "[8]\tvalid_0's multi_logloss: 0.712109\n",
      "[9]\tvalid_0's multi_logloss: 0.685693\n",
      "[10]\tvalid_0's multi_logloss: 0.663393\n",
      "[11]\tvalid_0's multi_logloss: 0.644203\n",
      "[12]\tvalid_0's multi_logloss: 0.627737\n",
      "[13]\tvalid_0's multi_logloss: 0.613393\n",
      "[14]\tvalid_0's multi_logloss: 0.601159\n",
      "[15]\tvalid_0's multi_logloss: 0.590398\n",
      "[16]\tvalid_0's multi_logloss: 0.581007\n",
      "[17]\tvalid_0's multi_logloss: 0.572647\n",
      "[18]\tvalid_0's multi_logloss: 0.565095\n",
      "[19]\tvalid_0's multi_logloss: 0.558584\n",
      "[20]\tvalid_0's multi_logloss: 0.552874\n",
      "[21]\tvalid_0's multi_logloss: 0.547677\n",
      "[22]\tvalid_0's multi_logloss: 0.543022\n",
      "[23]\tvalid_0's multi_logloss: 0.538717\n",
      "[24]\tvalid_0's multi_logloss: 0.534805\n",
      "[25]\tvalid_0's multi_logloss: 0.531113\n",
      "[26]\tvalid_0's multi_logloss: 0.528195\n",
      "[27]\tvalid_0's multi_logloss: 0.52528\n",
      "[28]\tvalid_0's multi_logloss: 0.52282\n",
      "[29]\tvalid_0's multi_logloss: 0.520539\n",
      "[30]\tvalid_0's multi_logloss: 0.518416\n",
      "[31]\tvalid_0's multi_logloss: 0.516244\n",
      "[32]\tvalid_0's multi_logloss: 0.514385\n",
      "[33]\tvalid_0's multi_logloss: 0.512657\n",
      "[34]\tvalid_0's multi_logloss: 0.511014\n",
      "[35]\tvalid_0's multi_logloss: 0.509696\n",
      "[36]\tvalid_0's multi_logloss: 0.508438\n",
      "[37]\tvalid_0's multi_logloss: 0.507219\n",
      "[38]\tvalid_0's multi_logloss: 0.506178\n",
      "[39]\tvalid_0's multi_logloss: 0.505241\n",
      "[40]\tvalid_0's multi_logloss: 0.504264\n",
      "[41]\tvalid_0's multi_logloss: 0.503261\n",
      "[42]\tvalid_0's multi_logloss: 0.503066\n",
      "[43]\tvalid_0's multi_logloss: 0.501452\n",
      "[44]\tvalid_0's multi_logloss: 0.501761\n",
      "[45]\tvalid_0's multi_logloss: 0.500158\n",
      "[46]\tvalid_0's multi_logloss: 0.499395\n",
      "[47]\tvalid_0's multi_logloss: 0.499614\n",
      "[48]\tvalid_0's multi_logloss: 0.497919\n",
      "[49]\tvalid_0's multi_logloss: 0.497941\n",
      "[50]\tvalid_0's multi_logloss: 0.496766\n",
      "[51]\tvalid_0's multi_logloss: 0.497009\n",
      "[52]\tvalid_0's multi_logloss: 0.496655\n",
      "[53]\tvalid_0's multi_logloss: 0.496984\n",
      "[54]\tvalid_0's multi_logloss: 0.496296\n",
      "[55]\tvalid_0's multi_logloss: 0.494478\n",
      "[56]\tvalid_0's multi_logloss: 0.493982\n",
      "[57]\tvalid_0's multi_logloss: 0.494885\n",
      "[58]\tvalid_0's multi_logloss: 0.496305\n",
      "[59]\tvalid_0's multi_logloss: 0.493052\n",
      "[60]\tvalid_0's multi_logloss: 0.494854\n",
      "[61]\tvalid_0's multi_logloss: 0.492559\n",
      "[62]\tvalid_0's multi_logloss: 0.494187\n",
      "[63]\tvalid_0's multi_logloss: 0.491853\n",
      "[64]\tvalid_0's multi_logloss: 0.491574\n",
      "[65]\tvalid_0's multi_logloss: 0.491209\n",
      "[66]\tvalid_0's multi_logloss: 0.490949\n",
      "[67]\tvalid_0's multi_logloss: 0.490875\n",
      "[68]\tvalid_0's multi_logloss: 0.490331\n",
      "[69]\tvalid_0's multi_logloss: 0.491865\n",
      "[70]\tvalid_0's multi_logloss: 0.491829\n",
      "[71]\tvalid_0's multi_logloss: 0.500095\n",
      "[72]\tvalid_0's multi_logloss: 0.498827\n",
      "[73]\tvalid_0's multi_logloss: 0.502189\n",
      "[74]\tvalid_0's multi_logloss: 0.494803\n",
      "[75]\tvalid_0's multi_logloss: 0.506804\n",
      "[76]\tvalid_0's multi_logloss: 0.491465\n",
      "[77]\tvalid_0's multi_logloss: 0.51144\n",
      "[78]\tvalid_0's multi_logloss: 0.507578\n",
      "[79]\tvalid_0's multi_logloss: 0.499833\n",
      "[80]\tvalid_0's multi_logloss: 0.51308\n",
      "[81]\tvalid_0's multi_logloss: 0.501008\n",
      "[82]\tvalid_0's multi_logloss: 0.513816\n",
      "[83]\tvalid_0's multi_logloss: 0.532117\n",
      "[84]\tvalid_0's multi_logloss: 0.505757\n",
      "[85]\tvalid_0's multi_logloss: 0.511934\n",
      "[86]\tvalid_0's multi_logloss: 0.504083\n",
      "[87]\tvalid_0's multi_logloss: 0.52987\n",
      "[88]\tvalid_0's multi_logloss: 0.526298\n",
      "[89]\tvalid_0's multi_logloss: 0.525835\n",
      "[90]\tvalid_0's multi_logloss: 0.576654\n",
      "[91]\tvalid_0's multi_logloss: 0.506155\n",
      "[92]\tvalid_0's multi_logloss: 0.530628\n",
      "[93]\tvalid_0's multi_logloss: 0.506347\n",
      "[94]\tvalid_0's multi_logloss: 0.533021\n",
      "[95]\tvalid_0's multi_logloss: 0.534533\n",
      "[96]\tvalid_0's multi_logloss: 0.520827\n",
      "[97]\tvalid_0's multi_logloss: 0.541637\n",
      "[98]\tvalid_0's multi_logloss: 0.525881\n",
      "[99]\tvalid_0's multi_logloss: 0.52768\n",
      "[100]\tvalid_0's multi_logloss: 0.545766\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001847 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 820733, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -2.163833\n",
      "[LightGBM] [Info] Start training from score -1.796397\n",
      "[LightGBM] [Info] Start training from score -1.843741\n",
      "[LightGBM] [Info] Start training from score -1.989576\n",
      "[LightGBM] [Info] Start training from score -1.941218\n",
      "[LightGBM] [Info] Start training from score -1.949016\n",
      "[LightGBM] [Info] Start training from score -1.978333\n",
      "[1]\tvalid_0's multi_logloss: 1.89669\n",
      "[2]\tvalid_0's multi_logloss: 1.86354\n",
      "[3]\tvalid_0's multi_logloss: 1.8371\n",
      "[4]\tvalid_0's multi_logloss: 1.81583\n",
      "[5]\tvalid_0's multi_logloss: 1.79848\n",
      "[6]\tvalid_0's multi_logloss: 1.78422\n",
      "[7]\tvalid_0's multi_logloss: 1.77242\n",
      "[8]\tvalid_0's multi_logloss: 1.76257\n",
      "[9]\tvalid_0's multi_logloss: 1.75426\n",
      "[10]\tvalid_0's multi_logloss: 1.7473\n",
      "[11]\tvalid_0's multi_logloss: 1.74144\n",
      "[12]\tvalid_0's multi_logloss: 1.73643\n",
      "[13]\tvalid_0's multi_logloss: 1.73216\n",
      "[14]\tvalid_0's multi_logloss: 1.72852\n",
      "[15]\tvalid_0's multi_logloss: 1.72536\n",
      "[16]\tvalid_0's multi_logloss: 1.72263\n",
      "[17]\tvalid_0's multi_logloss: 1.72026\n",
      "[18]\tvalid_0's multi_logloss: 1.71818\n",
      "[19]\tvalid_0's multi_logloss: 1.71643\n",
      "[20]\tvalid_0's multi_logloss: 1.71485\n",
      "[21]\tvalid_0's multi_logloss: 1.71346\n",
      "[22]\tvalid_0's multi_logloss: 1.71215\n",
      "[23]\tvalid_0's multi_logloss: 1.71106\n",
      "[24]\tvalid_0's multi_logloss: 1.71004\n",
      "[25]\tvalid_0's multi_logloss: 1.70914\n",
      "[26]\tvalid_0's multi_logloss: 1.70836\n",
      "[27]\tvalid_0's multi_logloss: 1.70762\n",
      "[28]\tvalid_0's multi_logloss: 1.70693\n",
      "[29]\tvalid_0's multi_logloss: 1.70632\n",
      "[30]\tvalid_0's multi_logloss: 1.7057\n",
      "[31]\tvalid_0's multi_logloss: 1.70516\n",
      "[32]\tvalid_0's multi_logloss: 1.70473\n",
      "[33]\tvalid_0's multi_logloss: 1.70429\n",
      "[34]\tvalid_0's multi_logloss: 1.70387\n",
      "[35]\tvalid_0's multi_logloss: 1.70342\n",
      "[36]\tvalid_0's multi_logloss: 1.70309\n",
      "[37]\tvalid_0's multi_logloss: 1.70269\n",
      "[38]\tvalid_0's multi_logloss: 1.70234\n",
      "[39]\tvalid_0's multi_logloss: 1.70196\n",
      "[40]\tvalid_0's multi_logloss: 1.70167\n",
      "[41]\tvalid_0's multi_logloss: 1.70144\n",
      "[42]\tvalid_0's multi_logloss: 1.70114\n",
      "[43]\tvalid_0's multi_logloss: 1.70091\n",
      "[44]\tvalid_0's multi_logloss: 1.70071\n",
      "[45]\tvalid_0's multi_logloss: 1.70049\n",
      "[46]\tvalid_0's multi_logloss: 1.70024\n",
      "[47]\tvalid_0's multi_logloss: 1.69998\n",
      "[48]\tvalid_0's multi_logloss: 1.69979\n",
      "[49]\tvalid_0's multi_logloss: 1.69961\n",
      "[50]\tvalid_0's multi_logloss: 1.6994\n",
      "[51]\tvalid_0's multi_logloss: 1.69923\n",
      "[52]\tvalid_0's multi_logloss: 1.69909\n",
      "[53]\tvalid_0's multi_logloss: 1.69893\n",
      "[54]\tvalid_0's multi_logloss: 1.6988\n",
      "[55]\tvalid_0's multi_logloss: 1.69866\n",
      "[56]\tvalid_0's multi_logloss: 1.69853\n",
      "[57]\tvalid_0's multi_logloss: 1.69835\n",
      "[58]\tvalid_0's multi_logloss: 1.69824\n",
      "[59]\tvalid_0's multi_logloss: 1.69808\n",
      "[60]\tvalid_0's multi_logloss: 1.69799\n",
      "[61]\tvalid_0's multi_logloss: 1.69784\n",
      "[62]\tvalid_0's multi_logloss: 1.69775\n",
      "[63]\tvalid_0's multi_logloss: 1.69763\n",
      "[64]\tvalid_0's multi_logloss: 1.69748\n",
      "[65]\tvalid_0's multi_logloss: 1.6974\n",
      "[66]\tvalid_0's multi_logloss: 1.69731\n",
      "[67]\tvalid_0's multi_logloss: 1.69721\n",
      "[68]\tvalid_0's multi_logloss: 1.69708\n",
      "[69]\tvalid_0's multi_logloss: 1.69696\n",
      "[70]\tvalid_0's multi_logloss: 1.69684\n",
      "[71]\tvalid_0's multi_logloss: 1.69677\n",
      "[72]\tvalid_0's multi_logloss: 1.69671\n",
      "[73]\tvalid_0's multi_logloss: 1.69656\n",
      "[74]\tvalid_0's multi_logloss: 1.69646\n",
      "[75]\tvalid_0's multi_logloss: 1.69641\n",
      "[76]\tvalid_0's multi_logloss: 1.6963\n",
      "[77]\tvalid_0's multi_logloss: 1.69621\n",
      "[78]\tvalid_0's multi_logloss: 1.69614\n",
      "[79]\tvalid_0's multi_logloss: 1.69607\n",
      "[80]\tvalid_0's multi_logloss: 1.69597\n",
      "[81]\tvalid_0's multi_logloss: 1.69589\n",
      "[82]\tvalid_0's multi_logloss: 1.69584\n",
      "[83]\tvalid_0's multi_logloss: 1.69579\n",
      "[84]\tvalid_0's multi_logloss: 1.69571\n",
      "[85]\tvalid_0's multi_logloss: 1.69564\n",
      "[86]\tvalid_0's multi_logloss: 1.69558\n",
      "[87]\tvalid_0's multi_logloss: 1.69553\n",
      "[88]\tvalid_0's multi_logloss: 1.6955\n",
      "[89]\tvalid_0's multi_logloss: 1.6954\n",
      "[90]\tvalid_0's multi_logloss: 1.69535\n",
      "[91]\tvalid_0's multi_logloss: 1.69527\n",
      "[92]\tvalid_0's multi_logloss: 1.69524\n",
      "[93]\tvalid_0's multi_logloss: 1.69517\n",
      "[94]\tvalid_0's multi_logloss: 1.69509\n",
      "[95]\tvalid_0's multi_logloss: 1.69502\n",
      "[96]\tvalid_0's multi_logloss: 1.69497\n",
      "[97]\tvalid_0's multi_logloss: 1.69494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [07:18, 115.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[98]\tvalid_0's multi_logloss: 1.69488\n",
      "[99]\tvalid_0's multi_logloss: 1.69483\n",
      "[100]\tvalid_0's multi_logloss: 1.69478\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017229 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.853404\n",
      "[LightGBM] [Info] Start training from score -2.123202\n",
      "[LightGBM] [Info] Start training from score -2.391862\n",
      "[LightGBM] [Info] Start training from score -2.719639\n",
      "[LightGBM] [Info] Start training from score -2.078311\n",
      "[LightGBM] [Info] Start training from score -2.161447\n",
      "[LightGBM] [Info] Start training from score -2.497610\n",
      "[LightGBM] [Info] Start training from score -2.232530\n",
      "[LightGBM] [Info] Start training from score -2.689447\n",
      "[LightGBM] [Info] Start training from score -2.680407\n",
      "[1]\tvalid_0's multi_logloss: 1.9447\n",
      "[2]\tvalid_0's multi_logloss: 1.78317\n",
      "[3]\tvalid_0's multi_logloss: 1.66849\n",
      "[4]\tvalid_0's multi_logloss: 1.58002\n",
      "[5]\tvalid_0's multi_logloss: 1.51015\n",
      "[6]\tvalid_0's multi_logloss: 1.4533\n",
      "[7]\tvalid_0's multi_logloss: 1.40563\n",
      "[8]\tvalid_0's multi_logloss: 1.36679\n",
      "[9]\tvalid_0's multi_logloss: 1.33136\n",
      "[10]\tvalid_0's multi_logloss: 1.30297\n",
      "[11]\tvalid_0's multi_logloss: 1.2781\n",
      "[12]\tvalid_0's multi_logloss: 1.25673\n",
      "[13]\tvalid_0's multi_logloss: 1.23767\n",
      "[14]\tvalid_0's multi_logloss: 1.22138\n",
      "[15]\tvalid_0's multi_logloss: 1.20686\n",
      "[16]\tvalid_0's multi_logloss: 1.19418\n",
      "[17]\tvalid_0's multi_logloss: 1.18359\n",
      "[18]\tvalid_0's multi_logloss: 1.17405\n",
      "[19]\tvalid_0's multi_logloss: 1.16533\n",
      "[20]\tvalid_0's multi_logloss: 1.15762\n",
      "[21]\tvalid_0's multi_logloss: 1.1501\n",
      "[22]\tvalid_0's multi_logloss: 1.14356\n",
      "[23]\tvalid_0's multi_logloss: 1.13748\n",
      "[24]\tvalid_0's multi_logloss: 1.13221\n",
      "[25]\tvalid_0's multi_logloss: 1.12736\n",
      "[26]\tvalid_0's multi_logloss: 1.12266\n",
      "[27]\tvalid_0's multi_logloss: 1.1183\n",
      "[28]\tvalid_0's multi_logloss: 1.11476\n",
      "[29]\tvalid_0's multi_logloss: 1.11087\n",
      "[30]\tvalid_0's multi_logloss: 1.10761\n",
      "[31]\tvalid_0's multi_logloss: 1.10416\n",
      "[32]\tvalid_0's multi_logloss: 1.10126\n",
      "[33]\tvalid_0's multi_logloss: 1.09851\n",
      "[34]\tvalid_0's multi_logloss: 1.09597\n",
      "[35]\tvalid_0's multi_logloss: 1.0931\n",
      "[36]\tvalid_0's multi_logloss: 1.09056\n",
      "[37]\tvalid_0's multi_logloss: 1.08828\n",
      "[38]\tvalid_0's multi_logloss: 1.08585\n",
      "[39]\tvalid_0's multi_logloss: 1.0839\n",
      "[40]\tvalid_0's multi_logloss: 1.08158\n",
      "[41]\tvalid_0's multi_logloss: 1.07986\n",
      "[42]\tvalid_0's multi_logloss: 1.07806\n",
      "[43]\tvalid_0's multi_logloss: 1.0764\n",
      "[44]\tvalid_0's multi_logloss: 1.07446\n",
      "[45]\tvalid_0's multi_logloss: 1.07279\n",
      "[46]\tvalid_0's multi_logloss: 1.07119\n",
      "[47]\tvalid_0's multi_logloss: 1.06956\n",
      "[48]\tvalid_0's multi_logloss: 1.06828\n",
      "[49]\tvalid_0's multi_logloss: 1.06712\n",
      "[50]\tvalid_0's multi_logloss: 1.06576\n",
      "[51]\tvalid_0's multi_logloss: 1.06419\n",
      "[52]\tvalid_0's multi_logloss: 1.06328\n",
      "[53]\tvalid_0's multi_logloss: 1.06215\n",
      "[54]\tvalid_0's multi_logloss: 1.06076\n",
      "[55]\tvalid_0's multi_logloss: 1.05946\n",
      "[56]\tvalid_0's multi_logloss: 1.05866\n",
      "[57]\tvalid_0's multi_logloss: 1.0575\n",
      "[58]\tvalid_0's multi_logloss: 1.05612\n",
      "[59]\tvalid_0's multi_logloss: 1.05528\n",
      "[60]\tvalid_0's multi_logloss: 1.05431\n",
      "[61]\tvalid_0's multi_logloss: 1.05336\n",
      "[62]\tvalid_0's multi_logloss: 1.05227\n",
      "[63]\tvalid_0's multi_logloss: 1.05144\n",
      "[64]\tvalid_0's multi_logloss: 1.05056\n",
      "[65]\tvalid_0's multi_logloss: 1.04962\n",
      "[66]\tvalid_0's multi_logloss: 1.04848\n",
      "[67]\tvalid_0's multi_logloss: 1.04746\n",
      "[68]\tvalid_0's multi_logloss: 1.04674\n",
      "[69]\tvalid_0's multi_logloss: 1.04562\n",
      "[70]\tvalid_0's multi_logloss: 1.04484\n",
      "[71]\tvalid_0's multi_logloss: 1.04406\n",
      "[72]\tvalid_0's multi_logloss: 1.04331\n",
      "[73]\tvalid_0's multi_logloss: 1.04236\n",
      "[74]\tvalid_0's multi_logloss: 1.04156\n",
      "[75]\tvalid_0's multi_logloss: 1.04109\n",
      "[76]\tvalid_0's multi_logloss: 1.04007\n",
      "[77]\tvalid_0's multi_logloss: 1.03933\n",
      "[78]\tvalid_0's multi_logloss: 1.0385\n",
      "[79]\tvalid_0's multi_logloss: 1.03744\n",
      "[80]\tvalid_0's multi_logloss: 1.03644\n",
      "[81]\tvalid_0's multi_logloss: 1.03553\n",
      "[82]\tvalid_0's multi_logloss: 1.03497\n",
      "[83]\tvalid_0's multi_logloss: 1.03439\n",
      "[84]\tvalid_0's multi_logloss: 1.03394\n",
      "[85]\tvalid_0's multi_logloss: 1.03289\n",
      "[86]\tvalid_0's multi_logloss: 1.03225\n",
      "[87]\tvalid_0's multi_logloss: 1.03158\n",
      "[88]\tvalid_0's multi_logloss: 1.03083\n",
      "[89]\tvalid_0's multi_logloss: 1.03009\n",
      "[90]\tvalid_0's multi_logloss: 1.02937\n",
      "[91]\tvalid_0's multi_logloss: 1.02851\n",
      "[92]\tvalid_0's multi_logloss: 1.02768\n",
      "[93]\tvalid_0's multi_logloss: 1.02692\n",
      "[94]\tvalid_0's multi_logloss: 1.02637\n",
      "[95]\tvalid_0's multi_logloss: 1.02554\n",
      "[96]\tvalid_0's multi_logloss: 1.02502\n",
      "[97]\tvalid_0's multi_logloss: 1.02446\n",
      "[98]\tvalid_0's multi_logloss: 1.02404\n",
      "[99]\tvalid_0's multi_logloss: 1.02349\n",
      "[100]\tvalid_0's multi_logloss: 1.02283\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017309 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.047228\n",
      "[LightGBM] [Info] Start training from score -1.516216\n",
      "[LightGBM] [Info] Start training from score -0.845018\n",
      "[1]\tvalid_0's multi_logloss: 1.00974\n",
      "[2]\tvalid_0's multi_logloss: 0.96607\n",
      "[3]\tvalid_0's multi_logloss: 0.929927\n",
      "[4]\tvalid_0's multi_logloss: 0.899502\n",
      "[5]\tvalid_0's multi_logloss: 0.873714\n",
      "[6]\tvalid_0's multi_logloss: 0.851631\n",
      "[7]\tvalid_0's multi_logloss: 0.8325\n",
      "[8]\tvalid_0's multi_logloss: 0.815966\n",
      "[9]\tvalid_0's multi_logloss: 0.801526\n",
      "[10]\tvalid_0's multi_logloss: 0.788737\n",
      "[11]\tvalid_0's multi_logloss: 0.777481\n",
      "[12]\tvalid_0's multi_logloss: 0.767478\n",
      "[13]\tvalid_0's multi_logloss: 0.758555\n",
      "[14]\tvalid_0's multi_logloss: 0.750475\n",
      "[15]\tvalid_0's multi_logloss: 0.743216\n",
      "[16]\tvalid_0's multi_logloss: 0.736705\n",
      "[17]\tvalid_0's multi_logloss: 0.730807\n",
      "[18]\tvalid_0's multi_logloss: 0.725435\n",
      "[19]\tvalid_0's multi_logloss: 0.720472\n",
      "[20]\tvalid_0's multi_logloss: 0.715985\n",
      "[21]\tvalid_0's multi_logloss: 0.711888\n",
      "[22]\tvalid_0's multi_logloss: 0.708101\n",
      "[23]\tvalid_0's multi_logloss: 0.704557\n",
      "[24]\tvalid_0's multi_logloss: 0.701372\n",
      "[25]\tvalid_0's multi_logloss: 0.698405\n",
      "[26]\tvalid_0's multi_logloss: 0.695712\n",
      "[27]\tvalid_0's multi_logloss: 0.693149\n",
      "[28]\tvalid_0's multi_logloss: 0.690818\n",
      "[29]\tvalid_0's multi_logloss: 0.688644\n",
      "[30]\tvalid_0's multi_logloss: 0.68663\n",
      "[31]\tvalid_0's multi_logloss: 0.684783\n",
      "[32]\tvalid_0's multi_logloss: 0.68306\n",
      "[33]\tvalid_0's multi_logloss: 0.681454\n",
      "[34]\tvalid_0's multi_logloss: 0.679943\n",
      "[35]\tvalid_0's multi_logloss: 0.678552\n",
      "[36]\tvalid_0's multi_logloss: 0.677249\n",
      "[37]\tvalid_0's multi_logloss: 0.676058\n",
      "[38]\tvalid_0's multi_logloss: 0.674917\n",
      "[39]\tvalid_0's multi_logloss: 0.673875\n",
      "[40]\tvalid_0's multi_logloss: 0.672752\n",
      "[41]\tvalid_0's multi_logloss: 0.671786\n",
      "[42]\tvalid_0's multi_logloss: 0.670868\n",
      "[43]\tvalid_0's multi_logloss: 0.670049\n",
      "[44]\tvalid_0's multi_logloss: 0.669296\n",
      "[45]\tvalid_0's multi_logloss: 0.668577\n",
      "[46]\tvalid_0's multi_logloss: 0.667928\n",
      "[47]\tvalid_0's multi_logloss: 0.667221\n",
      "[48]\tvalid_0's multi_logloss: 0.666587\n",
      "[49]\tvalid_0's multi_logloss: 0.665958\n",
      "[50]\tvalid_0's multi_logloss: 0.665442\n",
      "[51]\tvalid_0's multi_logloss: 0.664932\n",
      "[52]\tvalid_0's multi_logloss: 0.664494\n",
      "[53]\tvalid_0's multi_logloss: 0.66408\n",
      "[54]\tvalid_0's multi_logloss: 0.663658\n",
      "[55]\tvalid_0's multi_logloss: 0.663301\n",
      "[56]\tvalid_0's multi_logloss: 0.662945\n",
      "[57]\tvalid_0's multi_logloss: 0.662604\n",
      "[58]\tvalid_0's multi_logloss: 0.662282\n",
      "[59]\tvalid_0's multi_logloss: 0.661957\n",
      "[60]\tvalid_0's multi_logloss: 0.661609\n",
      "[61]\tvalid_0's multi_logloss: 0.661264\n",
      "[62]\tvalid_0's multi_logloss: 0.661014\n",
      "[63]\tvalid_0's multi_logloss: 0.660781\n",
      "[64]\tvalid_0's multi_logloss: 0.660543\n",
      "[65]\tvalid_0's multi_logloss: 0.660319\n",
      "[66]\tvalid_0's multi_logloss: 0.660054\n",
      "[67]\tvalid_0's multi_logloss: 0.659826\n",
      "[68]\tvalid_0's multi_logloss: 0.659588\n",
      "[69]\tvalid_0's multi_logloss: 0.659424\n",
      "[70]\tvalid_0's multi_logloss: 0.659249\n",
      "[71]\tvalid_0's multi_logloss: 0.659106\n",
      "[72]\tvalid_0's multi_logloss: 0.658921\n",
      "[73]\tvalid_0's multi_logloss: 0.658771\n",
      "[74]\tvalid_0's multi_logloss: 0.658637\n",
      "[75]\tvalid_0's multi_logloss: 0.658492\n",
      "[76]\tvalid_0's multi_logloss: 0.658313\n",
      "[77]\tvalid_0's multi_logloss: 0.658176\n",
      "[78]\tvalid_0's multi_logloss: 0.658066\n",
      "[79]\tvalid_0's multi_logloss: 0.657975\n",
      "[80]\tvalid_0's multi_logloss: 0.657879\n",
      "[81]\tvalid_0's multi_logloss: 0.657804\n",
      "[82]\tvalid_0's multi_logloss: 0.657689\n",
      "[83]\tvalid_0's multi_logloss: 0.657613\n",
      "[84]\tvalid_0's multi_logloss: 0.657506\n",
      "[85]\tvalid_0's multi_logloss: 0.657393\n",
      "[86]\tvalid_0's multi_logloss: 0.657337\n",
      "[87]\tvalid_0's multi_logloss: 0.657253\n",
      "[88]\tvalid_0's multi_logloss: 0.657163\n",
      "[89]\tvalid_0's multi_logloss: 0.657071\n",
      "[90]\tvalid_0's multi_logloss: 0.656974\n",
      "[91]\tvalid_0's multi_logloss: 0.656894\n",
      "[92]\tvalid_0's multi_logloss: 0.656812\n",
      "[93]\tvalid_0's multi_logloss: 0.656726\n",
      "[94]\tvalid_0's multi_logloss: 0.656681\n",
      "[95]\tvalid_0's multi_logloss: 0.656618\n",
      "[96]\tvalid_0's multi_logloss: 0.656569\n",
      "[97]\tvalid_0's multi_logloss: 0.656522\n",
      "[98]\tvalid_0's multi_logloss: 0.656465\n",
      "[99]\tvalid_0's multi_logloss: 0.656404\n",
      "[100]\tvalid_0's multi_logloss: 0.656349\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -3.244539\n",
      "[LightGBM] [Info] Start training from score -3.224920\n",
      "[LightGBM] [Info] Start training from score -3.369880\n",
      "[LightGBM] [Info] Start training from score -3.326941\n",
      "[LightGBM] [Info] Start training from score -3.378266\n",
      "[LightGBM] [Info] Start training from score -2.568017\n",
      "[LightGBM] [Info] Start training from score -1.914747\n",
      "[LightGBM] [Info] Start training from score -3.469579\n",
      "[LightGBM] [Info] Start training from score -1.919436\n",
      "[LightGBM] [Info] Start training from score -2.291576\n",
      "[LightGBM] [Info] Start training from score -2.007538\n",
      "[LightGBM] [Info] Start training from score -3.402200\n",
      "[LightGBM] [Info] Start training from score -3.212376\n",
      "[LightGBM] [Info] Start training from score -2.244521\n",
      "[1]\tvalid_0's multi_logloss: 2.39726\n",
      "[2]\tvalid_0's multi_logloss: 2.35732\n",
      "[3]\tvalid_0's multi_logloss: 2.32607\n",
      "[4]\tvalid_0's multi_logloss: 2.30102\n",
      "[5]\tvalid_0's multi_logloss: 2.28085\n",
      "[6]\tvalid_0's multi_logloss: 2.26411\n",
      "[7]\tvalid_0's multi_logloss: 2.24988\n",
      "[8]\tvalid_0's multi_logloss: 2.23754\n",
      "[9]\tvalid_0's multi_logloss: 2.22682\n",
      "[10]\tvalid_0's multi_logloss: 2.21779\n",
      "[11]\tvalid_0's multi_logloss: 2.20992\n",
      "[12]\tvalid_0's multi_logloss: 2.20295\n",
      "[13]\tvalid_0's multi_logloss: 2.19687\n",
      "[14]\tvalid_0's multi_logloss: 2.19143\n",
      "[15]\tvalid_0's multi_logloss: 2.18665\n",
      "[16]\tvalid_0's multi_logloss: 2.18217\n",
      "[17]\tvalid_0's multi_logloss: 2.17837\n",
      "[18]\tvalid_0's multi_logloss: 2.17481\n",
      "[19]\tvalid_0's multi_logloss: 2.17133\n",
      "[20]\tvalid_0's multi_logloss: 2.16832\n",
      "[21]\tvalid_0's multi_logloss: 2.16551\n",
      "[22]\tvalid_0's multi_logloss: 2.16299\n",
      "[23]\tvalid_0's multi_logloss: 2.16018\n",
      "[24]\tvalid_0's multi_logloss: 2.15775\n",
      "[25]\tvalid_0's multi_logloss: 2.15551\n",
      "[26]\tvalid_0's multi_logloss: 2.15317\n",
      "[27]\tvalid_0's multi_logloss: 2.15121\n",
      "[28]\tvalid_0's multi_logloss: 2.14935\n",
      "[29]\tvalid_0's multi_logloss: 2.14769\n",
      "[30]\tvalid_0's multi_logloss: 2.14628\n",
      "[31]\tvalid_0's multi_logloss: 2.14478\n",
      "[32]\tvalid_0's multi_logloss: 2.14318\n",
      "[33]\tvalid_0's multi_logloss: 2.14175\n",
      "[34]\tvalid_0's multi_logloss: 2.14038\n",
      "[35]\tvalid_0's multi_logloss: 2.13925\n",
      "[36]\tvalid_0's multi_logloss: 2.13805\n",
      "[37]\tvalid_0's multi_logloss: 2.13686\n",
      "[38]\tvalid_0's multi_logloss: 2.1358\n",
      "[39]\tvalid_0's multi_logloss: 2.13491\n",
      "[40]\tvalid_0's multi_logloss: 2.13402\n",
      "[41]\tvalid_0's multi_logloss: 2.13319\n",
      "[42]\tvalid_0's multi_logloss: 2.13217\n",
      "[43]\tvalid_0's multi_logloss: 2.13141\n",
      "[44]\tvalid_0's multi_logloss: 2.13059\n",
      "[45]\tvalid_0's multi_logloss: 2.12974\n",
      "[46]\tvalid_0's multi_logloss: 2.12898\n",
      "[47]\tvalid_0's multi_logloss: 2.12832\n",
      "[48]\tvalid_0's multi_logloss: 2.1276\n",
      "[49]\tvalid_0's multi_logloss: 2.12676\n",
      "[50]\tvalid_0's multi_logloss: 2.12605\n",
      "[51]\tvalid_0's multi_logloss: 2.1253\n",
      "[52]\tvalid_0's multi_logloss: 2.12467\n",
      "[53]\tvalid_0's multi_logloss: 2.12395\n",
      "[54]\tvalid_0's multi_logloss: 2.12335\n",
      "[55]\tvalid_0's multi_logloss: 2.12274\n",
      "[56]\tvalid_0's multi_logloss: 2.12207\n",
      "[57]\tvalid_0's multi_logloss: 2.12154\n",
      "[58]\tvalid_0's multi_logloss: 2.12086\n",
      "[59]\tvalid_0's multi_logloss: 2.12025\n",
      "[60]\tvalid_0's multi_logloss: 2.11969\n",
      "[61]\tvalid_0's multi_logloss: 2.11913\n",
      "[62]\tvalid_0's multi_logloss: 2.1187\n",
      "[63]\tvalid_0's multi_logloss: 2.11801\n",
      "[64]\tvalid_0's multi_logloss: 2.11757\n",
      "[65]\tvalid_0's multi_logloss: 2.1171\n",
      "[66]\tvalid_0's multi_logloss: 2.11662\n",
      "[67]\tvalid_0's multi_logloss: 2.11616\n",
      "[68]\tvalid_0's multi_logloss: 2.11559\n",
      "[69]\tvalid_0's multi_logloss: 2.11513\n",
      "[70]\tvalid_0's multi_logloss: 2.11459\n",
      "[71]\tvalid_0's multi_logloss: 2.11403\n",
      "[72]\tvalid_0's multi_logloss: 2.11359\n",
      "[73]\tvalid_0's multi_logloss: 2.11308\n",
      "[74]\tvalid_0's multi_logloss: 2.1126\n",
      "[75]\tvalid_0's multi_logloss: 2.11213\n",
      "[76]\tvalid_0's multi_logloss: 2.11164\n",
      "[77]\tvalid_0's multi_logloss: 2.11129\n",
      "[78]\tvalid_0's multi_logloss: 2.11088\n",
      "[79]\tvalid_0's multi_logloss: 2.1105\n",
      "[80]\tvalid_0's multi_logloss: 2.11008\n",
      "[81]\tvalid_0's multi_logloss: 2.10962\n",
      "[82]\tvalid_0's multi_logloss: 2.10914\n",
      "[83]\tvalid_0's multi_logloss: 2.10878\n",
      "[84]\tvalid_0's multi_logloss: 2.10848\n",
      "[85]\tvalid_0's multi_logloss: 2.10811\n",
      "[86]\tvalid_0's multi_logloss: 2.10776\n",
      "[87]\tvalid_0's multi_logloss: 2.10745\n",
      "[88]\tvalid_0's multi_logloss: 2.10706\n",
      "[89]\tvalid_0's multi_logloss: 2.10665\n",
      "[90]\tvalid_0's multi_logloss: 2.10634\n",
      "[91]\tvalid_0's multi_logloss: 2.10591\n",
      "[92]\tvalid_0's multi_logloss: 2.10555\n",
      "[93]\tvalid_0's multi_logloss: 2.10522\n",
      "[94]\tvalid_0's multi_logloss: 2.10494\n",
      "[95]\tvalid_0's multi_logloss: 2.10464\n",
      "[96]\tvalid_0's multi_logloss: 2.1043\n",
      "[97]\tvalid_0's multi_logloss: 2.10404\n",
      "[98]\tvalid_0's multi_logloss: 2.10378\n",
      "[99]\tvalid_0's multi_logloss: 2.10354\n",
      "[100]\tvalid_0's multi_logloss: 2.10326\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017672 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -0.501622\n",
      "[LightGBM] [Info] Start training from score -0.930257\n",
      "[1]\tvalid_0's multi_logloss: 0.575771\n",
      "[2]\tvalid_0's multi_logloss: 0.49937\n",
      "[3]\tvalid_0's multi_logloss: 0.436302\n",
      "[4]\tvalid_0's multi_logloss: 0.383324\n",
      "[5]\tvalid_0's multi_logloss: 0.338251\n",
      "[6]\tvalid_0's multi_logloss: 0.299527\n",
      "[7]\tvalid_0's multi_logloss: 0.266004\n",
      "[8]\tvalid_0's multi_logloss: 0.236803\n",
      "[9]\tvalid_0's multi_logloss: 0.211237\n",
      "[10]\tvalid_0's multi_logloss: 0.18876\n",
      "[11]\tvalid_0's multi_logloss: 0.168928\n",
      "[12]\tvalid_0's multi_logloss: 0.151377\n",
      "[13]\tvalid_0's multi_logloss: 0.135805\n",
      "[14]\tvalid_0's multi_logloss: 0.121957\n",
      "[15]\tvalid_0's multi_logloss: 0.109618\n",
      "[16]\tvalid_0's multi_logloss: 0.0986063\n",
      "[17]\tvalid_0's multi_logloss: 0.0887639\n",
      "[18]\tvalid_0's multi_logloss: 0.0799553\n",
      "[19]\tvalid_0's multi_logloss: 0.072063\n",
      "[20]\tvalid_0's multi_logloss: 0.0649845\n",
      "[21]\tvalid_0's multi_logloss: 0.0586303\n",
      "[22]\tvalid_0's multi_logloss: 0.0529217\n",
      "[23]\tvalid_0's multi_logloss: 0.0477897\n",
      "[24]\tvalid_0's multi_logloss: 0.0431723\n",
      "[25]\tvalid_0's multi_logloss: 0.0390164\n",
      "[26]\tvalid_0's multi_logloss: 0.0352739\n",
      "[27]\tvalid_0's multi_logloss: 0.0319023\n",
      "[28]\tvalid_0's multi_logloss: 0.0288636\n",
      "[29]\tvalid_0's multi_logloss: 0.026124\n",
      "[30]\tvalid_0's multi_logloss: 0.0236534\n",
      "[31]\tvalid_0's multi_logloss: 0.0214247\n",
      "[32]\tvalid_0's multi_logloss: 0.0194138\n",
      "[33]\tvalid_0's multi_logloss: 0.0175991\n",
      "[34]\tvalid_0's multi_logloss: 0.0159611\n",
      "[35]\tvalid_0's multi_logloss: 0.0144823\n",
      "[36]\tvalid_0's multi_logloss: 0.0131472\n",
      "[37]\tvalid_0's multi_logloss: 0.0119416\n",
      "[38]\tvalid_0's multi_logloss: 0.0108528\n",
      "[39]\tvalid_0's multi_logloss: 0.00986954\n",
      "[40]\tvalid_0's multi_logloss: 0.00898144\n",
      "[41]\tvalid_0's multi_logloss: 0.00817857\n",
      "[42]\tvalid_0's multi_logloss: 0.00745391\n",
      "[43]\tvalid_0's multi_logloss: 0.00679902\n",
      "[44]\tvalid_0's multi_logloss: 0.00620747\n",
      "[45]\tvalid_0's multi_logloss: 0.0056723\n",
      "[46]\tvalid_0's multi_logloss: 0.00518802\n",
      "[47]\tvalid_0's multi_logloss: 0.00475067\n",
      "[48]\tvalid_0's multi_logloss: 0.00435575\n",
      "[49]\tvalid_0's multi_logloss: 0.00399931\n",
      "[50]\tvalid_0's multi_logloss: 0.00367779\n",
      "[51]\tvalid_0's multi_logloss: 0.00338724\n",
      "[52]\tvalid_0's multi_logloss: 0.0031246\n",
      "[53]\tvalid_0's multi_logloss: 0.00288789\n",
      "[54]\tvalid_0's multi_logloss: 0.00267314\n",
      "[55]\tvalid_0's multi_logloss: 0.0024798\n",
      "[56]\tvalid_0's multi_logloss: 0.0023055\n",
      "[57]\tvalid_0's multi_logloss: 0.00214817\n",
      "[58]\tvalid_0's multi_logloss: 0.00200455\n",
      "[59]\tvalid_0's multi_logloss: 0.00187616\n",
      "[60]\tvalid_0's multi_logloss: 0.00176055\n",
      "[61]\tvalid_0's multi_logloss: 0.00165631\n",
      "[62]\tvalid_0's multi_logloss: 0.00156203\n",
      "[63]\tvalid_0's multi_logloss: 0.00149721\n",
      "[64]\tvalid_0's multi_logloss: 0.00143448\n",
      "[65]\tvalid_0's multi_logloss: 0.00136605\n",
      "[66]\tvalid_0's multi_logloss: 0.00130432\n",
      "[67]\tvalid_0's multi_logloss: 0.00122959\n",
      "[68]\tvalid_0's multi_logloss: 0.00117928\n",
      "[69]\tvalid_0's multi_logloss: 0.001134\n",
      "[70]\tvalid_0's multi_logloss: 0.00107229\n",
      "[71]\tvalid_0's multi_logloss: 0.00103344\n",
      "[72]\tvalid_0's multi_logloss: 0.00102581\n",
      "[73]\tvalid_0's multi_logloss: 0.000994979\n",
      "[74]\tvalid_0's multi_logloss: 0.000967951\n",
      "[75]\tvalid_0's multi_logloss: 0.00094273\n",
      "[76]\tvalid_0's multi_logloss: 0.000919997\n",
      "[77]\tvalid_0's multi_logloss: 0.000899728\n",
      "[78]\tvalid_0's multi_logloss: 0.000881384\n",
      "[79]\tvalid_0's multi_logloss: 0.000868225\n",
      "[80]\tvalid_0's multi_logloss: 0.000852181\n",
      "[81]\tvalid_0's multi_logloss: 0.000834574\n",
      "[82]\tvalid_0's multi_logloss: 0.00082238\n",
      "[83]\tvalid_0's multi_logloss: 0.00081329\n",
      "[84]\tvalid_0's multi_logloss: 0.000857925\n",
      "[85]\tvalid_0's multi_logloss: 0.000805035\n",
      "[86]\tvalid_0's multi_logloss: 0.000845771\n",
      "[87]\tvalid_0's multi_logloss: 0.000820206\n",
      "[88]\tvalid_0's multi_logloss: 0.00082082\n",
      "[89]\tvalid_0's multi_logloss: 0.000783544\n",
      "[90]\tvalid_0's multi_logloss: 0.000909398\n",
      "[91]\tvalid_0's multi_logloss: 0.000784726\n",
      "[92]\tvalid_0's multi_logloss: 0.00081096\n",
      "[93]\tvalid_0's multi_logloss: 0.000805645\n",
      "[94]\tvalid_0's multi_logloss: 0.00093035\n",
      "[95]\tvalid_0's multi_logloss: 0.000766743\n",
      "[96]\tvalid_0's multi_logloss: 0.000999646\n",
      "[97]\tvalid_0's multi_logloss: 0.00091112\n",
      "[98]\tvalid_0's multi_logloss: 0.00114201\n",
      "[99]\tvalid_0's multi_logloss: 0.000893166\n",
      "[100]\tvalid_0's multi_logloss: 0.000880618\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015864 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -0.141837\n",
      "[LightGBM] [Info] Start training from score -2.023158\n",
      "[1]\tvalid_0's multi_logloss: 0.355124\n",
      "[2]\tvalid_0's multi_logloss: 0.332944\n",
      "[3]\tvalid_0's multi_logloss: 0.31552\n",
      "[4]\tvalid_0's multi_logloss: 0.302227\n",
      "[5]\tvalid_0's multi_logloss: 0.291284\n",
      "[6]\tvalid_0's multi_logloss: 0.282088\n",
      "[7]\tvalid_0's multi_logloss: 0.274074\n",
      "[8]\tvalid_0's multi_logloss: 0.267691\n",
      "[9]\tvalid_0's multi_logloss: 0.26212\n",
      "[10]\tvalid_0's multi_logloss: 0.256815\n",
      "[11]\tvalid_0's multi_logloss: 0.252463\n",
      "[12]\tvalid_0's multi_logloss: 0.248518\n",
      "[13]\tvalid_0's multi_logloss: 0.244956\n",
      "[14]\tvalid_0's multi_logloss: 0.241793\n",
      "[15]\tvalid_0's multi_logloss: 0.239139\n",
      "[16]\tvalid_0's multi_logloss: 0.236634\n",
      "[17]\tvalid_0's multi_logloss: 0.234376\n",
      "[18]\tvalid_0's multi_logloss: 0.232505\n",
      "[19]\tvalid_0's multi_logloss: 0.230798\n",
      "[20]\tvalid_0's multi_logloss: 0.228943\n",
      "[21]\tvalid_0's multi_logloss: 0.227166\n",
      "[22]\tvalid_0's multi_logloss: 0.225698\n",
      "[23]\tvalid_0's multi_logloss: 0.224537\n",
      "[24]\tvalid_0's multi_logloss: 0.223419\n",
      "[25]\tvalid_0's multi_logloss: 0.222293\n",
      "[26]\tvalid_0's multi_logloss: 0.221222\n",
      "[27]\tvalid_0's multi_logloss: 0.220392\n",
      "[28]\tvalid_0's multi_logloss: 0.219415\n",
      "[29]\tvalid_0's multi_logloss: 0.218171\n",
      "[30]\tvalid_0's multi_logloss: 0.217234\n",
      "[31]\tvalid_0's multi_logloss: 0.21627\n",
      "[32]\tvalid_0's multi_logloss: 0.21552\n",
      "[33]\tvalid_0's multi_logloss: 0.214507\n",
      "[34]\tvalid_0's multi_logloss: 0.213677\n",
      "[35]\tvalid_0's multi_logloss: 0.21293\n",
      "[36]\tvalid_0's multi_logloss: 0.212194\n",
      "[37]\tvalid_0's multi_logloss: 0.211535\n",
      "[38]\tvalid_0's multi_logloss: 0.210926\n",
      "[39]\tvalid_0's multi_logloss: 0.210237\n",
      "[40]\tvalid_0's multi_logloss: 0.209746\n",
      "[41]\tvalid_0's multi_logloss: 0.209307\n",
      "[42]\tvalid_0's multi_logloss: 0.208902\n",
      "[43]\tvalid_0's multi_logloss: 0.208326\n",
      "[44]\tvalid_0's multi_logloss: 0.207892\n",
      "[45]\tvalid_0's multi_logloss: 0.207442\n",
      "[46]\tvalid_0's multi_logloss: 0.206973\n",
      "[47]\tvalid_0's multi_logloss: 0.206415\n",
      "[48]\tvalid_0's multi_logloss: 0.206006\n",
      "[49]\tvalid_0's multi_logloss: 0.205677\n",
      "[50]\tvalid_0's multi_logloss: 0.205249\n",
      "[51]\tvalid_0's multi_logloss: 0.204799\n",
      "[52]\tvalid_0's multi_logloss: 0.204391\n",
      "[53]\tvalid_0's multi_logloss: 0.203946\n",
      "[54]\tvalid_0's multi_logloss: 0.203643\n",
      "[55]\tvalid_0's multi_logloss: 0.203401\n",
      "[56]\tvalid_0's multi_logloss: 0.203127\n",
      "[57]\tvalid_0's multi_logloss: 0.202686\n",
      "[58]\tvalid_0's multi_logloss: 0.202491\n",
      "[59]\tvalid_0's multi_logloss: 0.202129\n",
      "[60]\tvalid_0's multi_logloss: 0.201982\n",
      "[61]\tvalid_0's multi_logloss: 0.201784\n",
      "[62]\tvalid_0's multi_logloss: 0.201502\n",
      "[63]\tvalid_0's multi_logloss: 0.201145\n",
      "[64]\tvalid_0's multi_logloss: 0.200941\n",
      "[65]\tvalid_0's multi_logloss: 0.200576\n",
      "[66]\tvalid_0's multi_logloss: 0.200271\n",
      "[67]\tvalid_0's multi_logloss: 0.200053\n",
      "[68]\tvalid_0's multi_logloss: 0.199745\n",
      "[69]\tvalid_0's multi_logloss: 0.199579\n",
      "[70]\tvalid_0's multi_logloss: 0.199161\n",
      "[71]\tvalid_0's multi_logloss: 0.198756\n",
      "[72]\tvalid_0's multi_logloss: 0.198314\n",
      "[73]\tvalid_0's multi_logloss: 0.198133\n",
      "[74]\tvalid_0's multi_logloss: 0.197899\n",
      "[75]\tvalid_0's multi_logloss: 0.197758\n",
      "[76]\tvalid_0's multi_logloss: 0.197589\n",
      "[77]\tvalid_0's multi_logloss: 0.197447\n",
      "[78]\tvalid_0's multi_logloss: 0.197295\n",
      "[79]\tvalid_0's multi_logloss: 0.197036\n",
      "[80]\tvalid_0's multi_logloss: 0.19684\n",
      "[81]\tvalid_0's multi_logloss: 0.196531\n",
      "[82]\tvalid_0's multi_logloss: 0.196335\n",
      "[83]\tvalid_0's multi_logloss: 0.196088\n",
      "[84]\tvalid_0's multi_logloss: 0.195736\n",
      "[85]\tvalid_0's multi_logloss: 0.195418\n",
      "[86]\tvalid_0's multi_logloss: 0.195082\n",
      "[87]\tvalid_0's multi_logloss: 0.194838\n",
      "[88]\tvalid_0's multi_logloss: 0.194623\n",
      "[89]\tvalid_0's multi_logloss: 0.194519\n",
      "[90]\tvalid_0's multi_logloss: 0.19426\n",
      "[91]\tvalid_0's multi_logloss: 0.194035\n",
      "[92]\tvalid_0's multi_logloss: 0.193891\n",
      "[93]\tvalid_0's multi_logloss: 0.193675\n",
      "[94]\tvalid_0's multi_logloss: 0.193515\n",
      "[95]\tvalid_0's multi_logloss: 0.193432\n",
      "[96]\tvalid_0's multi_logloss: 0.193244\n",
      "[97]\tvalid_0's multi_logloss: 0.193128\n",
      "[98]\tvalid_0's multi_logloss: 0.192955\n",
      "[99]\tvalid_0's multi_logloss: 0.192749\n",
      "[100]\tvalid_0's multi_logloss: 0.192692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [10:48, 152.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007549 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 7715638, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.249550\n",
      "[LightGBM] [Info] Start training from score -3.165534\n",
      "[LightGBM] [Info] Start training from score -1.726403\n",
      "[LightGBM] [Info] Start training from score -1.902421\n",
      "[LightGBM] [Info] Start training from score -1.667720\n",
      "[LightGBM] [Info] Start training from score -1.861961\n",
      "[1]\tvalid_0's multi_logloss: 1.6808\n",
      "[2]\tvalid_0's multi_logloss: 1.67632\n",
      "[3]\tvalid_0's multi_logloss: 1.67258\n",
      "[4]\tvalid_0's multi_logloss: 1.66957\n",
      "[5]\tvalid_0's multi_logloss: 1.66688\n",
      "[6]\tvalid_0's multi_logloss: 1.6648\n",
      "[7]\tvalid_0's multi_logloss: 1.66274\n",
      "[8]\tvalid_0's multi_logloss: 1.66108\n",
      "[9]\tvalid_0's multi_logloss: 1.65953\n",
      "[10]\tvalid_0's multi_logloss: 1.65818\n",
      "[11]\tvalid_0's multi_logloss: 1.65685\n",
      "[12]\tvalid_0's multi_logloss: 1.65578\n",
      "[13]\tvalid_0's multi_logloss: 1.65481\n",
      "[14]\tvalid_0's multi_logloss: 1.65392\n",
      "[15]\tvalid_0's multi_logloss: 1.65298\n",
      "[16]\tvalid_0's multi_logloss: 1.65224\n",
      "[17]\tvalid_0's multi_logloss: 1.65152\n",
      "[18]\tvalid_0's multi_logloss: 1.6508\n",
      "[19]\tvalid_0's multi_logloss: 1.65022\n",
      "[20]\tvalid_0's multi_logloss: 1.64971\n",
      "[21]\tvalid_0's multi_logloss: 1.64919\n",
      "[22]\tvalid_0's multi_logloss: 1.64867\n",
      "[23]\tvalid_0's multi_logloss: 1.64824\n",
      "[24]\tvalid_0's multi_logloss: 1.64774\n",
      "[25]\tvalid_0's multi_logloss: 1.64723\n",
      "[26]\tvalid_0's multi_logloss: 1.64685\n",
      "[27]\tvalid_0's multi_logloss: 1.64647\n",
      "[28]\tvalid_0's multi_logloss: 1.646\n",
      "[29]\tvalid_0's multi_logloss: 1.64562\n",
      "[30]\tvalid_0's multi_logloss: 1.64533\n",
      "[31]\tvalid_0's multi_logloss: 1.64506\n",
      "[32]\tvalid_0's multi_logloss: 1.64478\n",
      "[33]\tvalid_0's multi_logloss: 1.64451\n",
      "[34]\tvalid_0's multi_logloss: 1.64414\n",
      "[35]\tvalid_0's multi_logloss: 1.64389\n",
      "[36]\tvalid_0's multi_logloss: 1.64368\n",
      "[37]\tvalid_0's multi_logloss: 1.64337\n",
      "[38]\tvalid_0's multi_logloss: 1.64296\n",
      "[39]\tvalid_0's multi_logloss: 1.64271\n",
      "[40]\tvalid_0's multi_logloss: 1.64253\n",
      "[41]\tvalid_0's multi_logloss: 1.64235\n",
      "[42]\tvalid_0's multi_logloss: 1.64211\n",
      "[43]\tvalid_0's multi_logloss: 1.64189\n",
      "[44]\tvalid_0's multi_logloss: 1.64168\n",
      "[45]\tvalid_0's multi_logloss: 1.64151\n",
      "[46]\tvalid_0's multi_logloss: 1.64136\n",
      "[47]\tvalid_0's multi_logloss: 1.64114\n",
      "[48]\tvalid_0's multi_logloss: 1.6409\n",
      "[49]\tvalid_0's multi_logloss: 1.64061\n",
      "[50]\tvalid_0's multi_logloss: 1.64042\n",
      "[51]\tvalid_0's multi_logloss: 1.6403\n",
      "[52]\tvalid_0's multi_logloss: 1.63995\n",
      "[53]\tvalid_0's multi_logloss: 1.63968\n",
      "[54]\tvalid_0's multi_logloss: 1.63941\n",
      "[55]\tvalid_0's multi_logloss: 1.63924\n",
      "[56]\tvalid_0's multi_logloss: 1.63903\n",
      "[57]\tvalid_0's multi_logloss: 1.63887\n",
      "[58]\tvalid_0's multi_logloss: 1.63864\n",
      "[59]\tvalid_0's multi_logloss: 1.63851\n",
      "[60]\tvalid_0's multi_logloss: 1.63839\n",
      "[61]\tvalid_0's multi_logloss: 1.63813\n",
      "[62]\tvalid_0's multi_logloss: 1.63787\n",
      "[63]\tvalid_0's multi_logloss: 1.63773\n",
      "[64]\tvalid_0's multi_logloss: 1.63752\n",
      "[65]\tvalid_0's multi_logloss: 1.63736\n",
      "[66]\tvalid_0's multi_logloss: 1.63717\n",
      "[67]\tvalid_0's multi_logloss: 1.63699\n",
      "[68]\tvalid_0's multi_logloss: 1.63688\n",
      "[69]\tvalid_0's multi_logloss: 1.63679\n",
      "[70]\tvalid_0's multi_logloss: 1.63657\n",
      "[71]\tvalid_0's multi_logloss: 1.63645\n",
      "[72]\tvalid_0's multi_logloss: 1.63632\n",
      "[73]\tvalid_0's multi_logloss: 1.6361\n",
      "[74]\tvalid_0's multi_logloss: 1.63585\n",
      "[75]\tvalid_0's multi_logloss: 1.63572\n",
      "[76]\tvalid_0's multi_logloss: 1.63549\n",
      "[77]\tvalid_0's multi_logloss: 1.63536\n",
      "[78]\tvalid_0's multi_logloss: 1.63529\n",
      "[79]\tvalid_0's multi_logloss: 1.63516\n",
      "[80]\tvalid_0's multi_logloss: 1.63494\n",
      "[81]\tvalid_0's multi_logloss: 1.63481\n",
      "[82]\tvalid_0's multi_logloss: 1.63471\n",
      "[83]\tvalid_0's multi_logloss: 1.6345\n",
      "[84]\tvalid_0's multi_logloss: 1.63422\n",
      "[85]\tvalid_0's multi_logloss: 1.63401\n",
      "[86]\tvalid_0's multi_logloss: 1.63382\n",
      "[87]\tvalid_0's multi_logloss: 1.63364\n",
      "[88]\tvalid_0's multi_logloss: 1.63351\n",
      "[89]\tvalid_0's multi_logloss: 1.63341\n",
      "[90]\tvalid_0's multi_logloss: 1.63329\n",
      "[91]\tvalid_0's multi_logloss: 1.63314\n",
      "[92]\tvalid_0's multi_logloss: 1.63296\n",
      "[93]\tvalid_0's multi_logloss: 1.63275\n",
      "[94]\tvalid_0's multi_logloss: 1.63264\n",
      "[95]\tvalid_0's multi_logloss: 1.63255\n",
      "[96]\tvalid_0's multi_logloss: 1.63229\n",
      "[97]\tvalid_0's multi_logloss: 1.63216\n",
      "[98]\tvalid_0's multi_logloss: 1.63202\n",
      "[99]\tvalid_0's multi_logloss: 1.63192\n",
      "[100]\tvalid_0's multi_logloss: 1.63177\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007680 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 7715638, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -3.388563\n",
      "[LightGBM] [Info] Start training from score -3.286043\n",
      "[LightGBM] [Info] Start training from score -3.265766\n",
      "[LightGBM] [Info] Start training from score -3.814547\n",
      "[LightGBM] [Info] Start training from score -3.310265\n",
      "[LightGBM] [Info] Start training from score -3.206426\n",
      "[LightGBM] [Info] Start training from score -4.264605\n",
      "[LightGBM] [Info] Start training from score -3.385622\n",
      "[LightGBM] [Info] Start training from score -3.678169\n",
      "[LightGBM] [Info] Start training from score -3.401590\n",
      "[LightGBM] [Info] Start training from score -4.879144\n",
      "[LightGBM] [Info] Start training from score -3.027581\n",
      "[LightGBM] [Info] Start training from score -2.985319\n",
      "[LightGBM] [Info] Start training from score -3.251856\n",
      "[LightGBM] [Info] Start training from score -3.294527\n",
      "[LightGBM] [Info] Start training from score -3.372086\n",
      "[LightGBM] [Info] Start training from score -2.973489\n",
      "[LightGBM] [Info] Start training from score -2.489644\n",
      "[LightGBM] [Info] Start training from score -3.403357\n",
      "[LightGBM] [Info] Start training from score -4.161407\n",
      "[LightGBM] [Info] Start training from score -4.219942\n",
      "[LightGBM] [Info] Start training from score -3.454308\n",
      "[LightGBM] [Info] Start training from score -3.414970\n",
      "[LightGBM] [Info] Start training from score -3.160243\n",
      "[LightGBM] [Info] Start training from score -3.113230\n",
      "[LightGBM] [Info] Start training from score -3.209175\n",
      "[LightGBM] [Info] Start training from score -3.282600\n",
      "[LightGBM] [Info] Start training from score -3.180636\n",
      "[1]\tvalid_0's multi_logloss: 2.78492\n",
      "[2]\tvalid_0's multi_logloss: 2.65221\n",
      "[3]\tvalid_0's multi_logloss: 2.55267\n",
      "[4]\tvalid_0's multi_logloss: 2.4677\n",
      "[5]\tvalid_0's multi_logloss: 2.40463\n",
      "[6]\tvalid_0's multi_logloss: 2.35085\n",
      "[7]\tvalid_0's multi_logloss: 2.3113\n",
      "[8]\tvalid_0's multi_logloss: 2.27427\n",
      "[9]\tvalid_0's multi_logloss: 2.24961\n",
      "[10]\tvalid_0's multi_logloss: 2.23021\n",
      "[11]\tvalid_0's multi_logloss: 2.20656\n",
      "[12]\tvalid_0's multi_logloss: 2.18712\n",
      "[13]\tvalid_0's multi_logloss: 2.17753\n",
      "[14]\tvalid_0's multi_logloss: 2.16284\n",
      "[15]\tvalid_0's multi_logloss: 2.14929\n",
      "[16]\tvalid_0's multi_logloss: 2.13865\n",
      "[17]\tvalid_0's multi_logloss: 2.12969\n",
      "[18]\tvalid_0's multi_logloss: 2.11844\n",
      "[19]\tvalid_0's multi_logloss: 2.11102\n",
      "[20]\tvalid_0's multi_logloss: 2.1042\n",
      "[21]\tvalid_0's multi_logloss: 2.09275\n",
      "[22]\tvalid_0's multi_logloss: 2.09923\n",
      "[23]\tvalid_0's multi_logloss: 2.0955\n",
      "[24]\tvalid_0's multi_logloss: 2.07584\n",
      "[25]\tvalid_0's multi_logloss: 2.07095\n",
      "[26]\tvalid_0's multi_logloss: 2.07896\n",
      "[27]\tvalid_0's multi_logloss: 2.06196\n",
      "[28]\tvalid_0's multi_logloss: 2.07496\n",
      "[29]\tvalid_0's multi_logloss: 2.05803\n",
      "[30]\tvalid_0's multi_logloss: 2.05447\n",
      "[31]\tvalid_0's multi_logloss: 2.07517\n",
      "[32]\tvalid_0's multi_logloss: 2.07211\n",
      "[33]\tvalid_0's multi_logloss: 2.04648\n",
      "[34]\tvalid_0's multi_logloss: 2.04521\n",
      "[35]\tvalid_0's multi_logloss: 2.05139\n",
      "[36]\tvalid_0's multi_logloss: 2.04058\n",
      "[37]\tvalid_0's multi_logloss: 2.0548\n",
      "[38]\tvalid_0's multi_logloss: 2.03437\n",
      "[39]\tvalid_0's multi_logloss: 2.0504\n",
      "[40]\tvalid_0's multi_logloss: 2.03748\n",
      "[41]\tvalid_0's multi_logloss: 2.04881\n",
      "[42]\tvalid_0's multi_logloss: 2.0309\n",
      "[43]\tvalid_0's multi_logloss: 2.04691\n",
      "[44]\tvalid_0's multi_logloss: 2.03055\n",
      "[45]\tvalid_0's multi_logloss: 2.04876\n",
      "[46]\tvalid_0's multi_logloss: 2.02553\n",
      "[47]\tvalid_0's multi_logloss: 2.04988\n",
      "[48]\tvalid_0's multi_logloss: 2.02765\n",
      "[49]\tvalid_0's multi_logloss: 2.04453\n",
      "[50]\tvalid_0's multi_logloss: 2.045\n",
      "[51]\tvalid_0's multi_logloss: 2.04269\n",
      "[52]\tvalid_0's multi_logloss: 2.04599\n",
      "[53]\tvalid_0's multi_logloss: 2.05339\n",
      "[54]\tvalid_0's multi_logloss: 2.05169\n",
      "[55]\tvalid_0's multi_logloss: 2.04926\n",
      "[56]\tvalid_0's multi_logloss: 2.04857\n",
      "[57]\tvalid_0's multi_logloss: 2.04746\n",
      "[58]\tvalid_0's multi_logloss: 2.04728\n",
      "[59]\tvalid_0's multi_logloss: 2.0529\n",
      "[60]\tvalid_0's multi_logloss: 2.11546\n",
      "[61]\tvalid_0's multi_logloss: 2.11573\n",
      "[62]\tvalid_0's multi_logloss: 2.11686\n",
      "[63]\tvalid_0's multi_logloss: 2.12196\n",
      "[64]\tvalid_0's multi_logloss: 2.16102\n",
      "[65]\tvalid_0's multi_logloss: 2.17042\n",
      "[66]\tvalid_0's multi_logloss: 2.17596\n",
      "[67]\tvalid_0's multi_logloss: 2.14217\n",
      "[68]\tvalid_0's multi_logloss: 2.13357\n",
      "[69]\tvalid_0's multi_logloss: 2.17502\n",
      "[70]\tvalid_0's multi_logloss: 2.18262\n",
      "[71]\tvalid_0's multi_logloss: 2.18149\n",
      "[72]\tvalid_0's multi_logloss: 2.18756\n",
      "[73]\tvalid_0's multi_logloss: 2.20578\n",
      "[74]\tvalid_0's multi_logloss: 2.18974\n",
      "[75]\tvalid_0's multi_logloss: 2.20607\n",
      "[76]\tvalid_0's multi_logloss: 2.18445\n",
      "[77]\tvalid_0's multi_logloss: 2.19346\n",
      "[78]\tvalid_0's multi_logloss: 2.20815\n",
      "[79]\tvalid_0's multi_logloss: 2.21927\n",
      "[80]\tvalid_0's multi_logloss: 2.22642\n",
      "[81]\tvalid_0's multi_logloss: 2.2154\n",
      "[82]\tvalid_0's multi_logloss: 2.22919\n",
      "[83]\tvalid_0's multi_logloss: 2.28305\n",
      "[84]\tvalid_0's multi_logloss: 2.28794\n",
      "[85]\tvalid_0's multi_logloss: 2.34568\n",
      "[86]\tvalid_0's multi_logloss: 2.34162\n",
      "[87]\tvalid_0's multi_logloss: 2.31602\n",
      "[88]\tvalid_0's multi_logloss: 2.31116\n",
      "[89]\tvalid_0's multi_logloss: 2.34631\n",
      "[90]\tvalid_0's multi_logloss: 2.37574\n",
      "[91]\tvalid_0's multi_logloss: 2.4006\n",
      "[92]\tvalid_0's multi_logloss: 2.41791\n",
      "[93]\tvalid_0's multi_logloss: 2.38188\n",
      "[94]\tvalid_0's multi_logloss: 2.47583\n",
      "[95]\tvalid_0's multi_logloss: 2.49025\n",
      "[96]\tvalid_0's multi_logloss: 2.4633\n",
      "[97]\tvalid_0's multi_logloss: 2.50096\n",
      "[98]\tvalid_0's multi_logloss: 2.52347\n",
      "[99]\tvalid_0's multi_logloss: 2.52811\n",
      "[100]\tvalid_0's multi_logloss: 2.55522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [12:30, 134.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001274 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 820733, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -0.683185\n",
      "[LightGBM] [Info] Start training from score -2.382997\n",
      "[LightGBM] [Info] Start training from score -2.734975\n",
      "[LightGBM] [Info] Start training from score -3.826068\n",
      "[LightGBM] [Info] Start training from score -1.583719\n",
      "[LightGBM] [Info] Start training from score -2.199855\n",
      "[1]\tvalid_0's multi_logloss: 1.14858\n",
      "[2]\tvalid_0's multi_logloss: 1.03215\n",
      "[3]\tvalid_0's multi_logloss: 0.945052\n",
      "[4]\tvalid_0's multi_logloss: 0.876605\n",
      "[5]\tvalid_0's multi_logloss: 0.821758\n",
      "[6]\tvalid_0's multi_logloss: 0.777337\n",
      "[7]\tvalid_0's multi_logloss: 0.740513\n",
      "[8]\tvalid_0's multi_logloss: 0.709756\n",
      "[9]\tvalid_0's multi_logloss: 0.683875\n",
      "[10]\tvalid_0's multi_logloss: 0.661736\n",
      "[11]\tvalid_0's multi_logloss: 0.643063\n",
      "[12]\tvalid_0's multi_logloss: 0.627164\n",
      "[13]\tvalid_0's multi_logloss: 0.613411\n",
      "[14]\tvalid_0's multi_logloss: 0.601325\n",
      "[15]\tvalid_0's multi_logloss: 0.590818\n",
      "[16]\tvalid_0's multi_logloss: 0.581579\n",
      "[17]\tvalid_0's multi_logloss: 0.573447\n",
      "[18]\tvalid_0's multi_logloss: 0.566438\n",
      "[19]\tvalid_0's multi_logloss: 0.560124\n",
      "[20]\tvalid_0's multi_logloss: 0.554471\n",
      "[21]\tvalid_0's multi_logloss: 0.549463\n",
      "[22]\tvalid_0's multi_logloss: 0.544986\n",
      "[23]\tvalid_0's multi_logloss: 0.540925\n",
      "[24]\tvalid_0's multi_logloss: 0.537284\n",
      "[25]\tvalid_0's multi_logloss: 0.53404\n",
      "[26]\tvalid_0's multi_logloss: 0.531068\n",
      "[27]\tvalid_0's multi_logloss: 0.528416\n",
      "[28]\tvalid_0's multi_logloss: 0.525961\n",
      "[29]\tvalid_0's multi_logloss: 0.523671\n",
      "[30]\tvalid_0's multi_logloss: 0.521554\n",
      "[31]\tvalid_0's multi_logloss: 0.519714\n",
      "[32]\tvalid_0's multi_logloss: 0.518013\n",
      "[33]\tvalid_0's multi_logloss: 0.516393\n",
      "[34]\tvalid_0's multi_logloss: 0.514953\n",
      "[35]\tvalid_0's multi_logloss: 0.513574\n",
      "[36]\tvalid_0's multi_logloss: 0.512247\n",
      "[37]\tvalid_0's multi_logloss: 0.511099\n",
      "[38]\tvalid_0's multi_logloss: 0.510006\n",
      "[39]\tvalid_0's multi_logloss: 0.509088\n",
      "[40]\tvalid_0's multi_logloss: 0.508145\n",
      "[41]\tvalid_0's multi_logloss: 0.507161\n",
      "[42]\tvalid_0's multi_logloss: 0.506395\n",
      "[43]\tvalid_0's multi_logloss: 0.50573\n",
      "[44]\tvalid_0's multi_logloss: 0.504961\n",
      "[45]\tvalid_0's multi_logloss: 0.504301\n",
      "[46]\tvalid_0's multi_logloss: 0.503647\n",
      "[47]\tvalid_0's multi_logloss: 0.503055\n",
      "[48]\tvalid_0's multi_logloss: 0.503485\n",
      "[49]\tvalid_0's multi_logloss: 0.502214\n",
      "[50]\tvalid_0's multi_logloss: 0.5014\n",
      "[51]\tvalid_0's multi_logloss: 0.501824\n",
      "[52]\tvalid_0's multi_logloss: 0.501528\n",
      "[53]\tvalid_0's multi_logloss: 0.5021\n",
      "[54]\tvalid_0's multi_logloss: 0.502033\n",
      "[55]\tvalid_0's multi_logloss: 0.503043\n",
      "[56]\tvalid_0's multi_logloss: 0.501513\n",
      "[57]\tvalid_0's multi_logloss: 0.499349\n",
      "[58]\tvalid_0's multi_logloss: 0.498252\n",
      "[59]\tvalid_0's multi_logloss: 0.498667\n",
      "[60]\tvalid_0's multi_logloss: 0.497744\n",
      "[61]\tvalid_0's multi_logloss: 0.49833\n",
      "[62]\tvalid_0's multi_logloss: 0.497851\n",
      "[63]\tvalid_0's multi_logloss: 0.49751\n",
      "[64]\tvalid_0's multi_logloss: 0.502511\n",
      "[65]\tvalid_0's multi_logloss: 0.496314\n",
      "[66]\tvalid_0's multi_logloss: 0.497666\n",
      "[67]\tvalid_0's multi_logloss: 0.495893\n",
      "[68]\tvalid_0's multi_logloss: 0.496017\n",
      "[69]\tvalid_0's multi_logloss: 0.497039\n",
      "[70]\tvalid_0's multi_logloss: 0.495293\n",
      "[71]\tvalid_0's multi_logloss: 0.497185\n",
      "[72]\tvalid_0's multi_logloss: 0.500377\n",
      "[73]\tvalid_0's multi_logloss: 0.501937\n",
      "[74]\tvalid_0's multi_logloss: 0.50907\n",
      "[75]\tvalid_0's multi_logloss: 0.499149\n",
      "[76]\tvalid_0's multi_logloss: 0.499615\n",
      "[77]\tvalid_0's multi_logloss: 0.500748\n",
      "[78]\tvalid_0's multi_logloss: 0.496461\n",
      "[79]\tvalid_0's multi_logloss: 0.504729\n",
      "[80]\tvalid_0's multi_logloss: 0.506446\n",
      "[81]\tvalid_0's multi_logloss: 0.509327\n",
      "[82]\tvalid_0's multi_logloss: 0.515657\n",
      "[83]\tvalid_0's multi_logloss: 0.509169\n",
      "[84]\tvalid_0's multi_logloss: 0.502256\n",
      "[85]\tvalid_0's multi_logloss: 0.503334\n",
      "[86]\tvalid_0's multi_logloss: 0.507817\n",
      "[87]\tvalid_0's multi_logloss: 0.510601\n",
      "[88]\tvalid_0's multi_logloss: 0.52641\n",
      "[89]\tvalid_0's multi_logloss: 0.521181\n",
      "[90]\tvalid_0's multi_logloss: 0.539192\n",
      "[91]\tvalid_0's multi_logloss: 0.541287\n",
      "[92]\tvalid_0's multi_logloss: 0.528428\n",
      "[93]\tvalid_0's multi_logloss: 0.519538\n",
      "[94]\tvalid_0's multi_logloss: 0.520068\n",
      "[95]\tvalid_0's multi_logloss: 0.529674\n",
      "[96]\tvalid_0's multi_logloss: 0.514389\n",
      "[97]\tvalid_0's multi_logloss: 0.511598\n",
      "[98]\tvalid_0's multi_logloss: 0.512215\n",
      "[99]\tvalid_0's multi_logloss: 0.523533\n",
      "[100]\tvalid_0's multi_logloss: 0.548142\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001920 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 820733, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -2.163833\n",
      "[LightGBM] [Info] Start training from score -1.796397\n",
      "[LightGBM] [Info] Start training from score -1.843741\n",
      "[LightGBM] [Info] Start training from score -1.989576\n",
      "[LightGBM] [Info] Start training from score -1.941218\n",
      "[LightGBM] [Info] Start training from score -1.949016\n",
      "[LightGBM] [Info] Start training from score -1.978333\n",
      "[1]\tvalid_0's multi_logloss: 1.89779\n",
      "[2]\tvalid_0's multi_logloss: 1.86551\n",
      "[3]\tvalid_0's multi_logloss: 1.83991\n",
      "[4]\tvalid_0's multi_logloss: 1.81933\n",
      "[5]\tvalid_0's multi_logloss: 1.80254\n",
      "[6]\tvalid_0's multi_logloss: 1.78878\n",
      "[7]\tvalid_0's multi_logloss: 1.77734\n",
      "[8]\tvalid_0's multi_logloss: 1.76781\n",
      "[9]\tvalid_0's multi_logloss: 1.75986\n",
      "[10]\tvalid_0's multi_logloss: 1.7531\n",
      "[11]\tvalid_0's multi_logloss: 1.74736\n",
      "[12]\tvalid_0's multi_logloss: 1.7424\n",
      "[13]\tvalid_0's multi_logloss: 1.73823\n",
      "[14]\tvalid_0's multi_logloss: 1.7347\n",
      "[15]\tvalid_0's multi_logloss: 1.73166\n",
      "[16]\tvalid_0's multi_logloss: 1.72905\n",
      "[17]\tvalid_0's multi_logloss: 1.7268\n",
      "[18]\tvalid_0's multi_logloss: 1.7248\n",
      "[19]\tvalid_0's multi_logloss: 1.72302\n",
      "[20]\tvalid_0's multi_logloss: 1.72153\n",
      "[21]\tvalid_0's multi_logloss: 1.72021\n",
      "[22]\tvalid_0's multi_logloss: 1.71903\n",
      "[23]\tvalid_0's multi_logloss: 1.71795\n",
      "[24]\tvalid_0's multi_logloss: 1.71701\n",
      "[25]\tvalid_0's multi_logloss: 1.7161\n",
      "[26]\tvalid_0's multi_logloss: 1.7153\n",
      "[27]\tvalid_0's multi_logloss: 1.71457\n",
      "[28]\tvalid_0's multi_logloss: 1.7139\n",
      "[29]\tvalid_0's multi_logloss: 1.71327\n",
      "[30]\tvalid_0's multi_logloss: 1.71271\n",
      "[31]\tvalid_0's multi_logloss: 1.71224\n",
      "[32]\tvalid_0's multi_logloss: 1.7118\n",
      "[33]\tvalid_0's multi_logloss: 1.71137\n",
      "[34]\tvalid_0's multi_logloss: 1.71099\n",
      "[35]\tvalid_0's multi_logloss: 1.7106\n",
      "[36]\tvalid_0's multi_logloss: 1.71022\n",
      "[37]\tvalid_0's multi_logloss: 1.70987\n",
      "[38]\tvalid_0's multi_logloss: 1.70952\n",
      "[39]\tvalid_0's multi_logloss: 1.70922\n",
      "[40]\tvalid_0's multi_logloss: 1.70894\n",
      "[41]\tvalid_0's multi_logloss: 1.70867\n",
      "[42]\tvalid_0's multi_logloss: 1.70839\n",
      "[43]\tvalid_0's multi_logloss: 1.70813\n",
      "[44]\tvalid_0's multi_logloss: 1.7078\n",
      "[45]\tvalid_0's multi_logloss: 1.70748\n",
      "[46]\tvalid_0's multi_logloss: 1.7073\n",
      "[47]\tvalid_0's multi_logloss: 1.70702\n",
      "[48]\tvalid_0's multi_logloss: 1.70676\n",
      "[49]\tvalid_0's multi_logloss: 1.70658\n",
      "[50]\tvalid_0's multi_logloss: 1.70639\n",
      "[51]\tvalid_0's multi_logloss: 1.70622\n",
      "[52]\tvalid_0's multi_logloss: 1.70604\n",
      "[53]\tvalid_0's multi_logloss: 1.70589\n",
      "[54]\tvalid_0's multi_logloss: 1.70571\n",
      "[55]\tvalid_0's multi_logloss: 1.70553\n",
      "[56]\tvalid_0's multi_logloss: 1.70538\n",
      "[57]\tvalid_0's multi_logloss: 1.7052\n",
      "[58]\tvalid_0's multi_logloss: 1.70508\n",
      "[59]\tvalid_0's multi_logloss: 1.70489\n",
      "[60]\tvalid_0's multi_logloss: 1.70478\n",
      "[61]\tvalid_0's multi_logloss: 1.70469\n",
      "[62]\tvalid_0's multi_logloss: 1.70453\n",
      "[63]\tvalid_0's multi_logloss: 1.70442\n",
      "[64]\tvalid_0's multi_logloss: 1.70428\n",
      "[65]\tvalid_0's multi_logloss: 1.70409\n",
      "[66]\tvalid_0's multi_logloss: 1.70397\n",
      "[67]\tvalid_0's multi_logloss: 1.70385\n",
      "[68]\tvalid_0's multi_logloss: 1.70372\n",
      "[69]\tvalid_0's multi_logloss: 1.70359\n",
      "[70]\tvalid_0's multi_logloss: 1.70344\n",
      "[71]\tvalid_0's multi_logloss: 1.70336\n",
      "[72]\tvalid_0's multi_logloss: 1.70325\n",
      "[73]\tvalid_0's multi_logloss: 1.70318\n",
      "[74]\tvalid_0's multi_logloss: 1.70309\n",
      "[75]\tvalid_0's multi_logloss: 1.70295\n",
      "[76]\tvalid_0's multi_logloss: 1.70283\n",
      "[77]\tvalid_0's multi_logloss: 1.70277\n",
      "[78]\tvalid_0's multi_logloss: 1.7026\n",
      "[79]\tvalid_0's multi_logloss: 1.7025\n",
      "[80]\tvalid_0's multi_logloss: 1.7024\n",
      "[81]\tvalid_0's multi_logloss: 1.70231\n",
      "[82]\tvalid_0's multi_logloss: 1.70223\n",
      "[83]\tvalid_0's multi_logloss: 1.70218\n",
      "[84]\tvalid_0's multi_logloss: 1.70205\n",
      "[85]\tvalid_0's multi_logloss: 1.70194\n",
      "[86]\tvalid_0's multi_logloss: 1.70183\n",
      "[87]\tvalid_0's multi_logloss: 1.70178\n",
      "[88]\tvalid_0's multi_logloss: 1.70167\n",
      "[89]\tvalid_0's multi_logloss: 1.70159\n",
      "[90]\tvalid_0's multi_logloss: 1.70151\n",
      "[91]\tvalid_0's multi_logloss: 1.70144\n",
      "[92]\tvalid_0's multi_logloss: 1.70136\n",
      "[93]\tvalid_0's multi_logloss: 1.70127\n",
      "[94]\tvalid_0's multi_logloss: 1.70121\n",
      "[95]\tvalid_0's multi_logloss: 1.70118\n",
      "[96]\tvalid_0's multi_logloss: 1.70111\n",
      "[97]\tvalid_0's multi_logloss: 1.70103\n",
      "[98]\tvalid_0's multi_logloss: 1.70098\n",
      "[99]\tvalid_0's multi_logloss: 1.70094\n",
      "[100]\tvalid_0's multi_logloss: 1.70084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [12:37, 91.37s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025143 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -1.853404\n",
      "[LightGBM] [Info] Start training from score -2.123202\n",
      "[LightGBM] [Info] Start training from score -2.391862\n",
      "[LightGBM] [Info] Start training from score -2.719639\n",
      "[LightGBM] [Info] Start training from score -2.078311\n",
      "[LightGBM] [Info] Start training from score -2.161447\n",
      "[LightGBM] [Info] Start training from score -2.497610\n",
      "[LightGBM] [Info] Start training from score -2.232530\n",
      "[LightGBM] [Info] Start training from score -2.689447\n",
      "[LightGBM] [Info] Start training from score -2.680407\n",
      "[1]\tvalid_0's multi_logloss: 1.90465\n",
      "[2]\tvalid_0's multi_logloss: 1.72373\n",
      "[3]\tvalid_0's multi_logloss: 1.59601\n",
      "[4]\tvalid_0's multi_logloss: 1.49762\n",
      "[5]\tvalid_0's multi_logloss: 1.41971\n",
      "[6]\tvalid_0's multi_logloss: 1.35791\n",
      "[7]\tvalid_0's multi_logloss: 1.30629\n",
      "[8]\tvalid_0's multi_logloss: 1.2642\n",
      "[9]\tvalid_0's multi_logloss: 1.22848\n",
      "[10]\tvalid_0's multi_logloss: 1.19658\n",
      "[11]\tvalid_0's multi_logloss: 1.16862\n",
      "[12]\tvalid_0's multi_logloss: 1.14542\n",
      "[13]\tvalid_0's multi_logloss: 1.12523\n",
      "[14]\tvalid_0's multi_logloss: 1.10725\n",
      "[15]\tvalid_0's multi_logloss: 1.09128\n",
      "[16]\tvalid_0's multi_logloss: 1.07815\n",
      "[17]\tvalid_0's multi_logloss: 1.06603\n",
      "[18]\tvalid_0's multi_logloss: 1.05495\n",
      "[19]\tvalid_0's multi_logloss: 1.0449\n",
      "[20]\tvalid_0's multi_logloss: 1.03546\n",
      "[21]\tvalid_0's multi_logloss: 1.0272\n",
      "[22]\tvalid_0's multi_logloss: 1.01987\n",
      "[23]\tvalid_0's multi_logloss: 1.01339\n",
      "[24]\tvalid_0's multi_logloss: 1.00734\n",
      "[25]\tvalid_0's multi_logloss: 1.00182\n",
      "[26]\tvalid_0's multi_logloss: 0.996607\n",
      "[27]\tvalid_0's multi_logloss: 0.991626\n",
      "[28]\tvalid_0's multi_logloss: 0.987668\n",
      "[29]\tvalid_0's multi_logloss: 0.9835\n",
      "[30]\tvalid_0's multi_logloss: 0.979565\n",
      "[31]\tvalid_0's multi_logloss: 0.97632\n",
      "[32]\tvalid_0's multi_logloss: 0.973196\n",
      "[33]\tvalid_0's multi_logloss: 0.970023\n",
      "[34]\tvalid_0's multi_logloss: 0.967472\n",
      "[35]\tvalid_0's multi_logloss: 0.965176\n",
      "[36]\tvalid_0's multi_logloss: 0.962506\n",
      "[37]\tvalid_0's multi_logloss: 0.960506\n",
      "[38]\tvalid_0's multi_logloss: 0.958262\n",
      "[39]\tvalid_0's multi_logloss: 0.956588\n",
      "[40]\tvalid_0's multi_logloss: 0.954613\n",
      "[41]\tvalid_0's multi_logloss: 0.952817\n",
      "[42]\tvalid_0's multi_logloss: 0.950825\n",
      "[43]\tvalid_0's multi_logloss: 0.949134\n",
      "[44]\tvalid_0's multi_logloss: 0.94761\n",
      "[45]\tvalid_0's multi_logloss: 0.946184\n",
      "[46]\tvalid_0's multi_logloss: 0.944729\n",
      "[47]\tvalid_0's multi_logloss: 0.943347\n",
      "[48]\tvalid_0's multi_logloss: 0.941908\n",
      "[49]\tvalid_0's multi_logloss: 0.940656\n",
      "[50]\tvalid_0's multi_logloss: 0.939371\n",
      "[51]\tvalid_0's multi_logloss: 0.938225\n",
      "[52]\tvalid_0's multi_logloss: 0.9371\n",
      "[53]\tvalid_0's multi_logloss: 0.93604\n",
      "[54]\tvalid_0's multi_logloss: 0.934916\n",
      "[55]\tvalid_0's multi_logloss: 0.934025\n",
      "[56]\tvalid_0's multi_logloss: 0.933135\n",
      "[57]\tvalid_0's multi_logloss: 0.932058\n",
      "[58]\tvalid_0's multi_logloss: 0.93125\n",
      "[59]\tvalid_0's multi_logloss: 0.930361\n",
      "[60]\tvalid_0's multi_logloss: 0.929362\n",
      "[61]\tvalid_0's multi_logloss: 0.928658\n",
      "[62]\tvalid_0's multi_logloss: 0.927764\n",
      "[63]\tvalid_0's multi_logloss: 0.926883\n",
      "[64]\tvalid_0's multi_logloss: 0.925948\n",
      "[65]\tvalid_0's multi_logloss: 0.925221\n",
      "[66]\tvalid_0's multi_logloss: 0.924427\n",
      "[67]\tvalid_0's multi_logloss: 0.923705\n",
      "[68]\tvalid_0's multi_logloss: 0.923007\n",
      "[69]\tvalid_0's multi_logloss: 0.922265\n",
      "[70]\tvalid_0's multi_logloss: 0.921373\n",
      "[71]\tvalid_0's multi_logloss: 0.920769\n",
      "[72]\tvalid_0's multi_logloss: 0.920135\n",
      "[73]\tvalid_0's multi_logloss: 0.919274\n",
      "[74]\tvalid_0's multi_logloss: 0.918415\n",
      "[75]\tvalid_0's multi_logloss: 0.917685\n",
      "[76]\tvalid_0's multi_logloss: 0.916972\n",
      "[77]\tvalid_0's multi_logloss: 0.916405\n",
      "[78]\tvalid_0's multi_logloss: 0.915696\n",
      "[79]\tvalid_0's multi_logloss: 0.914948\n",
      "[80]\tvalid_0's multi_logloss: 0.914401\n",
      "[81]\tvalid_0's multi_logloss: 0.913822\n",
      "[82]\tvalid_0's multi_logloss: 0.91317\n",
      "[83]\tvalid_0's multi_logloss: 0.912457\n",
      "[84]\tvalid_0's multi_logloss: 0.911873\n",
      "[85]\tvalid_0's multi_logloss: 0.911335\n",
      "[86]\tvalid_0's multi_logloss: 0.910893\n",
      "[87]\tvalid_0's multi_logloss: 0.910323\n",
      "[88]\tvalid_0's multi_logloss: 0.909679\n",
      "[89]\tvalid_0's multi_logloss: 0.908985\n",
      "[90]\tvalid_0's multi_logloss: 0.908457\n",
      "[91]\tvalid_0's multi_logloss: 0.908006\n",
      "[92]\tvalid_0's multi_logloss: 0.907615\n",
      "[93]\tvalid_0's multi_logloss: 0.907051\n",
      "[94]\tvalid_0's multi_logloss: 0.906641\n",
      "[95]\tvalid_0's multi_logloss: 0.906149\n",
      "[96]\tvalid_0's multi_logloss: 0.905713\n",
      "[97]\tvalid_0's multi_logloss: 0.905169\n",
      "[98]\tvalid_0's multi_logloss: 0.904691\n",
      "[99]\tvalid_0's multi_logloss: 0.904198\n",
      "[100]\tvalid_0's multi_logloss: 0.903869\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017412 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -1.047228\n",
      "[LightGBM] [Info] Start training from score -1.516216\n",
      "[LightGBM] [Info] Start training from score -0.845018\n",
      "[1]\tvalid_0's multi_logloss: 1.01119\n",
      "[2]\tvalid_0's multi_logloss: 0.968592\n",
      "[3]\tvalid_0's multi_logloss: 0.933293\n",
      "[4]\tvalid_0's multi_logloss: 0.902797\n",
      "[5]\tvalid_0's multi_logloss: 0.876658\n",
      "[6]\tvalid_0's multi_logloss: 0.854597\n",
      "[7]\tvalid_0's multi_logloss: 0.835446\n",
      "[8]\tvalid_0's multi_logloss: 0.818821\n",
      "[9]\tvalid_0's multi_logloss: 0.803953\n",
      "[10]\tvalid_0's multi_logloss: 0.790739\n",
      "[11]\tvalid_0's multi_logloss: 0.778875\n",
      "[12]\tvalid_0's multi_logloss: 0.768502\n",
      "[13]\tvalid_0's multi_logloss: 0.759377\n",
      "[14]\tvalid_0's multi_logloss: 0.750909\n",
      "[15]\tvalid_0's multi_logloss: 0.743379\n",
      "[16]\tvalid_0's multi_logloss: 0.73644\n",
      "[17]\tvalid_0's multi_logloss: 0.730213\n",
      "[18]\tvalid_0's multi_logloss: 0.724497\n",
      "[19]\tvalid_0's multi_logloss: 0.719326\n",
      "[20]\tvalid_0's multi_logloss: 0.714577\n",
      "[21]\tvalid_0's multi_logloss: 0.710279\n",
      "[22]\tvalid_0's multi_logloss: 0.706252\n",
      "[23]\tvalid_0's multi_logloss: 0.70275\n",
      "[24]\tvalid_0's multi_logloss: 0.699305\n",
      "[25]\tvalid_0's multi_logloss: 0.696226\n",
      "[26]\tvalid_0's multi_logloss: 0.693354\n",
      "[27]\tvalid_0's multi_logloss: 0.690719\n",
      "[28]\tvalid_0's multi_logloss: 0.68832\n",
      "[29]\tvalid_0's multi_logloss: 0.686096\n",
      "[30]\tvalid_0's multi_logloss: 0.684033\n",
      "[31]\tvalid_0's multi_logloss: 0.682072\n",
      "[32]\tvalid_0's multi_logloss: 0.680216\n",
      "[33]\tvalid_0's multi_logloss: 0.678432\n",
      "[34]\tvalid_0's multi_logloss: 0.676863\n",
      "[35]\tvalid_0's multi_logloss: 0.675277\n",
      "[36]\tvalid_0's multi_logloss: 0.673903\n",
      "[37]\tvalid_0's multi_logloss: 0.672512\n",
      "[38]\tvalid_0's multi_logloss: 0.67128\n",
      "[39]\tvalid_0's multi_logloss: 0.670182\n",
      "[40]\tvalid_0's multi_logloss: 0.669076\n",
      "[41]\tvalid_0's multi_logloss: 0.668102\n",
      "[42]\tvalid_0's multi_logloss: 0.667154\n",
      "[43]\tvalid_0's multi_logloss: 0.666226\n",
      "[44]\tvalid_0's multi_logloss: 0.665353\n",
      "[45]\tvalid_0's multi_logloss: 0.664557\n",
      "[46]\tvalid_0's multi_logloss: 0.663781\n",
      "[47]\tvalid_0's multi_logloss: 0.663007\n",
      "[48]\tvalid_0's multi_logloss: 0.662357\n",
      "[49]\tvalid_0's multi_logloss: 0.661713\n",
      "[50]\tvalid_0's multi_logloss: 0.661092\n",
      "[51]\tvalid_0's multi_logloss: 0.660577\n",
      "[52]\tvalid_0's multi_logloss: 0.660044\n",
      "[53]\tvalid_0's multi_logloss: 0.659574\n",
      "[54]\tvalid_0's multi_logloss: 0.659155\n",
      "[55]\tvalid_0's multi_logloss: 0.658747\n",
      "[56]\tvalid_0's multi_logloss: 0.658341\n",
      "[57]\tvalid_0's multi_logloss: 0.657947\n",
      "[58]\tvalid_0's multi_logloss: 0.657535\n",
      "[59]\tvalid_0's multi_logloss: 0.657163\n",
      "[60]\tvalid_0's multi_logloss: 0.656812\n",
      "[61]\tvalid_0's multi_logloss: 0.656473\n",
      "[62]\tvalid_0's multi_logloss: 0.656117\n",
      "[63]\tvalid_0's multi_logloss: 0.655816\n",
      "[64]\tvalid_0's multi_logloss: 0.655568\n",
      "[65]\tvalid_0's multi_logloss: 0.655294\n",
      "[66]\tvalid_0's multi_logloss: 0.655041\n",
      "[67]\tvalid_0's multi_logloss: 0.65479\n",
      "[68]\tvalid_0's multi_logloss: 0.65453\n",
      "[69]\tvalid_0's multi_logloss: 0.654302\n",
      "[70]\tvalid_0's multi_logloss: 0.654098\n",
      "[71]\tvalid_0's multi_logloss: 0.653898\n",
      "[72]\tvalid_0's multi_logloss: 0.653712\n",
      "[73]\tvalid_0's multi_logloss: 0.653534\n",
      "[74]\tvalid_0's multi_logloss: 0.653355\n",
      "[75]\tvalid_0's multi_logloss: 0.653164\n",
      "[76]\tvalid_0's multi_logloss: 0.653001\n",
      "[77]\tvalid_0's multi_logloss: 0.652852\n",
      "[78]\tvalid_0's multi_logloss: 0.652699\n",
      "[79]\tvalid_0's multi_logloss: 0.652522\n",
      "[80]\tvalid_0's multi_logloss: 0.652378\n",
      "[81]\tvalid_0's multi_logloss: 0.652236\n",
      "[82]\tvalid_0's multi_logloss: 0.652098\n",
      "[83]\tvalid_0's multi_logloss: 0.651997\n",
      "[84]\tvalid_0's multi_logloss: 0.65182\n",
      "[85]\tvalid_0's multi_logloss: 0.651701\n",
      "[86]\tvalid_0's multi_logloss: 0.65161\n",
      "[87]\tvalid_0's multi_logloss: 0.651506\n",
      "[88]\tvalid_0's multi_logloss: 0.651364\n",
      "[89]\tvalid_0's multi_logloss: 0.651248\n",
      "[90]\tvalid_0's multi_logloss: 0.651159\n",
      "[91]\tvalid_0's multi_logloss: 0.65105\n",
      "[92]\tvalid_0's multi_logloss: 0.650924\n",
      "[93]\tvalid_0's multi_logloss: 0.650845\n",
      "[94]\tvalid_0's multi_logloss: 0.650766\n",
      "[95]\tvalid_0's multi_logloss: 0.650682\n",
      "[96]\tvalid_0's multi_logloss: 0.650622\n",
      "[97]\tvalid_0's multi_logloss: 0.650544\n",
      "[98]\tvalid_0's multi_logloss: 0.650468\n",
      "[99]\tvalid_0's multi_logloss: 0.650372\n",
      "[100]\tvalid_0's multi_logloss: 0.650278\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -3.244539\n",
      "[LightGBM] [Info] Start training from score -3.224920\n",
      "[LightGBM] [Info] Start training from score -3.369880\n",
      "[LightGBM] [Info] Start training from score -3.326941\n",
      "[LightGBM] [Info] Start training from score -3.378266\n",
      "[LightGBM] [Info] Start training from score -2.568017\n",
      "[LightGBM] [Info] Start training from score -1.914747\n",
      "[LightGBM] [Info] Start training from score -3.469579\n",
      "[LightGBM] [Info] Start training from score -1.919436\n",
      "[LightGBM] [Info] Start training from score -2.291576\n",
      "[LightGBM] [Info] Start training from score -2.007538\n",
      "[LightGBM] [Info] Start training from score -3.402200\n",
      "[LightGBM] [Info] Start training from score -3.212376\n",
      "[LightGBM] [Info] Start training from score -2.244521\n",
      "[1]\tvalid_0's multi_logloss: 2.38761\n",
      "[2]\tvalid_0's multi_logloss: 2.34068\n",
      "[3]\tvalid_0's multi_logloss: 2.30519\n",
      "[4]\tvalid_0's multi_logloss: 2.27689\n",
      "[5]\tvalid_0's multi_logloss: 2.2538\n",
      "[6]\tvalid_0's multi_logloss: 2.2344\n",
      "[7]\tvalid_0's multi_logloss: 2.21814\n",
      "[8]\tvalid_0's multi_logloss: 2.20423\n",
      "[9]\tvalid_0's multi_logloss: 2.1923\n",
      "[10]\tvalid_0's multi_logloss: 2.18175\n",
      "[11]\tvalid_0's multi_logloss: 2.17226\n",
      "[12]\tvalid_0's multi_logloss: 2.16368\n",
      "[13]\tvalid_0's multi_logloss: 2.15649\n",
      "[14]\tvalid_0's multi_logloss: 2.14968\n",
      "[15]\tvalid_0's multi_logloss: 2.14387\n",
      "[16]\tvalid_0's multi_logloss: 2.1386\n",
      "[17]\tvalid_0's multi_logloss: 2.13412\n",
      "[18]\tvalid_0's multi_logloss: 2.12953\n",
      "[19]\tvalid_0's multi_logloss: 2.12553\n",
      "[20]\tvalid_0's multi_logloss: 2.12195\n",
      "[21]\tvalid_0's multi_logloss: 2.11841\n",
      "[22]\tvalid_0's multi_logloss: 2.11486\n",
      "[23]\tvalid_0's multi_logloss: 2.11211\n",
      "[24]\tvalid_0's multi_logloss: 2.10943\n",
      "[25]\tvalid_0's multi_logloss: 2.10695\n",
      "[26]\tvalid_0's multi_logloss: 2.10445\n",
      "[27]\tvalid_0's multi_logloss: 2.1024\n",
      "[28]\tvalid_0's multi_logloss: 2.10047\n",
      "[29]\tvalid_0's multi_logloss: 2.09835\n",
      "[30]\tvalid_0's multi_logloss: 2.09673\n",
      "[31]\tvalid_0's multi_logloss: 2.09499\n",
      "[32]\tvalid_0's multi_logloss: 2.09335\n",
      "[33]\tvalid_0's multi_logloss: 2.09192\n",
      "[34]\tvalid_0's multi_logloss: 2.09044\n",
      "[35]\tvalid_0's multi_logloss: 2.08894\n",
      "[36]\tvalid_0's multi_logloss: 2.08775\n",
      "[37]\tvalid_0's multi_logloss: 2.08663\n",
      "[38]\tvalid_0's multi_logloss: 2.08562\n",
      "[39]\tvalid_0's multi_logloss: 2.08457\n",
      "[40]\tvalid_0's multi_logloss: 2.08357\n",
      "[41]\tvalid_0's multi_logloss: 2.08268\n",
      "[42]\tvalid_0's multi_logloss: 2.08168\n",
      "[43]\tvalid_0's multi_logloss: 2.08064\n",
      "[44]\tvalid_0's multi_logloss: 2.07974\n",
      "[45]\tvalid_0's multi_logloss: 2.07873\n",
      "[46]\tvalid_0's multi_logloss: 2.07792\n",
      "[47]\tvalid_0's multi_logloss: 2.07698\n",
      "[48]\tvalid_0's multi_logloss: 2.07618\n",
      "[49]\tvalid_0's multi_logloss: 2.07542\n",
      "[50]\tvalid_0's multi_logloss: 2.07452\n",
      "[51]\tvalid_0's multi_logloss: 2.07376\n",
      "[52]\tvalid_0's multi_logloss: 2.07312\n",
      "[53]\tvalid_0's multi_logloss: 2.07245\n",
      "[54]\tvalid_0's multi_logloss: 2.07177\n",
      "[55]\tvalid_0's multi_logloss: 2.07107\n",
      "[56]\tvalid_0's multi_logloss: 2.07055\n",
      "[57]\tvalid_0's multi_logloss: 2.06998\n",
      "[58]\tvalid_0's multi_logloss: 2.06948\n",
      "[59]\tvalid_0's multi_logloss: 2.0688\n",
      "[60]\tvalid_0's multi_logloss: 2.06827\n",
      "[61]\tvalid_0's multi_logloss: 2.06777\n",
      "[62]\tvalid_0's multi_logloss: 2.06715\n",
      "[63]\tvalid_0's multi_logloss: 2.06663\n",
      "[64]\tvalid_0's multi_logloss: 2.06617\n",
      "[65]\tvalid_0's multi_logloss: 2.0656\n",
      "[66]\tvalid_0's multi_logloss: 2.06502\n",
      "[67]\tvalid_0's multi_logloss: 2.06456\n",
      "[68]\tvalid_0's multi_logloss: 2.06411\n",
      "[69]\tvalid_0's multi_logloss: 2.06361\n",
      "[70]\tvalid_0's multi_logloss: 2.06325\n",
      "[71]\tvalid_0's multi_logloss: 2.06277\n",
      "[72]\tvalid_0's multi_logloss: 2.06232\n",
      "[73]\tvalid_0's multi_logloss: 2.06192\n",
      "[74]\tvalid_0's multi_logloss: 2.06151\n",
      "[75]\tvalid_0's multi_logloss: 2.06105\n",
      "[76]\tvalid_0's multi_logloss: 2.06063\n",
      "[77]\tvalid_0's multi_logloss: 2.06022\n",
      "[78]\tvalid_0's multi_logloss: 2.05982\n",
      "[79]\tvalid_0's multi_logloss: 2.05943\n",
      "[80]\tvalid_0's multi_logloss: 2.05907\n",
      "[81]\tvalid_0's multi_logloss: 2.05871\n",
      "[82]\tvalid_0's multi_logloss: 2.05831\n",
      "[83]\tvalid_0's multi_logloss: 2.05792\n",
      "[84]\tvalid_0's multi_logloss: 2.05753\n",
      "[85]\tvalid_0's multi_logloss: 2.05727\n",
      "[86]\tvalid_0's multi_logloss: 2.05689\n",
      "[87]\tvalid_0's multi_logloss: 2.0565\n",
      "[88]\tvalid_0's multi_logloss: 2.05628\n",
      "[89]\tvalid_0's multi_logloss: 2.05599\n",
      "[90]\tvalid_0's multi_logloss: 2.05569\n",
      "[91]\tvalid_0's multi_logloss: 2.05542\n",
      "[92]\tvalid_0's multi_logloss: 2.0551\n",
      "[93]\tvalid_0's multi_logloss: 2.05483\n",
      "[94]\tvalid_0's multi_logloss: 2.05457\n",
      "[95]\tvalid_0's multi_logloss: 2.05434\n",
      "[96]\tvalid_0's multi_logloss: 2.0541\n",
      "[97]\tvalid_0's multi_logloss: 2.05382\n",
      "[98]\tvalid_0's multi_logloss: 2.05361\n",
      "[99]\tvalid_0's multi_logloss: 2.05335\n",
      "[100]\tvalid_0's multi_logloss: 2.05301\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018588 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -0.501622\n",
      "[LightGBM] [Info] Start training from score -0.930257\n",
      "[1]\tvalid_0's multi_logloss: 0.576573\n",
      "[2]\tvalid_0's multi_logloss: 0.50071\n",
      "[3]\tvalid_0's multi_logloss: 0.438039\n",
      "[4]\tvalid_0's multi_logloss: 0.385235\n",
      "[5]\tvalid_0's multi_logloss: 0.3405\n",
      "[6]\tvalid_0's multi_logloss: 0.301907\n",
      "[7]\tvalid_0's multi_logloss: 0.268461\n",
      "[8]\tvalid_0's multi_logloss: 0.23932\n",
      "[9]\tvalid_0's multi_logloss: 0.213883\n",
      "[10]\tvalid_0's multi_logloss: 0.191437\n",
      "[11]\tvalid_0's multi_logloss: 0.171563\n",
      "[12]\tvalid_0's multi_logloss: 0.154175\n",
      "[13]\tvalid_0's multi_logloss: 0.13856\n",
      "[14]\tvalid_0's multi_logloss: 0.124716\n",
      "[15]\tvalid_0's multi_logloss: 0.11233\n",
      "[16]\tvalid_0's multi_logloss: 0.101279\n",
      "[17]\tvalid_0's multi_logloss: 0.0913835\n",
      "[18]\tvalid_0's multi_logloss: 0.0825158\n",
      "[19]\tvalid_0's multi_logloss: 0.0745801\n",
      "[20]\tvalid_0's multi_logloss: 0.0674558\n",
      "[21]\tvalid_0's multi_logloss: 0.0610716\n",
      "[22]\tvalid_0's multi_logloss: 0.0553206\n",
      "[23]\tvalid_0's multi_logloss: 0.0501565\n",
      "[24]\tvalid_0's multi_logloss: 0.0455085\n",
      "[25]\tvalid_0's multi_logloss: 0.0413253\n",
      "[26]\tvalid_0's multi_logloss: 0.0375582\n",
      "[27]\tvalid_0's multi_logloss: 0.0341368\n",
      "[28]\tvalid_0's multi_logloss: 0.0310381\n",
      "[29]\tvalid_0's multi_logloss: 0.0282699\n",
      "[30]\tvalid_0's multi_logloss: 0.0257926\n",
      "[31]\tvalid_0's multi_logloss: 0.0235385\n",
      "[32]\tvalid_0's multi_logloss: 0.0215085\n",
      "[33]\tvalid_0's multi_logloss: 0.0196686\n",
      "[34]\tvalid_0's multi_logloss: 0.0180159\n",
      "[35]\tvalid_0's multi_logloss: 0.0165254\n",
      "[36]\tvalid_0's multi_logloss: 0.0151799\n",
      "[37]\tvalid_0's multi_logloss: 0.0139534\n",
      "[38]\tvalid_0's multi_logloss: 0.0128418\n",
      "[39]\tvalid_0's multi_logloss: 0.0118481\n",
      "[40]\tvalid_0's multi_logloss: 0.010937\n",
      "[41]\tvalid_0's multi_logloss: 0.010131\n",
      "[42]\tvalid_0's multi_logloss: 0.00940343\n",
      "[43]\tvalid_0's multi_logloss: 0.00874362\n",
      "[44]\tvalid_0's multi_logloss: 0.00814676\n",
      "[45]\tvalid_0's multi_logloss: 0.00761096\n",
      "[46]\tvalid_0's multi_logloss: 0.00712632\n",
      "[47]\tvalid_0's multi_logloss: 0.00669243\n",
      "[48]\tvalid_0's multi_logloss: 0.00630208\n",
      "[49]\tvalid_0's multi_logloss: 0.00592729\n",
      "[50]\tvalid_0's multi_logloss: 0.0056043\n",
      "[51]\tvalid_0's multi_logloss: 0.00531613\n",
      "[52]\tvalid_0's multi_logloss: 0.00505671\n",
      "[53]\tvalid_0's multi_logloss: 0.00481441\n",
      "[54]\tvalid_0's multi_logloss: 0.00459598\n",
      "[55]\tvalid_0's multi_logloss: 0.00440215\n",
      "[56]\tvalid_0's multi_logloss: 0.00423665\n",
      "[57]\tvalid_0's multi_logloss: 0.00407562\n",
      "[58]\tvalid_0's multi_logloss: 0.00392958\n",
      "[59]\tvalid_0's multi_logloss: 0.00380761\n",
      "[60]\tvalid_0's multi_logloss: 0.00368846\n",
      "[61]\tvalid_0's multi_logloss: 0.00358276\n",
      "[62]\tvalid_0's multi_logloss: 0.0034837\n",
      "[63]\tvalid_0's multi_logloss: 0.00339941\n",
      "[64]\tvalid_0's multi_logloss: 0.00331778\n",
      "[65]\tvalid_0's multi_logloss: 0.00324399\n",
      "[66]\tvalid_0's multi_logloss: 0.00317714\n",
      "[67]\tvalid_0's multi_logloss: 0.00311542\n",
      "[68]\tvalid_0's multi_logloss: 0.00306205\n",
      "[69]\tvalid_0's multi_logloss: 0.00301145\n",
      "[70]\tvalid_0's multi_logloss: 0.00296684\n",
      "[71]\tvalid_0's multi_logloss: 0.00293412\n",
      "[72]\tvalid_0's multi_logloss: 0.00289698\n",
      "[73]\tvalid_0's multi_logloss: 0.00286481\n",
      "[74]\tvalid_0's multi_logloss: 0.00283384\n",
      "[75]\tvalid_0's multi_logloss: 0.00280621\n",
      "[76]\tvalid_0's multi_logloss: 0.00281166\n",
      "[77]\tvalid_0's multi_logloss: 0.00279552\n",
      "[78]\tvalid_0's multi_logloss: 0.00277382\n",
      "[79]\tvalid_0's multi_logloss: 0.00273864\n",
      "[80]\tvalid_0's multi_logloss: 0.0027538\n",
      "[81]\tvalid_0's multi_logloss: 0.00273696\n",
      "[82]\tvalid_0's multi_logloss: 0.00272188\n",
      "[83]\tvalid_0's multi_logloss: 0.00271755\n",
      "[84]\tvalid_0's multi_logloss: 0.00269558\n",
      "[85]\tvalid_0's multi_logloss: 0.00265612\n",
      "[86]\tvalid_0's multi_logloss: 0.00268412\n",
      "[87]\tvalid_0's multi_logloss: 0.0027413\n",
      "[88]\tvalid_0's multi_logloss: 0.00268196\n",
      "[89]\tvalid_0's multi_logloss: 0.00268534\n",
      "[90]\tvalid_0's multi_logloss: 0.00266738\n",
      "[91]\tvalid_0's multi_logloss: 0.00272869\n",
      "[92]\tvalid_0's multi_logloss: 0.00272006\n",
      "[93]\tvalid_0's multi_logloss: 0.00272341\n",
      "[94]\tvalid_0's multi_logloss: 0.00268039\n",
      "[95]\tvalid_0's multi_logloss: 0.00264614\n",
      "[96]\tvalid_0's multi_logloss: 0.00269216\n",
      "[97]\tvalid_0's multi_logloss: 0.0027642\n",
      "[98]\tvalid_0's multi_logloss: 0.00264681\n",
      "[99]\tvalid_0's multi_logloss: 0.00264118\n",
      "[100]\tvalid_0's multi_logloss: 0.00267498\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016580 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -0.141837\n",
      "[LightGBM] [Info] Start training from score -2.023158\n",
      "[1]\tvalid_0's multi_logloss: 0.346088\n",
      "[2]\tvalid_0's multi_logloss: 0.318481\n",
      "[3]\tvalid_0's multi_logloss: 0.297048\n",
      "[4]\tvalid_0's multi_logloss: 0.280621\n",
      "[5]\tvalid_0's multi_logloss: 0.266857\n",
      "[6]\tvalid_0's multi_logloss: 0.255453\n",
      "[7]\tvalid_0's multi_logloss: 0.245642\n",
      "[8]\tvalid_0's multi_logloss: 0.237234\n",
      "[9]\tvalid_0's multi_logloss: 0.229835\n",
      "[10]\tvalid_0's multi_logloss: 0.223537\n",
      "[11]\tvalid_0's multi_logloss: 0.218315\n",
      "[12]\tvalid_0's multi_logloss: 0.213632\n",
      "[13]\tvalid_0's multi_logloss: 0.209515\n",
      "[14]\tvalid_0's multi_logloss: 0.205164\n",
      "[15]\tvalid_0's multi_logloss: 0.201295\n",
      "[16]\tvalid_0's multi_logloss: 0.197986\n",
      "[17]\tvalid_0's multi_logloss: 0.195005\n",
      "[18]\tvalid_0's multi_logloss: 0.192384\n",
      "[19]\tvalid_0's multi_logloss: 0.190202\n",
      "[20]\tvalid_0's multi_logloss: 0.187839\n",
      "[21]\tvalid_0's multi_logloss: 0.185746\n",
      "[22]\tvalid_0's multi_logloss: 0.183956\n",
      "[23]\tvalid_0's multi_logloss: 0.182292\n",
      "[24]\tvalid_0's multi_logloss: 0.180824\n",
      "[25]\tvalid_0's multi_logloss: 0.179674\n",
      "[26]\tvalid_0's multi_logloss: 0.178428\n",
      "[27]\tvalid_0's multi_logloss: 0.177506\n",
      "[28]\tvalid_0's multi_logloss: 0.176567\n",
      "[29]\tvalid_0's multi_logloss: 0.175641\n",
      "[30]\tvalid_0's multi_logloss: 0.174592\n",
      "[31]\tvalid_0's multi_logloss: 0.173824\n",
      "[32]\tvalid_0's multi_logloss: 0.172767\n",
      "[33]\tvalid_0's multi_logloss: 0.172101\n",
      "[34]\tvalid_0's multi_logloss: 0.171298\n",
      "[35]\tvalid_0's multi_logloss: 0.170548\n",
      "[36]\tvalid_0's multi_logloss: 0.169982\n",
      "[37]\tvalid_0's multi_logloss: 0.169546\n",
      "[38]\tvalid_0's multi_logloss: 0.169065\n",
      "[39]\tvalid_0's multi_logloss: 0.168583\n",
      "[40]\tvalid_0's multi_logloss: 0.167942\n",
      "[41]\tvalid_0's multi_logloss: 0.167367\n",
      "[42]\tvalid_0's multi_logloss: 0.167005\n",
      "[43]\tvalid_0's multi_logloss: 0.166669\n",
      "[44]\tvalid_0's multi_logloss: 0.166278\n",
      "[45]\tvalid_0's multi_logloss: 0.16587\n",
      "[46]\tvalid_0's multi_logloss: 0.165508\n",
      "[47]\tvalid_0's multi_logloss: 0.165012\n",
      "[48]\tvalid_0's multi_logloss: 0.164743\n",
      "[49]\tvalid_0's multi_logloss: 0.164118\n",
      "[50]\tvalid_0's multi_logloss: 0.163676\n",
      "[51]\tvalid_0's multi_logloss: 0.163423\n",
      "[52]\tvalid_0's multi_logloss: 0.163032\n",
      "[53]\tvalid_0's multi_logloss: 0.162586\n",
      "[54]\tvalid_0's multi_logloss: 0.162314\n",
      "[55]\tvalid_0's multi_logloss: 0.161923\n",
      "[56]\tvalid_0's multi_logloss: 0.161641\n",
      "[57]\tvalid_0's multi_logloss: 0.161365\n",
      "[58]\tvalid_0's multi_logloss: 0.161102\n",
      "[59]\tvalid_0's multi_logloss: 0.160668\n",
      "[60]\tvalid_0's multi_logloss: 0.160363\n",
      "[61]\tvalid_0's multi_logloss: 0.160207\n",
      "[62]\tvalid_0's multi_logloss: 0.160061\n",
      "[63]\tvalid_0's multi_logloss: 0.159708\n",
      "[64]\tvalid_0's multi_logloss: 0.15938\n",
      "[65]\tvalid_0's multi_logloss: 0.159178\n",
      "[66]\tvalid_0's multi_logloss: 0.15903\n",
      "[67]\tvalid_0's multi_logloss: 0.158598\n",
      "[68]\tvalid_0's multi_logloss: 0.158327\n",
      "[69]\tvalid_0's multi_logloss: 0.158215\n",
      "[70]\tvalid_0's multi_logloss: 0.157967\n",
      "[71]\tvalid_0's multi_logloss: 0.157777\n",
      "[72]\tvalid_0's multi_logloss: 0.157562\n",
      "[73]\tvalid_0's multi_logloss: 0.157417\n",
      "[74]\tvalid_0's multi_logloss: 0.15725\n",
      "[75]\tvalid_0's multi_logloss: 0.156954\n",
      "[76]\tvalid_0's multi_logloss: 0.156717\n",
      "[77]\tvalid_0's multi_logloss: 0.156599\n",
      "[78]\tvalid_0's multi_logloss: 0.156413\n",
      "[79]\tvalid_0's multi_logloss: 0.156183\n",
      "[80]\tvalid_0's multi_logloss: 0.155914\n",
      "[81]\tvalid_0's multi_logloss: 0.155707\n",
      "[82]\tvalid_0's multi_logloss: 0.155491\n",
      "[83]\tvalid_0's multi_logloss: 0.155299\n",
      "[84]\tvalid_0's multi_logloss: 0.155097\n",
      "[85]\tvalid_0's multi_logloss: 0.155024\n",
      "[86]\tvalid_0's multi_logloss: 0.154837\n",
      "[87]\tvalid_0's multi_logloss: 0.154746\n",
      "[88]\tvalid_0's multi_logloss: 0.154661\n",
      "[89]\tvalid_0's multi_logloss: 0.154534\n",
      "[90]\tvalid_0's multi_logloss: 0.154358\n",
      "[91]\tvalid_0's multi_logloss: 0.154174\n",
      "[92]\tvalid_0's multi_logloss: 0.154124\n",
      "[93]\tvalid_0's multi_logloss: 0.154049\n",
      "[94]\tvalid_0's multi_logloss: 0.153974\n",
      "[95]\tvalid_0's multi_logloss: 0.153818\n",
      "[96]\tvalid_0's multi_logloss: 0.153637\n",
      "[97]\tvalid_0's multi_logloss: 0.153469\n",
      "[98]\tvalid_0's multi_logloss: 0.153315\n",
      "[99]\tvalid_0's multi_logloss: 0.153205\n",
      "[100]\tvalid_0's multi_logloss: 0.153037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [16:27, 136.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007975 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 7715638, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -1.249550\n",
      "[LightGBM] [Info] Start training from score -3.165534\n",
      "[LightGBM] [Info] Start training from score -1.726403\n",
      "[LightGBM] [Info] Start training from score -1.902421\n",
      "[LightGBM] [Info] Start training from score -1.667720\n",
      "[LightGBM] [Info] Start training from score -1.861961\n",
      "[1]\tvalid_0's multi_logloss: 1.6774\n",
      "[2]\tvalid_0's multi_logloss: 1.6703\n",
      "[3]\tvalid_0's multi_logloss: 1.6646\n",
      "[4]\tvalid_0's multi_logloss: 1.65994\n",
      "[5]\tvalid_0's multi_logloss: 1.65595\n",
      "[6]\tvalid_0's multi_logloss: 1.65267\n",
      "[7]\tvalid_0's multi_logloss: 1.64997\n",
      "[8]\tvalid_0's multi_logloss: 1.64742\n",
      "[9]\tvalid_0's multi_logloss: 1.64538\n",
      "[10]\tvalid_0's multi_logloss: 1.6435\n",
      "[11]\tvalid_0's multi_logloss: 1.64184\n",
      "[12]\tvalid_0's multi_logloss: 1.64031\n",
      "[13]\tvalid_0's multi_logloss: 1.63894\n",
      "[14]\tvalid_0's multi_logloss: 1.63762\n",
      "[15]\tvalid_0's multi_logloss: 1.63653\n",
      "[16]\tvalid_0's multi_logloss: 1.63544\n",
      "[17]\tvalid_0's multi_logloss: 1.63439\n",
      "[18]\tvalid_0's multi_logloss: 1.63348\n",
      "[19]\tvalid_0's multi_logloss: 1.63245\n",
      "[20]\tvalid_0's multi_logloss: 1.63167\n",
      "[21]\tvalid_0's multi_logloss: 1.6309\n",
      "[22]\tvalid_0's multi_logloss: 1.63014\n",
      "[23]\tvalid_0's multi_logloss: 1.62951\n",
      "[24]\tvalid_0's multi_logloss: 1.62895\n",
      "[25]\tvalid_0's multi_logloss: 1.62841\n",
      "[26]\tvalid_0's multi_logloss: 1.62775\n",
      "[27]\tvalid_0's multi_logloss: 1.62708\n",
      "[28]\tvalid_0's multi_logloss: 1.62651\n",
      "[29]\tvalid_0's multi_logloss: 1.62591\n",
      "[30]\tvalid_0's multi_logloss: 1.62545\n",
      "[31]\tvalid_0's multi_logloss: 1.62504\n",
      "[32]\tvalid_0's multi_logloss: 1.6246\n",
      "[33]\tvalid_0's multi_logloss: 1.62418\n",
      "[34]\tvalid_0's multi_logloss: 1.62379\n",
      "[35]\tvalid_0's multi_logloss: 1.62342\n",
      "[36]\tvalid_0's multi_logloss: 1.62308\n",
      "[37]\tvalid_0's multi_logloss: 1.62276\n",
      "[38]\tvalid_0's multi_logloss: 1.62234\n",
      "[39]\tvalid_0's multi_logloss: 1.62195\n",
      "[40]\tvalid_0's multi_logloss: 1.62166\n",
      "[41]\tvalid_0's multi_logloss: 1.62128\n",
      "[42]\tvalid_0's multi_logloss: 1.62097\n",
      "[43]\tvalid_0's multi_logloss: 1.62069\n",
      "[44]\tvalid_0's multi_logloss: 1.62039\n",
      "[45]\tvalid_0's multi_logloss: 1.62014\n",
      "[46]\tvalid_0's multi_logloss: 1.61971\n",
      "[47]\tvalid_0's multi_logloss: 1.61949\n",
      "[48]\tvalid_0's multi_logloss: 1.61923\n",
      "[49]\tvalid_0's multi_logloss: 1.61899\n",
      "[50]\tvalid_0's multi_logloss: 1.61877\n",
      "[51]\tvalid_0's multi_logloss: 1.61854\n",
      "[52]\tvalid_0's multi_logloss: 1.61831\n",
      "[53]\tvalid_0's multi_logloss: 1.6181\n",
      "[54]\tvalid_0's multi_logloss: 1.61778\n",
      "[55]\tvalid_0's multi_logloss: 1.61758\n",
      "[56]\tvalid_0's multi_logloss: 1.6173\n",
      "[57]\tvalid_0's multi_logloss: 1.61709\n",
      "[58]\tvalid_0's multi_logloss: 1.6169\n",
      "[59]\tvalid_0's multi_logloss: 1.61663\n",
      "[60]\tvalid_0's multi_logloss: 1.61637\n",
      "[61]\tvalid_0's multi_logloss: 1.61619\n",
      "[62]\tvalid_0's multi_logloss: 1.61595\n",
      "[63]\tvalid_0's multi_logloss: 1.61568\n",
      "[64]\tvalid_0's multi_logloss: 1.61552\n",
      "[65]\tvalid_0's multi_logloss: 1.61528\n",
      "[66]\tvalid_0's multi_logloss: 1.61512\n",
      "[67]\tvalid_0's multi_logloss: 1.61497\n",
      "[68]\tvalid_0's multi_logloss: 1.61477\n",
      "[69]\tvalid_0's multi_logloss: 1.61458\n",
      "[70]\tvalid_0's multi_logloss: 1.61445\n",
      "[71]\tvalid_0's multi_logloss: 1.61432\n",
      "[72]\tvalid_0's multi_logloss: 1.61409\n",
      "[73]\tvalid_0's multi_logloss: 1.61396\n",
      "[74]\tvalid_0's multi_logloss: 1.61383\n",
      "[75]\tvalid_0's multi_logloss: 1.61367\n",
      "[76]\tvalid_0's multi_logloss: 1.61345\n",
      "[77]\tvalid_0's multi_logloss: 1.61324\n",
      "[78]\tvalid_0's multi_logloss: 1.61306\n",
      "[79]\tvalid_0's multi_logloss: 1.61294\n",
      "[80]\tvalid_0's multi_logloss: 1.61279\n",
      "[81]\tvalid_0's multi_logloss: 1.61264\n",
      "[82]\tvalid_0's multi_logloss: 1.61245\n",
      "[83]\tvalid_0's multi_logloss: 1.61231\n",
      "[84]\tvalid_0's multi_logloss: 1.6122\n",
      "[85]\tvalid_0's multi_logloss: 1.61203\n",
      "[86]\tvalid_0's multi_logloss: 1.6119\n",
      "[87]\tvalid_0's multi_logloss: 1.61173\n",
      "[88]\tvalid_0's multi_logloss: 1.61158\n",
      "[89]\tvalid_0's multi_logloss: 1.61145\n",
      "[90]\tvalid_0's multi_logloss: 1.61129\n",
      "[91]\tvalid_0's multi_logloss: 1.61114\n",
      "[92]\tvalid_0's multi_logloss: 1.61097\n",
      "[93]\tvalid_0's multi_logloss: 1.61083\n",
      "[94]\tvalid_0's multi_logloss: 1.6107\n",
      "[95]\tvalid_0's multi_logloss: 1.61058\n",
      "[96]\tvalid_0's multi_logloss: 1.61048\n",
      "[97]\tvalid_0's multi_logloss: 1.61039\n",
      "[98]\tvalid_0's multi_logloss: 1.61027\n",
      "[99]\tvalid_0's multi_logloss: 1.61012\n",
      "[100]\tvalid_0's multi_logloss: 1.60998\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008025 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 7715638, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -3.388563\n",
      "[LightGBM] [Info] Start training from score -3.286043\n",
      "[LightGBM] [Info] Start training from score -3.265766\n",
      "[LightGBM] [Info] Start training from score -3.814547\n",
      "[LightGBM] [Info] Start training from score -3.310265\n",
      "[LightGBM] [Info] Start training from score -3.206426\n",
      "[LightGBM] [Info] Start training from score -4.264605\n",
      "[LightGBM] [Info] Start training from score -3.385622\n",
      "[LightGBM] [Info] Start training from score -3.678169\n",
      "[LightGBM] [Info] Start training from score -3.401590\n",
      "[LightGBM] [Info] Start training from score -4.879144\n",
      "[LightGBM] [Info] Start training from score -3.027581\n",
      "[LightGBM] [Info] Start training from score -2.985319\n",
      "[LightGBM] [Info] Start training from score -3.251856\n",
      "[LightGBM] [Info] Start training from score -3.294527\n",
      "[LightGBM] [Info] Start training from score -3.372086\n",
      "[LightGBM] [Info] Start training from score -2.973489\n",
      "[LightGBM] [Info] Start training from score -2.489644\n",
      "[LightGBM] [Info] Start training from score -3.403357\n",
      "[LightGBM] [Info] Start training from score -4.161407\n",
      "[LightGBM] [Info] Start training from score -4.219942\n",
      "[LightGBM] [Info] Start training from score -3.454308\n",
      "[LightGBM] [Info] Start training from score -3.414970\n",
      "[LightGBM] [Info] Start training from score -3.160243\n",
      "[LightGBM] [Info] Start training from score -3.113230\n",
      "[LightGBM] [Info] Start training from score -3.209175\n",
      "[LightGBM] [Info] Start training from score -3.282600\n",
      "[LightGBM] [Info] Start training from score -3.180636\n",
      "[1]\tvalid_0's multi_logloss: 2.61787\n",
      "[2]\tvalid_0's multi_logloss: 2.46598\n",
      "[3]\tvalid_0's multi_logloss: 2.34705\n",
      "[4]\tvalid_0's multi_logloss: 2.25961\n",
      "[5]\tvalid_0's multi_logloss: 2.19272\n",
      "[6]\tvalid_0's multi_logloss: 2.13796\n",
      "[7]\tvalid_0's multi_logloss: 2.09633\n",
      "[8]\tvalid_0's multi_logloss: 2.05863\n",
      "[9]\tvalid_0's multi_logloss: 2.02743\n",
      "[10]\tvalid_0's multi_logloss: 1.99981\n",
      "[11]\tvalid_0's multi_logloss: 1.97605\n",
      "[12]\tvalid_0's multi_logloss: 1.95678\n",
      "[13]\tvalid_0's multi_logloss: 1.94073\n",
      "[14]\tvalid_0's multi_logloss: 1.92383\n",
      "[15]\tvalid_0's multi_logloss: 1.91018\n",
      "[16]\tvalid_0's multi_logloss: 1.89802\n",
      "[17]\tvalid_0's multi_logloss: 1.88799\n",
      "[18]\tvalid_0's multi_logloss: 1.87807\n",
      "[19]\tvalid_0's multi_logloss: 1.86934\n",
      "[20]\tvalid_0's multi_logloss: 1.86299\n",
      "[21]\tvalid_0's multi_logloss: 1.85604\n",
      "[22]\tvalid_0's multi_logloss: 1.85103\n",
      "[23]\tvalid_0's multi_logloss: 1.84462\n",
      "[24]\tvalid_0's multi_logloss: 1.83945\n",
      "[25]\tvalid_0's multi_logloss: 1.83437\n",
      "[26]\tvalid_0's multi_logloss: 1.83224\n",
      "[27]\tvalid_0's multi_logloss: 1.8287\n",
      "[28]\tvalid_0's multi_logloss: 1.82347\n",
      "[29]\tvalid_0's multi_logloss: 1.82028\n",
      "[30]\tvalid_0's multi_logloss: 1.81478\n",
      "[31]\tvalid_0's multi_logloss: 1.81164\n",
      "[32]\tvalid_0's multi_logloss: 1.80895\n",
      "[33]\tvalid_0's multi_logloss: 1.80606\n",
      "[34]\tvalid_0's multi_logloss: 1.80504\n",
      "[35]\tvalid_0's multi_logloss: 1.80053\n",
      "[36]\tvalid_0's multi_logloss: 1.79976\n",
      "[37]\tvalid_0's multi_logloss: 1.79648\n",
      "[38]\tvalid_0's multi_logloss: 1.7956\n",
      "[39]\tvalid_0's multi_logloss: 1.79117\n",
      "[40]\tvalid_0's multi_logloss: 1.78996\n",
      "[41]\tvalid_0's multi_logloss: 1.78806\n",
      "[42]\tvalid_0's multi_logloss: 1.78741\n",
      "[43]\tvalid_0's multi_logloss: 1.78456\n",
      "[44]\tvalid_0's multi_logloss: 1.78308\n",
      "[45]\tvalid_0's multi_logloss: 1.78108\n",
      "[46]\tvalid_0's multi_logloss: 1.78275\n",
      "[47]\tvalid_0's multi_logloss: 1.77746\n",
      "[48]\tvalid_0's multi_logloss: 1.77601\n",
      "[49]\tvalid_0's multi_logloss: 1.77466\n",
      "[50]\tvalid_0's multi_logloss: 1.77259\n",
      "[51]\tvalid_0's multi_logloss: 1.77112\n",
      "[52]\tvalid_0's multi_logloss: 1.77056\n",
      "[53]\tvalid_0's multi_logloss: 1.7689\n",
      "[54]\tvalid_0's multi_logloss: 1.76722\n",
      "[55]\tvalid_0's multi_logloss: 1.76749\n",
      "[56]\tvalid_0's multi_logloss: 1.76762\n",
      "[57]\tvalid_0's multi_logloss: 1.76478\n",
      "[58]\tvalid_0's multi_logloss: 1.76432\n",
      "[59]\tvalid_0's multi_logloss: 1.7627\n",
      "[60]\tvalid_0's multi_logloss: 1.76921\n",
      "[61]\tvalid_0's multi_logloss: 1.76789\n",
      "[62]\tvalid_0's multi_logloss: 1.75876\n",
      "[63]\tvalid_0's multi_logloss: 1.75758\n",
      "[64]\tvalid_0's multi_logloss: 1.75629\n",
      "[65]\tvalid_0's multi_logloss: 1.75622\n",
      "[66]\tvalid_0's multi_logloss: 1.75559\n",
      "[67]\tvalid_0's multi_logloss: 1.75487\n",
      "[68]\tvalid_0's multi_logloss: 1.754\n",
      "[69]\tvalid_0's multi_logloss: 1.75508\n",
      "[70]\tvalid_0's multi_logloss: 1.75309\n",
      "[71]\tvalid_0's multi_logloss: 1.75671\n",
      "[72]\tvalid_0's multi_logloss: 1.75826\n",
      "[73]\tvalid_0's multi_logloss: 1.75398\n",
      "[74]\tvalid_0's multi_logloss: 1.75347\n",
      "[75]\tvalid_0's multi_logloss: 1.75233\n",
      "[76]\tvalid_0's multi_logloss: 1.74966\n",
      "[77]\tvalid_0's multi_logloss: 1.74871\n",
      "[78]\tvalid_0's multi_logloss: 1.74901\n",
      "[79]\tvalid_0's multi_logloss: 1.74806\n",
      "[80]\tvalid_0's multi_logloss: 1.74747\n",
      "[81]\tvalid_0's multi_logloss: 1.74591\n",
      "[82]\tvalid_0's multi_logloss: 1.74436\n",
      "[83]\tvalid_0's multi_logloss: 1.74591\n",
      "[84]\tvalid_0's multi_logloss: 1.74438\n",
      "[85]\tvalid_0's multi_logloss: 1.74567\n",
      "[86]\tvalid_0's multi_logloss: 1.74629\n",
      "[87]\tvalid_0's multi_logloss: 1.74283\n",
      "[88]\tvalid_0's multi_logloss: 1.74406\n",
      "[89]\tvalid_0's multi_logloss: 1.74323\n",
      "[90]\tvalid_0's multi_logloss: 1.74312\n",
      "[91]\tvalid_0's multi_logloss: 1.74238\n",
      "[92]\tvalid_0's multi_logloss: 1.74053\n",
      "[93]\tvalid_0's multi_logloss: 1.7401\n",
      "[94]\tvalid_0's multi_logloss: 1.73907\n",
      "[95]\tvalid_0's multi_logloss: 1.73715\n",
      "[96]\tvalid_0's multi_logloss: 1.73764\n",
      "[97]\tvalid_0's multi_logloss: 1.73595\n",
      "[98]\tvalid_0's multi_logloss: 1.7369\n",
      "[99]\tvalid_0's multi_logloss: 1.73655\n",
      "[100]\tvalid_0's multi_logloss: 1.73635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [18:07, 124.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001496 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 820733, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -0.683185\n",
      "[LightGBM] [Info] Start training from score -2.382997\n",
      "[LightGBM] [Info] Start training from score -2.734975\n",
      "[LightGBM] [Info] Start training from score -3.826068\n",
      "[LightGBM] [Info] Start training from score -1.583719\n",
      "[LightGBM] [Info] Start training from score -2.199855\n",
      "[1]\tvalid_0's multi_logloss: 1.15698\n",
      "[2]\tvalid_0's multi_logloss: 1.04463\n",
      "[3]\tvalid_0's multi_logloss: 0.960018\n",
      "[4]\tvalid_0's multi_logloss: 0.893814\n",
      "[5]\tvalid_0's multi_logloss: 0.840502\n",
      "[6]\tvalid_0's multi_logloss: 0.796864\n",
      "[7]\tvalid_0's multi_logloss: 0.760637\n",
      "[8]\tvalid_0's multi_logloss: 0.730354\n",
      "[9]\tvalid_0's multi_logloss: 0.704724\n",
      "[10]\tvalid_0's multi_logloss: 0.68304\n",
      "[11]\tvalid_0's multi_logloss: 0.66423\n",
      "[12]\tvalid_0's multi_logloss: 0.648367\n",
      "[13]\tvalid_0's multi_logloss: 0.634399\n",
      "[14]\tvalid_0's multi_logloss: 0.622342\n",
      "[15]\tvalid_0's multi_logloss: 0.611671\n",
      "[16]\tvalid_0's multi_logloss: 0.602371\n",
      "[17]\tvalid_0's multi_logloss: 0.59404\n",
      "[18]\tvalid_0's multi_logloss: 0.586551\n",
      "[19]\tvalid_0's multi_logloss: 0.579751\n",
      "[20]\tvalid_0's multi_logloss: 0.573882\n",
      "[21]\tvalid_0's multi_logloss: 0.568637\n",
      "[22]\tvalid_0's multi_logloss: 0.564019\n",
      "[23]\tvalid_0's multi_logloss: 0.55983\n",
      "[24]\tvalid_0's multi_logloss: 0.555735\n",
      "[25]\tvalid_0's multi_logloss: 0.552144\n",
      "[26]\tvalid_0's multi_logloss: 0.548907\n",
      "[27]\tvalid_0's multi_logloss: 0.546097\n",
      "[28]\tvalid_0's multi_logloss: 0.543468\n",
      "[29]\tvalid_0's multi_logloss: 0.5411\n",
      "[30]\tvalid_0's multi_logloss: 0.538879\n",
      "[31]\tvalid_0's multi_logloss: 0.536871\n",
      "[32]\tvalid_0's multi_logloss: 0.535023\n",
      "[33]\tvalid_0's multi_logloss: 0.533217\n",
      "[34]\tvalid_0's multi_logloss: 0.531435\n",
      "[35]\tvalid_0's multi_logloss: 0.529876\n",
      "[36]\tvalid_0's multi_logloss: 0.528445\n",
      "[37]\tvalid_0's multi_logloss: 0.527148\n",
      "[38]\tvalid_0's multi_logloss: 0.525839\n",
      "[39]\tvalid_0's multi_logloss: 0.524712\n",
      "[40]\tvalid_0's multi_logloss: 0.523452\n",
      "[41]\tvalid_0's multi_logloss: 0.522419\n",
      "[42]\tvalid_0's multi_logloss: 0.521326\n",
      "[43]\tvalid_0's multi_logloss: 0.520412\n",
      "[44]\tvalid_0's multi_logloss: 0.519527\n",
      "[45]\tvalid_0's multi_logloss: 0.518728\n",
      "[46]\tvalid_0's multi_logloss: 0.51784\n",
      "[47]\tvalid_0's multi_logloss: 0.517088\n",
      "[48]\tvalid_0's multi_logloss: 0.51642\n",
      "[49]\tvalid_0's multi_logloss: 0.515585\n",
      "[50]\tvalid_0's multi_logloss: 0.514936\n",
      "[51]\tvalid_0's multi_logloss: 0.514422\n",
      "[52]\tvalid_0's multi_logloss: 0.513919\n",
      "[53]\tvalid_0's multi_logloss: 0.513408\n",
      "[54]\tvalid_0's multi_logloss: 0.515005\n",
      "[55]\tvalid_0's multi_logloss: 0.512488\n",
      "[56]\tvalid_0's multi_logloss: 0.514355\n",
      "[57]\tvalid_0's multi_logloss: 0.512608\n",
      "[58]\tvalid_0's multi_logloss: 0.513873\n",
      "[59]\tvalid_0's multi_logloss: 0.512316\n",
      "[60]\tvalid_0's multi_logloss: 0.512504\n",
      "[61]\tvalid_0's multi_logloss: 0.513669\n",
      "[62]\tvalid_0's multi_logloss: 0.511204\n",
      "[63]\tvalid_0's multi_logloss: 0.513511\n",
      "[64]\tvalid_0's multi_logloss: 0.510689\n",
      "[65]\tvalid_0's multi_logloss: 0.510466\n",
      "[66]\tvalid_0's multi_logloss: 0.51098\n",
      "[67]\tvalid_0's multi_logloss: 0.509455\n",
      "[68]\tvalid_0's multi_logloss: 0.508834\n",
      "[69]\tvalid_0's multi_logloss: 0.511116\n",
      "[70]\tvalid_0's multi_logloss: 0.51155\n",
      "[71]\tvalid_0's multi_logloss: 0.509219\n",
      "[72]\tvalid_0's multi_logloss: 0.509695\n",
      "[73]\tvalid_0's multi_logloss: 0.506769\n",
      "[74]\tvalid_0's multi_logloss: 0.508786\n",
      "[75]\tvalid_0's multi_logloss: 0.509829\n",
      "[76]\tvalid_0's multi_logloss: 0.507411\n",
      "[77]\tvalid_0's multi_logloss: 0.507075\n",
      "[78]\tvalid_0's multi_logloss: 0.508612\n",
      "[79]\tvalid_0's multi_logloss: 0.506088\n",
      "[80]\tvalid_0's multi_logloss: 0.510115\n",
      "[81]\tvalid_0's multi_logloss: 0.508418\n",
      "[82]\tvalid_0's multi_logloss: 0.509107\n",
      "[83]\tvalid_0's multi_logloss: 0.506951\n",
      "[84]\tvalid_0's multi_logloss: 0.507977\n",
      "[85]\tvalid_0's multi_logloss: 0.50752\n",
      "[86]\tvalid_0's multi_logloss: 0.507201\n",
      "[87]\tvalid_0's multi_logloss: 0.508958\n",
      "[88]\tvalid_0's multi_logloss: 0.507409\n",
      "[89]\tvalid_0's multi_logloss: 0.508941\n",
      "[90]\tvalid_0's multi_logloss: 0.50785\n",
      "[91]\tvalid_0's multi_logloss: 0.510045\n",
      "[92]\tvalid_0's multi_logloss: 0.517555\n",
      "[93]\tvalid_0's multi_logloss: 0.508842\n",
      "[94]\tvalid_0's multi_logloss: 0.521279\n",
      "[95]\tvalid_0's multi_logloss: 0.515628\n",
      "[96]\tvalid_0's multi_logloss: 0.513758\n",
      "[97]\tvalid_0's multi_logloss: 0.50826\n",
      "[98]\tvalid_0's multi_logloss: 0.523448\n",
      "[99]\tvalid_0's multi_logloss: 0.505466\n",
      "[100]\tvalid_0's multi_logloss: 0.532321\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001161 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 820733, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -2.163833\n",
      "[LightGBM] [Info] Start training from score -1.796397\n",
      "[LightGBM] [Info] Start training from score -1.843741\n",
      "[LightGBM] [Info] Start training from score -1.989576\n",
      "[LightGBM] [Info] Start training from score -1.941218\n",
      "[LightGBM] [Info] Start training from score -1.949016\n",
      "[LightGBM] [Info] Start training from score -1.978333\n",
      "[1]\tvalid_0's multi_logloss: 1.89972\n",
      "[2]\tvalid_0's multi_logloss: 1.86835\n",
      "[3]\tvalid_0's multi_logloss: 1.84349\n",
      "[4]\tvalid_0's multi_logloss: 1.82337\n",
      "[5]\tvalid_0's multi_logloss: 1.80675\n",
      "[6]\tvalid_0's multi_logloss: 1.79303\n",
      "[7]\tvalid_0's multi_logloss: 1.78161\n",
      "[8]\tvalid_0's multi_logloss: 1.77197\n",
      "[9]\tvalid_0's multi_logloss: 1.76389\n",
      "[10]\tvalid_0's multi_logloss: 1.75708\n",
      "[11]\tvalid_0's multi_logloss: 1.75123\n",
      "[12]\tvalid_0's multi_logloss: 1.74633\n",
      "[13]\tvalid_0's multi_logloss: 1.74209\n",
      "[14]\tvalid_0's multi_logloss: 1.73847\n",
      "[15]\tvalid_0's multi_logloss: 1.73538\n",
      "[16]\tvalid_0's multi_logloss: 1.73264\n",
      "[17]\tvalid_0's multi_logloss: 1.73024\n",
      "[18]\tvalid_0's multi_logloss: 1.72821\n",
      "[19]\tvalid_0's multi_logloss: 1.72641\n",
      "[20]\tvalid_0's multi_logloss: 1.72472\n",
      "[21]\tvalid_0's multi_logloss: 1.72328\n",
      "[22]\tvalid_0's multi_logloss: 1.72198\n",
      "[23]\tvalid_0's multi_logloss: 1.72082\n",
      "[24]\tvalid_0's multi_logloss: 1.71977\n",
      "[25]\tvalid_0's multi_logloss: 1.71891\n",
      "[26]\tvalid_0's multi_logloss: 1.71794\n",
      "[27]\tvalid_0's multi_logloss: 1.71717\n",
      "[28]\tvalid_0's multi_logloss: 1.71646\n",
      "[29]\tvalid_0's multi_logloss: 1.71572\n",
      "[30]\tvalid_0's multi_logloss: 1.71509\n",
      "[31]\tvalid_0's multi_logloss: 1.71443\n",
      "[32]\tvalid_0's multi_logloss: 1.7139\n",
      "[33]\tvalid_0's multi_logloss: 1.71333\n",
      "[34]\tvalid_0's multi_logloss: 1.71277\n",
      "[35]\tvalid_0's multi_logloss: 1.71237\n",
      "[36]\tvalid_0's multi_logloss: 1.71182\n",
      "[37]\tvalid_0's multi_logloss: 1.71136\n",
      "[38]\tvalid_0's multi_logloss: 1.71091\n",
      "[39]\tvalid_0's multi_logloss: 1.71053\n",
      "[40]\tvalid_0's multi_logloss: 1.71015\n",
      "[41]\tvalid_0's multi_logloss: 1.70979\n",
      "[42]\tvalid_0's multi_logloss: 1.70946\n",
      "[43]\tvalid_0's multi_logloss: 1.70918\n",
      "[44]\tvalid_0's multi_logloss: 1.70891\n",
      "[45]\tvalid_0's multi_logloss: 1.70864\n",
      "[46]\tvalid_0's multi_logloss: 1.70839\n",
      "[47]\tvalid_0's multi_logloss: 1.70817\n",
      "[48]\tvalid_0's multi_logloss: 1.7079\n",
      "[49]\tvalid_0's multi_logloss: 1.7077\n",
      "[50]\tvalid_0's multi_logloss: 1.70751\n",
      "[51]\tvalid_0's multi_logloss: 1.70731\n",
      "[52]\tvalid_0's multi_logloss: 1.70714\n",
      "[53]\tvalid_0's multi_logloss: 1.70692\n",
      "[54]\tvalid_0's multi_logloss: 1.70674\n",
      "[55]\tvalid_0's multi_logloss: 1.70656\n",
      "[56]\tvalid_0's multi_logloss: 1.70642\n",
      "[57]\tvalid_0's multi_logloss: 1.70624\n",
      "[58]\tvalid_0's multi_logloss: 1.70608\n",
      "[59]\tvalid_0's multi_logloss: 1.70591\n",
      "[60]\tvalid_0's multi_logloss: 1.70578\n",
      "[61]\tvalid_0's multi_logloss: 1.70562\n",
      "[62]\tvalid_0's multi_logloss: 1.70545\n",
      "[63]\tvalid_0's multi_logloss: 1.70532\n",
      "[64]\tvalid_0's multi_logloss: 1.70511\n",
      "[65]\tvalid_0's multi_logloss: 1.70495\n",
      "[66]\tvalid_0's multi_logloss: 1.70483\n",
      "[67]\tvalid_0's multi_logloss: 1.70475\n",
      "[68]\tvalid_0's multi_logloss: 1.70464\n",
      "[69]\tvalid_0's multi_logloss: 1.70453\n",
      "[70]\tvalid_0's multi_logloss: 1.70436\n",
      "[71]\tvalid_0's multi_logloss: 1.7042\n",
      "[72]\tvalid_0's multi_logloss: 1.7041\n",
      "[73]\tvalid_0's multi_logloss: 1.70396\n",
      "[74]\tvalid_0's multi_logloss: 1.70388\n",
      "[75]\tvalid_0's multi_logloss: 1.7038\n",
      "[76]\tvalid_0's multi_logloss: 1.70364\n",
      "[77]\tvalid_0's multi_logloss: 1.70352\n",
      "[78]\tvalid_0's multi_logloss: 1.70344\n",
      "[79]\tvalid_0's multi_logloss: 1.70336\n",
      "[80]\tvalid_0's multi_logloss: 1.7033\n",
      "[81]\tvalid_0's multi_logloss: 1.70325\n",
      "[82]\tvalid_0's multi_logloss: 1.70319\n",
      "[83]\tvalid_0's multi_logloss: 1.7031\n",
      "[84]\tvalid_0's multi_logloss: 1.703\n",
      "[85]\tvalid_0's multi_logloss: 1.70288\n",
      "[86]\tvalid_0's multi_logloss: 1.70273\n",
      "[87]\tvalid_0's multi_logloss: 1.70266\n",
      "[88]\tvalid_0's multi_logloss: 1.70257\n",
      "[89]\tvalid_0's multi_logloss: 1.70247\n",
      "[90]\tvalid_0's multi_logloss: 1.70239\n",
      "[91]\tvalid_0's multi_logloss: 1.7023\n",
      "[92]\tvalid_0's multi_logloss: 1.70217\n",
      "[93]\tvalid_0's multi_logloss: 1.70211\n",
      "[94]\tvalid_0's multi_logloss: 1.70206\n",
      "[95]\tvalid_0's multi_logloss: 1.702\n",
      "[96]\tvalid_0's multi_logloss: 1.70192\n",
      "[97]\tvalid_0's multi_logloss: 1.70184\n",
      "[98]\tvalid_0's multi_logloss: 1.70174\n",
      "[99]\tvalid_0's multi_logloss: 1.7017\n",
      "[100]\tvalid_0's multi_logloss: 1.70161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [18:15, 88.35s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022031 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.853404\n",
      "[LightGBM] [Info] Start training from score -2.123202\n",
      "[LightGBM] [Info] Start training from score -2.391862\n",
      "[LightGBM] [Info] Start training from score -2.719639\n",
      "[LightGBM] [Info] Start training from score -2.078311\n",
      "[LightGBM] [Info] Start training from score -2.161447\n",
      "[LightGBM] [Info] Start training from score -2.497610\n",
      "[LightGBM] [Info] Start training from score -2.232530\n",
      "[LightGBM] [Info] Start training from score -2.689447\n",
      "[LightGBM] [Info] Start training from score -2.680407\n",
      "[1]\tvalid_0's multi_logloss: 1.92616\n",
      "[2]\tvalid_0's multi_logloss: 1.75331\n",
      "[3]\tvalid_0's multi_logloss: 1.63283\n",
      "[4]\tvalid_0's multi_logloss: 1.54171\n",
      "[5]\tvalid_0's multi_logloss: 1.47036\n",
      "[6]\tvalid_0's multi_logloss: 1.41314\n",
      "[7]\tvalid_0's multi_logloss: 1.36623\n",
      "[8]\tvalid_0's multi_logloss: 1.32763\n",
      "[9]\tvalid_0's multi_logloss: 1.2958\n",
      "[10]\tvalid_0's multi_logloss: 1.26923\n",
      "[11]\tvalid_0's multi_logloss: 1.24629\n",
      "[12]\tvalid_0's multi_logloss: 1.22708\n",
      "[13]\tvalid_0's multi_logloss: 1.21045\n",
      "[14]\tvalid_0's multi_logloss: 1.19605\n",
      "[15]\tvalid_0's multi_logloss: 1.18358\n",
      "[16]\tvalid_0's multi_logloss: 1.17276\n",
      "[17]\tvalid_0's multi_logloss: 1.16336\n",
      "[18]\tvalid_0's multi_logloss: 1.15514\n",
      "[19]\tvalid_0's multi_logloss: 1.1479\n",
      "[20]\tvalid_0's multi_logloss: 1.14167\n",
      "[21]\tvalid_0's multi_logloss: 1.13592\n",
      "[22]\tvalid_0's multi_logloss: 1.13086\n",
      "[23]\tvalid_0's multi_logloss: 1.12615\n",
      "[24]\tvalid_0's multi_logloss: 1.12197\n",
      "[25]\tvalid_0's multi_logloss: 1.11819\n",
      "[26]\tvalid_0's multi_logloss: 1.1145\n",
      "[27]\tvalid_0's multi_logloss: 1.11125\n",
      "[28]\tvalid_0's multi_logloss: 1.10831\n",
      "[29]\tvalid_0's multi_logloss: 1.10564\n",
      "[30]\tvalid_0's multi_logloss: 1.10289\n",
      "[31]\tvalid_0's multi_logloss: 1.10034\n",
      "[32]\tvalid_0's multi_logloss: 1.09797\n",
      "[33]\tvalid_0's multi_logloss: 1.09599\n",
      "[34]\tvalid_0's multi_logloss: 1.09385\n",
      "[35]\tvalid_0's multi_logloss: 1.09208\n",
      "[36]\tvalid_0's multi_logloss: 1.0903\n",
      "[37]\tvalid_0's multi_logloss: 1.08863\n",
      "[38]\tvalid_0's multi_logloss: 1.08716\n",
      "[39]\tvalid_0's multi_logloss: 1.08585\n",
      "[40]\tvalid_0's multi_logloss: 1.08451\n",
      "[41]\tvalid_0's multi_logloss: 1.0832\n",
      "[42]\tvalid_0's multi_logloss: 1.08214\n",
      "[43]\tvalid_0's multi_logloss: 1.08106\n",
      "[44]\tvalid_0's multi_logloss: 1.07997\n",
      "[45]\tvalid_0's multi_logloss: 1.07867\n",
      "[46]\tvalid_0's multi_logloss: 1.07761\n",
      "[47]\tvalid_0's multi_logloss: 1.07662\n",
      "[48]\tvalid_0's multi_logloss: 1.0758\n",
      "[49]\tvalid_0's multi_logloss: 1.07463\n",
      "[50]\tvalid_0's multi_logloss: 1.07368\n",
      "[51]\tvalid_0's multi_logloss: 1.07299\n",
      "[52]\tvalid_0's multi_logloss: 1.07218\n",
      "[53]\tvalid_0's multi_logloss: 1.0712\n",
      "[54]\tvalid_0's multi_logloss: 1.07034\n",
      "[55]\tvalid_0's multi_logloss: 1.06964\n",
      "[56]\tvalid_0's multi_logloss: 1.0687\n",
      "[57]\tvalid_0's multi_logloss: 1.06802\n",
      "[58]\tvalid_0's multi_logloss: 1.06738\n",
      "[59]\tvalid_0's multi_logloss: 1.06676\n",
      "[60]\tvalid_0's multi_logloss: 1.06611\n",
      "[61]\tvalid_0's multi_logloss: 1.06571\n",
      "[62]\tvalid_0's multi_logloss: 1.06476\n",
      "[63]\tvalid_0's multi_logloss: 1.06414\n",
      "[64]\tvalid_0's multi_logloss: 1.06357\n",
      "[65]\tvalid_0's multi_logloss: 1.06282\n",
      "[66]\tvalid_0's multi_logloss: 1.06205\n",
      "[67]\tvalid_0's multi_logloss: 1.06164\n",
      "[68]\tvalid_0's multi_logloss: 1.06109\n",
      "[69]\tvalid_0's multi_logloss: 1.06059\n",
      "[70]\tvalid_0's multi_logloss: 1.06012\n",
      "[71]\tvalid_0's multi_logloss: 1.05946\n",
      "[72]\tvalid_0's multi_logloss: 1.05905\n",
      "[73]\tvalid_0's multi_logloss: 1.05845\n",
      "[74]\tvalid_0's multi_logloss: 1.05803\n",
      "[75]\tvalid_0's multi_logloss: 1.05767\n",
      "[76]\tvalid_0's multi_logloss: 1.05721\n",
      "[77]\tvalid_0's multi_logloss: 1.05681\n",
      "[78]\tvalid_0's multi_logloss: 1.05642\n",
      "[79]\tvalid_0's multi_logloss: 1.05586\n",
      "[80]\tvalid_0's multi_logloss: 1.05524\n",
      "[81]\tvalid_0's multi_logloss: 1.05477\n",
      "[82]\tvalid_0's multi_logloss: 1.05434\n",
      "[83]\tvalid_0's multi_logloss: 1.05388\n",
      "[84]\tvalid_0's multi_logloss: 1.05358\n",
      "[85]\tvalid_0's multi_logloss: 1.05311\n",
      "[86]\tvalid_0's multi_logloss: 1.05279\n",
      "[87]\tvalid_0's multi_logloss: 1.05247\n",
      "[88]\tvalid_0's multi_logloss: 1.05205\n",
      "[89]\tvalid_0's multi_logloss: 1.05171\n",
      "[90]\tvalid_0's multi_logloss: 1.05132\n",
      "[91]\tvalid_0's multi_logloss: 1.05097\n",
      "[92]\tvalid_0's multi_logloss: 1.05065\n",
      "[93]\tvalid_0's multi_logloss: 1.0503\n",
      "[94]\tvalid_0's multi_logloss: 1.05006\n",
      "[95]\tvalid_0's multi_logloss: 1.04978\n",
      "[96]\tvalid_0's multi_logloss: 1.04954\n",
      "[97]\tvalid_0's multi_logloss: 1.04921\n",
      "[98]\tvalid_0's multi_logloss: 1.049\n",
      "[99]\tvalid_0's multi_logloss: 1.04854\n",
      "[100]\tvalid_0's multi_logloss: 1.04822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022375 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.047228\n",
      "[LightGBM] [Info] Start training from score -1.516216\n",
      "[LightGBM] [Info] Start training from score -0.845018\n",
      "[1]\tvalid_0's multi_logloss: 1.0091\n",
      "[2]\tvalid_0's multi_logloss: 0.964984\n",
      "[3]\tvalid_0's multi_logloss: 0.928329\n",
      "[4]\tvalid_0's multi_logloss: 0.897682\n",
      "[5]\tvalid_0's multi_logloss: 0.871562\n",
      "[6]\tvalid_0's multi_logloss: 0.849223\n",
      "[7]\tvalid_0's multi_logloss: 0.829863\n",
      "[8]\tvalid_0's multi_logloss: 0.813092\n",
      "[9]\tvalid_0's multi_logloss: 0.798322\n",
      "[10]\tvalid_0's multi_logloss: 0.785338\n",
      "[11]\tvalid_0's multi_logloss: 0.773755\n",
      "[12]\tvalid_0's multi_logloss: 0.763579\n",
      "[13]\tvalid_0's multi_logloss: 0.754492\n",
      "[14]\tvalid_0's multi_logloss: 0.746375\n",
      "[15]\tvalid_0's multi_logloss: 0.739057\n",
      "[16]\tvalid_0's multi_logloss: 0.732409\n",
      "[17]\tvalid_0's multi_logloss: 0.726436\n",
      "[18]\tvalid_0's multi_logloss: 0.72103\n",
      "[19]\tvalid_0's multi_logloss: 0.7161\n",
      "[20]\tvalid_0's multi_logloss: 0.711621\n",
      "[21]\tvalid_0's multi_logloss: 0.707511\n",
      "[22]\tvalid_0's multi_logloss: 0.703714\n",
      "[23]\tvalid_0's multi_logloss: 0.700256\n",
      "[24]\tvalid_0's multi_logloss: 0.697044\n",
      "[25]\tvalid_0's multi_logloss: 0.694091\n",
      "[26]\tvalid_0's multi_logloss: 0.691363\n",
      "[27]\tvalid_0's multi_logloss: 0.688855\n",
      "[28]\tvalid_0's multi_logloss: 0.686515\n",
      "[29]\tvalid_0's multi_logloss: 0.684375\n",
      "[30]\tvalid_0's multi_logloss: 0.682387\n",
      "[31]\tvalid_0's multi_logloss: 0.680537\n",
      "[32]\tvalid_0's multi_logloss: 0.678772\n",
      "[33]\tvalid_0's multi_logloss: 0.677175\n",
      "[34]\tvalid_0's multi_logloss: 0.675701\n",
      "[35]\tvalid_0's multi_logloss: 0.674299\n",
      "[36]\tvalid_0's multi_logloss: 0.673017\n",
      "[37]\tvalid_0's multi_logloss: 0.671793\n",
      "[38]\tvalid_0's multi_logloss: 0.670671\n",
      "[39]\tvalid_0's multi_logloss: 0.669594\n",
      "[40]\tvalid_0's multi_logloss: 0.668624\n",
      "[41]\tvalid_0's multi_logloss: 0.667706\n",
      "[42]\tvalid_0's multi_logloss: 0.666831\n",
      "[43]\tvalid_0's multi_logloss: 0.666027\n",
      "[44]\tvalid_0's multi_logloss: 0.665304\n",
      "[45]\tvalid_0's multi_logloss: 0.664574\n",
      "[46]\tvalid_0's multi_logloss: 0.663916\n",
      "[47]\tvalid_0's multi_logloss: 0.6633\n",
      "[48]\tvalid_0's multi_logloss: 0.662732\n",
      "[49]\tvalid_0's multi_logloss: 0.662205\n",
      "[50]\tvalid_0's multi_logloss: 0.661678\n",
      "[51]\tvalid_0's multi_logloss: 0.661191\n",
      "[52]\tvalid_0's multi_logloss: 0.660737\n",
      "[53]\tvalid_0's multi_logloss: 0.660324\n",
      "[54]\tvalid_0's multi_logloss: 0.65992\n",
      "[55]\tvalid_0's multi_logloss: 0.659555\n",
      "[56]\tvalid_0's multi_logloss: 0.6592\n",
      "[57]\tvalid_0's multi_logloss: 0.658884\n",
      "[58]\tvalid_0's multi_logloss: 0.658557\n",
      "[59]\tvalid_0's multi_logloss: 0.658262\n",
      "[60]\tvalid_0's multi_logloss: 0.657984\n",
      "[61]\tvalid_0's multi_logloss: 0.657737\n",
      "[62]\tvalid_0's multi_logloss: 0.65748\n",
      "[63]\tvalid_0's multi_logloss: 0.657248\n",
      "[64]\tvalid_0's multi_logloss: 0.657047\n",
      "[65]\tvalid_0's multi_logloss: 0.656849\n",
      "[66]\tvalid_0's multi_logloss: 0.656651\n",
      "[67]\tvalid_0's multi_logloss: 0.656439\n",
      "[68]\tvalid_0's multi_logloss: 0.656273\n",
      "[69]\tvalid_0's multi_logloss: 0.656114\n",
      "[70]\tvalid_0's multi_logloss: 0.65597\n",
      "[71]\tvalid_0's multi_logloss: 0.655819\n",
      "[72]\tvalid_0's multi_logloss: 0.655669\n",
      "[73]\tvalid_0's multi_logloss: 0.655516\n",
      "[74]\tvalid_0's multi_logloss: 0.655404\n",
      "[75]\tvalid_0's multi_logloss: 0.655294\n",
      "[76]\tvalid_0's multi_logloss: 0.65518\n",
      "[77]\tvalid_0's multi_logloss: 0.655067\n",
      "[78]\tvalid_0's multi_logloss: 0.654972\n",
      "[79]\tvalid_0's multi_logloss: 0.654885\n",
      "[80]\tvalid_0's multi_logloss: 0.654795\n",
      "[81]\tvalid_0's multi_logloss: 0.654711\n",
      "[82]\tvalid_0's multi_logloss: 0.654626\n",
      "[83]\tvalid_0's multi_logloss: 0.65455\n",
      "[84]\tvalid_0's multi_logloss: 0.654468\n",
      "[85]\tvalid_0's multi_logloss: 0.65438\n",
      "[86]\tvalid_0's multi_logloss: 0.65432\n",
      "[87]\tvalid_0's multi_logloss: 0.654257\n",
      "[88]\tvalid_0's multi_logloss: 0.654181\n",
      "[89]\tvalid_0's multi_logloss: 0.654094\n",
      "[90]\tvalid_0's multi_logloss: 0.654046\n",
      "[91]\tvalid_0's multi_logloss: 0.653989\n",
      "[92]\tvalid_0's multi_logloss: 0.653935\n",
      "[93]\tvalid_0's multi_logloss: 0.653885\n",
      "[94]\tvalid_0's multi_logloss: 0.653821\n",
      "[95]\tvalid_0's multi_logloss: 0.653772\n",
      "[96]\tvalid_0's multi_logloss: 0.653728\n",
      "[97]\tvalid_0's multi_logloss: 0.653673\n",
      "[98]\tvalid_0's multi_logloss: 0.653618\n",
      "[99]\tvalid_0's multi_logloss: 0.653573\n",
      "[100]\tvalid_0's multi_logloss: 0.653543\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021862 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -3.244539\n",
      "[LightGBM] [Info] Start training from score -3.224920\n",
      "[LightGBM] [Info] Start training from score -3.369880\n",
      "[LightGBM] [Info] Start training from score -3.326941\n",
      "[LightGBM] [Info] Start training from score -3.378266\n",
      "[LightGBM] [Info] Start training from score -2.568017\n",
      "[LightGBM] [Info] Start training from score -1.914747\n",
      "[LightGBM] [Info] Start training from score -3.469579\n",
      "[LightGBM] [Info] Start training from score -1.919436\n",
      "[LightGBM] [Info] Start training from score -2.291576\n",
      "[LightGBM] [Info] Start training from score -2.007538\n",
      "[LightGBM] [Info] Start training from score -3.402200\n",
      "[LightGBM] [Info] Start training from score -3.212376\n",
      "[LightGBM] [Info] Start training from score -2.244521\n",
      "[1]\tvalid_0's multi_logloss: 2.39554\n",
      "[2]\tvalid_0's multi_logloss: 2.3545\n",
      "[3]\tvalid_0's multi_logloss: 2.32233\n",
      "[4]\tvalid_0's multi_logloss: 2.29694\n",
      "[5]\tvalid_0's multi_logloss: 2.27611\n",
      "[6]\tvalid_0's multi_logloss: 2.2586\n",
      "[7]\tvalid_0's multi_logloss: 2.24407\n",
      "[8]\tvalid_0's multi_logloss: 2.23152\n",
      "[9]\tvalid_0's multi_logloss: 2.22092\n",
      "[10]\tvalid_0's multi_logloss: 2.21175\n",
      "[11]\tvalid_0's multi_logloss: 2.20348\n",
      "[12]\tvalid_0's multi_logloss: 2.19622\n",
      "[13]\tvalid_0's multi_logloss: 2.18982\n",
      "[14]\tvalid_0's multi_logloss: 2.18416\n",
      "[15]\tvalid_0's multi_logloss: 2.17911\n",
      "[16]\tvalid_0's multi_logloss: 2.17462\n",
      "[17]\tvalid_0's multi_logloss: 2.17079\n",
      "[18]\tvalid_0's multi_logloss: 2.16708\n",
      "[19]\tvalid_0's multi_logloss: 2.16369\n",
      "[20]\tvalid_0's multi_logloss: 2.16074\n",
      "[21]\tvalid_0's multi_logloss: 2.15796\n",
      "[22]\tvalid_0's multi_logloss: 2.15554\n",
      "[23]\tvalid_0's multi_logloss: 2.15317\n",
      "[24]\tvalid_0's multi_logloss: 2.15103\n",
      "[25]\tvalid_0's multi_logloss: 2.14921\n",
      "[26]\tvalid_0's multi_logloss: 2.1475\n",
      "[27]\tvalid_0's multi_logloss: 2.14578\n",
      "[28]\tvalid_0's multi_logloss: 2.14413\n",
      "[29]\tvalid_0's multi_logloss: 2.14259\n",
      "[30]\tvalid_0's multi_logloss: 2.14113\n",
      "[31]\tvalid_0's multi_logloss: 2.13976\n",
      "[32]\tvalid_0's multi_logloss: 2.13856\n",
      "[33]\tvalid_0's multi_logloss: 2.13743\n",
      "[34]\tvalid_0's multi_logloss: 2.13634\n",
      "[35]\tvalid_0's multi_logloss: 2.13529\n",
      "[36]\tvalid_0's multi_logloss: 2.13433\n",
      "[37]\tvalid_0's multi_logloss: 2.13342\n",
      "[38]\tvalid_0's multi_logloss: 2.13253\n",
      "[39]\tvalid_0's multi_logloss: 2.13174\n",
      "[40]\tvalid_0's multi_logloss: 2.13093\n",
      "[41]\tvalid_0's multi_logloss: 2.1302\n",
      "[42]\tvalid_0's multi_logloss: 2.12949\n",
      "[43]\tvalid_0's multi_logloss: 2.12879\n",
      "[44]\tvalid_0's multi_logloss: 2.12816\n",
      "[45]\tvalid_0's multi_logloss: 2.12751\n",
      "[46]\tvalid_0's multi_logloss: 2.12695\n",
      "[47]\tvalid_0's multi_logloss: 2.12645\n",
      "[48]\tvalid_0's multi_logloss: 2.12589\n",
      "[49]\tvalid_0's multi_logloss: 2.1253\n",
      "[50]\tvalid_0's multi_logloss: 2.12473\n",
      "[51]\tvalid_0's multi_logloss: 2.12418\n",
      "[52]\tvalid_0's multi_logloss: 2.12364\n",
      "[53]\tvalid_0's multi_logloss: 2.12318\n",
      "[54]\tvalid_0's multi_logloss: 2.1228\n",
      "[55]\tvalid_0's multi_logloss: 2.12235\n",
      "[56]\tvalid_0's multi_logloss: 2.12191\n",
      "[57]\tvalid_0's multi_logloss: 2.12145\n",
      "[58]\tvalid_0's multi_logloss: 2.121\n",
      "[59]\tvalid_0's multi_logloss: 2.12057\n",
      "[60]\tvalid_0's multi_logloss: 2.12011\n",
      "[61]\tvalid_0's multi_logloss: 2.11966\n",
      "[62]\tvalid_0's multi_logloss: 2.11923\n",
      "[63]\tvalid_0's multi_logloss: 2.11885\n",
      "[64]\tvalid_0's multi_logloss: 2.11849\n",
      "[65]\tvalid_0's multi_logloss: 2.1181\n",
      "[66]\tvalid_0's multi_logloss: 2.11775\n",
      "[67]\tvalid_0's multi_logloss: 2.11739\n",
      "[68]\tvalid_0's multi_logloss: 2.11707\n",
      "[69]\tvalid_0's multi_logloss: 2.11676\n",
      "[70]\tvalid_0's multi_logloss: 2.11642\n",
      "[71]\tvalid_0's multi_logloss: 2.11615\n",
      "[72]\tvalid_0's multi_logloss: 2.11572\n",
      "[73]\tvalid_0's multi_logloss: 2.11544\n",
      "[74]\tvalid_0's multi_logloss: 2.11518\n",
      "[75]\tvalid_0's multi_logloss: 2.11491\n",
      "[76]\tvalid_0's multi_logloss: 2.11466\n",
      "[77]\tvalid_0's multi_logloss: 2.11443\n",
      "[78]\tvalid_0's multi_logloss: 2.11419\n",
      "[79]\tvalid_0's multi_logloss: 2.11398\n",
      "[80]\tvalid_0's multi_logloss: 2.11376\n",
      "[81]\tvalid_0's multi_logloss: 2.11344\n",
      "[82]\tvalid_0's multi_logloss: 2.11322\n",
      "[83]\tvalid_0's multi_logloss: 2.11299\n",
      "[84]\tvalid_0's multi_logloss: 2.11276\n",
      "[85]\tvalid_0's multi_logloss: 2.11256\n",
      "[86]\tvalid_0's multi_logloss: 2.11232\n",
      "[87]\tvalid_0's multi_logloss: 2.1121\n",
      "[88]\tvalid_0's multi_logloss: 2.11185\n",
      "[89]\tvalid_0's multi_logloss: 2.11163\n",
      "[90]\tvalid_0's multi_logloss: 2.11149\n",
      "[91]\tvalid_0's multi_logloss: 2.11134\n",
      "[92]\tvalid_0's multi_logloss: 2.11116\n",
      "[93]\tvalid_0's multi_logloss: 2.11096\n",
      "[94]\tvalid_0's multi_logloss: 2.11073\n",
      "[95]\tvalid_0's multi_logloss: 2.11053\n",
      "[96]\tvalid_0's multi_logloss: 2.11035\n",
      "[97]\tvalid_0's multi_logloss: 2.11013\n",
      "[98]\tvalid_0's multi_logloss: 2.10996\n",
      "[99]\tvalid_0's multi_logloss: 2.10971\n",
      "[100]\tvalid_0's multi_logloss: 2.10954\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022065 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -0.501622\n",
      "[LightGBM] [Info] Start training from score -0.930257\n",
      "[1]\tvalid_0's multi_logloss: 0.575829\n",
      "[2]\tvalid_0's multi_logloss: 0.49948\n",
      "[3]\tvalid_0's multi_logloss: 0.436457\n",
      "[4]\tvalid_0's multi_logloss: 0.38351\n",
      "[5]\tvalid_0's multi_logloss: 0.338468\n",
      "[6]\tvalid_0's multi_logloss: 0.299773\n",
      "[7]\tvalid_0's multi_logloss: 0.266276\n",
      "[8]\tvalid_0's multi_logloss: 0.23709\n",
      "[9]\tvalid_0's multi_logloss: 0.21154\n",
      "[10]\tvalid_0's multi_logloss: 0.189078\n",
      "[11]\tvalid_0's multi_logloss: 0.169256\n",
      "[12]\tvalid_0's multi_logloss: 0.151715\n",
      "[13]\tvalid_0's multi_logloss: 0.136153\n",
      "[14]\tvalid_0's multi_logloss: 0.122314\n",
      "[15]\tvalid_0's multi_logloss: 0.109985\n",
      "[16]\tvalid_0's multi_logloss: 0.0989825\n",
      "[17]\tvalid_0's multi_logloss: 0.0891495\n",
      "[18]\tvalid_0's multi_logloss: 0.0803484\n",
      "[19]\tvalid_0's multi_logloss: 0.0724656\n",
      "[20]\tvalid_0's multi_logloss: 0.0653942\n",
      "[21]\tvalid_0's multi_logloss: 0.0590474\n",
      "[22]\tvalid_0's multi_logloss: 0.0533464\n",
      "[23]\tvalid_0's multi_logloss: 0.0482217\n",
      "[24]\tvalid_0's multi_logloss: 0.0436126\n",
      "[25]\tvalid_0's multi_logloss: 0.0394655\n",
      "[26]\tvalid_0's multi_logloss: 0.0357308\n",
      "[27]\tvalid_0's multi_logloss: 0.0323657\n",
      "[28]\tvalid_0's multi_logloss: 0.0293346\n",
      "[29]\tvalid_0's multi_logloss: 0.0266025\n",
      "[30]\tvalid_0's multi_logloss: 0.0241391\n",
      "[31]\tvalid_0's multi_logloss: 0.0219173\n",
      "[32]\tvalid_0's multi_logloss: 0.0199136\n",
      "[33]\tvalid_0's multi_logloss: 0.0181069\n",
      "[34]\tvalid_0's multi_logloss: 0.0164755\n",
      "[35]\tvalid_0's multi_logloss: 0.015003\n",
      "[36]\tvalid_0's multi_logloss: 0.0136738\n",
      "[37]\tvalid_0's multi_logloss: 0.0124745\n",
      "[38]\tvalid_0's multi_logloss: 0.0113921\n",
      "[39]\tvalid_0's multi_logloss: 0.0104148\n",
      "[40]\tvalid_0's multi_logloss: 0.00953285\n",
      "[41]\tvalid_0's multi_logloss: 0.0087368\n",
      "[42]\tvalid_0's multi_logloss: 0.00801814\n",
      "[43]\tvalid_0's multi_logloss: 0.00736592\n",
      "[44]\tvalid_0's multi_logloss: 0.00678045\n",
      "[45]\tvalid_0's multi_logloss: 0.00625219\n",
      "[46]\tvalid_0's multi_logloss: 0.0057758\n",
      "[47]\tvalid_0's multi_logloss: 0.00534574\n",
      "[48]\tvalid_0's multi_logloss: 0.00495587\n",
      "[49]\tvalid_0's multi_logloss: 0.00460436\n",
      "[50]\tvalid_0's multi_logloss: 0.00428733\n",
      "[51]\tvalid_0's multi_logloss: 0.00400136\n",
      "[52]\tvalid_0's multi_logloss: 0.00374324\n",
      "[53]\tvalid_0's multi_logloss: 0.00351068\n",
      "[54]\tvalid_0's multi_logloss: 0.00330129\n",
      "[55]\tvalid_0's multi_logloss: 0.00311185\n",
      "[56]\tvalid_0's multi_logloss: 0.00294149\n",
      "[57]\tvalid_0's multi_logloss: 0.00278836\n",
      "[58]\tvalid_0's multi_logloss: 0.00264979\n",
      "[59]\tvalid_0's multi_logloss: 0.00252219\n",
      "[60]\tvalid_0's multi_logloss: 0.00240968\n",
      "[61]\tvalid_0's multi_logloss: 0.00230772\n",
      "[62]\tvalid_0's multi_logloss: 0.00221602\n",
      "[63]\tvalid_0's multi_logloss: 0.00213412\n",
      "[64]\tvalid_0's multi_logloss: 0.00205945\n",
      "[65]\tvalid_0's multi_logloss: 0.00199177\n",
      "[66]\tvalid_0's multi_logloss: 0.00193147\n",
      "[67]\tvalid_0's multi_logloss: 0.00187736\n",
      "[68]\tvalid_0's multi_logloss: 0.00183123\n",
      "[69]\tvalid_0's multi_logloss: 0.00179143\n",
      "[70]\tvalid_0's multi_logloss: 0.00175166\n",
      "[71]\tvalid_0's multi_logloss: 0.00171524\n",
      "[72]\tvalid_0's multi_logloss: 0.0016831\n",
      "[73]\tvalid_0's multi_logloss: 0.0016535\n",
      "[74]\tvalid_0's multi_logloss: 0.00162696\n",
      "[75]\tvalid_0's multi_logloss: 0.00160372\n",
      "[76]\tvalid_0's multi_logloss: 0.00159308\n",
      "[77]\tvalid_0's multi_logloss: 0.00156464\n",
      "[78]\tvalid_0's multi_logloss: 0.00157015\n",
      "[79]\tvalid_0's multi_logloss: 0.00155476\n",
      "[80]\tvalid_0's multi_logloss: 0.00154066\n",
      "[81]\tvalid_0's multi_logloss: 0.00152947\n",
      "[82]\tvalid_0's multi_logloss: 0.00152197\n",
      "[83]\tvalid_0's multi_logloss: 0.00151078\n",
      "[84]\tvalid_0's multi_logloss: 0.00150932\n",
      "[85]\tvalid_0's multi_logloss: 0.00147369\n",
      "[86]\tvalid_0's multi_logloss: 0.00146585\n",
      "[87]\tvalid_0's multi_logloss: 0.00152463\n",
      "[88]\tvalid_0's multi_logloss: 0.00145243\n",
      "[89]\tvalid_0's multi_logloss: 0.00146876\n",
      "[90]\tvalid_0's multi_logloss: 0.0014419\n",
      "[91]\tvalid_0's multi_logloss: 0.00143681\n",
      "[92]\tvalid_0's multi_logloss: 0.0014325\n",
      "[93]\tvalid_0's multi_logloss: 0.00142859\n",
      "[94]\tvalid_0's multi_logloss: 0.00142445\n",
      "[95]\tvalid_0's multi_logloss: 0.00142254\n",
      "[96]\tvalid_0's multi_logloss: 0.00141951\n",
      "[97]\tvalid_0's multi_logloss: 0.00141651\n",
      "[98]\tvalid_0's multi_logloss: 0.00141429\n",
      "[99]\tvalid_0's multi_logloss: 0.00141209\n",
      "[100]\tvalid_0's multi_logloss: 0.00144769\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021737 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -0.141837\n",
      "[LightGBM] [Info] Start training from score -2.023158\n",
      "[1]\tvalid_0's multi_logloss: 0.352963\n",
      "[2]\tvalid_0's multi_logloss: 0.329215\n",
      "[3]\tvalid_0's multi_logloss: 0.311522\n",
      "[4]\tvalid_0's multi_logloss: 0.29746\n",
      "[5]\tvalid_0's multi_logloss: 0.285686\n",
      "[6]\tvalid_0's multi_logloss: 0.275736\n",
      "[7]\tvalid_0's multi_logloss: 0.26763\n",
      "[8]\tvalid_0's multi_logloss: 0.260718\n",
      "[9]\tvalid_0's multi_logloss: 0.254692\n",
      "[10]\tvalid_0's multi_logloss: 0.249738\n",
      "[11]\tvalid_0's multi_logloss: 0.245524\n",
      "[12]\tvalid_0's multi_logloss: 0.241391\n",
      "[13]\tvalid_0's multi_logloss: 0.237786\n",
      "[14]\tvalid_0's multi_logloss: 0.234877\n",
      "[15]\tvalid_0's multi_logloss: 0.231898\n",
      "[16]\tvalid_0's multi_logloss: 0.22935\n",
      "[17]\tvalid_0's multi_logloss: 0.227135\n",
      "[18]\tvalid_0's multi_logloss: 0.225155\n",
      "[19]\tvalid_0's multi_logloss: 0.223502\n",
      "[20]\tvalid_0's multi_logloss: 0.22199\n",
      "[21]\tvalid_0's multi_logloss: 0.220157\n",
      "[22]\tvalid_0's multi_logloss: 0.2189\n",
      "[23]\tvalid_0's multi_logloss: 0.217823\n",
      "[24]\tvalid_0's multi_logloss: 0.216784\n",
      "[25]\tvalid_0's multi_logloss: 0.215689\n",
      "[26]\tvalid_0's multi_logloss: 0.214689\n",
      "[27]\tvalid_0's multi_logloss: 0.213587\n",
      "[28]\tvalid_0's multi_logloss: 0.21284\n",
      "[29]\tvalid_0's multi_logloss: 0.21216\n",
      "[30]\tvalid_0's multi_logloss: 0.211381\n",
      "[31]\tvalid_0's multi_logloss: 0.210782\n",
      "[32]\tvalid_0's multi_logloss: 0.210259\n",
      "[33]\tvalid_0's multi_logloss: 0.209619\n",
      "[34]\tvalid_0's multi_logloss: 0.209129\n",
      "[35]\tvalid_0's multi_logloss: 0.208594\n",
      "[36]\tvalid_0's multi_logloss: 0.208194\n",
      "[37]\tvalid_0's multi_logloss: 0.207548\n",
      "[38]\tvalid_0's multi_logloss: 0.206911\n",
      "[39]\tvalid_0's multi_logloss: 0.206329\n",
      "[40]\tvalid_0's multi_logloss: 0.20595\n",
      "[41]\tvalid_0's multi_logloss: 0.205615\n",
      "[42]\tvalid_0's multi_logloss: 0.205267\n",
      "[43]\tvalid_0's multi_logloss: 0.20495\n",
      "[44]\tvalid_0's multi_logloss: 0.204467\n",
      "[45]\tvalid_0's multi_logloss: 0.204051\n",
      "[46]\tvalid_0's multi_logloss: 0.203781\n",
      "[47]\tvalid_0's multi_logloss: 0.203414\n",
      "[48]\tvalid_0's multi_logloss: 0.203081\n",
      "[49]\tvalid_0's multi_logloss: 0.202737\n",
      "[50]\tvalid_0's multi_logloss: 0.20242\n",
      "[51]\tvalid_0's multi_logloss: 0.202257\n",
      "[52]\tvalid_0's multi_logloss: 0.202024\n",
      "[53]\tvalid_0's multi_logloss: 0.201807\n",
      "[54]\tvalid_0's multi_logloss: 0.201589\n",
      "[55]\tvalid_0's multi_logloss: 0.2013\n",
      "[56]\tvalid_0's multi_logloss: 0.201052\n",
      "[57]\tvalid_0's multi_logloss: 0.200849\n",
      "[58]\tvalid_0's multi_logloss: 0.200668\n",
      "[59]\tvalid_0's multi_logloss: 0.200519\n",
      "[60]\tvalid_0's multi_logloss: 0.200356\n",
      "[61]\tvalid_0's multi_logloss: 0.20007\n",
      "[62]\tvalid_0's multi_logloss: 0.199895\n",
      "[63]\tvalid_0's multi_logloss: 0.199747\n",
      "[64]\tvalid_0's multi_logloss: 0.199628\n",
      "[65]\tvalid_0's multi_logloss: 0.199373\n",
      "[66]\tvalid_0's multi_logloss: 0.199167\n",
      "[67]\tvalid_0's multi_logloss: 0.198986\n",
      "[68]\tvalid_0's multi_logloss: 0.198762\n",
      "[69]\tvalid_0's multi_logloss: 0.198597\n",
      "[70]\tvalid_0's multi_logloss: 0.198448\n",
      "[71]\tvalid_0's multi_logloss: 0.198359\n",
      "[72]\tvalid_0's multi_logloss: 0.198257\n",
      "[73]\tvalid_0's multi_logloss: 0.198173\n",
      "[74]\tvalid_0's multi_logloss: 0.198018\n",
      "[75]\tvalid_0's multi_logloss: 0.197918\n",
      "[76]\tvalid_0's multi_logloss: 0.197807\n",
      "[77]\tvalid_0's multi_logloss: 0.197742\n",
      "[78]\tvalid_0's multi_logloss: 0.197579\n",
      "[79]\tvalid_0's multi_logloss: 0.197486\n",
      "[80]\tvalid_0's multi_logloss: 0.197336\n",
      "[81]\tvalid_0's multi_logloss: 0.197192\n",
      "[82]\tvalid_0's multi_logloss: 0.197129\n",
      "[83]\tvalid_0's multi_logloss: 0.197026\n",
      "[84]\tvalid_0's multi_logloss: 0.196904\n",
      "[85]\tvalid_0's multi_logloss: 0.196768\n",
      "[86]\tvalid_0's multi_logloss: 0.196727\n",
      "[87]\tvalid_0's multi_logloss: 0.196661\n",
      "[88]\tvalid_0's multi_logloss: 0.196594\n",
      "[89]\tvalid_0's multi_logloss: 0.196528\n",
      "[90]\tvalid_0's multi_logloss: 0.196444\n",
      "[91]\tvalid_0's multi_logloss: 0.196299\n",
      "[92]\tvalid_0's multi_logloss: 0.196171\n",
      "[93]\tvalid_0's multi_logloss: 0.196015\n",
      "[94]\tvalid_0's multi_logloss: 0.195958\n",
      "[95]\tvalid_0's multi_logloss: 0.195847\n",
      "[96]\tvalid_0's multi_logloss: 0.195749\n",
      "[97]\tvalid_0's multi_logloss: 0.195659\n",
      "[98]\tvalid_0's multi_logloss: 0.195549\n",
      "[99]\tvalid_0's multi_logloss: 0.195427\n",
      "[100]\tvalid_0's multi_logloss: 0.195341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [21:57, 129.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 7715638, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.249550\n",
      "[LightGBM] [Info] Start training from score -3.165534\n",
      "[LightGBM] [Info] Start training from score -1.726403\n",
      "[LightGBM] [Info] Start training from score -1.902421\n",
      "[LightGBM] [Info] Start training from score -1.667720\n",
      "[LightGBM] [Info] Start training from score -1.861961\n",
      "[1]\tvalid_0's multi_logloss: 1.67573\n",
      "[2]\tvalid_0's multi_logloss: 1.66812\n",
      "[3]\tvalid_0's multi_logloss: 1.66108\n",
      "[4]\tvalid_0's multi_logloss: 1.65546\n",
      "[5]\tvalid_0's multi_logloss: 1.65053\n",
      "[6]\tvalid_0's multi_logloss: 1.64642\n",
      "[7]\tvalid_0's multi_logloss: 1.64283\n",
      "[8]\tvalid_0's multi_logloss: 1.63969\n",
      "[9]\tvalid_0's multi_logloss: 1.63702\n",
      "[10]\tvalid_0's multi_logloss: 1.63471\n",
      "[11]\tvalid_0's multi_logloss: 1.63249\n",
      "[12]\tvalid_0's multi_logloss: 1.63047\n",
      "[13]\tvalid_0's multi_logloss: 1.62896\n",
      "[14]\tvalid_0's multi_logloss: 1.62757\n",
      "[15]\tvalid_0's multi_logloss: 1.62642\n",
      "[16]\tvalid_0's multi_logloss: 1.62522\n",
      "[17]\tvalid_0's multi_logloss: 1.62422\n",
      "[18]\tvalid_0's multi_logloss: 1.62327\n",
      "[19]\tvalid_0's multi_logloss: 1.62228\n",
      "[20]\tvalid_0's multi_logloss: 1.62151\n",
      "[21]\tvalid_0's multi_logloss: 1.6209\n",
      "[22]\tvalid_0's multi_logloss: 1.62031\n",
      "[23]\tvalid_0's multi_logloss: 1.61966\n",
      "[24]\tvalid_0's multi_logloss: 1.61885\n",
      "[25]\tvalid_0's multi_logloss: 1.61829\n",
      "[26]\tvalid_0's multi_logloss: 1.61778\n",
      "[27]\tvalid_0's multi_logloss: 1.61719\n",
      "[28]\tvalid_0's multi_logloss: 1.61673\n",
      "[29]\tvalid_0's multi_logloss: 1.6163\n",
      "[30]\tvalid_0's multi_logloss: 1.61581\n",
      "[31]\tvalid_0's multi_logloss: 1.61512\n",
      "[32]\tvalid_0's multi_logloss: 1.61449\n",
      "[33]\tvalid_0's multi_logloss: 1.61407\n",
      "[34]\tvalid_0's multi_logloss: 1.61353\n",
      "[35]\tvalid_0's multi_logloss: 1.61317\n",
      "[36]\tvalid_0's multi_logloss: 1.61264\n",
      "[37]\tvalid_0's multi_logloss: 1.61227\n",
      "[38]\tvalid_0's multi_logloss: 1.61195\n",
      "[39]\tvalid_0's multi_logloss: 1.61169\n",
      "[40]\tvalid_0's multi_logloss: 1.61143\n",
      "[41]\tvalid_0's multi_logloss: 1.61112\n",
      "[42]\tvalid_0's multi_logloss: 1.6109\n",
      "[43]\tvalid_0's multi_logloss: 1.61059\n",
      "[44]\tvalid_0's multi_logloss: 1.61027\n",
      "[45]\tvalid_0's multi_logloss: 1.61004\n",
      "[46]\tvalid_0's multi_logloss: 1.6098\n",
      "[47]\tvalid_0's multi_logloss: 1.60959\n",
      "[48]\tvalid_0's multi_logloss: 1.60939\n",
      "[49]\tvalid_0's multi_logloss: 1.60918\n",
      "[50]\tvalid_0's multi_logloss: 1.60897\n",
      "[51]\tvalid_0's multi_logloss: 1.60873\n",
      "[52]\tvalid_0's multi_logloss: 1.60861\n",
      "[53]\tvalid_0's multi_logloss: 1.60842\n",
      "[54]\tvalid_0's multi_logloss: 1.60799\n",
      "[55]\tvalid_0's multi_logloss: 1.60776\n",
      "[56]\tvalid_0's multi_logloss: 1.60758\n",
      "[57]\tvalid_0's multi_logloss: 1.60746\n",
      "[58]\tvalid_0's multi_logloss: 1.6073\n",
      "[59]\tvalid_0's multi_logloss: 1.60712\n",
      "[60]\tvalid_0's multi_logloss: 1.60691\n",
      "[61]\tvalid_0's multi_logloss: 1.60677\n",
      "[62]\tvalid_0's multi_logloss: 1.60647\n",
      "[63]\tvalid_0's multi_logloss: 1.60634\n",
      "[64]\tvalid_0's multi_logloss: 1.60615\n",
      "[65]\tvalid_0's multi_logloss: 1.60581\n",
      "[66]\tvalid_0's multi_logloss: 1.60563\n",
      "[67]\tvalid_0's multi_logloss: 1.60546\n",
      "[68]\tvalid_0's multi_logloss: 1.60534\n",
      "[69]\tvalid_0's multi_logloss: 1.60519\n",
      "[70]\tvalid_0's multi_logloss: 1.60501\n",
      "[71]\tvalid_0's multi_logloss: 1.60488\n",
      "[72]\tvalid_0's multi_logloss: 1.60471\n",
      "[73]\tvalid_0's multi_logloss: 1.60456\n",
      "[74]\tvalid_0's multi_logloss: 1.60434\n",
      "[75]\tvalid_0's multi_logloss: 1.60421\n",
      "[76]\tvalid_0's multi_logloss: 1.60411\n",
      "[77]\tvalid_0's multi_logloss: 1.60399\n",
      "[78]\tvalid_0's multi_logloss: 1.60389\n",
      "[79]\tvalid_0's multi_logloss: 1.60377\n",
      "[80]\tvalid_0's multi_logloss: 1.60364\n",
      "[81]\tvalid_0's multi_logloss: 1.60343\n",
      "[82]\tvalid_0's multi_logloss: 1.60323\n",
      "[83]\tvalid_0's multi_logloss: 1.60305\n",
      "[84]\tvalid_0's multi_logloss: 1.6029\n",
      "[85]\tvalid_0's multi_logloss: 1.60276\n",
      "[86]\tvalid_0's multi_logloss: 1.60255\n",
      "[87]\tvalid_0's multi_logloss: 1.60244\n",
      "[88]\tvalid_0's multi_logloss: 1.60228\n",
      "[89]\tvalid_0's multi_logloss: 1.60216\n",
      "[90]\tvalid_0's multi_logloss: 1.60208\n",
      "[91]\tvalid_0's multi_logloss: 1.60195\n",
      "[92]\tvalid_0's multi_logloss: 1.6019\n",
      "[93]\tvalid_0's multi_logloss: 1.60177\n",
      "[94]\tvalid_0's multi_logloss: 1.60162\n",
      "[95]\tvalid_0's multi_logloss: 1.60142\n",
      "[96]\tvalid_0's multi_logloss: 1.60124\n",
      "[97]\tvalid_0's multi_logloss: 1.60104\n",
      "[98]\tvalid_0's multi_logloss: 1.60093\n",
      "[99]\tvalid_0's multi_logloss: 1.60085\n",
      "[100]\tvalid_0's multi_logloss: 1.60074\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007490 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 7715638, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -3.388563\n",
      "[LightGBM] [Info] Start training from score -3.286043\n",
      "[LightGBM] [Info] Start training from score -3.265766\n",
      "[LightGBM] [Info] Start training from score -3.814547\n",
      "[LightGBM] [Info] Start training from score -3.310265\n",
      "[LightGBM] [Info] Start training from score -3.206426\n",
      "[LightGBM] [Info] Start training from score -4.264605\n",
      "[LightGBM] [Info] Start training from score -3.385622\n",
      "[LightGBM] [Info] Start training from score -3.678169\n",
      "[LightGBM] [Info] Start training from score -3.401590\n",
      "[LightGBM] [Info] Start training from score -4.879144\n",
      "[LightGBM] [Info] Start training from score -3.027581\n",
      "[LightGBM] [Info] Start training from score -2.985319\n",
      "[LightGBM] [Info] Start training from score -3.251856\n",
      "[LightGBM] [Info] Start training from score -3.294527\n",
      "[LightGBM] [Info] Start training from score -3.372086\n",
      "[LightGBM] [Info] Start training from score -2.973489\n",
      "[LightGBM] [Info] Start training from score -2.489644\n",
      "[LightGBM] [Info] Start training from score -3.403357\n",
      "[LightGBM] [Info] Start training from score -4.161407\n",
      "[LightGBM] [Info] Start training from score -4.219942\n",
      "[LightGBM] [Info] Start training from score -3.454308\n",
      "[LightGBM] [Info] Start training from score -3.414970\n",
      "[LightGBM] [Info] Start training from score -3.160243\n",
      "[LightGBM] [Info] Start training from score -3.113230\n",
      "[LightGBM] [Info] Start training from score -3.209175\n",
      "[LightGBM] [Info] Start training from score -3.282600\n",
      "[LightGBM] [Info] Start training from score -3.180636\n",
      "[1]\tvalid_0's multi_logloss: 2.89151\n",
      "[2]\tvalid_0's multi_logloss: 2.74376\n",
      "[3]\tvalid_0's multi_logloss: 2.64662\n",
      "[4]\tvalid_0's multi_logloss: 2.57875\n",
      "[5]\tvalid_0's multi_logloss: 2.51783\n",
      "[6]\tvalid_0's multi_logloss: 2.46863\n",
      "[7]\tvalid_0's multi_logloss: 2.43162\n",
      "[8]\tvalid_0's multi_logloss: 2.39766\n",
      "[9]\tvalid_0's multi_logloss: 2.36661\n",
      "[10]\tvalid_0's multi_logloss: 2.34144\n",
      "[11]\tvalid_0's multi_logloss: 2.31717\n",
      "[12]\tvalid_0's multi_logloss: 2.29809\n",
      "[13]\tvalid_0's multi_logloss: 2.28078\n",
      "[14]\tvalid_0's multi_logloss: 2.26975\n",
      "[15]\tvalid_0's multi_logloss: 2.25602\n",
      "[16]\tvalid_0's multi_logloss: 2.24263\n",
      "[17]\tvalid_0's multi_logloss: 2.23031\n",
      "[18]\tvalid_0's multi_logloss: 2.21912\n",
      "[19]\tvalid_0's multi_logloss: 2.20888\n",
      "[20]\tvalid_0's multi_logloss: 2.19904\n",
      "[21]\tvalid_0's multi_logloss: 2.19102\n",
      "[22]\tvalid_0's multi_logloss: 2.18329\n",
      "[23]\tvalid_0's multi_logloss: 2.17691\n",
      "[24]\tvalid_0's multi_logloss: 2.16627\n",
      "[25]\tvalid_0's multi_logloss: 2.15897\n",
      "[26]\tvalid_0's multi_logloss: 2.15145\n",
      "[27]\tvalid_0's multi_logloss: 2.1468\n",
      "[28]\tvalid_0's multi_logloss: 2.14175\n",
      "[29]\tvalid_0's multi_logloss: 2.13644\n",
      "[30]\tvalid_0's multi_logloss: 2.13193\n",
      "[31]\tvalid_0's multi_logloss: 2.13172\n",
      "[32]\tvalid_0's multi_logloss: 2.1267\n",
      "[33]\tvalid_0's multi_logloss: 2.12226\n",
      "[34]\tvalid_0's multi_logloss: 2.11737\n",
      "[35]\tvalid_0's multi_logloss: 2.11163\n",
      "[36]\tvalid_0's multi_logloss: 2.10753\n",
      "[37]\tvalid_0's multi_logloss: 2.09827\n",
      "[38]\tvalid_0's multi_logloss: 2.09462\n",
      "[39]\tvalid_0's multi_logloss: 2.09111\n",
      "[40]\tvalid_0's multi_logloss: 2.08761\n",
      "[41]\tvalid_0's multi_logloss: 2.08372\n",
      "[42]\tvalid_0's multi_logloss: 2.08044\n",
      "[43]\tvalid_0's multi_logloss: 2.07654\n",
      "[44]\tvalid_0's multi_logloss: 2.0735\n",
      "[45]\tvalid_0's multi_logloss: 2.0696\n",
      "[46]\tvalid_0's multi_logloss: 2.06871\n",
      "[47]\tvalid_0's multi_logloss: 2.06846\n",
      "[48]\tvalid_0's multi_logloss: 2.06232\n",
      "[49]\tvalid_0's multi_logloss: 2.05949\n",
      "[50]\tvalid_0's multi_logloss: 2.05808\n",
      "[51]\tvalid_0's multi_logloss: 2.05626\n",
      "[52]\tvalid_0's multi_logloss: 2.05459\n",
      "[53]\tvalid_0's multi_logloss: 2.05684\n",
      "[54]\tvalid_0's multi_logloss: 2.0524\n",
      "[55]\tvalid_0's multi_logloss: 2.04684\n",
      "[56]\tvalid_0's multi_logloss: 2.04135\n",
      "[57]\tvalid_0's multi_logloss: 2.04004\n",
      "[58]\tvalid_0's multi_logloss: 2.037\n",
      "[59]\tvalid_0's multi_logloss: 2.03481\n",
      "[60]\tvalid_0's multi_logloss: 2.03108\n",
      "[61]\tvalid_0's multi_logloss: 2.03125\n",
      "[62]\tvalid_0's multi_logloss: 2.03086\n",
      "[63]\tvalid_0's multi_logloss: 2.02628\n",
      "[64]\tvalid_0's multi_logloss: 2.0239\n",
      "[65]\tvalid_0's multi_logloss: 2.02141\n",
      "[66]\tvalid_0's multi_logloss: 2.01927\n",
      "[67]\tvalid_0's multi_logloss: 2.02085\n",
      "[68]\tvalid_0's multi_logloss: 2.02107\n",
      "[69]\tvalid_0's multi_logloss: 2.01838\n",
      "[70]\tvalid_0's multi_logloss: 2.01351\n",
      "[71]\tvalid_0's multi_logloss: 2.0115\n",
      "[72]\tvalid_0's multi_logloss: 2.00983\n",
      "[73]\tvalid_0's multi_logloss: 2.01089\n",
      "[74]\tvalid_0's multi_logloss: 2.00927\n",
      "[75]\tvalid_0's multi_logloss: 2.00724\n",
      "[76]\tvalid_0's multi_logloss: 2.00516\n",
      "[77]\tvalid_0's multi_logloss: 2.00448\n",
      "[78]\tvalid_0's multi_logloss: 2.00321\n",
      "[79]\tvalid_0's multi_logloss: 2.00187\n",
      "[80]\tvalid_0's multi_logloss: 1.9989\n",
      "[81]\tvalid_0's multi_logloss: 1.99841\n",
      "[82]\tvalid_0's multi_logloss: 2.00231\n",
      "[83]\tvalid_0's multi_logloss: 1.99917\n",
      "[84]\tvalid_0's multi_logloss: 2.00005\n",
      "[85]\tvalid_0's multi_logloss: 2.00682\n",
      "[86]\tvalid_0's multi_logloss: 2.00322\n",
      "[87]\tvalid_0's multi_logloss: 2.00575\n",
      "[88]\tvalid_0's multi_logloss: 2.0047\n",
      "[89]\tvalid_0's multi_logloss: 2.00415\n",
      "[90]\tvalid_0's multi_logloss: 1.99701\n",
      "[91]\tvalid_0's multi_logloss: 1.99858\n",
      "[92]\tvalid_0's multi_logloss: 1.99362\n",
      "[93]\tvalid_0's multi_logloss: 1.99725\n",
      "[94]\tvalid_0's multi_logloss: 1.99585\n",
      "[95]\tvalid_0's multi_logloss: 1.9965\n",
      "[96]\tvalid_0's multi_logloss: 1.99436\n",
      "[97]\tvalid_0's multi_logloss: 1.99835\n",
      "[98]\tvalid_0's multi_logloss: 2.01318\n",
      "[99]\tvalid_0's multi_logloss: 2.01278\n",
      "[100]\tvalid_0's multi_logloss: 2.00041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [23:33, 119.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001367 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 820733, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -0.683185\n",
      "[LightGBM] [Info] Start training from score -2.382997\n",
      "[LightGBM] [Info] Start training from score -2.734975\n",
      "[LightGBM] [Info] Start training from score -3.826068\n",
      "[LightGBM] [Info] Start training from score -1.583719\n",
      "[LightGBM] [Info] Start training from score -2.199855\n",
      "[1]\tvalid_0's multi_logloss: 1.16907\n",
      "[2]\tvalid_0's multi_logloss: 1.06119\n",
      "[3]\tvalid_0's multi_logloss: 0.979719\n",
      "[4]\tvalid_0's multi_logloss: 0.915818\n",
      "[5]\tvalid_0's multi_logloss: 0.864337\n",
      "[6]\tvalid_0's multi_logloss: 0.821758\n",
      "[7]\tvalid_0's multi_logloss: 0.786858\n",
      "[8]\tvalid_0's multi_logloss: 0.758022\n",
      "[9]\tvalid_0's multi_logloss: 0.732902\n",
      "[10]\tvalid_0's multi_logloss: 0.711713\n",
      "[11]\tvalid_0's multi_logloss: 0.693862\n",
      "[12]\tvalid_0's multi_logloss: 0.678309\n",
      "[13]\tvalid_0's multi_logloss: 0.664309\n",
      "[14]\tvalid_0's multi_logloss: 0.652141\n",
      "[15]\tvalid_0's multi_logloss: 0.641571\n",
      "[16]\tvalid_0's multi_logloss: 0.632349\n",
      "[17]\tvalid_0's multi_logloss: 0.623945\n",
      "[18]\tvalid_0's multi_logloss: 0.616813\n",
      "[19]\tvalid_0's multi_logloss: 0.610235\n",
      "[20]\tvalid_0's multi_logloss: 0.604397\n",
      "[21]\tvalid_0's multi_logloss: 0.599136\n",
      "[22]\tvalid_0's multi_logloss: 0.59446\n",
      "[23]\tvalid_0's multi_logloss: 0.590212\n",
      "[24]\tvalid_0's multi_logloss: 0.586194\n",
      "[25]\tvalid_0's multi_logloss: 0.58267\n",
      "[26]\tvalid_0's multi_logloss: 0.579356\n",
      "[27]\tvalid_0's multi_logloss: 0.576218\n",
      "[28]\tvalid_0's multi_logloss: 0.573506\n",
      "[29]\tvalid_0's multi_logloss: 0.570929\n",
      "[30]\tvalid_0's multi_logloss: 0.568731\n",
      "[31]\tvalid_0's multi_logloss: 0.566762\n",
      "[32]\tvalid_0's multi_logloss: 0.564851\n",
      "[33]\tvalid_0's multi_logloss: 0.563223\n",
      "[34]\tvalid_0's multi_logloss: 0.561425\n",
      "[35]\tvalid_0's multi_logloss: 0.559823\n",
      "[36]\tvalid_0's multi_logloss: 0.558573\n",
      "[37]\tvalid_0's multi_logloss: 0.557151\n",
      "[38]\tvalid_0's multi_logloss: 0.555967\n",
      "[39]\tvalid_0's multi_logloss: 0.554762\n",
      "[40]\tvalid_0's multi_logloss: 0.553975\n",
      "[41]\tvalid_0's multi_logloss: 0.552994\n",
      "[42]\tvalid_0's multi_logloss: 0.551948\n",
      "[43]\tvalid_0's multi_logloss: 0.551092\n",
      "[44]\tvalid_0's multi_logloss: 0.549808\n",
      "[45]\tvalid_0's multi_logloss: 0.549014\n",
      "[46]\tvalid_0's multi_logloss: 0.548494\n",
      "[47]\tvalid_0's multi_logloss: 0.547605\n",
      "[48]\tvalid_0's multi_logloss: 0.547222\n",
      "[49]\tvalid_0's multi_logloss: 0.546224\n",
      "[50]\tvalid_0's multi_logloss: 0.546419\n",
      "[51]\tvalid_0's multi_logloss: 0.545613\n",
      "[52]\tvalid_0's multi_logloss: 0.545426\n",
      "[53]\tvalid_0's multi_logloss: 0.544846\n",
      "[54]\tvalid_0's multi_logloss: 0.544341\n",
      "[55]\tvalid_0's multi_logloss: 0.543629\n",
      "[56]\tvalid_0's multi_logloss: 0.542248\n",
      "[57]\tvalid_0's multi_logloss: 0.541899\n",
      "[58]\tvalid_0's multi_logloss: 0.543204\n",
      "[59]\tvalid_0's multi_logloss: 0.547248\n",
      "[60]\tvalid_0's multi_logloss: 0.541713\n",
      "[61]\tvalid_0's multi_logloss: 0.540888\n",
      "[62]\tvalid_0's multi_logloss: 0.550958\n",
      "[63]\tvalid_0's multi_logloss: 0.541342\n",
      "[64]\tvalid_0's multi_logloss: 0.540057\n",
      "[65]\tvalid_0's multi_logloss: 0.540278\n",
      "[66]\tvalid_0's multi_logloss: 0.53949\n",
      "[67]\tvalid_0's multi_logloss: 0.53905\n",
      "[68]\tvalid_0's multi_logloss: 0.549306\n",
      "[69]\tvalid_0's multi_logloss: 0.53876\n",
      "[70]\tvalid_0's multi_logloss: 0.543319\n",
      "[71]\tvalid_0's multi_logloss: 0.542745\n",
      "[72]\tvalid_0's multi_logloss: 0.542929\n",
      "[73]\tvalid_0's multi_logloss: 0.539039\n",
      "[74]\tvalid_0's multi_logloss: 0.538486\n",
      "[75]\tvalid_0's multi_logloss: 0.545942\n",
      "[76]\tvalid_0's multi_logloss: 0.538598\n",
      "[77]\tvalid_0's multi_logloss: 0.539994\n",
      "[78]\tvalid_0's multi_logloss: 0.540716\n",
      "[79]\tvalid_0's multi_logloss: 0.538887\n",
      "[80]\tvalid_0's multi_logloss: 0.538821\n",
      "[81]\tvalid_0's multi_logloss: 0.546317\n",
      "[82]\tvalid_0's multi_logloss: 0.548645\n",
      "[83]\tvalid_0's multi_logloss: 0.54991\n",
      "[84]\tvalid_0's multi_logloss: 0.546712\n",
      "[85]\tvalid_0's multi_logloss: 0.551036\n",
      "[86]\tvalid_0's multi_logloss: 0.542752\n",
      "[87]\tvalid_0's multi_logloss: 0.553431\n",
      "[88]\tvalid_0's multi_logloss: 0.541742\n",
      "[89]\tvalid_0's multi_logloss: 0.564773\n",
      "[90]\tvalid_0's multi_logloss: 0.538155\n",
      "[91]\tvalid_0's multi_logloss: 0.55337\n",
      "[92]\tvalid_0's multi_logloss: 0.561616\n",
      "[93]\tvalid_0's multi_logloss: 0.617042\n",
      "[94]\tvalid_0's multi_logloss: 0.541979\n",
      "[95]\tvalid_0's multi_logloss: 0.562215\n",
      "[96]\tvalid_0's multi_logloss: 0.555316\n",
      "[97]\tvalid_0's multi_logloss: 0.549128\n",
      "[98]\tvalid_0's multi_logloss: 0.543276\n",
      "[99]\tvalid_0's multi_logloss: 0.579406\n",
      "[100]\tvalid_0's multi_logloss: 0.550348\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001635 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 820733, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -2.163833\n",
      "[LightGBM] [Info] Start training from score -1.796397\n",
      "[LightGBM] [Info] Start training from score -1.843741\n",
      "[LightGBM] [Info] Start training from score -1.989576\n",
      "[LightGBM] [Info] Start training from score -1.941218\n",
      "[LightGBM] [Info] Start training from score -1.949016\n",
      "[LightGBM] [Info] Start training from score -1.978333\n",
      "[1]\tvalid_0's multi_logloss: 1.9\n",
      "[2]\tvalid_0's multi_logloss: 1.8692\n",
      "[3]\tvalid_0's multi_logloss: 1.84464\n",
      "[4]\tvalid_0's multi_logloss: 1.82477\n",
      "[5]\tvalid_0's multi_logloss: 1.80852\n",
      "[6]\tvalid_0's multi_logloss: 1.7951\n",
      "[7]\tvalid_0's multi_logloss: 1.78392\n",
      "[8]\tvalid_0's multi_logloss: 1.77466\n",
      "[9]\tvalid_0's multi_logloss: 1.76681\n",
      "[10]\tvalid_0's multi_logloss: 1.76006\n",
      "[11]\tvalid_0's multi_logloss: 1.7545\n",
      "[12]\tvalid_0's multi_logloss: 1.74971\n",
      "[13]\tvalid_0's multi_logloss: 1.74562\n",
      "[14]\tvalid_0's multi_logloss: 1.74209\n",
      "[15]\tvalid_0's multi_logloss: 1.73913\n",
      "[16]\tvalid_0's multi_logloss: 1.73655\n",
      "[17]\tvalid_0's multi_logloss: 1.73431\n",
      "[18]\tvalid_0's multi_logloss: 1.73226\n",
      "[19]\tvalid_0's multi_logloss: 1.73057\n",
      "[20]\tvalid_0's multi_logloss: 1.72907\n",
      "[21]\tvalid_0's multi_logloss: 1.72768\n",
      "[22]\tvalid_0's multi_logloss: 1.72649\n",
      "[23]\tvalid_0's multi_logloss: 1.72535\n",
      "[24]\tvalid_0's multi_logloss: 1.72445\n",
      "[25]\tvalid_0's multi_logloss: 1.72349\n",
      "[26]\tvalid_0's multi_logloss: 1.72272\n",
      "[27]\tvalid_0's multi_logloss: 1.72201\n",
      "[28]\tvalid_0's multi_logloss: 1.72124\n",
      "[29]\tvalid_0's multi_logloss: 1.72066\n",
      "[30]\tvalid_0's multi_logloss: 1.72013\n",
      "[31]\tvalid_0's multi_logloss: 1.71952\n",
      "[32]\tvalid_0's multi_logloss: 1.71903\n",
      "[33]\tvalid_0's multi_logloss: 1.71858\n",
      "[34]\tvalid_0's multi_logloss: 1.71817\n",
      "[35]\tvalid_0's multi_logloss: 1.71771\n",
      "[36]\tvalid_0's multi_logloss: 1.71733\n",
      "[37]\tvalid_0's multi_logloss: 1.71693\n",
      "[38]\tvalid_0's multi_logloss: 1.7166\n",
      "[39]\tvalid_0's multi_logloss: 1.71621\n",
      "[40]\tvalid_0's multi_logloss: 1.71583\n",
      "[41]\tvalid_0's multi_logloss: 1.71554\n",
      "[42]\tvalid_0's multi_logloss: 1.71524\n",
      "[43]\tvalid_0's multi_logloss: 1.71498\n",
      "[44]\tvalid_0's multi_logloss: 1.71463\n",
      "[45]\tvalid_0's multi_logloss: 1.71432\n",
      "[46]\tvalid_0's multi_logloss: 1.71407\n",
      "[47]\tvalid_0's multi_logloss: 1.71382\n",
      "[48]\tvalid_0's multi_logloss: 1.71362\n",
      "[49]\tvalid_0's multi_logloss: 1.71333\n",
      "[50]\tvalid_0's multi_logloss: 1.71307\n",
      "[51]\tvalid_0's multi_logloss: 1.71284\n",
      "[52]\tvalid_0's multi_logloss: 1.71262\n",
      "[53]\tvalid_0's multi_logloss: 1.71244\n",
      "[54]\tvalid_0's multi_logloss: 1.71224\n",
      "[55]\tvalid_0's multi_logloss: 1.71209\n",
      "[56]\tvalid_0's multi_logloss: 1.71191\n",
      "[57]\tvalid_0's multi_logloss: 1.71173\n",
      "[58]\tvalid_0's multi_logloss: 1.71157\n",
      "[59]\tvalid_0's multi_logloss: 1.71146\n",
      "[60]\tvalid_0's multi_logloss: 1.7112\n",
      "[61]\tvalid_0's multi_logloss: 1.71108\n",
      "[62]\tvalid_0's multi_logloss: 1.71092\n",
      "[63]\tvalid_0's multi_logloss: 1.71073\n",
      "[64]\tvalid_0's multi_logloss: 1.71059\n",
      "[65]\tvalid_0's multi_logloss: 1.71052\n",
      "[66]\tvalid_0's multi_logloss: 1.71035\n",
      "[67]\tvalid_0's multi_logloss: 1.71022\n",
      "[68]\tvalid_0's multi_logloss: 1.71013\n",
      "[69]\tvalid_0's multi_logloss: 1.70999\n",
      "[70]\tvalid_0's multi_logloss: 1.70985\n",
      "[71]\tvalid_0's multi_logloss: 1.70969\n",
      "[72]\tvalid_0's multi_logloss: 1.70953\n",
      "[73]\tvalid_0's multi_logloss: 1.70941\n",
      "[74]\tvalid_0's multi_logloss: 1.70929\n",
      "[75]\tvalid_0's multi_logloss: 1.70918\n",
      "[76]\tvalid_0's multi_logloss: 1.70905\n",
      "[77]\tvalid_0's multi_logloss: 1.70896\n",
      "[78]\tvalid_0's multi_logloss: 1.70886\n",
      "[79]\tvalid_0's multi_logloss: 1.70872\n",
      "[80]\tvalid_0's multi_logloss: 1.70865\n",
      "[81]\tvalid_0's multi_logloss: 1.70852\n",
      "[82]\tvalid_0's multi_logloss: 1.70846\n",
      "[83]\tvalid_0's multi_logloss: 1.70834\n",
      "[84]\tvalid_0's multi_logloss: 1.70825\n",
      "[85]\tvalid_0's multi_logloss: 1.70817\n",
      "[86]\tvalid_0's multi_logloss: 1.7081\n",
      "[87]\tvalid_0's multi_logloss: 1.70803\n",
      "[88]\tvalid_0's multi_logloss: 1.70797\n",
      "[89]\tvalid_0's multi_logloss: 1.70784\n",
      "[90]\tvalid_0's multi_logloss: 1.70777\n",
      "[91]\tvalid_0's multi_logloss: 1.70767\n",
      "[92]\tvalid_0's multi_logloss: 1.70757\n",
      "[93]\tvalid_0's multi_logloss: 1.70748\n",
      "[94]\tvalid_0's multi_logloss: 1.70742\n",
      "[95]\tvalid_0's multi_logloss: 1.70734\n",
      "[96]\tvalid_0's multi_logloss: 1.70727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [23:41, 85.42s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[97]\tvalid_0's multi_logloss: 1.7072\n",
      "[98]\tvalid_0's multi_logloss: 1.70712\n",
      "[99]\tvalid_0's multi_logloss: 1.70707\n",
      "[100]\tvalid_0's multi_logloss: 1.70701\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017824 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -1.853404\n",
      "[LightGBM] [Info] Start training from score -2.123202\n",
      "[LightGBM] [Info] Start training from score -2.391862\n",
      "[LightGBM] [Info] Start training from score -2.719639\n",
      "[LightGBM] [Info] Start training from score -2.078311\n",
      "[LightGBM] [Info] Start training from score -2.161447\n",
      "[LightGBM] [Info] Start training from score -2.497610\n",
      "[LightGBM] [Info] Start training from score -2.232530\n",
      "[LightGBM] [Info] Start training from score -2.689447\n",
      "[LightGBM] [Info] Start training from score -2.680407\n",
      "[1]\tvalid_0's multi_logloss: 1.85365\n",
      "[2]\tvalid_0's multi_logloss: 1.65314\n",
      "[3]\tvalid_0's multi_logloss: 1.51376\n",
      "[4]\tvalid_0's multi_logloss: 1.40697\n",
      "[5]\tvalid_0's multi_logloss: 1.3236\n",
      "[6]\tvalid_0's multi_logloss: 1.256\n",
      "[7]\tvalid_0's multi_logloss: 1.20099\n",
      "[8]\tvalid_0's multi_logloss: 1.15542\n",
      "[9]\tvalid_0's multi_logloss: 1.11693\n",
      "[10]\tvalid_0's multi_logloss: 1.08396\n",
      "[11]\tvalid_0's multi_logloss: 1.05559\n",
      "[12]\tvalid_0's multi_logloss: 1.03072\n",
      "[13]\tvalid_0's multi_logloss: 1.00996\n",
      "[14]\tvalid_0's multi_logloss: 0.991751\n",
      "[15]\tvalid_0's multi_logloss: 0.975723\n",
      "[16]\tvalid_0's multi_logloss: 0.961771\n",
      "[17]\tvalid_0's multi_logloss: 0.949779\n",
      "[18]\tvalid_0's multi_logloss: 0.938834\n",
      "[19]\tvalid_0's multi_logloss: 0.929208\n",
      "[20]\tvalid_0's multi_logloss: 0.920427\n",
      "[21]\tvalid_0's multi_logloss: 0.912567\n",
      "[22]\tvalid_0's multi_logloss: 0.905279\n",
      "[23]\tvalid_0's multi_logloss: 0.898683\n",
      "[24]\tvalid_0's multi_logloss: 0.892756\n",
      "[25]\tvalid_0's multi_logloss: 0.887772\n",
      "[26]\tvalid_0's multi_logloss: 0.882856\n",
      "[27]\tvalid_0's multi_logloss: 0.878424\n",
      "[28]\tvalid_0's multi_logloss: 0.873725\n",
      "[29]\tvalid_0's multi_logloss: 0.869286\n",
      "[30]\tvalid_0's multi_logloss: 0.865234\n",
      "[31]\tvalid_0's multi_logloss: 0.861681\n",
      "[32]\tvalid_0's multi_logloss: 0.858223\n",
      "[33]\tvalid_0's multi_logloss: 0.855046\n",
      "[34]\tvalid_0's multi_logloss: 0.852108\n",
      "[35]\tvalid_0's multi_logloss: 0.849411\n",
      "[36]\tvalid_0's multi_logloss: 0.846887\n",
      "[37]\tvalid_0's multi_logloss: 0.844596\n",
      "[38]\tvalid_0's multi_logloss: 0.842409\n",
      "[39]\tvalid_0's multi_logloss: 0.84024\n",
      "[40]\tvalid_0's multi_logloss: 0.83814\n",
      "[41]\tvalid_0's multi_logloss: 0.836301\n",
      "[42]\tvalid_0's multi_logloss: 0.834541\n",
      "[43]\tvalid_0's multi_logloss: 0.832757\n",
      "[44]\tvalid_0's multi_logloss: 0.831318\n",
      "[45]\tvalid_0's multi_logloss: 0.829861\n",
      "[46]\tvalid_0's multi_logloss: 0.828415\n",
      "[47]\tvalid_0's multi_logloss: 0.826905\n",
      "[48]\tvalid_0's multi_logloss: 0.825532\n",
      "[49]\tvalid_0's multi_logloss: 0.824193\n",
      "[50]\tvalid_0's multi_logloss: 0.822755\n",
      "[51]\tvalid_0's multi_logloss: 0.821503\n",
      "[52]\tvalid_0's multi_logloss: 0.820282\n",
      "[53]\tvalid_0's multi_logloss: 0.819193\n",
      "[54]\tvalid_0's multi_logloss: 0.818123\n",
      "[55]\tvalid_0's multi_logloss: 0.817005\n",
      "[56]\tvalid_0's multi_logloss: 0.815974\n",
      "[57]\tvalid_0's multi_logloss: 0.81492\n",
      "[58]\tvalid_0's multi_logloss: 0.813786\n",
      "[59]\tvalid_0's multi_logloss: 0.812865\n",
      "[60]\tvalid_0's multi_logloss: 0.812097\n",
      "[61]\tvalid_0's multi_logloss: 0.811252\n",
      "[62]\tvalid_0's multi_logloss: 0.81036\n",
      "[63]\tvalid_0's multi_logloss: 0.809444\n",
      "[64]\tvalid_0's multi_logloss: 0.808573\n",
      "[65]\tvalid_0's multi_logloss: 0.807819\n",
      "[66]\tvalid_0's multi_logloss: 0.806906\n",
      "[67]\tvalid_0's multi_logloss: 0.806195\n",
      "[68]\tvalid_0's multi_logloss: 0.805488\n",
      "[69]\tvalid_0's multi_logloss: 0.804744\n",
      "[70]\tvalid_0's multi_logloss: 0.804132\n",
      "[71]\tvalid_0's multi_logloss: 0.803463\n",
      "[72]\tvalid_0's multi_logloss: 0.802837\n",
      "[73]\tvalid_0's multi_logloss: 0.802105\n",
      "[74]\tvalid_0's multi_logloss: 0.801452\n",
      "[75]\tvalid_0's multi_logloss: 0.800829\n",
      "[76]\tvalid_0's multi_logloss: 0.800092\n",
      "[77]\tvalid_0's multi_logloss: 0.799392\n",
      "[78]\tvalid_0's multi_logloss: 0.798798\n",
      "[79]\tvalid_0's multi_logloss: 0.798212\n",
      "[80]\tvalid_0's multi_logloss: 0.797613\n",
      "[81]\tvalid_0's multi_logloss: 0.796996\n",
      "[82]\tvalid_0's multi_logloss: 0.796399\n",
      "[83]\tvalid_0's multi_logloss: 0.795832\n",
      "[84]\tvalid_0's multi_logloss: 0.795309\n",
      "[85]\tvalid_0's multi_logloss: 0.794767\n",
      "[86]\tvalid_0's multi_logloss: 0.794262\n",
      "[87]\tvalid_0's multi_logloss: 0.793798\n",
      "[88]\tvalid_0's multi_logloss: 0.793303\n",
      "[89]\tvalid_0's multi_logloss: 0.792942\n",
      "[90]\tvalid_0's multi_logloss: 0.792456\n",
      "[91]\tvalid_0's multi_logloss: 0.791975\n",
      "[92]\tvalid_0's multi_logloss: 0.791488\n",
      "[93]\tvalid_0's multi_logloss: 0.791049\n",
      "[94]\tvalid_0's multi_logloss: 0.790591\n",
      "[95]\tvalid_0's multi_logloss: 0.790316\n",
      "[96]\tvalid_0's multi_logloss: 0.789791\n",
      "[97]\tvalid_0's multi_logloss: 0.789381\n",
      "[98]\tvalid_0's multi_logloss: 0.789038\n",
      "[99]\tvalid_0's multi_logloss: 0.78873\n",
      "[100]\tvalid_0's multi_logloss: 0.788407\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017293 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -1.047228\n",
      "[LightGBM] [Info] Start training from score -1.516216\n",
      "[LightGBM] [Info] Start training from score -0.845018\n",
      "[1]\tvalid_0's multi_logloss: 1.00915\n",
      "[2]\tvalid_0's multi_logloss: 0.965089\n",
      "[3]\tvalid_0's multi_logloss: 0.928412\n",
      "[4]\tvalid_0's multi_logloss: 0.897696\n",
      "[5]\tvalid_0's multi_logloss: 0.871343\n",
      "[6]\tvalid_0's multi_logloss: 0.84886\n",
      "[7]\tvalid_0's multi_logloss: 0.829453\n",
      "[8]\tvalid_0's multi_logloss: 0.812425\n",
      "[9]\tvalid_0's multi_logloss: 0.797545\n",
      "[10]\tvalid_0's multi_logloss: 0.784444\n",
      "[11]\tvalid_0's multi_logloss: 0.772799\n",
      "[12]\tvalid_0's multi_logloss: 0.76256\n",
      "[13]\tvalid_0's multi_logloss: 0.75319\n",
      "[14]\tvalid_0's multi_logloss: 0.744961\n",
      "[15]\tvalid_0's multi_logloss: 0.737403\n",
      "[16]\tvalid_0's multi_logloss: 0.730619\n",
      "[17]\tvalid_0's multi_logloss: 0.724494\n",
      "[18]\tvalid_0's multi_logloss: 0.718919\n",
      "[19]\tvalid_0's multi_logloss: 0.713739\n",
      "[20]\tvalid_0's multi_logloss: 0.709\n",
      "[21]\tvalid_0's multi_logloss: 0.704577\n",
      "[22]\tvalid_0's multi_logloss: 0.700504\n",
      "[23]\tvalid_0's multi_logloss: 0.696781\n",
      "[24]\tvalid_0's multi_logloss: 0.693395\n",
      "[25]\tvalid_0's multi_logloss: 0.690274\n",
      "[26]\tvalid_0's multi_logloss: 0.687345\n",
      "[27]\tvalid_0's multi_logloss: 0.684652\n",
      "[28]\tvalid_0's multi_logloss: 0.682169\n",
      "[29]\tvalid_0's multi_logloss: 0.679912\n",
      "[30]\tvalid_0's multi_logloss: 0.677738\n",
      "[31]\tvalid_0's multi_logloss: 0.675765\n",
      "[32]\tvalid_0's multi_logloss: 0.673908\n",
      "[33]\tvalid_0's multi_logloss: 0.6722\n",
      "[34]\tvalid_0's multi_logloss: 0.670667\n",
      "[35]\tvalid_0's multi_logloss: 0.669133\n",
      "[36]\tvalid_0's multi_logloss: 0.667773\n",
      "[37]\tvalid_0's multi_logloss: 0.666435\n",
      "[38]\tvalid_0's multi_logloss: 0.665159\n",
      "[39]\tvalid_0's multi_logloss: 0.664036\n",
      "[40]\tvalid_0's multi_logloss: 0.66295\n",
      "[41]\tvalid_0's multi_logloss: 0.661921\n",
      "[42]\tvalid_0's multi_logloss: 0.660934\n",
      "[43]\tvalid_0's multi_logloss: 0.660096\n",
      "[44]\tvalid_0's multi_logloss: 0.659262\n",
      "[45]\tvalid_0's multi_logloss: 0.65847\n",
      "[46]\tvalid_0's multi_logloss: 0.657748\n",
      "[47]\tvalid_0's multi_logloss: 0.65703\n",
      "[48]\tvalid_0's multi_logloss: 0.656357\n",
      "[49]\tvalid_0's multi_logloss: 0.655719\n",
      "[50]\tvalid_0's multi_logloss: 0.655132\n",
      "[51]\tvalid_0's multi_logloss: 0.654607\n",
      "[52]\tvalid_0's multi_logloss: 0.654113\n",
      "[53]\tvalid_0's multi_logloss: 0.65364\n",
      "[54]\tvalid_0's multi_logloss: 0.653142\n",
      "[55]\tvalid_0's multi_logloss: 0.652644\n",
      "[56]\tvalid_0's multi_logloss: 0.652235\n",
      "[57]\tvalid_0's multi_logloss: 0.65179\n",
      "[58]\tvalid_0's multi_logloss: 0.651428\n",
      "[59]\tvalid_0's multi_logloss: 0.651049\n",
      "[60]\tvalid_0's multi_logloss: 0.650636\n",
      "[61]\tvalid_0's multi_logloss: 0.650283\n",
      "[62]\tvalid_0's multi_logloss: 0.649971\n",
      "[63]\tvalid_0's multi_logloss: 0.649671\n",
      "[64]\tvalid_0's multi_logloss: 0.649316\n",
      "[65]\tvalid_0's multi_logloss: 0.649038\n",
      "[66]\tvalid_0's multi_logloss: 0.648699\n",
      "[67]\tvalid_0's multi_logloss: 0.648426\n",
      "[68]\tvalid_0's multi_logloss: 0.648198\n",
      "[69]\tvalid_0's multi_logloss: 0.647972\n",
      "[70]\tvalid_0's multi_logloss: 0.647749\n",
      "[71]\tvalid_0's multi_logloss: 0.647555\n",
      "[72]\tvalid_0's multi_logloss: 0.647372\n",
      "[73]\tvalid_0's multi_logloss: 0.64714\n",
      "[74]\tvalid_0's multi_logloss: 0.646939\n",
      "[75]\tvalid_0's multi_logloss: 0.64673\n",
      "[76]\tvalid_0's multi_logloss: 0.646528\n",
      "[77]\tvalid_0's multi_logloss: 0.646351\n",
      "[78]\tvalid_0's multi_logloss: 0.646173\n",
      "[79]\tvalid_0's multi_logloss: 0.645939\n",
      "[80]\tvalid_0's multi_logloss: 0.645773\n",
      "[81]\tvalid_0's multi_logloss: 0.645658\n",
      "[82]\tvalid_0's multi_logloss: 0.645498\n",
      "[83]\tvalid_0's multi_logloss: 0.645367\n",
      "[84]\tvalid_0's multi_logloss: 0.645225\n",
      "[85]\tvalid_0's multi_logloss: 0.645082\n",
      "[86]\tvalid_0's multi_logloss: 0.644915\n",
      "[87]\tvalid_0's multi_logloss: 0.644804\n",
      "[88]\tvalid_0's multi_logloss: 0.644617\n",
      "[89]\tvalid_0's multi_logloss: 0.644514\n",
      "[90]\tvalid_0's multi_logloss: 0.644339\n",
      "[91]\tvalid_0's multi_logloss: 0.644214\n",
      "[92]\tvalid_0's multi_logloss: 0.644112\n",
      "[93]\tvalid_0's multi_logloss: 0.644001\n",
      "[94]\tvalid_0's multi_logloss: 0.643889\n",
      "[95]\tvalid_0's multi_logloss: 0.643818\n",
      "[96]\tvalid_0's multi_logloss: 0.643723\n",
      "[97]\tvalid_0's multi_logloss: 0.643579\n",
      "[98]\tvalid_0's multi_logloss: 0.643506\n",
      "[99]\tvalid_0's multi_logloss: 0.64342\n",
      "[100]\tvalid_0's multi_logloss: 0.643341\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017724 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -3.244539\n",
      "[LightGBM] [Info] Start training from score -3.224920\n",
      "[LightGBM] [Info] Start training from score -3.369880\n",
      "[LightGBM] [Info] Start training from score -3.326941\n",
      "[LightGBM] [Info] Start training from score -3.378266\n",
      "[LightGBM] [Info] Start training from score -2.568017\n",
      "[LightGBM] [Info] Start training from score -1.914747\n",
      "[LightGBM] [Info] Start training from score -3.469579\n",
      "[LightGBM] [Info] Start training from score -1.919436\n",
      "[LightGBM] [Info] Start training from score -2.291576\n",
      "[LightGBM] [Info] Start training from score -2.007538\n",
      "[LightGBM] [Info] Start training from score -3.402200\n",
      "[LightGBM] [Info] Start training from score -3.212376\n",
      "[LightGBM] [Info] Start training from score -2.244521\n",
      "[1]\tvalid_0's multi_logloss: 2.38197\n",
      "[2]\tvalid_0's multi_logloss: 2.33353\n",
      "[3]\tvalid_0's multi_logloss: 2.29703\n",
      "[4]\tvalid_0's multi_logloss: 2.26819\n",
      "[5]\tvalid_0's multi_logloss: 2.2441\n",
      "[6]\tvalid_0's multi_logloss: 2.22335\n",
      "[7]\tvalid_0's multi_logloss: 2.20587\n",
      "[8]\tvalid_0's multi_logloss: 2.19021\n",
      "[9]\tvalid_0's multi_logloss: 2.17655\n",
      "[10]\tvalid_0's multi_logloss: 2.16517\n",
      "[11]\tvalid_0's multi_logloss: 2.15489\n",
      "[12]\tvalid_0's multi_logloss: 2.14595\n",
      "[13]\tvalid_0's multi_logloss: 2.13726\n",
      "[14]\tvalid_0's multi_logloss: 2.12929\n",
      "[15]\tvalid_0's multi_logloss: 2.12257\n",
      "[16]\tvalid_0's multi_logloss: 2.11603\n",
      "[17]\tvalid_0's multi_logloss: 2.11073\n",
      "[18]\tvalid_0's multi_logloss: 2.10586\n",
      "[19]\tvalid_0's multi_logloss: 2.10128\n",
      "[20]\tvalid_0's multi_logloss: 2.09719\n",
      "[21]\tvalid_0's multi_logloss: 2.09308\n",
      "[22]\tvalid_0's multi_logloss: 2.08971\n",
      "[23]\tvalid_0's multi_logloss: 2.08663\n",
      "[24]\tvalid_0's multi_logloss: 2.08372\n",
      "[25]\tvalid_0's multi_logloss: 2.08098\n",
      "[26]\tvalid_0's multi_logloss: 2.07823\n",
      "[27]\tvalid_0's multi_logloss: 2.07591\n",
      "[28]\tvalid_0's multi_logloss: 2.07354\n",
      "[29]\tvalid_0's multi_logloss: 2.07142\n",
      "[30]\tvalid_0's multi_logloss: 2.06932\n",
      "[31]\tvalid_0's multi_logloss: 2.06736\n",
      "[32]\tvalid_0's multi_logloss: 2.06535\n",
      "[33]\tvalid_0's multi_logloss: 2.0635\n",
      "[34]\tvalid_0's multi_logloss: 2.06184\n",
      "[35]\tvalid_0's multi_logloss: 2.05997\n",
      "[36]\tvalid_0's multi_logloss: 2.05853\n",
      "[37]\tvalid_0's multi_logloss: 2.05713\n",
      "[38]\tvalid_0's multi_logloss: 2.05567\n",
      "[39]\tvalid_0's multi_logloss: 2.05442\n",
      "[40]\tvalid_0's multi_logloss: 2.05313\n",
      "[41]\tvalid_0's multi_logloss: 2.05175\n",
      "[42]\tvalid_0's multi_logloss: 2.0507\n",
      "[43]\tvalid_0's multi_logloss: 2.04964\n",
      "[44]\tvalid_0's multi_logloss: 2.04865\n",
      "[45]\tvalid_0's multi_logloss: 2.04776\n",
      "[46]\tvalid_0's multi_logloss: 2.04688\n",
      "[47]\tvalid_0's multi_logloss: 2.04593\n",
      "[48]\tvalid_0's multi_logloss: 2.04505\n",
      "[49]\tvalid_0's multi_logloss: 2.04425\n",
      "[50]\tvalid_0's multi_logloss: 2.04314\n",
      "[51]\tvalid_0's multi_logloss: 2.04214\n",
      "[52]\tvalid_0's multi_logloss: 2.04122\n",
      "[53]\tvalid_0's multi_logloss: 2.04034\n",
      "[54]\tvalid_0's multi_logloss: 2.0397\n",
      "[55]\tvalid_0's multi_logloss: 2.03902\n",
      "[56]\tvalid_0's multi_logloss: 2.03832\n",
      "[57]\tvalid_0's multi_logloss: 2.03746\n",
      "[58]\tvalid_0's multi_logloss: 2.03682\n",
      "[59]\tvalid_0's multi_logloss: 2.03607\n",
      "[60]\tvalid_0's multi_logloss: 2.03536\n",
      "[61]\tvalid_0's multi_logloss: 2.03473\n",
      "[62]\tvalid_0's multi_logloss: 2.03423\n",
      "[63]\tvalid_0's multi_logloss: 2.03359\n",
      "[64]\tvalid_0's multi_logloss: 2.03306\n",
      "[65]\tvalid_0's multi_logloss: 2.0326\n",
      "[66]\tvalid_0's multi_logloss: 2.03205\n",
      "[67]\tvalid_0's multi_logloss: 2.03158\n",
      "[68]\tvalid_0's multi_logloss: 2.0311\n",
      "[69]\tvalid_0's multi_logloss: 2.03058\n",
      "[70]\tvalid_0's multi_logloss: 2.03011\n",
      "[71]\tvalid_0's multi_logloss: 2.02959\n",
      "[72]\tvalid_0's multi_logloss: 2.02909\n",
      "[73]\tvalid_0's multi_logloss: 2.02861\n",
      "[74]\tvalid_0's multi_logloss: 2.02823\n",
      "[75]\tvalid_0's multi_logloss: 2.02776\n",
      "[76]\tvalid_0's multi_logloss: 2.02735\n",
      "[77]\tvalid_0's multi_logloss: 2.02687\n",
      "[78]\tvalid_0's multi_logloss: 2.02643\n",
      "[79]\tvalid_0's multi_logloss: 2.02599\n",
      "[80]\tvalid_0's multi_logloss: 2.02558\n",
      "[81]\tvalid_0's multi_logloss: 2.02502\n",
      "[82]\tvalid_0's multi_logloss: 2.02457\n",
      "[83]\tvalid_0's multi_logloss: 2.0242\n",
      "[84]\tvalid_0's multi_logloss: 2.02376\n",
      "[85]\tvalid_0's multi_logloss: 2.02333\n",
      "[86]\tvalid_0's multi_logloss: 2.02288\n",
      "[87]\tvalid_0's multi_logloss: 2.02242\n",
      "[88]\tvalid_0's multi_logloss: 2.02194\n",
      "[89]\tvalid_0's multi_logloss: 2.02155\n",
      "[90]\tvalid_0's multi_logloss: 2.02108\n",
      "[91]\tvalid_0's multi_logloss: 2.02076\n",
      "[92]\tvalid_0's multi_logloss: 2.02043\n",
      "[93]\tvalid_0's multi_logloss: 2.01998\n",
      "[94]\tvalid_0's multi_logloss: 2.01963\n",
      "[95]\tvalid_0's multi_logloss: 2.01923\n",
      "[96]\tvalid_0's multi_logloss: 2.01896\n",
      "[97]\tvalid_0's multi_logloss: 2.01872\n",
      "[98]\tvalid_0's multi_logloss: 2.01834\n",
      "[99]\tvalid_0's multi_logloss: 2.01803\n",
      "[100]\tvalid_0's multi_logloss: 2.01779\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025665 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -0.501622\n",
      "[LightGBM] [Info] Start training from score -0.930257\n",
      "[1]\tvalid_0's multi_logloss: 0.576087\n",
      "[2]\tvalid_0's multi_logloss: 0.499967\n",
      "[3]\tvalid_0's multi_logloss: 0.437077\n",
      "[4]\tvalid_0's multi_logloss: 0.384223\n",
      "[5]\tvalid_0's multi_logloss: 0.339239\n",
      "[6]\tvalid_0's multi_logloss: 0.300624\n",
      "[7]\tvalid_0's multi_logloss: 0.267163\n",
      "[8]\tvalid_0's multi_logloss: 0.238054\n",
      "[9]\tvalid_0's multi_logloss: 0.212505\n",
      "[10]\tvalid_0's multi_logloss: 0.190023\n",
      "[11]\tvalid_0's multi_logloss: 0.170168\n",
      "[12]\tvalid_0's multi_logloss: 0.152595\n",
      "[13]\tvalid_0's multi_logloss: 0.137052\n",
      "[14]\tvalid_0's multi_logloss: 0.123186\n",
      "[15]\tvalid_0's multi_logloss: 0.110838\n",
      "[16]\tvalid_0's multi_logloss: 0.09981\n",
      "[17]\tvalid_0's multi_logloss: 0.0899589\n",
      "[18]\tvalid_0's multi_logloss: 0.0811184\n",
      "[19]\tvalid_0's multi_logloss: 0.0731958\n",
      "[20]\tvalid_0's multi_logloss: 0.0660958\n",
      "[21]\tvalid_0's multi_logloss: 0.0597226\n",
      "[22]\tvalid_0's multi_logloss: 0.0539912\n",
      "[23]\tvalid_0's multi_logloss: 0.0488376\n",
      "[24]\tvalid_0's multi_logloss: 0.0442085\n",
      "[25]\tvalid_0's multi_logloss: 0.0400371\n",
      "[26]\tvalid_0's multi_logloss: 0.03627\n",
      "[27]\tvalid_0's multi_logloss: 0.0328841\n",
      "[28]\tvalid_0's multi_logloss: 0.0298345\n",
      "[29]\tvalid_0's multi_logloss: 0.0270839\n",
      "[30]\tvalid_0's multi_logloss: 0.0246118\n",
      "[31]\tvalid_0's multi_logloss: 0.0223754\n",
      "[32]\tvalid_0's multi_logloss: 0.0203564\n",
      "[33]\tvalid_0's multi_logloss: 0.0185268\n",
      "[34]\tvalid_0's multi_logloss: 0.0168762\n",
      "[35]\tvalid_0's multi_logloss: 0.0153867\n",
      "[36]\tvalid_0's multi_logloss: 0.0140442\n",
      "[37]\tvalid_0's multi_logloss: 0.0128327\n",
      "[38]\tvalid_0's multi_logloss: 0.0117315\n",
      "[39]\tvalid_0's multi_logloss: 0.0107238\n",
      "[40]\tvalid_0's multi_logloss: 0.00983116\n",
      "[41]\tvalid_0's multi_logloss: 0.0090251\n",
      "[42]\tvalid_0's multi_logloss: 0.00829317\n",
      "[43]\tvalid_0's multi_logloss: 0.00763515\n",
      "[44]\tvalid_0's multi_logloss: 0.00704107\n",
      "[45]\tvalid_0's multi_logloss: 0.00650376\n",
      "[46]\tvalid_0's multi_logloss: 0.00601678\n",
      "[47]\tvalid_0's multi_logloss: 0.00556189\n",
      "[48]\tvalid_0's multi_logloss: 0.00516326\n",
      "[49]\tvalid_0's multi_logloss: 0.00479845\n",
      "[50]\tvalid_0's multi_logloss: 0.00447356\n",
      "[51]\tvalid_0's multi_logloss: 0.00417738\n",
      "[52]\tvalid_0's multi_logloss: 0.00390915\n",
      "[53]\tvalid_0's multi_logloss: 0.00366969\n",
      "[54]\tvalid_0's multi_logloss: 0.00345391\n",
      "[55]\tvalid_0's multi_logloss: 0.0032576\n",
      "[56]\tvalid_0's multi_logloss: 0.00308074\n",
      "[57]\tvalid_0's multi_logloss: 0.00292118\n",
      "[58]\tvalid_0's multi_logloss: 0.00277683\n",
      "[59]\tvalid_0's multi_logloss: 0.00264718\n",
      "[60]\tvalid_0's multi_logloss: 0.00253\n",
      "[61]\tvalid_0's multi_logloss: 0.00242322\n",
      "[62]\tvalid_0's multi_logloss: 0.00232704\n",
      "[63]\tvalid_0's multi_logloss: 0.00224114\n",
      "[64]\tvalid_0's multi_logloss: 0.00216326\n",
      "[65]\tvalid_0's multi_logloss: 0.0020938\n",
      "[66]\tvalid_0's multi_logloss: 0.00203215\n",
      "[67]\tvalid_0's multi_logloss: 0.0019762\n",
      "[68]\tvalid_0's multi_logloss: 0.00192498\n",
      "[69]\tvalid_0's multi_logloss: 0.00187817\n",
      "[70]\tvalid_0's multi_logloss: 0.00183526\n",
      "[71]\tvalid_0's multi_logloss: 0.00179699\n",
      "[72]\tvalid_0's multi_logloss: 0.00176249\n",
      "[73]\tvalid_0's multi_logloss: 0.00173144\n",
      "[74]\tvalid_0's multi_logloss: 0.00170375\n",
      "[75]\tvalid_0's multi_logloss: 0.00167807\n",
      "[76]\tvalid_0's multi_logloss: 0.00165507\n",
      "[77]\tvalid_0's multi_logloss: 0.00163392\n",
      "[78]\tvalid_0's multi_logloss: 0.00164643\n",
      "[79]\tvalid_0's multi_logloss: 0.00160676\n",
      "[80]\tvalid_0's multi_logloss: 0.00163058\n",
      "[81]\tvalid_0's multi_logloss: 0.00161512\n",
      "[82]\tvalid_0's multi_logloss: 0.00156674\n",
      "[83]\tvalid_0's multi_logloss: 0.00155469\n",
      "[84]\tvalid_0's multi_logloss: 0.00154296\n",
      "[85]\tvalid_0's multi_logloss: 0.00153305\n",
      "[86]\tvalid_0's multi_logloss: 0.00153347\n",
      "[87]\tvalid_0's multi_logloss: 0.00152378\n",
      "[88]\tvalid_0's multi_logloss: 0.00151648\n",
      "[89]\tvalid_0's multi_logloss: 0.00150978\n",
      "[90]\tvalid_0's multi_logloss: 0.00150345\n",
      "[91]\tvalid_0's multi_logloss: 0.00149927\n",
      "[92]\tvalid_0's multi_logloss: 0.00157292\n",
      "[93]\tvalid_0's multi_logloss: 0.00156827\n",
      "[94]\tvalid_0's multi_logloss: 0.00148673\n",
      "[95]\tvalid_0's multi_logloss: 0.00149024\n",
      "[96]\tvalid_0's multi_logloss: 0.00148889\n",
      "[97]\tvalid_0's multi_logloss: 0.00147655\n",
      "[98]\tvalid_0's multi_logloss: 0.00162736\n",
      "[99]\tvalid_0's multi_logloss: 0.00147684\n",
      "[100]\tvalid_0's multi_logloss: 0.00148936\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017809 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -0.141837\n",
      "[LightGBM] [Info] Start training from score -2.023158\n",
      "[1]\tvalid_0's multi_logloss: 0.340286\n",
      "[2]\tvalid_0's multi_logloss: 0.310326\n",
      "[3]\tvalid_0's multi_logloss: 0.288318\n",
      "[4]\tvalid_0's multi_logloss: 0.270409\n",
      "[5]\tvalid_0's multi_logloss: 0.256211\n",
      "[6]\tvalid_0's multi_logloss: 0.243844\n",
      "[7]\tvalid_0's multi_logloss: 0.233912\n",
      "[8]\tvalid_0's multi_logloss: 0.224827\n",
      "[9]\tvalid_0's multi_logloss: 0.217096\n",
      "[10]\tvalid_0's multi_logloss: 0.210462\n",
      "[11]\tvalid_0's multi_logloss: 0.203929\n",
      "[12]\tvalid_0's multi_logloss: 0.197714\n",
      "[13]\tvalid_0's multi_logloss: 0.192532\n",
      "[14]\tvalid_0's multi_logloss: 0.187879\n",
      "[15]\tvalid_0's multi_logloss: 0.183163\n",
      "[16]\tvalid_0's multi_logloss: 0.179302\n",
      "[17]\tvalid_0's multi_logloss: 0.175832\n",
      "[18]\tvalid_0's multi_logloss: 0.172938\n",
      "[19]\tvalid_0's multi_logloss: 0.170385\n",
      "[20]\tvalid_0's multi_logloss: 0.167599\n",
      "[21]\tvalid_0's multi_logloss: 0.16517\n",
      "[22]\tvalid_0's multi_logloss: 0.163264\n",
      "[23]\tvalid_0's multi_logloss: 0.161711\n",
      "[24]\tvalid_0's multi_logloss: 0.159776\n",
      "[25]\tvalid_0's multi_logloss: 0.158351\n",
      "[26]\tvalid_0's multi_logloss: 0.157243\n",
      "[27]\tvalid_0's multi_logloss: 0.155736\n",
      "[28]\tvalid_0's multi_logloss: 0.154657\n",
      "[29]\tvalid_0's multi_logloss: 0.153351\n",
      "[30]\tvalid_0's multi_logloss: 0.151994\n",
      "[31]\tvalid_0's multi_logloss: 0.150899\n",
      "[32]\tvalid_0's multi_logloss: 0.149715\n",
      "[33]\tvalid_0's multi_logloss: 0.148882\n",
      "[34]\tvalid_0's multi_logloss: 0.147975\n",
      "[35]\tvalid_0's multi_logloss: 0.147216\n",
      "[36]\tvalid_0's multi_logloss: 0.146269\n",
      "[37]\tvalid_0's multi_logloss: 0.145488\n",
      "[38]\tvalid_0's multi_logloss: 0.144763\n",
      "[39]\tvalid_0's multi_logloss: 0.143841\n",
      "[40]\tvalid_0's multi_logloss: 0.143296\n",
      "[41]\tvalid_0's multi_logloss: 0.142785\n",
      "[42]\tvalid_0's multi_logloss: 0.142071\n",
      "[43]\tvalid_0's multi_logloss: 0.141426\n",
      "[44]\tvalid_0's multi_logloss: 0.140834\n",
      "[45]\tvalid_0's multi_logloss: 0.140334\n",
      "[46]\tvalid_0's multi_logloss: 0.139729\n",
      "[47]\tvalid_0's multi_logloss: 0.139291\n",
      "[48]\tvalid_0's multi_logloss: 0.138812\n",
      "[49]\tvalid_0's multi_logloss: 0.138321\n",
      "[50]\tvalid_0's multi_logloss: 0.13797\n",
      "[51]\tvalid_0's multi_logloss: 0.137672\n",
      "[52]\tvalid_0's multi_logloss: 0.13715\n",
      "[53]\tvalid_0's multi_logloss: 0.136715\n",
      "[54]\tvalid_0's multi_logloss: 0.136118\n",
      "[55]\tvalid_0's multi_logloss: 0.13575\n",
      "[56]\tvalid_0's multi_logloss: 0.135374\n",
      "[57]\tvalid_0's multi_logloss: 0.135094\n",
      "[58]\tvalid_0's multi_logloss: 0.13486\n",
      "[59]\tvalid_0's multi_logloss: 0.134414\n",
      "[60]\tvalid_0's multi_logloss: 0.1341\n",
      "[61]\tvalid_0's multi_logloss: 0.133837\n",
      "[62]\tvalid_0's multi_logloss: 0.133524\n",
      "[63]\tvalid_0's multi_logloss: 0.133151\n",
      "[64]\tvalid_0's multi_logloss: 0.132941\n",
      "[65]\tvalid_0's multi_logloss: 0.13269\n",
      "[66]\tvalid_0's multi_logloss: 0.132535\n",
      "[67]\tvalid_0's multi_logloss: 0.132307\n",
      "[68]\tvalid_0's multi_logloss: 0.131974\n",
      "[69]\tvalid_0's multi_logloss: 0.131756\n",
      "[70]\tvalid_0's multi_logloss: 0.131531\n",
      "[71]\tvalid_0's multi_logloss: 0.131307\n",
      "[72]\tvalid_0's multi_logloss: 0.131104\n",
      "[73]\tvalid_0's multi_logloss: 0.130833\n",
      "[74]\tvalid_0's multi_logloss: 0.130529\n",
      "[75]\tvalid_0's multi_logloss: 0.130329\n",
      "[76]\tvalid_0's multi_logloss: 0.130071\n",
      "[77]\tvalid_0's multi_logloss: 0.129858\n",
      "[78]\tvalid_0's multi_logloss: 0.129734\n",
      "[79]\tvalid_0's multi_logloss: 0.129411\n",
      "[80]\tvalid_0's multi_logloss: 0.129238\n",
      "[81]\tvalid_0's multi_logloss: 0.128867\n",
      "[82]\tvalid_0's multi_logloss: 0.128515\n",
      "[83]\tvalid_0's multi_logloss: 0.128411\n",
      "[84]\tvalid_0's multi_logloss: 0.128323\n",
      "[85]\tvalid_0's multi_logloss: 0.128053\n",
      "[86]\tvalid_0's multi_logloss: 0.127858\n",
      "[87]\tvalid_0's multi_logloss: 0.127585\n",
      "[88]\tvalid_0's multi_logloss: 0.127501\n",
      "[89]\tvalid_0's multi_logloss: 0.127282\n",
      "[90]\tvalid_0's multi_logloss: 0.127142\n",
      "[91]\tvalid_0's multi_logloss: 0.126966\n",
      "[92]\tvalid_0's multi_logloss: 0.126851\n",
      "[93]\tvalid_0's multi_logloss: 0.126728\n",
      "[94]\tvalid_0's multi_logloss: 0.126507\n",
      "[95]\tvalid_0's multi_logloss: 0.126429\n",
      "[96]\tvalid_0's multi_logloss: 0.126235\n",
      "[97]\tvalid_0's multi_logloss: 0.125992\n",
      "[98]\tvalid_0's multi_logloss: 0.125879\n",
      "[99]\tvalid_0's multi_logloss: 0.125686\n",
      "[100]\tvalid_0's multi_logloss: 0.125537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [27:31, 129.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007881 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 7715638, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -1.249550\n",
      "[LightGBM] [Info] Start training from score -3.165534\n",
      "[LightGBM] [Info] Start training from score -1.726403\n",
      "[LightGBM] [Info] Start training from score -1.902421\n",
      "[LightGBM] [Info] Start training from score -1.667720\n",
      "[LightGBM] [Info] Start training from score -1.861961\n",
      "[1]\tvalid_0's multi_logloss: 1.66579\n",
      "[2]\tvalid_0's multi_logloss: 1.65088\n",
      "[3]\tvalid_0's multi_logloss: 1.6391\n",
      "[4]\tvalid_0's multi_logloss: 1.62929\n",
      "[5]\tvalid_0's multi_logloss: 1.62138\n",
      "[6]\tvalid_0's multi_logloss: 1.61464\n",
      "[7]\tvalid_0's multi_logloss: 1.60899\n",
      "[8]\tvalid_0's multi_logloss: 1.60428\n",
      "[9]\tvalid_0's multi_logloss: 1.59984\n",
      "[10]\tvalid_0's multi_logloss: 1.59595\n",
      "[11]\tvalid_0's multi_logloss: 1.59263\n",
      "[12]\tvalid_0's multi_logloss: 1.58954\n",
      "[13]\tvalid_0's multi_logloss: 1.58683\n",
      "[14]\tvalid_0's multi_logloss: 1.5843\n",
      "[15]\tvalid_0's multi_logloss: 1.5822\n",
      "[16]\tvalid_0's multi_logloss: 1.5803\n",
      "[17]\tvalid_0's multi_logloss: 1.57852\n",
      "[18]\tvalid_0's multi_logloss: 1.57676\n",
      "[19]\tvalid_0's multi_logloss: 1.57516\n",
      "[20]\tvalid_0's multi_logloss: 1.57334\n",
      "[21]\tvalid_0's multi_logloss: 1.57176\n",
      "[22]\tvalid_0's multi_logloss: 1.57059\n",
      "[23]\tvalid_0's multi_logloss: 1.5693\n",
      "[24]\tvalid_0's multi_logloss: 1.56791\n",
      "[25]\tvalid_0's multi_logloss: 1.56681\n",
      "[26]\tvalid_0's multi_logloss: 1.56554\n",
      "[27]\tvalid_0's multi_logloss: 1.56459\n",
      "[28]\tvalid_0's multi_logloss: 1.56368\n",
      "[29]\tvalid_0's multi_logloss: 1.56254\n",
      "[30]\tvalid_0's multi_logloss: 1.56172\n",
      "[31]\tvalid_0's multi_logloss: 1.56082\n",
      "[32]\tvalid_0's multi_logloss: 1.56018\n",
      "[33]\tvalid_0's multi_logloss: 1.5595\n",
      "[34]\tvalid_0's multi_logloss: 1.5584\n",
      "[35]\tvalid_0's multi_logloss: 1.55749\n",
      "[36]\tvalid_0's multi_logloss: 1.55659\n",
      "[37]\tvalid_0's multi_logloss: 1.55592\n",
      "[38]\tvalid_0's multi_logloss: 1.55499\n",
      "[39]\tvalid_0's multi_logloss: 1.55427\n",
      "[40]\tvalid_0's multi_logloss: 1.55368\n",
      "[41]\tvalid_0's multi_logloss: 1.5529\n",
      "[42]\tvalid_0's multi_logloss: 1.55222\n",
      "[43]\tvalid_0's multi_logloss: 1.55134\n",
      "[44]\tvalid_0's multi_logloss: 1.55091\n",
      "[45]\tvalid_0's multi_logloss: 1.55037\n",
      "[46]\tvalid_0's multi_logloss: 1.54975\n",
      "[47]\tvalid_0's multi_logloss: 1.54922\n",
      "[48]\tvalid_0's multi_logloss: 1.54873\n",
      "[49]\tvalid_0's multi_logloss: 1.54819\n",
      "[50]\tvalid_0's multi_logloss: 1.54748\n",
      "[51]\tvalid_0's multi_logloss: 1.54692\n",
      "[52]\tvalid_0's multi_logloss: 1.54645\n",
      "[53]\tvalid_0's multi_logloss: 1.54589\n",
      "[54]\tvalid_0's multi_logloss: 1.54544\n",
      "[55]\tvalid_0's multi_logloss: 1.54506\n",
      "[56]\tvalid_0's multi_logloss: 1.54466\n",
      "[57]\tvalid_0's multi_logloss: 1.54427\n",
      "[58]\tvalid_0's multi_logloss: 1.54392\n",
      "[59]\tvalid_0's multi_logloss: 1.54353\n",
      "[60]\tvalid_0's multi_logloss: 1.54314\n",
      "[61]\tvalid_0's multi_logloss: 1.5426\n",
      "[62]\tvalid_0's multi_logloss: 1.54224\n",
      "[63]\tvalid_0's multi_logloss: 1.54191\n",
      "[64]\tvalid_0's multi_logloss: 1.54137\n",
      "[65]\tvalid_0's multi_logloss: 1.54074\n",
      "[66]\tvalid_0's multi_logloss: 1.5404\n",
      "[67]\tvalid_0's multi_logloss: 1.54008\n",
      "[68]\tvalid_0's multi_logloss: 1.53969\n",
      "[69]\tvalid_0's multi_logloss: 1.53934\n",
      "[70]\tvalid_0's multi_logloss: 1.53896\n",
      "[71]\tvalid_0's multi_logloss: 1.53861\n",
      "[72]\tvalid_0's multi_logloss: 1.53822\n",
      "[73]\tvalid_0's multi_logloss: 1.53762\n",
      "[74]\tvalid_0's multi_logloss: 1.5373\n",
      "[75]\tvalid_0's multi_logloss: 1.53705\n",
      "[76]\tvalid_0's multi_logloss: 1.53682\n",
      "[77]\tvalid_0's multi_logloss: 1.53655\n",
      "[78]\tvalid_0's multi_logloss: 1.53624\n",
      "[79]\tvalid_0's multi_logloss: 1.53585\n",
      "[80]\tvalid_0's multi_logloss: 1.53557\n",
      "[81]\tvalid_0's multi_logloss: 1.5353\n",
      "[82]\tvalid_0's multi_logloss: 1.53503\n",
      "[83]\tvalid_0's multi_logloss: 1.53474\n",
      "[84]\tvalid_0's multi_logloss: 1.53447\n",
      "[85]\tvalid_0's multi_logloss: 1.53414\n",
      "[86]\tvalid_0's multi_logloss: 1.53382\n",
      "[87]\tvalid_0's multi_logloss: 1.53346\n",
      "[88]\tvalid_0's multi_logloss: 1.53317\n",
      "[89]\tvalid_0's multi_logloss: 1.53289\n",
      "[90]\tvalid_0's multi_logloss: 1.5326\n",
      "[91]\tvalid_0's multi_logloss: 1.53226\n",
      "[92]\tvalid_0's multi_logloss: 1.5321\n",
      "[93]\tvalid_0's multi_logloss: 1.53184\n",
      "[94]\tvalid_0's multi_logloss: 1.53164\n",
      "[95]\tvalid_0's multi_logloss: 1.53147\n",
      "[96]\tvalid_0's multi_logloss: 1.53121\n",
      "[97]\tvalid_0's multi_logloss: 1.53096\n",
      "[98]\tvalid_0's multi_logloss: 1.53073\n",
      "[99]\tvalid_0's multi_logloss: 1.53051\n",
      "[100]\tvalid_0's multi_logloss: 1.53033\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007896 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 7715638, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -3.388563\n",
      "[LightGBM] [Info] Start training from score -3.286043\n",
      "[LightGBM] [Info] Start training from score -3.265766\n",
      "[LightGBM] [Info] Start training from score -3.814547\n",
      "[LightGBM] [Info] Start training from score -3.310265\n",
      "[LightGBM] [Info] Start training from score -3.206426\n",
      "[LightGBM] [Info] Start training from score -4.264605\n",
      "[LightGBM] [Info] Start training from score -3.385622\n",
      "[LightGBM] [Info] Start training from score -3.678169\n",
      "[LightGBM] [Info] Start training from score -3.401590\n",
      "[LightGBM] [Info] Start training from score -4.879144\n",
      "[LightGBM] [Info] Start training from score -3.027581\n",
      "[LightGBM] [Info] Start training from score -2.985319\n",
      "[LightGBM] [Info] Start training from score -3.251856\n",
      "[LightGBM] [Info] Start training from score -3.294527\n",
      "[LightGBM] [Info] Start training from score -3.372086\n",
      "[LightGBM] [Info] Start training from score -2.973489\n",
      "[LightGBM] [Info] Start training from score -2.489644\n",
      "[LightGBM] [Info] Start training from score -3.403357\n",
      "[LightGBM] [Info] Start training from score -4.161407\n",
      "[LightGBM] [Info] Start training from score -4.219942\n",
      "[LightGBM] [Info] Start training from score -3.454308\n",
      "[LightGBM] [Info] Start training from score -3.414970\n",
      "[LightGBM] [Info] Start training from score -3.160243\n",
      "[LightGBM] [Info] Start training from score -3.113230\n",
      "[LightGBM] [Info] Start training from score -3.209175\n",
      "[LightGBM] [Info] Start training from score -3.282600\n",
      "[LightGBM] [Info] Start training from score -3.180636\n",
      "[1]\tvalid_0's multi_logloss: 2.2364\n",
      "[2]\tvalid_0's multi_logloss: 2.023\n",
      "[3]\tvalid_0's multi_logloss: 1.88508\n",
      "[4]\tvalid_0's multi_logloss: 1.78205\n",
      "[5]\tvalid_0's multi_logloss: 1.70124\n",
      "[6]\tvalid_0's multi_logloss: 1.63758\n",
      "[7]\tvalid_0's multi_logloss: 1.5851\n",
      "[8]\tvalid_0's multi_logloss: 1.54231\n",
      "[9]\tvalid_0's multi_logloss: 1.50575\n",
      "[10]\tvalid_0's multi_logloss: 1.47566\n",
      "[11]\tvalid_0's multi_logloss: 1.44968\n",
      "[12]\tvalid_0's multi_logloss: 1.42755\n",
      "[13]\tvalid_0's multi_logloss: 1.40868\n",
      "[14]\tvalid_0's multi_logloss: 1.39188\n",
      "[15]\tvalid_0's multi_logloss: 1.37715\n",
      "[16]\tvalid_0's multi_logloss: 1.36418\n",
      "[17]\tvalid_0's multi_logloss: 1.35288\n",
      "[18]\tvalid_0's multi_logloss: 1.34425\n",
      "[19]\tvalid_0's multi_logloss: 1.33493\n",
      "[20]\tvalid_0's multi_logloss: 1.32694\n",
      "[21]\tvalid_0's multi_logloss: 1.31951\n",
      "[22]\tvalid_0's multi_logloss: 1.31341\n",
      "[23]\tvalid_0's multi_logloss: 1.30743\n",
      "[24]\tvalid_0's multi_logloss: 1.30231\n",
      "[25]\tvalid_0's multi_logloss: 1.29749\n",
      "[26]\tvalid_0's multi_logloss: 1.29333\n",
      "[27]\tvalid_0's multi_logloss: 1.28917\n",
      "[28]\tvalid_0's multi_logloss: 1.28504\n",
      "[29]\tvalid_0's multi_logloss: 1.28178\n",
      "[30]\tvalid_0's multi_logloss: 1.27837\n",
      "[31]\tvalid_0's multi_logloss: 1.27663\n",
      "[32]\tvalid_0's multi_logloss: 1.27559\n",
      "[33]\tvalid_0's multi_logloss: 1.27102\n",
      "[34]\tvalid_0's multi_logloss: 1.26797\n",
      "[35]\tvalid_0's multi_logloss: 1.26641\n",
      "[36]\tvalid_0's multi_logloss: 1.26467\n",
      "[37]\tvalid_0's multi_logloss: 1.26404\n",
      "[38]\tvalid_0's multi_logloss: 1.26284\n",
      "[39]\tvalid_0's multi_logloss: 1.26013\n",
      "[40]\tvalid_0's multi_logloss: 1.25702\n",
      "[41]\tvalid_0's multi_logloss: 1.25506\n",
      "[42]\tvalid_0's multi_logloss: 1.25463\n",
      "[43]\tvalid_0's multi_logloss: 1.25171\n",
      "[44]\tvalid_0's multi_logloss: 1.25041\n",
      "[45]\tvalid_0's multi_logloss: 1.24921\n",
      "[46]\tvalid_0's multi_logloss: 1.24988\n",
      "[47]\tvalid_0's multi_logloss: 1.24869\n",
      "[48]\tvalid_0's multi_logloss: 1.24838\n",
      "[49]\tvalid_0's multi_logloss: 1.24389\n",
      "[50]\tvalid_0's multi_logloss: 1.24357\n",
      "[51]\tvalid_0's multi_logloss: 1.24174\n",
      "[52]\tvalid_0's multi_logloss: 1.24101\n",
      "[53]\tvalid_0's multi_logloss: 1.24062\n",
      "[54]\tvalid_0's multi_logloss: 1.23984\n",
      "[55]\tvalid_0's multi_logloss: 1.23925\n",
      "[56]\tvalid_0's multi_logloss: 1.23804\n",
      "[57]\tvalid_0's multi_logloss: 1.23689\n",
      "[58]\tvalid_0's multi_logloss: 1.23585\n",
      "[59]\tvalid_0's multi_logloss: 1.23843\n",
      "[60]\tvalid_0's multi_logloss: 1.23483\n",
      "[61]\tvalid_0's multi_logloss: 1.23447\n",
      "[62]\tvalid_0's multi_logloss: 1.23424\n",
      "[63]\tvalid_0's multi_logloss: 1.23336\n",
      "[64]\tvalid_0's multi_logloss: 1.23372\n",
      "[65]\tvalid_0's multi_logloss: 1.23163\n",
      "[66]\tvalid_0's multi_logloss: 1.2309\n",
      "[67]\tvalid_0's multi_logloss: 1.23027\n",
      "[68]\tvalid_0's multi_logloss: 1.23025\n",
      "[69]\tvalid_0's multi_logloss: 1.22884\n",
      "[70]\tvalid_0's multi_logloss: 1.22828\n",
      "[71]\tvalid_0's multi_logloss: 1.22758\n",
      "[72]\tvalid_0's multi_logloss: 1.22753\n",
      "[73]\tvalid_0's multi_logloss: 1.22701\n",
      "[74]\tvalid_0's multi_logloss: 1.22659\n",
      "[75]\tvalid_0's multi_logloss: 1.22546\n",
      "[76]\tvalid_0's multi_logloss: 1.22704\n",
      "[77]\tvalid_0's multi_logloss: 1.22573\n",
      "[78]\tvalid_0's multi_logloss: 1.2267\n",
      "[79]\tvalid_0's multi_logloss: 1.22563\n",
      "[80]\tvalid_0's multi_logloss: 1.22451\n",
      "[81]\tvalid_0's multi_logloss: 1.22372\n",
      "[82]\tvalid_0's multi_logloss: 1.22543\n",
      "[83]\tvalid_0's multi_logloss: 1.22618\n",
      "[84]\tvalid_0's multi_logloss: 1.22301\n",
      "[85]\tvalid_0's multi_logloss: 1.22409\n",
      "[86]\tvalid_0's multi_logloss: 1.22818\n",
      "[87]\tvalid_0's multi_logloss: 1.22033\n",
      "[88]\tvalid_0's multi_logloss: 1.22003\n",
      "[89]\tvalid_0's multi_logloss: 1.22082\n",
      "[90]\tvalid_0's multi_logloss: 1.2223\n",
      "[91]\tvalid_0's multi_logloss: 1.22551\n",
      "[92]\tvalid_0's multi_logloss: 1.21959\n",
      "[93]\tvalid_0's multi_logloss: 1.2195\n",
      "[94]\tvalid_0's multi_logloss: 1.21943\n",
      "[95]\tvalid_0's multi_logloss: 1.21839\n",
      "[96]\tvalid_0's multi_logloss: 1.21898\n",
      "[97]\tvalid_0's multi_logloss: 1.21979\n",
      "[98]\tvalid_0's multi_logloss: 1.22122\n",
      "[99]\tvalid_0's multi_logloss: 1.21836\n",
      "[100]\tvalid_0's multi_logloss: 1.21742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [29:15, 121.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 820733, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -0.683185\n",
      "[LightGBM] [Info] Start training from score -2.382997\n",
      "[LightGBM] [Info] Start training from score -2.734975\n",
      "[LightGBM] [Info] Start training from score -3.826068\n",
      "[LightGBM] [Info] Start training from score -1.583719\n",
      "[LightGBM] [Info] Start training from score -2.199855\n",
      "[1]\tvalid_0's multi_logloss: 1.13589\n",
      "[2]\tvalid_0's multi_logloss: 1.01017\n",
      "[3]\tvalid_0's multi_logloss: 0.916116\n",
      "[4]\tvalid_0's multi_logloss: 0.842573\n",
      "[5]\tvalid_0's multi_logloss: 0.783013\n",
      "[6]\tvalid_0's multi_logloss: 0.735123\n",
      "[7]\tvalid_0's multi_logloss: 0.695129\n",
      "[8]\tvalid_0's multi_logloss: 0.661511\n",
      "[9]\tvalid_0's multi_logloss: 0.633344\n",
      "[10]\tvalid_0's multi_logloss: 0.60972\n",
      "[11]\tvalid_0's multi_logloss: 0.589151\n",
      "[12]\tvalid_0's multi_logloss: 0.5714\n",
      "[13]\tvalid_0's multi_logloss: 0.556183\n",
      "[14]\tvalid_0's multi_logloss: 0.542876\n",
      "[15]\tvalid_0's multi_logloss: 0.531137\n",
      "[16]\tvalid_0's multi_logloss: 0.520879\n",
      "[17]\tvalid_0's multi_logloss: 0.511985\n",
      "[18]\tvalid_0's multi_logloss: 0.503983\n",
      "[19]\tvalid_0's multi_logloss: 0.496903\n",
      "[20]\tvalid_0's multi_logloss: 0.4905\n",
      "[21]\tvalid_0's multi_logloss: 0.484701\n",
      "[22]\tvalid_0's multi_logloss: 0.479766\n",
      "[23]\tvalid_0's multi_logloss: 0.475235\n",
      "[24]\tvalid_0's multi_logloss: 0.471363\n",
      "[25]\tvalid_0's multi_logloss: 0.467798\n",
      "[26]\tvalid_0's multi_logloss: 0.464691\n",
      "[27]\tvalid_0's multi_logloss: 0.461641\n",
      "[28]\tvalid_0's multi_logloss: 0.458797\n",
      "[29]\tvalid_0's multi_logloss: 0.456271\n",
      "[30]\tvalid_0's multi_logloss: 0.453844\n",
      "[31]\tvalid_0's multi_logloss: 0.451797\n",
      "[32]\tvalid_0's multi_logloss: 0.44978\n",
      "[33]\tvalid_0's multi_logloss: 0.44786\n",
      "[34]\tvalid_0's multi_logloss: 0.44606\n",
      "[35]\tvalid_0's multi_logloss: 0.444401\n",
      "[36]\tvalid_0's multi_logloss: 0.442944\n",
      "[37]\tvalid_0's multi_logloss: 0.441503\n",
      "[38]\tvalid_0's multi_logloss: 0.440181\n",
      "[39]\tvalid_0's multi_logloss: 0.439007\n",
      "[40]\tvalid_0's multi_logloss: 0.43796\n",
      "[41]\tvalid_0's multi_logloss: 0.436889\n",
      "[42]\tvalid_0's multi_logloss: 0.436486\n",
      "[43]\tvalid_0's multi_logloss: 0.435225\n",
      "[44]\tvalid_0's multi_logloss: 0.43424\n",
      "[45]\tvalid_0's multi_logloss: 0.433385\n",
      "[46]\tvalid_0's multi_logloss: 0.432738\n",
      "[47]\tvalid_0's multi_logloss: 0.431813\n",
      "[48]\tvalid_0's multi_logloss: 0.431185\n",
      "[49]\tvalid_0's multi_logloss: 0.430476\n",
      "[50]\tvalid_0's multi_logloss: 0.430506\n",
      "[51]\tvalid_0's multi_logloss: 0.429452\n",
      "[52]\tvalid_0's multi_logloss: 0.429205\n",
      "[53]\tvalid_0's multi_logloss: 0.429642\n",
      "[54]\tvalid_0's multi_logloss: 0.428117\n",
      "[55]\tvalid_0's multi_logloss: 0.427647\n",
      "[56]\tvalid_0's multi_logloss: 0.427161\n",
      "[57]\tvalid_0's multi_logloss: 0.426781\n",
      "[58]\tvalid_0's multi_logloss: 0.426372\n",
      "[59]\tvalid_0's multi_logloss: 0.429429\n",
      "[60]\tvalid_0's multi_logloss: 0.430631\n",
      "[61]\tvalid_0's multi_logloss: 0.426208\n",
      "[62]\tvalid_0's multi_logloss: 0.425827\n",
      "[63]\tvalid_0's multi_logloss: 0.440445\n",
      "[64]\tvalid_0's multi_logloss: 0.428481\n",
      "[65]\tvalid_0's multi_logloss: 0.429292\n",
      "[66]\tvalid_0's multi_logloss: 0.425815\n",
      "[67]\tvalid_0's multi_logloss: 0.42472\n",
      "[68]\tvalid_0's multi_logloss: 0.425002\n",
      "[69]\tvalid_0's multi_logloss: 0.424874\n",
      "[70]\tvalid_0's multi_logloss: 0.424583\n",
      "[71]\tvalid_0's multi_logloss: 0.425065\n",
      "[72]\tvalid_0's multi_logloss: 0.424661\n",
      "[73]\tvalid_0's multi_logloss: 0.431901\n",
      "[74]\tvalid_0's multi_logloss: 0.423911\n",
      "[75]\tvalid_0's multi_logloss: 0.424276\n",
      "[76]\tvalid_0's multi_logloss: 0.429193\n",
      "[77]\tvalid_0's multi_logloss: 0.427812\n",
      "[78]\tvalid_0's multi_logloss: 0.425139\n",
      "[79]\tvalid_0's multi_logloss: 0.428824\n",
      "[80]\tvalid_0's multi_logloss: 0.426748\n",
      "[81]\tvalid_0's multi_logloss: 0.433055\n",
      "[82]\tvalid_0's multi_logloss: 0.427349\n",
      "[83]\tvalid_0's multi_logloss: 0.429721\n",
      "[84]\tvalid_0's multi_logloss: 0.429004\n",
      "[85]\tvalid_0's multi_logloss: 0.435231\n",
      "[86]\tvalid_0's multi_logloss: 0.431637\n",
      "[87]\tvalid_0's multi_logloss: 0.436173\n",
      "[88]\tvalid_0's multi_logloss: 0.426867\n",
      "[89]\tvalid_0's multi_logloss: 0.430052\n",
      "[90]\tvalid_0's multi_logloss: 0.428933\n",
      "[91]\tvalid_0's multi_logloss: 0.439776\n",
      "[92]\tvalid_0's multi_logloss: 0.424284\n",
      "[93]\tvalid_0's multi_logloss: 0.429934\n",
      "[94]\tvalid_0's multi_logloss: 0.432578\n",
      "[95]\tvalid_0's multi_logloss: 0.430621\n",
      "[96]\tvalid_0's multi_logloss: 0.48046\n",
      "[97]\tvalid_0's multi_logloss: 0.441712\n",
      "[98]\tvalid_0's multi_logloss: 0.446105\n",
      "[99]\tvalid_0's multi_logloss: 0.443378\n",
      "[100]\tvalid_0's multi_logloss: 0.438165\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001301 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 820733, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -2.163833\n",
      "[LightGBM] [Info] Start training from score -1.796397\n",
      "[LightGBM] [Info] Start training from score -1.843741\n",
      "[LightGBM] [Info] Start training from score -1.989576\n",
      "[LightGBM] [Info] Start training from score -1.941218\n",
      "[LightGBM] [Info] Start training from score -1.949016\n",
      "[LightGBM] [Info] Start training from score -1.978333\n",
      "[1]\tvalid_0's multi_logloss: 1.89891\n",
      "[2]\tvalid_0's multi_logloss: 1.86714\n",
      "[3]\tvalid_0's multi_logloss: 1.84185\n",
      "[4]\tvalid_0's multi_logloss: 1.82127\n",
      "[5]\tvalid_0's multi_logloss: 1.80422\n",
      "[6]\tvalid_0's multi_logloss: 1.79023\n",
      "[7]\tvalid_0's multi_logloss: 1.77872\n",
      "[8]\tvalid_0's multi_logloss: 1.76874\n",
      "[9]\tvalid_0's multi_logloss: 1.76037\n",
      "[10]\tvalid_0's multi_logloss: 1.75331\n",
      "[11]\tvalid_0's multi_logloss: 1.74711\n",
      "[12]\tvalid_0's multi_logloss: 1.74186\n",
      "[13]\tvalid_0's multi_logloss: 1.73747\n",
      "[14]\tvalid_0's multi_logloss: 1.73342\n",
      "[15]\tvalid_0's multi_logloss: 1.73\n",
      "[16]\tvalid_0's multi_logloss: 1.72667\n",
      "[17]\tvalid_0's multi_logloss: 1.72386\n",
      "[18]\tvalid_0's multi_logloss: 1.72131\n",
      "[19]\tvalid_0's multi_logloss: 1.71918\n",
      "[20]\tvalid_0's multi_logloss: 1.71704\n",
      "[21]\tvalid_0's multi_logloss: 1.71528\n",
      "[22]\tvalid_0's multi_logloss: 1.71354\n",
      "[23]\tvalid_0's multi_logloss: 1.71206\n",
      "[24]\tvalid_0's multi_logloss: 1.71074\n",
      "[25]\tvalid_0's multi_logloss: 1.70943\n",
      "[26]\tvalid_0's multi_logloss: 1.70833\n",
      "[27]\tvalid_0's multi_logloss: 1.70719\n",
      "[28]\tvalid_0's multi_logloss: 1.70627\n",
      "[29]\tvalid_0's multi_logloss: 1.70537\n",
      "[30]\tvalid_0's multi_logloss: 1.70446\n",
      "[31]\tvalid_0's multi_logloss: 1.70358\n",
      "[32]\tvalid_0's multi_logloss: 1.70292\n",
      "[33]\tvalid_0's multi_logloss: 1.70215\n",
      "[34]\tvalid_0's multi_logloss: 1.70155\n",
      "[35]\tvalid_0's multi_logloss: 1.70087\n",
      "[36]\tvalid_0's multi_logloss: 1.70019\n",
      "[37]\tvalid_0's multi_logloss: 1.69955\n",
      "[38]\tvalid_0's multi_logloss: 1.69886\n",
      "[39]\tvalid_0's multi_logloss: 1.69844\n",
      "[40]\tvalid_0's multi_logloss: 1.69784\n",
      "[41]\tvalid_0's multi_logloss: 1.69738\n",
      "[42]\tvalid_0's multi_logloss: 1.69698\n",
      "[43]\tvalid_0's multi_logloss: 1.69647\n",
      "[44]\tvalid_0's multi_logloss: 1.69611\n",
      "[45]\tvalid_0's multi_logloss: 1.69572\n",
      "[46]\tvalid_0's multi_logloss: 1.69532\n",
      "[47]\tvalid_0's multi_logloss: 1.69488\n",
      "[48]\tvalid_0's multi_logloss: 1.69455\n",
      "[49]\tvalid_0's multi_logloss: 1.6942\n",
      "[50]\tvalid_0's multi_logloss: 1.69392\n",
      "[51]\tvalid_0's multi_logloss: 1.69361\n",
      "[52]\tvalid_0's multi_logloss: 1.69332\n",
      "[53]\tvalid_0's multi_logloss: 1.69299\n",
      "[54]\tvalid_0's multi_logloss: 1.69277\n",
      "[55]\tvalid_0's multi_logloss: 1.69257\n",
      "[56]\tvalid_0's multi_logloss: 1.6923\n",
      "[57]\tvalid_0's multi_logloss: 1.69204\n",
      "[58]\tvalid_0's multi_logloss: 1.69179\n",
      "[59]\tvalid_0's multi_logloss: 1.69164\n",
      "[60]\tvalid_0's multi_logloss: 1.6914\n",
      "[61]\tvalid_0's multi_logloss: 1.69122\n",
      "[62]\tvalid_0's multi_logloss: 1.69101\n",
      "[63]\tvalid_0's multi_logloss: 1.69084\n",
      "[64]\tvalid_0's multi_logloss: 1.69066\n",
      "[65]\tvalid_0's multi_logloss: 1.69051\n",
      "[66]\tvalid_0's multi_logloss: 1.69023\n",
      "[67]\tvalid_0's multi_logloss: 1.69004\n",
      "[68]\tvalid_0's multi_logloss: 1.68977\n",
      "[69]\tvalid_0's multi_logloss: 1.68962\n",
      "[70]\tvalid_0's multi_logloss: 1.68947\n",
      "[71]\tvalid_0's multi_logloss: 1.68936\n",
      "[72]\tvalid_0's multi_logloss: 1.68925\n",
      "[73]\tvalid_0's multi_logloss: 1.68911\n",
      "[74]\tvalid_0's multi_logloss: 1.68894\n",
      "[75]\tvalid_0's multi_logloss: 1.68884\n",
      "[76]\tvalid_0's multi_logloss: 1.68871\n",
      "[77]\tvalid_0's multi_logloss: 1.68858\n",
      "[78]\tvalid_0's multi_logloss: 1.68843\n",
      "[79]\tvalid_0's multi_logloss: 1.68825\n",
      "[80]\tvalid_0's multi_logloss: 1.6881\n",
      "[81]\tvalid_0's multi_logloss: 1.68797\n",
      "[82]\tvalid_0's multi_logloss: 1.68781\n",
      "[83]\tvalid_0's multi_logloss: 1.6877\n",
      "[84]\tvalid_0's multi_logloss: 1.68761\n",
      "[85]\tvalid_0's multi_logloss: 1.68754\n",
      "[86]\tvalid_0's multi_logloss: 1.68746\n",
      "[87]\tvalid_0's multi_logloss: 1.6874\n",
      "[88]\tvalid_0's multi_logloss: 1.68733\n",
      "[89]\tvalid_0's multi_logloss: 1.68722\n",
      "[90]\tvalid_0's multi_logloss: 1.68716\n",
      "[91]\tvalid_0's multi_logloss: 1.68706\n",
      "[92]\tvalid_0's multi_logloss: 1.68698\n",
      "[93]\tvalid_0's multi_logloss: 1.68674\n",
      "[94]\tvalid_0's multi_logloss: 1.68665\n",
      "[95]\tvalid_0's multi_logloss: 1.68651\n",
      "[96]\tvalid_0's multi_logloss: 1.68633\n",
      "[97]\tvalid_0's multi_logloss: 1.68626\n",
      "[98]\tvalid_0's multi_logloss: 1.68615\n",
      "[99]\tvalid_0's multi_logloss: 1.68605\n",
      "[100]\tvalid_0's multi_logloss: 1.68603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [29:23, 87.38s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017599 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -1.853404\n",
      "[LightGBM] [Info] Start training from score -2.123202\n",
      "[LightGBM] [Info] Start training from score -2.391862\n",
      "[LightGBM] [Info] Start training from score -2.719639\n",
      "[LightGBM] [Info] Start training from score -2.078311\n",
      "[LightGBM] [Info] Start training from score -2.161447\n",
      "[LightGBM] [Info] Start training from score -2.497610\n",
      "[LightGBM] [Info] Start training from score -2.232530\n",
      "[LightGBM] [Info] Start training from score -2.689447\n",
      "[LightGBM] [Info] Start training from score -2.680407\n",
      "[1]\tvalid_0's multi_logloss: 1.92818\n",
      "[2]\tvalid_0's multi_logloss: 1.75529\n",
      "[3]\tvalid_0's multi_logloss: 1.63325\n",
      "[4]\tvalid_0's multi_logloss: 1.54116\n",
      "[5]\tvalid_0's multi_logloss: 1.46669\n",
      "[6]\tvalid_0's multi_logloss: 1.40645\n",
      "[7]\tvalid_0's multi_logloss: 1.35534\n",
      "[8]\tvalid_0's multi_logloss: 1.31271\n",
      "[9]\tvalid_0's multi_logloss: 1.27697\n",
      "[10]\tvalid_0's multi_logloss: 1.24608\n",
      "[11]\tvalid_0's multi_logloss: 1.21887\n",
      "[12]\tvalid_0's multi_logloss: 1.19535\n",
      "[13]\tvalid_0's multi_logloss: 1.17423\n",
      "[14]\tvalid_0's multi_logloss: 1.1563\n",
      "[15]\tvalid_0's multi_logloss: 1.13999\n",
      "[16]\tvalid_0's multi_logloss: 1.12585\n",
      "[17]\tvalid_0's multi_logloss: 1.11295\n",
      "[18]\tvalid_0's multi_logloss: 1.10115\n",
      "[19]\tvalid_0's multi_logloss: 1.09057\n",
      "[20]\tvalid_0's multi_logloss: 1.08106\n",
      "[21]\tvalid_0's multi_logloss: 1.07219\n",
      "[22]\tvalid_0's multi_logloss: 1.06407\n",
      "[23]\tvalid_0's multi_logloss: 1.05661\n",
      "[24]\tvalid_0's multi_logloss: 1.04957\n",
      "[25]\tvalid_0's multi_logloss: 1.04348\n",
      "[26]\tvalid_0's multi_logloss: 1.03735\n",
      "[27]\tvalid_0's multi_logloss: 1.03188\n",
      "[28]\tvalid_0's multi_logloss: 1.02659\n",
      "[29]\tvalid_0's multi_logloss: 1.02182\n",
      "[30]\tvalid_0's multi_logloss: 1.0179\n",
      "[31]\tvalid_0's multi_logloss: 1.01387\n",
      "[32]\tvalid_0's multi_logloss: 1.01013\n",
      "[33]\tvalid_0's multi_logloss: 1.00678\n",
      "[34]\tvalid_0's multi_logloss: 1.00298\n",
      "[35]\tvalid_0's multi_logloss: 0.999798\n",
      "[36]\tvalid_0's multi_logloss: 0.996358\n",
      "[37]\tvalid_0's multi_logloss: 0.993064\n",
      "[38]\tvalid_0's multi_logloss: 0.990344\n",
      "[39]\tvalid_0's multi_logloss: 0.987911\n",
      "[40]\tvalid_0's multi_logloss: 0.985262\n",
      "[41]\tvalid_0's multi_logloss: 0.98264\n",
      "[42]\tvalid_0's multi_logloss: 0.98012\n",
      "[43]\tvalid_0's multi_logloss: 0.978033\n",
      "[44]\tvalid_0's multi_logloss: 0.976314\n",
      "[45]\tvalid_0's multi_logloss: 0.974159\n",
      "[46]\tvalid_0's multi_logloss: 0.972231\n",
      "[47]\tvalid_0's multi_logloss: 0.970034\n",
      "[48]\tvalid_0's multi_logloss: 0.967864\n",
      "[49]\tvalid_0's multi_logloss: 0.966253\n",
      "[50]\tvalid_0's multi_logloss: 0.964572\n",
      "[51]\tvalid_0's multi_logloss: 0.963011\n",
      "[52]\tvalid_0's multi_logloss: 0.96133\n",
      "[53]\tvalid_0's multi_logloss: 0.960021\n",
      "[54]\tvalid_0's multi_logloss: 0.958672\n",
      "[55]\tvalid_0's multi_logloss: 0.957423\n",
      "[56]\tvalid_0's multi_logloss: 0.955871\n",
      "[57]\tvalid_0's multi_logloss: 0.954225\n",
      "[58]\tvalid_0's multi_logloss: 0.952974\n",
      "[59]\tvalid_0's multi_logloss: 0.951771\n",
      "[60]\tvalid_0's multi_logloss: 0.950647\n",
      "[61]\tvalid_0's multi_logloss: 0.949433\n",
      "[62]\tvalid_0's multi_logloss: 0.948041\n",
      "[63]\tvalid_0's multi_logloss: 0.946882\n",
      "[64]\tvalid_0's multi_logloss: 0.945812\n",
      "[65]\tvalid_0's multi_logloss: 0.944816\n",
      "[66]\tvalid_0's multi_logloss: 0.943777\n",
      "[67]\tvalid_0's multi_logloss: 0.942801\n",
      "[68]\tvalid_0's multi_logloss: 0.941741\n",
      "[69]\tvalid_0's multi_logloss: 0.940465\n",
      "[70]\tvalid_0's multi_logloss: 0.939761\n",
      "[71]\tvalid_0's multi_logloss: 0.938407\n",
      "[72]\tvalid_0's multi_logloss: 0.937372\n",
      "[73]\tvalid_0's multi_logloss: 0.936146\n",
      "[74]\tvalid_0's multi_logloss: 0.935144\n",
      "[75]\tvalid_0's multi_logloss: 0.933988\n",
      "[76]\tvalid_0's multi_logloss: 0.933282\n",
      "[77]\tvalid_0's multi_logloss: 0.932564\n",
      "[78]\tvalid_0's multi_logloss: 0.931299\n",
      "[79]\tvalid_0's multi_logloss: 0.930604\n",
      "[80]\tvalid_0's multi_logloss: 0.929676\n",
      "[81]\tvalid_0's multi_logloss: 0.928857\n",
      "[82]\tvalid_0's multi_logloss: 0.928084\n",
      "[83]\tvalid_0's multi_logloss: 0.927332\n",
      "[84]\tvalid_0's multi_logloss: 0.926613\n",
      "[85]\tvalid_0's multi_logloss: 0.925563\n",
      "[86]\tvalid_0's multi_logloss: 0.924647\n",
      "[87]\tvalid_0's multi_logloss: 0.923973\n",
      "[88]\tvalid_0's multi_logloss: 0.922964\n",
      "[89]\tvalid_0's multi_logloss: 0.92225\n",
      "[90]\tvalid_0's multi_logloss: 0.921497\n",
      "[91]\tvalid_0's multi_logloss: 0.92087\n",
      "[92]\tvalid_0's multi_logloss: 0.920285\n",
      "[93]\tvalid_0's multi_logloss: 0.919501\n",
      "[94]\tvalid_0's multi_logloss: 0.918624\n",
      "[95]\tvalid_0's multi_logloss: 0.917647\n",
      "[96]\tvalid_0's multi_logloss: 0.917089\n",
      "[97]\tvalid_0's multi_logloss: 0.91639\n",
      "[98]\tvalid_0's multi_logloss: 0.915635\n",
      "[99]\tvalid_0's multi_logloss: 0.915273\n",
      "[100]\tvalid_0's multi_logloss: 0.914239\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017433 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -1.047228\n",
      "[LightGBM] [Info] Start training from score -1.516216\n",
      "[LightGBM] [Info] Start training from score -0.845018\n",
      "[1]\tvalid_0's multi_logloss: 1.01034\n",
      "[2]\tvalid_0's multi_logloss: 0.967256\n",
      "[3]\tvalid_0's multi_logloss: 0.931069\n",
      "[4]\tvalid_0's multi_logloss: 0.900638\n",
      "[5]\tvalid_0's multi_logloss: 0.874746\n",
      "[6]\tvalid_0's multi_logloss: 0.852465\n",
      "[7]\tvalid_0's multi_logloss: 0.833225\n",
      "[8]\tvalid_0's multi_logloss: 0.816622\n",
      "[9]\tvalid_0's multi_logloss: 0.801887\n",
      "[10]\tvalid_0's multi_logloss: 0.788892\n",
      "[11]\tvalid_0's multi_logloss: 0.77743\n",
      "[12]\tvalid_0's multi_logloss: 0.767286\n",
      "[13]\tvalid_0's multi_logloss: 0.757899\n",
      "[14]\tvalid_0's multi_logloss: 0.749613\n",
      "[15]\tvalid_0's multi_logloss: 0.742064\n",
      "[16]\tvalid_0's multi_logloss: 0.735199\n",
      "[17]\tvalid_0's multi_logloss: 0.72904\n",
      "[18]\tvalid_0's multi_logloss: 0.723421\n",
      "[19]\tvalid_0's multi_logloss: 0.718282\n",
      "[20]\tvalid_0's multi_logloss: 0.713564\n",
      "[21]\tvalid_0's multi_logloss: 0.709142\n",
      "[22]\tvalid_0's multi_logloss: 0.705243\n",
      "[23]\tvalid_0's multi_logloss: 0.70153\n",
      "[24]\tvalid_0's multi_logloss: 0.698212\n",
      "[25]\tvalid_0's multi_logloss: 0.695088\n",
      "[26]\tvalid_0's multi_logloss: 0.69227\n",
      "[27]\tvalid_0's multi_logloss: 0.689646\n",
      "[28]\tvalid_0's multi_logloss: 0.687215\n",
      "[29]\tvalid_0's multi_logloss: 0.685002\n",
      "[30]\tvalid_0's multi_logloss: 0.68288\n",
      "[31]\tvalid_0's multi_logloss: 0.680877\n",
      "[32]\tvalid_0's multi_logloss: 0.679049\n",
      "[33]\tvalid_0's multi_logloss: 0.677384\n",
      "[34]\tvalid_0's multi_logloss: 0.675827\n",
      "[35]\tvalid_0's multi_logloss: 0.674372\n",
      "[36]\tvalid_0's multi_logloss: 0.673043\n",
      "[37]\tvalid_0's multi_logloss: 0.671766\n",
      "[38]\tvalid_0's multi_logloss: 0.67053\n",
      "[39]\tvalid_0's multi_logloss: 0.669412\n",
      "[40]\tvalid_0's multi_logloss: 0.668356\n",
      "[41]\tvalid_0's multi_logloss: 0.667368\n",
      "[42]\tvalid_0's multi_logloss: 0.666458\n",
      "[43]\tvalid_0's multi_logloss: 0.665476\n",
      "[44]\tvalid_0's multi_logloss: 0.664664\n",
      "[45]\tvalid_0's multi_logloss: 0.663729\n",
      "[46]\tvalid_0's multi_logloss: 0.662993\n",
      "[47]\tvalid_0's multi_logloss: 0.662318\n",
      "[48]\tvalid_0's multi_logloss: 0.661653\n",
      "[49]\tvalid_0's multi_logloss: 0.661055\n",
      "[50]\tvalid_0's multi_logloss: 0.660496\n",
      "[51]\tvalid_0's multi_logloss: 0.659868\n",
      "[52]\tvalid_0's multi_logloss: 0.65929\n",
      "[53]\tvalid_0's multi_logloss: 0.658825\n",
      "[54]\tvalid_0's multi_logloss: 0.658287\n",
      "[55]\tvalid_0's multi_logloss: 0.657833\n",
      "[56]\tvalid_0's multi_logloss: 0.657376\n",
      "[57]\tvalid_0's multi_logloss: 0.657005\n",
      "[58]\tvalid_0's multi_logloss: 0.656602\n",
      "[59]\tvalid_0's multi_logloss: 0.656288\n",
      "[60]\tvalid_0's multi_logloss: 0.655956\n",
      "[61]\tvalid_0's multi_logloss: 0.655621\n",
      "[62]\tvalid_0's multi_logloss: 0.655307\n",
      "[63]\tvalid_0's multi_logloss: 0.655016\n",
      "[64]\tvalid_0's multi_logloss: 0.654731\n",
      "[65]\tvalid_0's multi_logloss: 0.65446\n",
      "[66]\tvalid_0's multi_logloss: 0.654235\n",
      "[67]\tvalid_0's multi_logloss: 0.653994\n",
      "[68]\tvalid_0's multi_logloss: 0.653716\n",
      "[69]\tvalid_0's multi_logloss: 0.653485\n",
      "[70]\tvalid_0's multi_logloss: 0.653257\n",
      "[71]\tvalid_0's multi_logloss: 0.653084\n",
      "[72]\tvalid_0's multi_logloss: 0.652909\n",
      "[73]\tvalid_0's multi_logloss: 0.652696\n",
      "[74]\tvalid_0's multi_logloss: 0.652484\n",
      "[75]\tvalid_0's multi_logloss: 0.652279\n",
      "[76]\tvalid_0's multi_logloss: 0.652078\n",
      "[77]\tvalid_0's multi_logloss: 0.651871\n",
      "[78]\tvalid_0's multi_logloss: 0.651688\n",
      "[79]\tvalid_0's multi_logloss: 0.651569\n",
      "[80]\tvalid_0's multi_logloss: 0.651374\n",
      "[81]\tvalid_0's multi_logloss: 0.651187\n",
      "[82]\tvalid_0's multi_logloss: 0.651033\n",
      "[83]\tvalid_0's multi_logloss: 0.650806\n",
      "[84]\tvalid_0's multi_logloss: 0.650651\n",
      "[85]\tvalid_0's multi_logloss: 0.650507\n",
      "[86]\tvalid_0's multi_logloss: 0.65036\n",
      "[87]\tvalid_0's multi_logloss: 0.650244\n",
      "[88]\tvalid_0's multi_logloss: 0.650029\n",
      "[89]\tvalid_0's multi_logloss: 0.649924\n",
      "[90]\tvalid_0's multi_logloss: 0.649787\n",
      "[91]\tvalid_0's multi_logloss: 0.649685\n",
      "[92]\tvalid_0's multi_logloss: 0.649576\n",
      "[93]\tvalid_0's multi_logloss: 0.649439\n",
      "[94]\tvalid_0's multi_logloss: 0.649334\n",
      "[95]\tvalid_0's multi_logloss: 0.649247\n",
      "[96]\tvalid_0's multi_logloss: 0.649123\n",
      "[97]\tvalid_0's multi_logloss: 0.648988\n",
      "[98]\tvalid_0's multi_logloss: 0.648889\n",
      "[99]\tvalid_0's multi_logloss: 0.648784\n",
      "[100]\tvalid_0's multi_logloss: 0.648712\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017514 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -3.244539\n",
      "[LightGBM] [Info] Start training from score -3.224920\n",
      "[LightGBM] [Info] Start training from score -3.369880\n",
      "[LightGBM] [Info] Start training from score -3.326941\n",
      "[LightGBM] [Info] Start training from score -3.378266\n",
      "[LightGBM] [Info] Start training from score -2.568017\n",
      "[LightGBM] [Info] Start training from score -1.914747\n",
      "[LightGBM] [Info] Start training from score -3.469579\n",
      "[LightGBM] [Info] Start training from score -1.919436\n",
      "[LightGBM] [Info] Start training from score -2.291576\n",
      "[LightGBM] [Info] Start training from score -2.007538\n",
      "[LightGBM] [Info] Start training from score -3.402200\n",
      "[LightGBM] [Info] Start training from score -3.212376\n",
      "[LightGBM] [Info] Start training from score -2.244521\n",
      "[1]\tvalid_0's multi_logloss: 2.39725\n",
      "[2]\tvalid_0's multi_logloss: 2.3575\n",
      "[3]\tvalid_0's multi_logloss: 2.32706\n",
      "[4]\tvalid_0's multi_logloss: 2.30233\n",
      "[5]\tvalid_0's multi_logloss: 2.28191\n",
      "[6]\tvalid_0's multi_logloss: 2.26471\n",
      "[7]\tvalid_0's multi_logloss: 2.2503\n",
      "[8]\tvalid_0's multi_logloss: 2.23758\n",
      "[9]\tvalid_0's multi_logloss: 2.22668\n",
      "[10]\tvalid_0's multi_logloss: 2.21675\n",
      "[11]\tvalid_0's multi_logloss: 2.20806\n",
      "[12]\tvalid_0's multi_logloss: 2.20065\n",
      "[13]\tvalid_0's multi_logloss: 2.19403\n",
      "[14]\tvalid_0's multi_logloss: 2.18806\n",
      "[15]\tvalid_0's multi_logloss: 2.18262\n",
      "[16]\tvalid_0's multi_logloss: 2.17758\n",
      "[17]\tvalid_0's multi_logloss: 2.17312\n",
      "[18]\tvalid_0's multi_logloss: 2.16905\n",
      "[19]\tvalid_0's multi_logloss: 2.16529\n",
      "[20]\tvalid_0's multi_logloss: 2.16175\n",
      "[21]\tvalid_0's multi_logloss: 2.15866\n",
      "[22]\tvalid_0's multi_logloss: 2.15542\n",
      "[23]\tvalid_0's multi_logloss: 2.15272\n",
      "[24]\tvalid_0's multi_logloss: 2.14992\n",
      "[25]\tvalid_0's multi_logloss: 2.14722\n",
      "[26]\tvalid_0's multi_logloss: 2.14469\n",
      "[27]\tvalid_0's multi_logloss: 2.14235\n",
      "[28]\tvalid_0's multi_logloss: 2.14022\n",
      "[29]\tvalid_0's multi_logloss: 2.13801\n",
      "[30]\tvalid_0's multi_logloss: 2.13614\n",
      "[31]\tvalid_0's multi_logloss: 2.13429\n",
      "[32]\tvalid_0's multi_logloss: 2.13252\n",
      "[33]\tvalid_0's multi_logloss: 2.13076\n",
      "[34]\tvalid_0's multi_logloss: 2.12909\n",
      "[35]\tvalid_0's multi_logloss: 2.12754\n",
      "[36]\tvalid_0's multi_logloss: 2.12618\n",
      "[37]\tvalid_0's multi_logloss: 2.12477\n",
      "[38]\tvalid_0's multi_logloss: 2.12343\n",
      "[39]\tvalid_0's multi_logloss: 2.12207\n",
      "[40]\tvalid_0's multi_logloss: 2.12092\n",
      "[41]\tvalid_0's multi_logloss: 2.11978\n",
      "[42]\tvalid_0's multi_logloss: 2.11866\n",
      "[43]\tvalid_0's multi_logloss: 2.11772\n",
      "[44]\tvalid_0's multi_logloss: 2.11669\n",
      "[45]\tvalid_0's multi_logloss: 2.11578\n",
      "[46]\tvalid_0's multi_logloss: 2.11484\n",
      "[47]\tvalid_0's multi_logloss: 2.11373\n",
      "[48]\tvalid_0's multi_logloss: 2.11275\n",
      "[49]\tvalid_0's multi_logloss: 2.11195\n",
      "[50]\tvalid_0's multi_logloss: 2.11099\n",
      "[51]\tvalid_0's multi_logloss: 2.11003\n",
      "[52]\tvalid_0's multi_logloss: 2.10901\n",
      "[53]\tvalid_0's multi_logloss: 2.1082\n",
      "[54]\tvalid_0's multi_logloss: 2.10737\n",
      "[55]\tvalid_0's multi_logloss: 2.10677\n",
      "[56]\tvalid_0's multi_logloss: 2.10599\n",
      "[57]\tvalid_0's multi_logloss: 2.10524\n",
      "[58]\tvalid_0's multi_logloss: 2.10459\n",
      "[59]\tvalid_0's multi_logloss: 2.10392\n",
      "[60]\tvalid_0's multi_logloss: 2.10327\n",
      "[61]\tvalid_0's multi_logloss: 2.10267\n",
      "[62]\tvalid_0's multi_logloss: 2.102\n",
      "[63]\tvalid_0's multi_logloss: 2.10138\n",
      "[64]\tvalid_0's multi_logloss: 2.1007\n",
      "[65]\tvalid_0's multi_logloss: 2.10008\n",
      "[66]\tvalid_0's multi_logloss: 2.09952\n",
      "[67]\tvalid_0's multi_logloss: 2.09885\n",
      "[68]\tvalid_0's multi_logloss: 2.09834\n",
      "[69]\tvalid_0's multi_logloss: 2.09764\n",
      "[70]\tvalid_0's multi_logloss: 2.09703\n",
      "[71]\tvalid_0's multi_logloss: 2.09649\n",
      "[72]\tvalid_0's multi_logloss: 2.09606\n",
      "[73]\tvalid_0's multi_logloss: 2.09548\n",
      "[74]\tvalid_0's multi_logloss: 2.09487\n",
      "[75]\tvalid_0's multi_logloss: 2.09447\n",
      "[76]\tvalid_0's multi_logloss: 2.09397\n",
      "[77]\tvalid_0's multi_logloss: 2.09352\n",
      "[78]\tvalid_0's multi_logloss: 2.09307\n",
      "[79]\tvalid_0's multi_logloss: 2.09261\n",
      "[80]\tvalid_0's multi_logloss: 2.0922\n",
      "[81]\tvalid_0's multi_logloss: 2.09181\n",
      "[82]\tvalid_0's multi_logloss: 2.09144\n",
      "[83]\tvalid_0's multi_logloss: 2.09114\n",
      "[84]\tvalid_0's multi_logloss: 2.09063\n",
      "[85]\tvalid_0's multi_logloss: 2.09047\n",
      "[86]\tvalid_0's multi_logloss: 2.09023\n",
      "[87]\tvalid_0's multi_logloss: 2.0897\n",
      "[88]\tvalid_0's multi_logloss: 2.08924\n",
      "[89]\tvalid_0's multi_logloss: 2.08877\n",
      "[90]\tvalid_0's multi_logloss: 2.0883\n",
      "[91]\tvalid_0's multi_logloss: 2.08792\n",
      "[92]\tvalid_0's multi_logloss: 2.08763\n",
      "[93]\tvalid_0's multi_logloss: 2.08732\n",
      "[94]\tvalid_0's multi_logloss: 2.08688\n",
      "[95]\tvalid_0's multi_logloss: 2.08652\n",
      "[96]\tvalid_0's multi_logloss: 2.08618\n",
      "[97]\tvalid_0's multi_logloss: 2.08592\n",
      "[98]\tvalid_0's multi_logloss: 2.08566\n",
      "[99]\tvalid_0's multi_logloss: 2.08544\n",
      "[100]\tvalid_0's multi_logloss: 2.08507\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016915 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -0.501622\n",
      "[LightGBM] [Info] Start training from score -0.930257\n",
      "[1]\tvalid_0's multi_logloss: 0.576397\n",
      "[2]\tvalid_0's multi_logloss: 0.50046\n",
      "[3]\tvalid_0's multi_logloss: 0.437757\n",
      "[4]\tvalid_0's multi_logloss: 0.385027\n",
      "[5]\tvalid_0's multi_logloss: 0.340152\n",
      "[6]\tvalid_0's multi_logloss: 0.301472\n",
      "[7]\tvalid_0's multi_logloss: 0.267948\n",
      "[8]\tvalid_0's multi_logloss: 0.238719\n",
      "[9]\tvalid_0's multi_logloss: 0.213138\n",
      "[10]\tvalid_0's multi_logloss: 0.190617\n",
      "[11]\tvalid_0's multi_logloss: 0.170749\n",
      "[12]\tvalid_0's multi_logloss: 0.153123\n",
      "[13]\tvalid_0's multi_logloss: 0.137487\n",
      "[14]\tvalid_0's multi_logloss: 0.123584\n",
      "[15]\tvalid_0's multi_logloss: 0.111183\n",
      "[16]\tvalid_0's multi_logloss: 0.100115\n",
      "[17]\tvalid_0's multi_logloss: 0.0902217\n",
      "[18]\tvalid_0's multi_logloss: 0.0812888\n",
      "[19]\tvalid_0's multi_logloss: 0.0733524\n",
      "[20]\tvalid_0's multi_logloss: 0.0662139\n",
      "[21]\tvalid_0's multi_logloss: 0.0597971\n",
      "[22]\tvalid_0's multi_logloss: 0.0540374\n",
      "[23]\tvalid_0's multi_logloss: 0.0488412\n",
      "[24]\tvalid_0's multi_logloss: 0.0441321\n",
      "[25]\tvalid_0's multi_logloss: 0.0399149\n",
      "[26]\tvalid_0's multi_logloss: 0.0361321\n",
      "[27]\tvalid_0's multi_logloss: 0.0327231\n",
      "[28]\tvalid_0's multi_logloss: 0.0296475\n",
      "[29]\tvalid_0's multi_logloss: 0.0268784\n",
      "[30]\tvalid_0's multi_logloss: 0.0243731\n",
      "[31]\tvalid_0's multi_logloss: 0.0221219\n",
      "[32]\tvalid_0's multi_logloss: 0.0200809\n",
      "[33]\tvalid_0's multi_logloss: 0.0182273\n",
      "[34]\tvalid_0's multi_logloss: 0.0165697\n",
      "[35]\tvalid_0's multi_logloss: 0.0150534\n",
      "[36]\tvalid_0's multi_logloss: 0.0136998\n",
      "[37]\tvalid_0's multi_logloss: 0.0124795\n",
      "[38]\tvalid_0's multi_logloss: 0.0113764\n",
      "[39]\tvalid_0's multi_logloss: 0.010378\n",
      "[40]\tvalid_0's multi_logloss: 0.00947679\n",
      "[41]\tvalid_0's multi_logloss: 0.00866007\n",
      "[42]\tvalid_0's multi_logloss: 0.00792352\n",
      "[43]\tvalid_0's multi_logloss: 0.00725826\n",
      "[44]\tvalid_0's multi_logloss: 0.00664581\n",
      "[45]\tvalid_0's multi_logloss: 0.0061009\n",
      "[46]\tvalid_0's multi_logloss: 0.00561035\n",
      "[47]\tvalid_0's multi_logloss: 0.00516266\n",
      "[48]\tvalid_0's multi_logloss: 0.00476114\n",
      "[49]\tvalid_0's multi_logloss: 0.00439679\n",
      "[50]\tvalid_0's multi_logloss: 0.00406784\n",
      "[51]\tvalid_0's multi_logloss: 0.00376929\n",
      "[52]\tvalid_0's multi_logloss: 0.0034989\n",
      "[53]\tvalid_0's multi_logloss: 0.00325487\n",
      "[54]\tvalid_0's multi_logloss: 0.00303426\n",
      "[55]\tvalid_0's multi_logloss: 0.00283499\n",
      "[56]\tvalid_0's multi_logloss: 0.00265498\n",
      "[57]\tvalid_0's multi_logloss: 0.00250061\n",
      "[58]\tvalid_0's multi_logloss: 0.00235386\n",
      "[59]\tvalid_0's multi_logloss: 0.00222181\n",
      "[60]\tvalid_0's multi_logloss: 0.00210243\n",
      "[61]\tvalid_0's multi_logloss: 0.00199515\n",
      "[62]\tvalid_0's multi_logloss: 0.00189899\n",
      "[63]\tvalid_0's multi_logloss: 0.00181168\n",
      "[64]\tvalid_0's multi_logloss: 0.00173443\n",
      "[65]\tvalid_0's multi_logloss: 0.00166241\n",
      "[66]\tvalid_0's multi_logloss: 0.00159947\n",
      "[67]\tvalid_0's multi_logloss: 0.00152892\n",
      "[68]\tvalid_0's multi_logloss: 0.00147513\n",
      "[69]\tvalid_0's multi_logloss: 0.00142684\n",
      "[70]\tvalid_0's multi_logloss: 0.00138468\n",
      "[71]\tvalid_0's multi_logloss: 0.00139048\n",
      "[72]\tvalid_0's multi_logloss: 0.00136815\n",
      "[73]\tvalid_0's multi_logloss: 0.00133606\n",
      "[74]\tvalid_0's multi_logloss: 0.00130728\n",
      "[75]\tvalid_0's multi_logloss: 0.0012795\n",
      "[76]\tvalid_0's multi_logloss: 0.00128571\n",
      "[77]\tvalid_0's multi_logloss: 0.00131744\n",
      "[78]\tvalid_0's multi_logloss: 0.00125764\n",
      "[79]\tvalid_0's multi_logloss: 0.00124045\n",
      "[80]\tvalid_0's multi_logloss: 0.00122389\n",
      "[81]\tvalid_0's multi_logloss: 0.00121751\n",
      "[82]\tvalid_0's multi_logloss: 0.0012059\n",
      "[83]\tvalid_0's multi_logloss: 0.00119411\n",
      "[84]\tvalid_0's multi_logloss: 0.00118031\n",
      "[85]\tvalid_0's multi_logloss: 0.00117052\n",
      "[86]\tvalid_0's multi_logloss: 0.00142975\n",
      "[87]\tvalid_0's multi_logloss: 0.0012215\n",
      "[88]\tvalid_0's multi_logloss: 0.00120621\n",
      "[89]\tvalid_0's multi_logloss: 0.00151414\n",
      "[90]\tvalid_0's multi_logloss: 0.00119497\n",
      "[91]\tvalid_0's multi_logloss: 0.00118922\n",
      "[92]\tvalid_0's multi_logloss: 0.00173693\n",
      "[93]\tvalid_0's multi_logloss: 0.00122692\n",
      "[94]\tvalid_0's multi_logloss: 0.00118932\n",
      "[95]\tvalid_0's multi_logloss: 0.00121479\n",
      "[96]\tvalid_0's multi_logloss: 0.00133578\n",
      "[97]\tvalid_0's multi_logloss: 0.00125124\n",
      "[98]\tvalid_0's multi_logloss: 0.0012634\n",
      "[99]\tvalid_0's multi_logloss: 0.00120899\n",
      "[100]\tvalid_0's multi_logloss: 0.00126161\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018075 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -0.141837\n",
      "[LightGBM] [Info] Start training from score -2.023158\n",
      "[1]\tvalid_0's multi_logloss: 0.356057\n",
      "[2]\tvalid_0's multi_logloss: 0.333955\n",
      "[3]\tvalid_0's multi_logloss: 0.317433\n",
      "[4]\tvalid_0's multi_logloss: 0.304538\n",
      "[5]\tvalid_0's multi_logloss: 0.293844\n",
      "[6]\tvalid_0's multi_logloss: 0.284534\n",
      "[7]\tvalid_0's multi_logloss: 0.27669\n",
      "[8]\tvalid_0's multi_logloss: 0.269822\n",
      "[9]\tvalid_0's multi_logloss: 0.263618\n",
      "[10]\tvalid_0's multi_logloss: 0.258328\n",
      "[11]\tvalid_0's multi_logloss: 0.253594\n",
      "[12]\tvalid_0's multi_logloss: 0.249292\n",
      "[13]\tvalid_0's multi_logloss: 0.245577\n",
      "[14]\tvalid_0's multi_logloss: 0.242153\n",
      "[15]\tvalid_0's multi_logloss: 0.239138\n",
      "[16]\tvalid_0's multi_logloss: 0.236417\n",
      "[17]\tvalid_0's multi_logloss: 0.234049\n",
      "[18]\tvalid_0's multi_logloss: 0.231594\n",
      "[19]\tvalid_0's multi_logloss: 0.229449\n",
      "[20]\tvalid_0's multi_logloss: 0.227348\n",
      "[21]\tvalid_0's multi_logloss: 0.225577\n",
      "[22]\tvalid_0's multi_logloss: 0.22382\n",
      "[23]\tvalid_0's multi_logloss: 0.222381\n",
      "[24]\tvalid_0's multi_logloss: 0.220593\n",
      "[25]\tvalid_0's multi_logloss: 0.219163\n",
      "[26]\tvalid_0's multi_logloss: 0.217443\n",
      "[27]\tvalid_0's multi_logloss: 0.216108\n",
      "[28]\tvalid_0's multi_logloss: 0.214739\n",
      "[29]\tvalid_0's multi_logloss: 0.213478\n",
      "[30]\tvalid_0's multi_logloss: 0.212456\n",
      "[31]\tvalid_0's multi_logloss: 0.211498\n",
      "[32]\tvalid_0's multi_logloss: 0.210318\n",
      "[33]\tvalid_0's multi_logloss: 0.209444\n",
      "[34]\tvalid_0's multi_logloss: 0.208395\n",
      "[35]\tvalid_0's multi_logloss: 0.207356\n",
      "[36]\tvalid_0's multi_logloss: 0.206534\n",
      "[37]\tvalid_0's multi_logloss: 0.205752\n",
      "[38]\tvalid_0's multi_logloss: 0.205084\n",
      "[39]\tvalid_0's multi_logloss: 0.204156\n",
      "[40]\tvalid_0's multi_logloss: 0.203486\n",
      "[41]\tvalid_0's multi_logloss: 0.202799\n",
      "[42]\tvalid_0's multi_logloss: 0.202259\n",
      "[43]\tvalid_0's multi_logloss: 0.201695\n",
      "[44]\tvalid_0's multi_logloss: 0.201061\n",
      "[45]\tvalid_0's multi_logloss: 0.200533\n",
      "[46]\tvalid_0's multi_logloss: 0.199842\n",
      "[47]\tvalid_0's multi_logloss: 0.199257\n",
      "[48]\tvalid_0's multi_logloss: 0.198912\n",
      "[49]\tvalid_0's multi_logloss: 0.198446\n",
      "[50]\tvalid_0's multi_logloss: 0.197906\n",
      "[51]\tvalid_0's multi_logloss: 0.197469\n",
      "[52]\tvalid_0's multi_logloss: 0.196933\n",
      "[53]\tvalid_0's multi_logloss: 0.196646\n",
      "[54]\tvalid_0's multi_logloss: 0.196321\n",
      "[55]\tvalid_0's multi_logloss: 0.195903\n",
      "[56]\tvalid_0's multi_logloss: 0.195528\n",
      "[57]\tvalid_0's multi_logloss: 0.195214\n",
      "[58]\tvalid_0's multi_logloss: 0.194844\n",
      "[59]\tvalid_0's multi_logloss: 0.194395\n",
      "[60]\tvalid_0's multi_logloss: 0.193936\n",
      "[61]\tvalid_0's multi_logloss: 0.193583\n",
      "[62]\tvalid_0's multi_logloss: 0.19321\n",
      "[63]\tvalid_0's multi_logloss: 0.192894\n",
      "[64]\tvalid_0's multi_logloss: 0.192281\n",
      "[65]\tvalid_0's multi_logloss: 0.192014\n",
      "[66]\tvalid_0's multi_logloss: 0.191613\n",
      "[67]\tvalid_0's multi_logloss: 0.191253\n",
      "[68]\tvalid_0's multi_logloss: 0.19109\n",
      "[69]\tvalid_0's multi_logloss: 0.190519\n",
      "[70]\tvalid_0's multi_logloss: 0.190217\n",
      "[71]\tvalid_0's multi_logloss: 0.189826\n",
      "[72]\tvalid_0's multi_logloss: 0.189545\n",
      "[73]\tvalid_0's multi_logloss: 0.189188\n",
      "[74]\tvalid_0's multi_logloss: 0.188931\n",
      "[75]\tvalid_0's multi_logloss: 0.188626\n",
      "[76]\tvalid_0's multi_logloss: 0.18835\n",
      "[77]\tvalid_0's multi_logloss: 0.188109\n",
      "[78]\tvalid_0's multi_logloss: 0.187835\n",
      "[79]\tvalid_0's multi_logloss: 0.187677\n",
      "[80]\tvalid_0's multi_logloss: 0.187382\n",
      "[81]\tvalid_0's multi_logloss: 0.187018\n",
      "[82]\tvalid_0's multi_logloss: 0.186916\n",
      "[83]\tvalid_0's multi_logloss: 0.186702\n",
      "[84]\tvalid_0's multi_logloss: 0.186454\n",
      "[85]\tvalid_0's multi_logloss: 0.186245\n",
      "[86]\tvalid_0's multi_logloss: 0.185994\n",
      "[87]\tvalid_0's multi_logloss: 0.185555\n",
      "[88]\tvalid_0's multi_logloss: 0.185395\n",
      "[89]\tvalid_0's multi_logloss: 0.185084\n",
      "[90]\tvalid_0's multi_logloss: 0.184844\n",
      "[91]\tvalid_0's multi_logloss: 0.184534\n",
      "[92]\tvalid_0's multi_logloss: 0.184116\n",
      "[93]\tvalid_0's multi_logloss: 0.183588\n",
      "[94]\tvalid_0's multi_logloss: 0.183418\n",
      "[95]\tvalid_0's multi_logloss: 0.183269\n",
      "[96]\tvalid_0's multi_logloss: 0.182911\n",
      "[97]\tvalid_0's multi_logloss: 0.182736\n",
      "[98]\tvalid_0's multi_logloss: 0.182323\n",
      "[99]\tvalid_0's multi_logloss: 0.182174\n",
      "[100]\tvalid_0's multi_logloss: 0.181994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [33:12, 129.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008210 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 7715638, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -1.249550\n",
      "[LightGBM] [Info] Start training from score -3.165534\n",
      "[LightGBM] [Info] Start training from score -1.726403\n",
      "[LightGBM] [Info] Start training from score -1.902421\n",
      "[LightGBM] [Info] Start training from score -1.667720\n",
      "[LightGBM] [Info] Start training from score -1.861961\n",
      "[1]\tvalid_0's multi_logloss: 1.67886\n",
      "[2]\tvalid_0's multi_logloss: 1.67293\n",
      "[3]\tvalid_0's multi_logloss: 1.66824\n",
      "[4]\tvalid_0's multi_logloss: 1.66404\n",
      "[5]\tvalid_0's multi_logloss: 1.66077\n",
      "[6]\tvalid_0's multi_logloss: 1.65787\n",
      "[7]\tvalid_0's multi_logloss: 1.65524\n",
      "[8]\tvalid_0's multi_logloss: 1.65298\n",
      "[9]\tvalid_0's multi_logloss: 1.65093\n",
      "[10]\tvalid_0's multi_logloss: 1.64914\n",
      "[11]\tvalid_0's multi_logloss: 1.64749\n",
      "[12]\tvalid_0's multi_logloss: 1.64563\n",
      "[13]\tvalid_0's multi_logloss: 1.6442\n",
      "[14]\tvalid_0's multi_logloss: 1.64294\n",
      "[15]\tvalid_0's multi_logloss: 1.64152\n",
      "[16]\tvalid_0's multi_logloss: 1.64047\n",
      "[17]\tvalid_0's multi_logloss: 1.63933\n",
      "[18]\tvalid_0's multi_logloss: 1.63823\n",
      "[19]\tvalid_0's multi_logloss: 1.63716\n",
      "[20]\tvalid_0's multi_logloss: 1.63629\n",
      "[21]\tvalid_0's multi_logloss: 1.63528\n",
      "[22]\tvalid_0's multi_logloss: 1.63425\n",
      "[23]\tvalid_0's multi_logloss: 1.6334\n",
      "[24]\tvalid_0's multi_logloss: 1.63252\n",
      "[25]\tvalid_0's multi_logloss: 1.63175\n",
      "[26]\tvalid_0's multi_logloss: 1.631\n",
      "[27]\tvalid_0's multi_logloss: 1.63028\n",
      "[28]\tvalid_0's multi_logloss: 1.62964\n",
      "[29]\tvalid_0's multi_logloss: 1.62896\n",
      "[30]\tvalid_0's multi_logloss: 1.6284\n",
      "[31]\tvalid_0's multi_logloss: 1.62785\n",
      "[32]\tvalid_0's multi_logloss: 1.62728\n",
      "[33]\tvalid_0's multi_logloss: 1.62675\n",
      "[34]\tvalid_0's multi_logloss: 1.62616\n",
      "[35]\tvalid_0's multi_logloss: 1.62569\n",
      "[36]\tvalid_0's multi_logloss: 1.62516\n",
      "[37]\tvalid_0's multi_logloss: 1.6245\n",
      "[38]\tvalid_0's multi_logloss: 1.62399\n",
      "[39]\tvalid_0's multi_logloss: 1.62364\n",
      "[40]\tvalid_0's multi_logloss: 1.62314\n",
      "[41]\tvalid_0's multi_logloss: 1.62265\n",
      "[42]\tvalid_0's multi_logloss: 1.6223\n",
      "[43]\tvalid_0's multi_logloss: 1.62192\n",
      "[44]\tvalid_0's multi_logloss: 1.62147\n",
      "[45]\tvalid_0's multi_logloss: 1.62102\n",
      "[46]\tvalid_0's multi_logloss: 1.62066\n",
      "[47]\tvalid_0's multi_logloss: 1.6202\n",
      "[48]\tvalid_0's multi_logloss: 1.6198\n",
      "[49]\tvalid_0's multi_logloss: 1.61942\n",
      "[50]\tvalid_0's multi_logloss: 1.61899\n",
      "[51]\tvalid_0's multi_logloss: 1.61867\n",
      "[52]\tvalid_0's multi_logloss: 1.61819\n",
      "[53]\tvalid_0's multi_logloss: 1.61773\n",
      "[54]\tvalid_0's multi_logloss: 1.61747\n",
      "[55]\tvalid_0's multi_logloss: 1.61713\n",
      "[56]\tvalid_0's multi_logloss: 1.61689\n",
      "[57]\tvalid_0's multi_logloss: 1.61646\n",
      "[58]\tvalid_0's multi_logloss: 1.61615\n",
      "[59]\tvalid_0's multi_logloss: 1.61593\n",
      "[60]\tvalid_0's multi_logloss: 1.61564\n",
      "[61]\tvalid_0's multi_logloss: 1.61534\n",
      "[62]\tvalid_0's multi_logloss: 1.61503\n",
      "[63]\tvalid_0's multi_logloss: 1.61481\n",
      "[64]\tvalid_0's multi_logloss: 1.61446\n",
      "[65]\tvalid_0's multi_logloss: 1.61417\n",
      "[66]\tvalid_0's multi_logloss: 1.61391\n",
      "[67]\tvalid_0's multi_logloss: 1.61355\n",
      "[68]\tvalid_0's multi_logloss: 1.61319\n",
      "[69]\tvalid_0's multi_logloss: 1.61298\n",
      "[70]\tvalid_0's multi_logloss: 1.61259\n",
      "[71]\tvalid_0's multi_logloss: 1.61233\n",
      "[72]\tvalid_0's multi_logloss: 1.61199\n",
      "[73]\tvalid_0's multi_logloss: 1.61173\n",
      "[74]\tvalid_0's multi_logloss: 1.61109\n",
      "[75]\tvalid_0's multi_logloss: 1.61078\n",
      "[76]\tvalid_0's multi_logloss: 1.61049\n",
      "[77]\tvalid_0's multi_logloss: 1.61026\n",
      "[78]\tvalid_0's multi_logloss: 1.61007\n",
      "[79]\tvalid_0's multi_logloss: 1.60967\n",
      "[80]\tvalid_0's multi_logloss: 1.60943\n",
      "[81]\tvalid_0's multi_logloss: 1.60926\n",
      "[82]\tvalid_0's multi_logloss: 1.60898\n",
      "[83]\tvalid_0's multi_logloss: 1.60859\n",
      "[84]\tvalid_0's multi_logloss: 1.6083\n",
      "[85]\tvalid_0's multi_logloss: 1.60806\n",
      "[86]\tvalid_0's multi_logloss: 1.60783\n",
      "[87]\tvalid_0's multi_logloss: 1.60763\n",
      "[88]\tvalid_0's multi_logloss: 1.60748\n",
      "[89]\tvalid_0's multi_logloss: 1.60722\n",
      "[90]\tvalid_0's multi_logloss: 1.60681\n",
      "[91]\tvalid_0's multi_logloss: 1.60659\n",
      "[92]\tvalid_0's multi_logloss: 1.60645\n",
      "[93]\tvalid_0's multi_logloss: 1.60612\n",
      "[94]\tvalid_0's multi_logloss: 1.60568\n",
      "[95]\tvalid_0's multi_logloss: 1.6055\n",
      "[96]\tvalid_0's multi_logloss: 1.60531\n",
      "[97]\tvalid_0's multi_logloss: 1.60512\n",
      "[98]\tvalid_0's multi_logloss: 1.60494\n",
      "[99]\tvalid_0's multi_logloss: 1.60472\n",
      "[100]\tvalid_0's multi_logloss: 1.60454\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007798 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 7715638, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -3.388563\n",
      "[LightGBM] [Info] Start training from score -3.286043\n",
      "[LightGBM] [Info] Start training from score -3.265766\n",
      "[LightGBM] [Info] Start training from score -3.814547\n",
      "[LightGBM] [Info] Start training from score -3.310265\n",
      "[LightGBM] [Info] Start training from score -3.206426\n",
      "[LightGBM] [Info] Start training from score -4.264605\n",
      "[LightGBM] [Info] Start training from score -3.385622\n",
      "[LightGBM] [Info] Start training from score -3.678169\n",
      "[LightGBM] [Info] Start training from score -3.401590\n",
      "[LightGBM] [Info] Start training from score -4.879144\n",
      "[LightGBM] [Info] Start training from score -3.027581\n",
      "[LightGBM] [Info] Start training from score -2.985319\n",
      "[LightGBM] [Info] Start training from score -3.251856\n",
      "[LightGBM] [Info] Start training from score -3.294527\n",
      "[LightGBM] [Info] Start training from score -3.372086\n",
      "[LightGBM] [Info] Start training from score -2.973489\n",
      "[LightGBM] [Info] Start training from score -2.489644\n",
      "[LightGBM] [Info] Start training from score -3.403357\n",
      "[LightGBM] [Info] Start training from score -4.161407\n",
      "[LightGBM] [Info] Start training from score -4.219942\n",
      "[LightGBM] [Info] Start training from score -3.454308\n",
      "[LightGBM] [Info] Start training from score -3.414970\n",
      "[LightGBM] [Info] Start training from score -3.160243\n",
      "[LightGBM] [Info] Start training from score -3.113230\n",
      "[LightGBM] [Info] Start training from score -3.209175\n",
      "[LightGBM] [Info] Start training from score -3.282600\n",
      "[LightGBM] [Info] Start training from score -3.180636\n",
      "[1]\tvalid_0's multi_logloss: 2.57687\n",
      "[2]\tvalid_0's multi_logloss: 2.40801\n",
      "[3]\tvalid_0's multi_logloss: 2.2672\n",
      "[4]\tvalid_0's multi_logloss: 2.19695\n",
      "[5]\tvalid_0's multi_logloss: 2.11053\n",
      "[6]\tvalid_0's multi_logloss: 2.04726\n",
      "[7]\tvalid_0's multi_logloss: 1.99715\n",
      "[8]\tvalid_0's multi_logloss: 1.95799\n",
      "[9]\tvalid_0's multi_logloss: 1.92437\n",
      "[10]\tvalid_0's multi_logloss: 1.88878\n",
      "[11]\tvalid_0's multi_logloss: 1.86303\n",
      "[12]\tvalid_0's multi_logloss: 1.836\n",
      "[13]\tvalid_0's multi_logloss: 1.81552\n",
      "[14]\tvalid_0's multi_logloss: 1.79738\n",
      "[15]\tvalid_0's multi_logloss: 1.78059\n",
      "[16]\tvalid_0's multi_logloss: 1.76552\n",
      "[17]\tvalid_0's multi_logloss: 1.75215\n",
      "[18]\tvalid_0's multi_logloss: 1.7401\n",
      "[19]\tvalid_0's multi_logloss: 1.72988\n",
      "[20]\tvalid_0's multi_logloss: 1.71972\n",
      "[21]\tvalid_0's multi_logloss: 1.7106\n",
      "[22]\tvalid_0's multi_logloss: 1.70276\n",
      "[23]\tvalid_0's multi_logloss: 1.69536\n",
      "[24]\tvalid_0's multi_logloss: 1.68847\n",
      "[25]\tvalid_0's multi_logloss: 1.68343\n",
      "[26]\tvalid_0's multi_logloss: 1.67591\n",
      "[27]\tvalid_0's multi_logloss: 1.6705\n",
      "[28]\tvalid_0's multi_logloss: 1.66533\n",
      "[29]\tvalid_0's multi_logloss: 1.66016\n",
      "[30]\tvalid_0's multi_logloss: 1.65505\n",
      "[31]\tvalid_0's multi_logloss: 1.65024\n",
      "[32]\tvalid_0's multi_logloss: 1.64618\n",
      "[33]\tvalid_0's multi_logloss: 1.64224\n",
      "[34]\tvalid_0's multi_logloss: 1.63978\n",
      "[35]\tvalid_0's multi_logloss: 1.63704\n",
      "[36]\tvalid_0's multi_logloss: 1.63573\n",
      "[37]\tvalid_0's multi_logloss: 1.63168\n",
      "[38]\tvalid_0's multi_logloss: 1.62834\n",
      "[39]\tvalid_0's multi_logloss: 1.62516\n",
      "[40]\tvalid_0's multi_logloss: 1.6227\n",
      "[41]\tvalid_0's multi_logloss: 1.61868\n",
      "[42]\tvalid_0's multi_logloss: 1.61515\n",
      "[43]\tvalid_0's multi_logloss: 1.61331\n",
      "[44]\tvalid_0's multi_logloss: 1.6077\n",
      "[45]\tvalid_0's multi_logloss: 1.60647\n",
      "[46]\tvalid_0's multi_logloss: 1.60462\n",
      "[47]\tvalid_0's multi_logloss: 1.61733\n",
      "[48]\tvalid_0's multi_logloss: 1.61487\n",
      "[49]\tvalid_0's multi_logloss: 1.61377\n",
      "[50]\tvalid_0's multi_logloss: 1.61186\n",
      "[51]\tvalid_0's multi_logloss: 1.61228\n",
      "[52]\tvalid_0's multi_logloss: 1.60619\n",
      "[53]\tvalid_0's multi_logloss: 1.60655\n",
      "[54]\tvalid_0's multi_logloss: 1.59837\n",
      "[55]\tvalid_0's multi_logloss: 1.59815\n",
      "[56]\tvalid_0's multi_logloss: 1.58987\n",
      "[57]\tvalid_0's multi_logloss: 1.58744\n",
      "[58]\tvalid_0's multi_logloss: 1.59076\n",
      "[59]\tvalid_0's multi_logloss: 1.58752\n",
      "[60]\tvalid_0's multi_logloss: 1.58089\n",
      "[61]\tvalid_0's multi_logloss: 1.58848\n",
      "[62]\tvalid_0's multi_logloss: 1.58363\n",
      "[63]\tvalid_0's multi_logloss: 1.57898\n",
      "[64]\tvalid_0's multi_logloss: 1.57855\n",
      "[65]\tvalid_0's multi_logloss: 1.57106\n",
      "[66]\tvalid_0's multi_logloss: 1.57409\n",
      "[67]\tvalid_0's multi_logloss: 1.57109\n",
      "[68]\tvalid_0's multi_logloss: 1.56978\n",
      "[69]\tvalid_0's multi_logloss: 1.56675\n",
      "[70]\tvalid_0's multi_logloss: 1.57828\n",
      "[71]\tvalid_0's multi_logloss: 1.56455\n",
      "[72]\tvalid_0's multi_logloss: 1.56553\n",
      "[73]\tvalid_0's multi_logloss: 1.5632\n",
      "[74]\tvalid_0's multi_logloss: 1.56319\n",
      "[75]\tvalid_0's multi_logloss: 1.56102\n",
      "[76]\tvalid_0's multi_logloss: 1.56139\n",
      "[77]\tvalid_0's multi_logloss: 1.55749\n",
      "[78]\tvalid_0's multi_logloss: 1.55678\n",
      "[79]\tvalid_0's multi_logloss: 1.55288\n",
      "[80]\tvalid_0's multi_logloss: 1.55397\n",
      "[81]\tvalid_0's multi_logloss: 1.56624\n",
      "[82]\tvalid_0's multi_logloss: 1.55872\n",
      "[83]\tvalid_0's multi_logloss: 1.55863\n",
      "[84]\tvalid_0's multi_logloss: 1.5565\n",
      "[85]\tvalid_0's multi_logloss: 1.55719\n",
      "[86]\tvalid_0's multi_logloss: 1.56269\n",
      "[87]\tvalid_0's multi_logloss: 1.55579\n",
      "[88]\tvalid_0's multi_logloss: 1.55972\n",
      "[89]\tvalid_0's multi_logloss: 1.55535\n",
      "[90]\tvalid_0's multi_logloss: 1.55328\n",
      "[91]\tvalid_0's multi_logloss: 1.56076\n",
      "[92]\tvalid_0's multi_logloss: 1.56973\n",
      "[93]\tvalid_0's multi_logloss: 1.56592\n",
      "[94]\tvalid_0's multi_logloss: 1.56193\n",
      "[95]\tvalid_0's multi_logloss: 1.56171\n",
      "[96]\tvalid_0's multi_logloss: 1.56876\n",
      "[97]\tvalid_0's multi_logloss: 1.57024\n",
      "[98]\tvalid_0's multi_logloss: 1.5663\n",
      "[99]\tvalid_0's multi_logloss: 1.56525\n",
      "[100]\tvalid_0's multi_logloss: 1.57161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [34:50, 120.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001215 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 820733, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -0.683185\n",
      "[LightGBM] [Info] Start training from score -2.382997\n",
      "[LightGBM] [Info] Start training from score -2.734975\n",
      "[LightGBM] [Info] Start training from score -3.826068\n",
      "[LightGBM] [Info] Start training from score -1.583719\n",
      "[LightGBM] [Info] Start training from score -2.199855\n",
      "[1]\tvalid_0's multi_logloss: 1.1616\n",
      "[2]\tvalid_0's multi_logloss: 1.0478\n",
      "[3]\tvalid_0's multi_logloss: 0.962338\n",
      "[4]\tvalid_0's multi_logloss: 0.894582\n",
      "[5]\tvalid_0's multi_logloss: 0.839789\n",
      "[6]\tvalid_0's multi_logloss: 0.795332\n",
      "[7]\tvalid_0's multi_logloss: 0.757771\n",
      "[8]\tvalid_0's multi_logloss: 0.726606\n",
      "[9]\tvalid_0's multi_logloss: 0.700046\n",
      "[10]\tvalid_0's multi_logloss: 0.678013\n",
      "[11]\tvalid_0's multi_logloss: 0.658725\n",
      "[12]\tvalid_0's multi_logloss: 0.642192\n",
      "[13]\tvalid_0's multi_logloss: 0.627835\n",
      "[14]\tvalid_0's multi_logloss: 0.615507\n",
      "[15]\tvalid_0's multi_logloss: 0.604313\n",
      "[16]\tvalid_0's multi_logloss: 0.59459\n",
      "[17]\tvalid_0's multi_logloss: 0.586153\n",
      "[18]\tvalid_0's multi_logloss: 0.578382\n",
      "[19]\tvalid_0's multi_logloss: 0.571708\n",
      "[20]\tvalid_0's multi_logloss: 0.565551\n",
      "[21]\tvalid_0's multi_logloss: 0.560137\n",
      "[22]\tvalid_0's multi_logloss: 0.555305\n",
      "[23]\tvalid_0's multi_logloss: 0.550779\n",
      "[24]\tvalid_0's multi_logloss: 0.546715\n",
      "[25]\tvalid_0's multi_logloss: 0.542884\n",
      "[26]\tvalid_0's multi_logloss: 0.5396\n",
      "[27]\tvalid_0's multi_logloss: 0.536488\n",
      "[28]\tvalid_0's multi_logloss: 0.533654\n",
      "[29]\tvalid_0's multi_logloss: 0.531169\n",
      "[30]\tvalid_0's multi_logloss: 0.528716\n",
      "[31]\tvalid_0's multi_logloss: 0.526621\n",
      "[32]\tvalid_0's multi_logloss: 0.52444\n",
      "[33]\tvalid_0's multi_logloss: 0.522485\n",
      "[34]\tvalid_0's multi_logloss: 0.520592\n",
      "[35]\tvalid_0's multi_logloss: 0.518789\n",
      "[36]\tvalid_0's multi_logloss: 0.5171\n",
      "[37]\tvalid_0's multi_logloss: 0.515442\n",
      "[38]\tvalid_0's multi_logloss: 0.514071\n",
      "[39]\tvalid_0's multi_logloss: 0.512573\n",
      "[40]\tvalid_0's multi_logloss: 0.511381\n",
      "[41]\tvalid_0's multi_logloss: 0.510205\n",
      "[42]\tvalid_0's multi_logloss: 0.511159\n",
      "[43]\tvalid_0's multi_logloss: 0.507891\n",
      "[44]\tvalid_0's multi_logloss: 0.506737\n",
      "[45]\tvalid_0's multi_logloss: 0.505709\n",
      "[46]\tvalid_0's multi_logloss: 0.506501\n",
      "[47]\tvalid_0's multi_logloss: 0.504011\n",
      "[48]\tvalid_0's multi_logloss: 0.503505\n",
      "[49]\tvalid_0's multi_logloss: 0.5022\n",
      "[50]\tvalid_0's multi_logloss: 0.502685\n",
      "[51]\tvalid_0's multi_logloss: 0.500767\n",
      "[52]\tvalid_0's multi_logloss: 0.499989\n",
      "[53]\tvalid_0's multi_logloss: 0.499537\n",
      "[54]\tvalid_0's multi_logloss: 0.498765\n",
      "[55]\tvalid_0's multi_logloss: 0.498086\n",
      "[56]\tvalid_0's multi_logloss: 0.497304\n",
      "[57]\tvalid_0's multi_logloss: 0.496805\n",
      "[58]\tvalid_0's multi_logloss: 0.496281\n",
      "[59]\tvalid_0's multi_logloss: 0.495816\n",
      "[60]\tvalid_0's multi_logloss: 0.495629\n",
      "[61]\tvalid_0's multi_logloss: 0.495023\n",
      "[62]\tvalid_0's multi_logloss: 0.494925\n",
      "[63]\tvalid_0's multi_logloss: 0.494166\n",
      "[64]\tvalid_0's multi_logloss: 0.493583\n",
      "[65]\tvalid_0's multi_logloss: 0.493043\n",
      "[66]\tvalid_0's multi_logloss: 0.492921\n",
      "[67]\tvalid_0's multi_logloss: 0.494447\n",
      "[68]\tvalid_0's multi_logloss: 0.49216\n",
      "[69]\tvalid_0's multi_logloss: 0.493649\n",
      "[70]\tvalid_0's multi_logloss: 0.493349\n",
      "[71]\tvalid_0's multi_logloss: 0.491392\n",
      "[72]\tvalid_0's multi_logloss: 0.49092\n",
      "[73]\tvalid_0's multi_logloss: 0.491733\n",
      "[74]\tvalid_0's multi_logloss: 0.491507\n",
      "[75]\tvalid_0's multi_logloss: 0.490401\n",
      "[76]\tvalid_0's multi_logloss: 0.49059\n",
      "[77]\tvalid_0's multi_logloss: 0.490569\n",
      "[78]\tvalid_0's multi_logloss: 0.489863\n",
      "[79]\tvalid_0's multi_logloss: 0.49018\n",
      "[80]\tvalid_0's multi_logloss: 0.489138\n",
      "[81]\tvalid_0's multi_logloss: 0.488844\n",
      "[82]\tvalid_0's multi_logloss: 0.491394\n",
      "[83]\tvalid_0's multi_logloss: 0.488227\n",
      "[84]\tvalid_0's multi_logloss: 0.488337\n",
      "[85]\tvalid_0's multi_logloss: 0.494257\n",
      "[86]\tvalid_0's multi_logloss: 0.489843\n",
      "[87]\tvalid_0's multi_logloss: 0.489819\n",
      "[88]\tvalid_0's multi_logloss: 0.491938\n",
      "[89]\tvalid_0's multi_logloss: 0.48962\n",
      "[90]\tvalid_0's multi_logloss: 0.489633\n",
      "[91]\tvalid_0's multi_logloss: 0.493413\n",
      "[92]\tvalid_0's multi_logloss: 0.488472\n",
      "[93]\tvalid_0's multi_logloss: 0.490042\n",
      "[94]\tvalid_0's multi_logloss: 0.490962\n",
      "[95]\tvalid_0's multi_logloss: 0.492187\n",
      "[96]\tvalid_0's multi_logloss: 0.494166\n",
      "[97]\tvalid_0's multi_logloss: 0.486745\n",
      "[98]\tvalid_0's multi_logloss: 0.510208\n",
      "[99]\tvalid_0's multi_logloss: 0.495084\n",
      "[100]\tvalid_0's multi_logloss: 0.499201\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001286 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 820733, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -2.163833\n",
      "[LightGBM] [Info] Start training from score -1.796397\n",
      "[LightGBM] [Info] Start training from score -1.843741\n",
      "[LightGBM] [Info] Start training from score -1.989576\n",
      "[LightGBM] [Info] Start training from score -1.941218\n",
      "[LightGBM] [Info] Start training from score -1.949016\n",
      "[LightGBM] [Info] Start training from score -1.978333\n",
      "[1]\tvalid_0's multi_logloss: 1.90085\n",
      "[2]\tvalid_0's multi_logloss: 1.87056\n",
      "[3]\tvalid_0's multi_logloss: 1.84647\n",
      "[4]\tvalid_0's multi_logloss: 1.82703\n",
      "[5]\tvalid_0's multi_logloss: 1.81099\n",
      "[6]\tvalid_0's multi_logloss: 1.79776\n",
      "[7]\tvalid_0's multi_logloss: 1.78664\n",
      "[8]\tvalid_0's multi_logloss: 1.77725\n",
      "[9]\tvalid_0's multi_logloss: 1.76935\n",
      "[10]\tvalid_0's multi_logloss: 1.76272\n",
      "[11]\tvalid_0's multi_logloss: 1.75699\n",
      "[12]\tvalid_0's multi_logloss: 1.75212\n",
      "[13]\tvalid_0's multi_logloss: 1.74794\n",
      "[14]\tvalid_0's multi_logloss: 1.74429\n",
      "[15]\tvalid_0's multi_logloss: 1.74122\n",
      "[16]\tvalid_0's multi_logloss: 1.73846\n",
      "[17]\tvalid_0's multi_logloss: 1.73615\n",
      "[18]\tvalid_0's multi_logloss: 1.73403\n",
      "[19]\tvalid_0's multi_logloss: 1.73215\n",
      "[20]\tvalid_0's multi_logloss: 1.73056\n",
      "[21]\tvalid_0's multi_logloss: 1.72913\n",
      "[22]\tvalid_0's multi_logloss: 1.72785\n",
      "[23]\tvalid_0's multi_logloss: 1.72665\n",
      "[24]\tvalid_0's multi_logloss: 1.7256\n",
      "[25]\tvalid_0's multi_logloss: 1.72468\n",
      "[26]\tvalid_0's multi_logloss: 1.7238\n",
      "[27]\tvalid_0's multi_logloss: 1.72294\n",
      "[28]\tvalid_0's multi_logloss: 1.72218\n",
      "[29]\tvalid_0's multi_logloss: 1.72148\n",
      "[30]\tvalid_0's multi_logloss: 1.72085\n",
      "[31]\tvalid_0's multi_logloss: 1.72024\n",
      "[32]\tvalid_0's multi_logloss: 1.7197\n",
      "[33]\tvalid_0's multi_logloss: 1.71922\n",
      "[34]\tvalid_0's multi_logloss: 1.71869\n",
      "[35]\tvalid_0's multi_logloss: 1.71814\n",
      "[36]\tvalid_0's multi_logloss: 1.71762\n",
      "[37]\tvalid_0's multi_logloss: 1.71717\n",
      "[38]\tvalid_0's multi_logloss: 1.71661\n",
      "[39]\tvalid_0's multi_logloss: 1.71622\n",
      "[40]\tvalid_0's multi_logloss: 1.7159\n",
      "[41]\tvalid_0's multi_logloss: 1.71553\n",
      "[42]\tvalid_0's multi_logloss: 1.7152\n",
      "[43]\tvalid_0's multi_logloss: 1.71487\n",
      "[44]\tvalid_0's multi_logloss: 1.7146\n",
      "[45]\tvalid_0's multi_logloss: 1.71426\n",
      "[46]\tvalid_0's multi_logloss: 1.714\n",
      "[47]\tvalid_0's multi_logloss: 1.71365\n",
      "[48]\tvalid_0's multi_logloss: 1.71336\n",
      "[49]\tvalid_0's multi_logloss: 1.71306\n",
      "[50]\tvalid_0's multi_logloss: 1.71292\n",
      "[51]\tvalid_0's multi_logloss: 1.71267\n",
      "[52]\tvalid_0's multi_logloss: 1.7125\n",
      "[53]\tvalid_0's multi_logloss: 1.71224\n",
      "[54]\tvalid_0's multi_logloss: 1.71204\n",
      "[55]\tvalid_0's multi_logloss: 1.71189\n",
      "[56]\tvalid_0's multi_logloss: 1.71173\n",
      "[57]\tvalid_0's multi_logloss: 1.71146\n",
      "[58]\tvalid_0's multi_logloss: 1.71126\n",
      "[59]\tvalid_0's multi_logloss: 1.71111\n",
      "[60]\tvalid_0's multi_logloss: 1.71094\n",
      "[61]\tvalid_0's multi_logloss: 1.71083\n",
      "[62]\tvalid_0's multi_logloss: 1.71063\n",
      "[63]\tvalid_0's multi_logloss: 1.71045\n",
      "[64]\tvalid_0's multi_logloss: 1.71023\n",
      "[65]\tvalid_0's multi_logloss: 1.71007\n",
      "[66]\tvalid_0's multi_logloss: 1.70986\n",
      "[67]\tvalid_0's multi_logloss: 1.70975\n",
      "[68]\tvalid_0's multi_logloss: 1.7096\n",
      "[69]\tvalid_0's multi_logloss: 1.70937\n",
      "[70]\tvalid_0's multi_logloss: 1.70922\n",
      "[71]\tvalid_0's multi_logloss: 1.70913\n",
      "[72]\tvalid_0's multi_logloss: 1.70899\n",
      "[73]\tvalid_0's multi_logloss: 1.70879\n",
      "[74]\tvalid_0's multi_logloss: 1.70858\n",
      "[75]\tvalid_0's multi_logloss: 1.70847\n",
      "[76]\tvalid_0's multi_logloss: 1.70835\n",
      "[77]\tvalid_0's multi_logloss: 1.70822\n",
      "[78]\tvalid_0's multi_logloss: 1.70804\n",
      "[79]\tvalid_0's multi_logloss: 1.70786\n",
      "[80]\tvalid_0's multi_logloss: 1.70776\n",
      "[81]\tvalid_0's multi_logloss: 1.70766\n",
      "[82]\tvalid_0's multi_logloss: 1.70751\n",
      "[83]\tvalid_0's multi_logloss: 1.70745\n",
      "[84]\tvalid_0's multi_logloss: 1.70724\n",
      "[85]\tvalid_0's multi_logloss: 1.70711\n",
      "[86]\tvalid_0's multi_logloss: 1.70695\n",
      "[87]\tvalid_0's multi_logloss: 1.70682\n",
      "[88]\tvalid_0's multi_logloss: 1.70669\n",
      "[89]\tvalid_0's multi_logloss: 1.70657\n",
      "[90]\tvalid_0's multi_logloss: 1.7064\n",
      "[91]\tvalid_0's multi_logloss: 1.70632\n",
      "[92]\tvalid_0's multi_logloss: 1.70627\n",
      "[93]\tvalid_0's multi_logloss: 1.70623\n",
      "[94]\tvalid_0's multi_logloss: 1.70614\n",
      "[95]\tvalid_0's multi_logloss: 1.70604\n",
      "[96]\tvalid_0's multi_logloss: 1.70598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [34:58, 86.72s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[97]\tvalid_0's multi_logloss: 1.7059\n",
      "[98]\tvalid_0's multi_logloss: 1.70585\n",
      "[99]\tvalid_0's multi_logloss: 1.70575\n",
      "[100]\tvalid_0's multi_logloss: 1.70566\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028091 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score -1.853404\n",
      "[LightGBM] [Info] Start training from score -2.123202\n",
      "[LightGBM] [Info] Start training from score -2.391862\n",
      "[LightGBM] [Info] Start training from score -2.719639\n",
      "[LightGBM] [Info] Start training from score -2.078311\n",
      "[LightGBM] [Info] Start training from score -2.161447\n",
      "[LightGBM] [Info] Start training from score -2.497610\n",
      "[LightGBM] [Info] Start training from score -2.232530\n",
      "[LightGBM] [Info] Start training from score -2.689447\n",
      "[LightGBM] [Info] Start training from score -2.680407\n",
      "[1]\tvalid_0's multi_logloss: 1.93344\n",
      "[2]\tvalid_0's multi_logloss: 1.76286\n",
      "[3]\tvalid_0's multi_logloss: 1.64205\n",
      "[4]\tvalid_0's multi_logloss: 1.54625\n",
      "[5]\tvalid_0's multi_logloss: 1.47072\n",
      "[6]\tvalid_0's multi_logloss: 1.40669\n",
      "[7]\tvalid_0's multi_logloss: 1.35367\n",
      "[8]\tvalid_0's multi_logloss: 1.30958\n",
      "[9]\tvalid_0's multi_logloss: 1.27172\n",
      "[10]\tvalid_0's multi_logloss: 1.23855\n",
      "[11]\tvalid_0's multi_logloss: 1.20965\n",
      "[12]\tvalid_0's multi_logloss: 1.18436\n",
      "[13]\tvalid_0's multi_logloss: 1.16259\n",
      "[14]\tvalid_0's multi_logloss: 1.14346\n",
      "[15]\tvalid_0's multi_logloss: 1.12608\n",
      "[16]\tvalid_0's multi_logloss: 1.11089\n",
      "[17]\tvalid_0's multi_logloss: 1.09784\n",
      "[18]\tvalid_0's multi_logloss: 1.08489\n",
      "[19]\tvalid_0's multi_logloss: 1.07412\n",
      "[20]\tvalid_0's multi_logloss: 1.06422\n",
      "[21]\tvalid_0's multi_logloss: 1.05477\n",
      "[22]\tvalid_0's multi_logloss: 1.04658\n",
      "[23]\tvalid_0's multi_logloss: 1.03928\n",
      "[24]\tvalid_0's multi_logloss: 1.03228\n",
      "[25]\tvalid_0's multi_logloss: 1.02634\n",
      "[26]\tvalid_0's multi_logloss: 1.02035\n",
      "[27]\tvalid_0's multi_logloss: 1.01443\n",
      "[28]\tvalid_0's multi_logloss: 1.00911\n",
      "[29]\tvalid_0's multi_logloss: 1.0044\n",
      "[30]\tvalid_0's multi_logloss: 0.999999\n",
      "[31]\tvalid_0's multi_logloss: 0.995894\n",
      "[32]\tvalid_0's multi_logloss: 0.991532\n",
      "[33]\tvalid_0's multi_logloss: 0.987693\n",
      "[34]\tvalid_0's multi_logloss: 0.984121\n",
      "[35]\tvalid_0's multi_logloss: 0.980656\n",
      "[36]\tvalid_0's multi_logloss: 0.977329\n",
      "[37]\tvalid_0's multi_logloss: 0.974161\n",
      "[38]\tvalid_0's multi_logloss: 0.971466\n",
      "[39]\tvalid_0's multi_logloss: 0.969224\n",
      "[40]\tvalid_0's multi_logloss: 0.966449\n",
      "[41]\tvalid_0's multi_logloss: 0.963859\n",
      "[42]\tvalid_0's multi_logloss: 0.961336\n",
      "[43]\tvalid_0's multi_logloss: 0.958596\n",
      "[44]\tvalid_0's multi_logloss: 0.956089\n",
      "[45]\tvalid_0's multi_logloss: 0.953792\n",
      "[46]\tvalid_0's multi_logloss: 0.951531\n",
      "[47]\tvalid_0's multi_logloss: 0.949455\n",
      "[48]\tvalid_0's multi_logloss: 0.947559\n",
      "[49]\tvalid_0's multi_logloss: 0.94576\n",
      "[50]\tvalid_0's multi_logloss: 0.943797\n",
      "[51]\tvalid_0's multi_logloss: 0.942171\n",
      "[52]\tvalid_0's multi_logloss: 0.940597\n",
      "[53]\tvalid_0's multi_logloss: 0.938964\n",
      "[54]\tvalid_0's multi_logloss: 0.937423\n",
      "[55]\tvalid_0's multi_logloss: 0.935818\n",
      "[56]\tvalid_0's multi_logloss: 0.934168\n",
      "[57]\tvalid_0's multi_logloss: 0.932689\n",
      "[58]\tvalid_0's multi_logloss: 0.931151\n",
      "[59]\tvalid_0's multi_logloss: 0.92972\n",
      "[60]\tvalid_0's multi_logloss: 0.928436\n",
      "[61]\tvalid_0's multi_logloss: 0.926992\n",
      "[62]\tvalid_0's multi_logloss: 0.925856\n",
      "[63]\tvalid_0's multi_logloss: 0.924472\n",
      "[64]\tvalid_0's multi_logloss: 0.923534\n",
      "[65]\tvalid_0's multi_logloss: 0.922406\n",
      "[66]\tvalid_0's multi_logloss: 0.921279\n",
      "[67]\tvalid_0's multi_logloss: 0.920145\n",
      "[68]\tvalid_0's multi_logloss: 0.918868\n",
      "[69]\tvalid_0's multi_logloss: 0.917674\n",
      "[70]\tvalid_0's multi_logloss: 0.916646\n",
      "[71]\tvalid_0's multi_logloss: 0.915514\n",
      "[72]\tvalid_0's multi_logloss: 0.914436\n",
      "[73]\tvalid_0's multi_logloss: 0.913273\n",
      "[74]\tvalid_0's multi_logloss: 0.912123\n",
      "[75]\tvalid_0's multi_logloss: 0.911251\n",
      "[76]\tvalid_0's multi_logloss: 0.910419\n",
      "[77]\tvalid_0's multi_logloss: 0.909711\n",
      "[78]\tvalid_0's multi_logloss: 0.908946\n",
      "[79]\tvalid_0's multi_logloss: 0.908094\n",
      "[80]\tvalid_0's multi_logloss: 0.907527\n",
      "[81]\tvalid_0's multi_logloss: 0.906593\n",
      "[82]\tvalid_0's multi_logloss: 0.905794\n",
      "[83]\tvalid_0's multi_logloss: 0.904951\n",
      "[84]\tvalid_0's multi_logloss: 0.90415\n",
      "[85]\tvalid_0's multi_logloss: 0.903537\n",
      "[86]\tvalid_0's multi_logloss: 0.902839\n",
      "[87]\tvalid_0's multi_logloss: 0.902045\n",
      "[88]\tvalid_0's multi_logloss: 0.901213\n",
      "[89]\tvalid_0's multi_logloss: 0.900393\n",
      "[90]\tvalid_0's multi_logloss: 0.899612\n",
      "[91]\tvalid_0's multi_logloss: 0.898973\n",
      "[92]\tvalid_0's multi_logloss: 0.898364\n",
      "[93]\tvalid_0's multi_logloss: 0.897593\n",
      "[94]\tvalid_0's multi_logloss: 0.896981\n",
      "[95]\tvalid_0's multi_logloss: 0.896342\n",
      "[96]\tvalid_0's multi_logloss: 0.895287\n",
      "[97]\tvalid_0's multi_logloss: 0.894394\n",
      "[98]\tvalid_0's multi_logloss: 0.893798\n",
      "[99]\tvalid_0's multi_logloss: 0.893227\n",
      "[100]\tvalid_0's multi_logloss: 0.892622\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026832 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score -1.047228\n",
      "[LightGBM] [Info] Start training from score -1.516216\n",
      "[LightGBM] [Info] Start training from score -0.845018\n",
      "[1]\tvalid_0's multi_logloss: 1.01256\n",
      "[2]\tvalid_0's multi_logloss: 0.97087\n",
      "[3]\tvalid_0's multi_logloss: 0.93604\n",
      "[4]\tvalid_0's multi_logloss: 0.906618\n",
      "[5]\tvalid_0's multi_logloss: 0.881367\n",
      "[6]\tvalid_0's multi_logloss: 0.859647\n",
      "[7]\tvalid_0's multi_logloss: 0.840782\n",
      "[8]\tvalid_0's multi_logloss: 0.824339\n",
      "[9]\tvalid_0's multi_logloss: 0.809859\n",
      "[10]\tvalid_0's multi_logloss: 0.797176\n",
      "[11]\tvalid_0's multi_logloss: 0.785704\n",
      "[12]\tvalid_0's multi_logloss: 0.775669\n",
      "[13]\tvalid_0's multi_logloss: 0.766752\n",
      "[14]\tvalid_0's multi_logloss: 0.758735\n",
      "[15]\tvalid_0's multi_logloss: 0.751502\n",
      "[16]\tvalid_0's multi_logloss: 0.744825\n",
      "[17]\tvalid_0's multi_logloss: 0.738805\n",
      "[18]\tvalid_0's multi_logloss: 0.733241\n",
      "[19]\tvalid_0's multi_logloss: 0.7283\n",
      "[20]\tvalid_0's multi_logloss: 0.723789\n",
      "[21]\tvalid_0's multi_logloss: 0.719551\n",
      "[22]\tvalid_0's multi_logloss: 0.71555\n",
      "[23]\tvalid_0's multi_logloss: 0.711984\n",
      "[24]\tvalid_0's multi_logloss: 0.70868\n",
      "[25]\tvalid_0's multi_logloss: 0.705521\n",
      "[26]\tvalid_0's multi_logloss: 0.702724\n",
      "[27]\tvalid_0's multi_logloss: 0.69992\n",
      "[28]\tvalid_0's multi_logloss: 0.697465\n",
      "[29]\tvalid_0's multi_logloss: 0.695185\n",
      "[30]\tvalid_0's multi_logloss: 0.693036\n",
      "[31]\tvalid_0's multi_logloss: 0.690939\n",
      "[32]\tvalid_0's multi_logloss: 0.689008\n",
      "[33]\tvalid_0's multi_logloss: 0.687247\n",
      "[34]\tvalid_0's multi_logloss: 0.685589\n",
      "[35]\tvalid_0's multi_logloss: 0.683991\n",
      "[36]\tvalid_0's multi_logloss: 0.682488\n",
      "[37]\tvalid_0's multi_logloss: 0.681135\n",
      "[38]\tvalid_0's multi_logloss: 0.679857\n",
      "[39]\tvalid_0's multi_logloss: 0.678641\n",
      "[40]\tvalid_0's multi_logloss: 0.677493\n",
      "[41]\tvalid_0's multi_logloss: 0.676431\n",
      "[42]\tvalid_0's multi_logloss: 0.675387\n",
      "[43]\tvalid_0's multi_logloss: 0.67447\n",
      "[44]\tvalid_0's multi_logloss: 0.673549\n",
      "[45]\tvalid_0's multi_logloss: 0.672736\n",
      "[46]\tvalid_0's multi_logloss: 0.671944\n",
      "[47]\tvalid_0's multi_logloss: 0.671091\n",
      "[48]\tvalid_0's multi_logloss: 0.670346\n",
      "[49]\tvalid_0's multi_logloss: 0.669679\n",
      "[50]\tvalid_0's multi_logloss: 0.669024\n",
      "[51]\tvalid_0's multi_logloss: 0.668393\n",
      "[52]\tvalid_0's multi_logloss: 0.667777\n",
      "[53]\tvalid_0's multi_logloss: 0.667227\n",
      "[54]\tvalid_0's multi_logloss: 0.66672\n",
      "[55]\tvalid_0's multi_logloss: 0.666253\n",
      "[56]\tvalid_0's multi_logloss: 0.66572\n",
      "[57]\tvalid_0's multi_logloss: 0.665228\n",
      "[58]\tvalid_0's multi_logloss: 0.664809\n",
      "[59]\tvalid_0's multi_logloss: 0.664344\n",
      "[60]\tvalid_0's multi_logloss: 0.663922\n",
      "[61]\tvalid_0's multi_logloss: 0.663543\n",
      "[62]\tvalid_0's multi_logloss: 0.663211\n",
      "[63]\tvalid_0's multi_logloss: 0.662914\n",
      "[64]\tvalid_0's multi_logloss: 0.662556\n",
      "[65]\tvalid_0's multi_logloss: 0.662236\n",
      "[66]\tvalid_0's multi_logloss: 0.661992\n",
      "[67]\tvalid_0's multi_logloss: 0.661712\n",
      "[68]\tvalid_0's multi_logloss: 0.661419\n",
      "[69]\tvalid_0's multi_logloss: 0.661126\n",
      "[70]\tvalid_0's multi_logloss: 0.660825\n",
      "[71]\tvalid_0's multi_logloss: 0.660585\n",
      "[72]\tvalid_0's multi_logloss: 0.660348\n",
      "[73]\tvalid_0's multi_logloss: 0.660167\n",
      "[74]\tvalid_0's multi_logloss: 0.659936\n",
      "[75]\tvalid_0's multi_logloss: 0.659662\n",
      "[76]\tvalid_0's multi_logloss: 0.65945\n",
      "[77]\tvalid_0's multi_logloss: 0.659203\n",
      "[78]\tvalid_0's multi_logloss: 0.658996\n",
      "[79]\tvalid_0's multi_logloss: 0.658821\n",
      "[80]\tvalid_0's multi_logloss: 0.65859\n",
      "[81]\tvalid_0's multi_logloss: 0.658379\n",
      "[82]\tvalid_0's multi_logloss: 0.658153\n",
      "[83]\tvalid_0's multi_logloss: 0.658014\n",
      "[84]\tvalid_0's multi_logloss: 0.657811\n",
      "[85]\tvalid_0's multi_logloss: 0.657603\n",
      "[86]\tvalid_0's multi_logloss: 0.657414\n",
      "[87]\tvalid_0's multi_logloss: 0.657235\n",
      "[88]\tvalid_0's multi_logloss: 0.657064\n",
      "[89]\tvalid_0's multi_logloss: 0.656922\n",
      "[90]\tvalid_0's multi_logloss: 0.656758\n",
      "[91]\tvalid_0's multi_logloss: 0.656605\n",
      "[92]\tvalid_0's multi_logloss: 0.656391\n",
      "[93]\tvalid_0's multi_logloss: 0.656293\n",
      "[94]\tvalid_0's multi_logloss: 0.656147\n",
      "[95]\tvalid_0's multi_logloss: 0.656041\n",
      "[96]\tvalid_0's multi_logloss: 0.655933\n",
      "[97]\tvalid_0's multi_logloss: 0.655735\n",
      "[98]\tvalid_0's multi_logloss: 0.655625\n",
      "[99]\tvalid_0's multi_logloss: 0.655501\n",
      "[100]\tvalid_0's multi_logloss: 0.655433\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026778 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score -3.244539\n",
      "[LightGBM] [Info] Start training from score -3.224920\n",
      "[LightGBM] [Info] Start training from score -3.369880\n",
      "[LightGBM] [Info] Start training from score -3.326941\n",
      "[LightGBM] [Info] Start training from score -3.378266\n",
      "[LightGBM] [Info] Start training from score -2.568017\n",
      "[LightGBM] [Info] Start training from score -1.914747\n",
      "[LightGBM] [Info] Start training from score -3.469579\n",
      "[LightGBM] [Info] Start training from score -1.919436\n",
      "[LightGBM] [Info] Start training from score -2.291576\n",
      "[LightGBM] [Info] Start training from score -2.007538\n",
      "[LightGBM] [Info] Start training from score -3.402200\n",
      "[LightGBM] [Info] Start training from score -3.212376\n",
      "[LightGBM] [Info] Start training from score -2.244521\n",
      "[1]\tvalid_0's multi_logloss: 2.40077\n",
      "[2]\tvalid_0's multi_logloss: 2.36263\n",
      "[3]\tvalid_0's multi_logloss: 2.33328\n",
      "[4]\tvalid_0's multi_logloss: 2.30911\n",
      "[5]\tvalid_0's multi_logloss: 2.2892\n",
      "[6]\tvalid_0's multi_logloss: 2.27195\n",
      "[7]\tvalid_0's multi_logloss: 2.25715\n",
      "[8]\tvalid_0's multi_logloss: 2.24421\n",
      "[9]\tvalid_0's multi_logloss: 2.23273\n",
      "[10]\tvalid_0's multi_logloss: 2.22264\n",
      "[11]\tvalid_0's multi_logloss: 2.21354\n",
      "[12]\tvalid_0's multi_logloss: 2.20581\n",
      "[13]\tvalid_0's multi_logloss: 2.1987\n",
      "[14]\tvalid_0's multi_logloss: 2.19199\n",
      "[15]\tvalid_0's multi_logloss: 2.18616\n",
      "[16]\tvalid_0's multi_logloss: 2.18075\n",
      "[17]\tvalid_0's multi_logloss: 2.1759\n",
      "[18]\tvalid_0's multi_logloss: 2.17119\n",
      "[19]\tvalid_0's multi_logloss: 2.16709\n",
      "[20]\tvalid_0's multi_logloss: 2.16264\n",
      "[21]\tvalid_0's multi_logloss: 2.15907\n",
      "[22]\tvalid_0's multi_logloss: 2.15547\n",
      "[23]\tvalid_0's multi_logloss: 2.15242\n",
      "[24]\tvalid_0's multi_logloss: 2.14961\n",
      "[25]\tvalid_0's multi_logloss: 2.14644\n",
      "[26]\tvalid_0's multi_logloss: 2.1436\n",
      "[27]\tvalid_0's multi_logloss: 2.14111\n",
      "[28]\tvalid_0's multi_logloss: 2.13875\n",
      "[29]\tvalid_0's multi_logloss: 2.13648\n",
      "[30]\tvalid_0's multi_logloss: 2.1347\n",
      "[31]\tvalid_0's multi_logloss: 2.13266\n",
      "[32]\tvalid_0's multi_logloss: 2.13073\n",
      "[33]\tvalid_0's multi_logloss: 2.129\n",
      "[34]\tvalid_0's multi_logloss: 2.12734\n",
      "[35]\tvalid_0's multi_logloss: 2.12574\n",
      "[36]\tvalid_0's multi_logloss: 2.12407\n",
      "[37]\tvalid_0's multi_logloss: 2.12281\n",
      "[38]\tvalid_0's multi_logloss: 2.12138\n",
      "[39]\tvalid_0's multi_logloss: 2.11989\n",
      "[40]\tvalid_0's multi_logloss: 2.11855\n",
      "[41]\tvalid_0's multi_logloss: 2.11745\n",
      "[42]\tvalid_0's multi_logloss: 2.11618\n",
      "[43]\tvalid_0's multi_logloss: 2.11513\n",
      "[44]\tvalid_0's multi_logloss: 2.11407\n",
      "[45]\tvalid_0's multi_logloss: 2.11299\n",
      "[46]\tvalid_0's multi_logloss: 2.11204\n",
      "[47]\tvalid_0's multi_logloss: 2.11109\n",
      "[48]\tvalid_0's multi_logloss: 2.11032\n",
      "[49]\tvalid_0's multi_logloss: 2.10942\n",
      "[50]\tvalid_0's multi_logloss: 2.10862\n",
      "[51]\tvalid_0's multi_logloss: 2.1078\n",
      "[52]\tvalid_0's multi_logloss: 2.10708\n",
      "[53]\tvalid_0's multi_logloss: 2.10625\n",
      "[54]\tvalid_0's multi_logloss: 2.10534\n",
      "[55]\tvalid_0's multi_logloss: 2.10438\n",
      "[56]\tvalid_0's multi_logloss: 2.10356\n",
      "[57]\tvalid_0's multi_logloss: 2.10275\n",
      "[58]\tvalid_0's multi_logloss: 2.10187\n",
      "[59]\tvalid_0's multi_logloss: 2.10106\n",
      "[60]\tvalid_0's multi_logloss: 2.10026\n",
      "[61]\tvalid_0's multi_logloss: 2.09938\n",
      "[62]\tvalid_0's multi_logloss: 2.09863\n",
      "[63]\tvalid_0's multi_logloss: 2.09788\n",
      "[64]\tvalid_0's multi_logloss: 2.09719\n",
      "[65]\tvalid_0's multi_logloss: 2.09634\n",
      "[66]\tvalid_0's multi_logloss: 2.09566\n",
      "[67]\tvalid_0's multi_logloss: 2.095\n",
      "[68]\tvalid_0's multi_logloss: 2.0944\n",
      "[69]\tvalid_0's multi_logloss: 2.0938\n",
      "[70]\tvalid_0's multi_logloss: 2.09303\n",
      "[71]\tvalid_0's multi_logloss: 2.09242\n",
      "[72]\tvalid_0's multi_logloss: 2.09172\n",
      "[73]\tvalid_0's multi_logloss: 2.09105\n",
      "[74]\tvalid_0's multi_logloss: 2.09034\n",
      "[75]\tvalid_0's multi_logloss: 2.08951\n",
      "[76]\tvalid_0's multi_logloss: 2.0889\n",
      "[77]\tvalid_0's multi_logloss: 2.08825\n",
      "[78]\tvalid_0's multi_logloss: 2.08762\n",
      "[79]\tvalid_0's multi_logloss: 2.08697\n",
      "[80]\tvalid_0's multi_logloss: 2.08643\n",
      "[81]\tvalid_0's multi_logloss: 2.08589\n",
      "[82]\tvalid_0's multi_logloss: 2.08541\n",
      "[83]\tvalid_0's multi_logloss: 2.08498\n",
      "[84]\tvalid_0's multi_logloss: 2.08452\n",
      "[85]\tvalid_0's multi_logloss: 2.08405\n",
      "[86]\tvalid_0's multi_logloss: 2.08353\n",
      "[87]\tvalid_0's multi_logloss: 2.08302\n",
      "[88]\tvalid_0's multi_logloss: 2.08252\n",
      "[89]\tvalid_0's multi_logloss: 2.08196\n",
      "[90]\tvalid_0's multi_logloss: 2.08156\n",
      "[91]\tvalid_0's multi_logloss: 2.08112\n",
      "[92]\tvalid_0's multi_logloss: 2.08073\n",
      "[93]\tvalid_0's multi_logloss: 2.08027\n",
      "[94]\tvalid_0's multi_logloss: 2.07982\n",
      "[95]\tvalid_0's multi_logloss: 2.0794\n",
      "[96]\tvalid_0's multi_logloss: 2.07905\n",
      "[97]\tvalid_0's multi_logloss: 2.07868\n",
      "[98]\tvalid_0's multi_logloss: 2.07829\n",
      "[99]\tvalid_0's multi_logloss: 2.07778\n",
      "[100]\tvalid_0's multi_logloss: 2.07733\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027288 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score -0.501622\n",
      "[LightGBM] [Info] Start training from score -0.930257\n",
      "[1]\tvalid_0's multi_logloss: 0.578578\n",
      "[2]\tvalid_0's multi_logloss: 0.504008\n",
      "[3]\tvalid_0's multi_logloss: 0.442748\n",
      "[4]\tvalid_0's multi_logloss: 0.390844\n",
      "[5]\tvalid_0's multi_logloss: 0.346639\n",
      "[6]\tvalid_0's multi_logloss: 0.308788\n",
      "[7]\tvalid_0's multi_logloss: 0.275802\n",
      "[8]\tvalid_0's multi_logloss: 0.246776\n",
      "[9]\tvalid_0's multi_logloss: 0.221257\n",
      "[10]\tvalid_0's multi_logloss: 0.198819\n",
      "[11]\tvalid_0's multi_logloss: 0.178968\n",
      "[12]\tvalid_0's multi_logloss: 0.161378\n",
      "[13]\tvalid_0's multi_logloss: 0.145793\n",
      "[14]\tvalid_0's multi_logloss: 0.131713\n",
      "[15]\tvalid_0's multi_logloss: 0.119078\n",
      "[16]\tvalid_0's multi_logloss: 0.107698\n",
      "[17]\tvalid_0's multi_logloss: 0.0976842\n",
      "[18]\tvalid_0's multi_logloss: 0.0886351\n",
      "[19]\tvalid_0's multi_logloss: 0.0803998\n",
      "[20]\tvalid_0's multi_logloss: 0.0729729\n",
      "[21]\tvalid_0's multi_logloss: 0.0663645\n",
      "[22]\tvalid_0's multi_logloss: 0.0603785\n",
      "[23]\tvalid_0's multi_logloss: 0.0549312\n",
      "[24]\tvalid_0's multi_logloss: 0.0500624\n",
      "[25]\tvalid_0's multi_logloss: 0.0456238\n",
      "[26]\tvalid_0's multi_logloss: 0.0416364\n",
      "[27]\tvalid_0's multi_logloss: 0.0380736\n",
      "[28]\tvalid_0's multi_logloss: 0.0348047\n",
      "[29]\tvalid_0's multi_logloss: 0.0317828\n",
      "[30]\tvalid_0's multi_logloss: 0.0290501\n",
      "[31]\tvalid_0's multi_logloss: 0.0265848\n",
      "[32]\tvalid_0's multi_logloss: 0.0243255\n",
      "[33]\tvalid_0's multi_logloss: 0.022306\n",
      "[34]\tvalid_0's multi_logloss: 0.0204836\n",
      "[35]\tvalid_0's multi_logloss: 0.0188001\n",
      "[36]\tvalid_0's multi_logloss: 0.0172938\n",
      "[37]\tvalid_0's multi_logloss: 0.015937\n",
      "[38]\tvalid_0's multi_logloss: 0.0147084\n",
      "[39]\tvalid_0's multi_logloss: 0.0135594\n",
      "[40]\tvalid_0's multi_logloss: 0.0125224\n",
      "[41]\tvalid_0's multi_logloss: 0.0115804\n",
      "[42]\tvalid_0's multi_logloss: 0.010733\n",
      "[43]\tvalid_0's multi_logloss: 0.00993374\n",
      "[44]\tvalid_0's multi_logloss: 0.00920852\n",
      "[45]\tvalid_0's multi_logloss: 0.00856387\n",
      "[46]\tvalid_0's multi_logloss: 0.00797073\n",
      "[47]\tvalid_0's multi_logloss: 0.00743412\n",
      "[48]\tvalid_0's multi_logloss: 0.00693822\n",
      "[49]\tvalid_0's multi_logloss: 0.00648155\n",
      "[50]\tvalid_0's multi_logloss: 0.0060743\n",
      "[51]\tvalid_0's multi_logloss: 0.00568617\n",
      "[52]\tvalid_0's multi_logloss: 0.00533975\n",
      "[53]\tvalid_0's multi_logloss: 0.00502188\n",
      "[54]\tvalid_0's multi_logloss: 0.004737\n",
      "[55]\tvalid_0's multi_logloss: 0.00447295\n",
      "[56]\tvalid_0's multi_logloss: 0.00422399\n",
      "[57]\tvalid_0's multi_logloss: 0.0040068\n",
      "[58]\tvalid_0's multi_logloss: 0.00380329\n",
      "[59]\tvalid_0's multi_logloss: 0.00361094\n",
      "[60]\tvalid_0's multi_logloss: 0.00343953\n",
      "[61]\tvalid_0's multi_logloss: 0.00327072\n",
      "[62]\tvalid_0's multi_logloss: 0.00312786\n",
      "[63]\tvalid_0's multi_logloss: 0.00299201\n",
      "[64]\tvalid_0's multi_logloss: 0.00286884\n",
      "[65]\tvalid_0's multi_logloss: 0.00275375\n",
      "[66]\tvalid_0's multi_logloss: 0.00265414\n",
      "[67]\tvalid_0's multi_logloss: 0.00256825\n",
      "[68]\tvalid_0's multi_logloss: 0.00247865\n",
      "[69]\tvalid_0's multi_logloss: 0.00239004\n",
      "[70]\tvalid_0's multi_logloss: 0.00231197\n",
      "[71]\tvalid_0's multi_logloss: 0.00224031\n",
      "[72]\tvalid_0's multi_logloss: 0.00217386\n",
      "[73]\tvalid_0's multi_logloss: 0.00211155\n",
      "[74]\tvalid_0's multi_logloss: 0.00205312\n",
      "[75]\tvalid_0's multi_logloss: 0.00200077\n",
      "[76]\tvalid_0's multi_logloss: 0.00195284\n",
      "[77]\tvalid_0's multi_logloss: 0.00190982\n",
      "[78]\tvalid_0's multi_logloss: 0.00186905\n",
      "[79]\tvalid_0's multi_logloss: 0.00183219\n",
      "[80]\tvalid_0's multi_logloss: 0.00179688\n",
      "[81]\tvalid_0's multi_logloss: 0.00176833\n",
      "[82]\tvalid_0's multi_logloss: 0.00173552\n",
      "[83]\tvalid_0's multi_logloss: 0.00170715\n",
      "[84]\tvalid_0's multi_logloss: 0.00171939\n",
      "[85]\tvalid_0's multi_logloss: 0.0017443\n",
      "[86]\tvalid_0's multi_logloss: 0.00171907\n",
      "[87]\tvalid_0's multi_logloss: 0.00175797\n",
      "[88]\tvalid_0's multi_logloss: 0.00168433\n",
      "[89]\tvalid_0's multi_logloss: 0.00166634\n",
      "[90]\tvalid_0's multi_logloss: 0.00164909\n",
      "[91]\tvalid_0's multi_logloss: 0.00177145\n",
      "[92]\tvalid_0's multi_logloss: 0.00165741\n",
      "[93]\tvalid_0's multi_logloss: 0.00171142\n",
      "[94]\tvalid_0's multi_logloss: 0.00172546\n",
      "[95]\tvalid_0's multi_logloss: 0.0016488\n",
      "[96]\tvalid_0's multi_logloss: 0.00163532\n",
      "[97]\tvalid_0's multi_logloss: 0.00163012\n",
      "[98]\tvalid_0's multi_logloss: 0.00163156\n",
      "[99]\tvalid_0's multi_logloss: 0.00160949\n",
      "[100]\tvalid_0's multi_logloss: 0.00161388\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026283 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score -0.141837\n",
      "[LightGBM] [Info] Start training from score -2.023158\n",
      "[1]\tvalid_0's multi_logloss: 0.356433\n",
      "[2]\tvalid_0's multi_logloss: 0.33333\n",
      "[3]\tvalid_0's multi_logloss: 0.316187\n",
      "[4]\tvalid_0's multi_logloss: 0.302278\n",
      "[5]\tvalid_0's multi_logloss: 0.29046\n",
      "[6]\tvalid_0's multi_logloss: 0.280098\n",
      "[7]\tvalid_0's multi_logloss: 0.271578\n",
      "[8]\tvalid_0's multi_logloss: 0.263604\n",
      "[9]\tvalid_0's multi_logloss: 0.256946\n",
      "[10]\tvalid_0's multi_logloss: 0.25107\n",
      "[11]\tvalid_0's multi_logloss: 0.245988\n",
      "[12]\tvalid_0's multi_logloss: 0.241289\n",
      "[13]\tvalid_0's multi_logloss: 0.237192\n",
      "[14]\tvalid_0's multi_logloss: 0.233921\n",
      "[15]\tvalid_0's multi_logloss: 0.230235\n",
      "[16]\tvalid_0's multi_logloss: 0.227402\n",
      "[17]\tvalid_0's multi_logloss: 0.224984\n",
      "[18]\tvalid_0's multi_logloss: 0.221723\n",
      "[19]\tvalid_0's multi_logloss: 0.219638\n",
      "[20]\tvalid_0's multi_logloss: 0.217359\n",
      "[21]\tvalid_0's multi_logloss: 0.214984\n",
      "[22]\tvalid_0's multi_logloss: 0.213001\n",
      "[23]\tvalid_0's multi_logloss: 0.211004\n",
      "[24]\tvalid_0's multi_logloss: 0.209525\n",
      "[25]\tvalid_0's multi_logloss: 0.20752\n",
      "[26]\tvalid_0's multi_logloss: 0.206343\n",
      "[27]\tvalid_0's multi_logloss: 0.204737\n",
      "[28]\tvalid_0's multi_logloss: 0.203112\n",
      "[29]\tvalid_0's multi_logloss: 0.201436\n",
      "[30]\tvalid_0's multi_logloss: 0.200178\n",
      "[31]\tvalid_0's multi_logloss: 0.198781\n",
      "[32]\tvalid_0's multi_logloss: 0.197866\n",
      "[33]\tvalid_0's multi_logloss: 0.196796\n",
      "[34]\tvalid_0's multi_logloss: 0.196085\n",
      "[35]\tvalid_0's multi_logloss: 0.19504\n",
      "[36]\tvalid_0's multi_logloss: 0.194383\n",
      "[37]\tvalid_0's multi_logloss: 0.193795\n",
      "[38]\tvalid_0's multi_logloss: 0.193251\n",
      "[39]\tvalid_0's multi_logloss: 0.19241\n",
      "[40]\tvalid_0's multi_logloss: 0.191699\n",
      "[41]\tvalid_0's multi_logloss: 0.190604\n",
      "[42]\tvalid_0's multi_logloss: 0.190059\n",
      "[43]\tvalid_0's multi_logloss: 0.189632\n",
      "[44]\tvalid_0's multi_logloss: 0.189307\n",
      "[45]\tvalid_0's multi_logloss: 0.189027\n",
      "[46]\tvalid_0's multi_logloss: 0.188443\n",
      "[47]\tvalid_0's multi_logloss: 0.187876\n",
      "[48]\tvalid_0's multi_logloss: 0.18733\n",
      "[49]\tvalid_0's multi_logloss: 0.186572\n",
      "[50]\tvalid_0's multi_logloss: 0.185927\n",
      "[51]\tvalid_0's multi_logloss: 0.185374\n",
      "[52]\tvalid_0's multi_logloss: 0.184629\n",
      "[53]\tvalid_0's multi_logloss: 0.184251\n",
      "[54]\tvalid_0's multi_logloss: 0.183928\n",
      "[55]\tvalid_0's multi_logloss: 0.183426\n",
      "[56]\tvalid_0's multi_logloss: 0.183151\n",
      "[57]\tvalid_0's multi_logloss: 0.182227\n",
      "[58]\tvalid_0's multi_logloss: 0.182012\n",
      "[59]\tvalid_0's multi_logloss: 0.181621\n",
      "[60]\tvalid_0's multi_logloss: 0.180944\n",
      "[61]\tvalid_0's multi_logloss: 0.180462\n",
      "[62]\tvalid_0's multi_logloss: 0.180141\n",
      "[63]\tvalid_0's multi_logloss: 0.179513\n",
      "[64]\tvalid_0's multi_logloss: 0.179159\n",
      "[65]\tvalid_0's multi_logloss: 0.178911\n",
      "[66]\tvalid_0's multi_logloss: 0.178399\n",
      "[67]\tvalid_0's multi_logloss: 0.178142\n",
      "[68]\tvalid_0's multi_logloss: 0.177605\n",
      "[69]\tvalid_0's multi_logloss: 0.177181\n",
      "[70]\tvalid_0's multi_logloss: 0.17676\n",
      "[71]\tvalid_0's multi_logloss: 0.176462\n",
      "[72]\tvalid_0's multi_logloss: 0.176208\n",
      "[73]\tvalid_0's multi_logloss: 0.175671\n",
      "[74]\tvalid_0's multi_logloss: 0.175397\n",
      "[75]\tvalid_0's multi_logloss: 0.174951\n",
      "[76]\tvalid_0's multi_logloss: 0.174699\n",
      "[77]\tvalid_0's multi_logloss: 0.174197\n",
      "[78]\tvalid_0's multi_logloss: 0.174044\n",
      "[79]\tvalid_0's multi_logloss: 0.173858\n",
      "[80]\tvalid_0's multi_logloss: 0.173546\n",
      "[81]\tvalid_0's multi_logloss: 0.17341\n",
      "[82]\tvalid_0's multi_logloss: 0.173119\n",
      "[83]\tvalid_0's multi_logloss: 0.172719\n",
      "[84]\tvalid_0's multi_logloss: 0.172477\n",
      "[85]\tvalid_0's multi_logloss: 0.172186\n",
      "[86]\tvalid_0's multi_logloss: 0.171972\n",
      "[87]\tvalid_0's multi_logloss: 0.171779\n",
      "[88]\tvalid_0's multi_logloss: 0.171521\n",
      "[89]\tvalid_0's multi_logloss: 0.171353\n",
      "[90]\tvalid_0's multi_logloss: 0.171257\n",
      "[91]\tvalid_0's multi_logloss: 0.171062\n",
      "[92]\tvalid_0's multi_logloss: 0.170447\n",
      "[93]\tvalid_0's multi_logloss: 0.170147\n",
      "[94]\tvalid_0's multi_logloss: 0.16996\n",
      "[95]\tvalid_0's multi_logloss: 0.169582\n",
      "[96]\tvalid_0's multi_logloss: 0.169469\n",
      "[97]\tvalid_0's multi_logloss: 0.169313\n",
      "[98]\tvalid_0's multi_logloss: 0.169082\n",
      "[99]\tvalid_0's multi_logloss: 0.168843\n",
      "[100]\tvalid_0's multi_logloss: 0.168587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [38:57, 132.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008064 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 7715638, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score -1.249550\n",
      "[LightGBM] [Info] Start training from score -3.165534\n",
      "[LightGBM] [Info] Start training from score -1.726403\n",
      "[LightGBM] [Info] Start training from score -1.902421\n",
      "[LightGBM] [Info] Start training from score -1.667720\n",
      "[LightGBM] [Info] Start training from score -1.861961\n",
      "[1]\tvalid_0's multi_logloss: 1.67564\n",
      "[2]\tvalid_0's multi_logloss: 1.66702\n",
      "[3]\tvalid_0's multi_logloss: 1.65993\n",
      "[4]\tvalid_0's multi_logloss: 1.65384\n",
      "[5]\tvalid_0's multi_logloss: 1.64839\n",
      "[6]\tvalid_0's multi_logloss: 1.64375\n",
      "[7]\tvalid_0's multi_logloss: 1.63942\n",
      "[8]\tvalid_0's multi_logloss: 1.63543\n",
      "[9]\tvalid_0's multi_logloss: 1.63191\n",
      "[10]\tvalid_0's multi_logloss: 1.62928\n",
      "[11]\tvalid_0's multi_logloss: 1.62642\n",
      "[12]\tvalid_0's multi_logloss: 1.62391\n",
      "[13]\tvalid_0's multi_logloss: 1.62135\n",
      "[14]\tvalid_0's multi_logloss: 1.61922\n",
      "[15]\tvalid_0's multi_logloss: 1.61701\n",
      "[16]\tvalid_0's multi_logloss: 1.61524\n",
      "[17]\tvalid_0's multi_logloss: 1.61348\n",
      "[18]\tvalid_0's multi_logloss: 1.61183\n",
      "[19]\tvalid_0's multi_logloss: 1.6104\n",
      "[20]\tvalid_0's multi_logloss: 1.60914\n",
      "[21]\tvalid_0's multi_logloss: 1.60793\n",
      "[22]\tvalid_0's multi_logloss: 1.60667\n",
      "[23]\tvalid_0's multi_logloss: 1.60563\n",
      "[24]\tvalid_0's multi_logloss: 1.60456\n",
      "[25]\tvalid_0's multi_logloss: 1.60368\n",
      "[26]\tvalid_0's multi_logloss: 1.60265\n",
      "[27]\tvalid_0's multi_logloss: 1.6017\n",
      "[28]\tvalid_0's multi_logloss: 1.60089\n",
      "[29]\tvalid_0's multi_logloss: 1.60005\n",
      "[30]\tvalid_0's multi_logloss: 1.59923\n",
      "[31]\tvalid_0's multi_logloss: 1.59844\n",
      "[32]\tvalid_0's multi_logloss: 1.5976\n",
      "[33]\tvalid_0's multi_logloss: 1.59677\n",
      "[34]\tvalid_0's multi_logloss: 1.59614\n",
      "[35]\tvalid_0's multi_logloss: 1.59557\n",
      "[36]\tvalid_0's multi_logloss: 1.59493\n",
      "[37]\tvalid_0's multi_logloss: 1.5943\n",
      "[38]\tvalid_0's multi_logloss: 1.59375\n",
      "[39]\tvalid_0's multi_logloss: 1.59329\n",
      "[40]\tvalid_0's multi_logloss: 1.59275\n",
      "[41]\tvalid_0's multi_logloss: 1.59225\n",
      "[42]\tvalid_0's multi_logloss: 1.59179\n",
      "[43]\tvalid_0's multi_logloss: 1.59121\n",
      "[44]\tvalid_0's multi_logloss: 1.5907\n",
      "[45]\tvalid_0's multi_logloss: 1.59026\n",
      "[46]\tvalid_0's multi_logloss: 1.58982\n",
      "[47]\tvalid_0's multi_logloss: 1.58938\n",
      "[48]\tvalid_0's multi_logloss: 1.58891\n",
      "[49]\tvalid_0's multi_logloss: 1.58855\n",
      "[50]\tvalid_0's multi_logloss: 1.58807\n",
      "[51]\tvalid_0's multi_logloss: 1.58764\n",
      "[52]\tvalid_0's multi_logloss: 1.58736\n",
      "[53]\tvalid_0's multi_logloss: 1.5868\n",
      "[54]\tvalid_0's multi_logloss: 1.58636\n",
      "[55]\tvalid_0's multi_logloss: 1.58599\n",
      "[56]\tvalid_0's multi_logloss: 1.58557\n",
      "[57]\tvalid_0's multi_logloss: 1.58515\n",
      "[58]\tvalid_0's multi_logloss: 1.58484\n",
      "[59]\tvalid_0's multi_logloss: 1.58454\n",
      "[60]\tvalid_0's multi_logloss: 1.58427\n",
      "[61]\tvalid_0's multi_logloss: 1.58395\n",
      "[62]\tvalid_0's multi_logloss: 1.58357\n",
      "[63]\tvalid_0's multi_logloss: 1.58329\n",
      "[64]\tvalid_0's multi_logloss: 1.58301\n",
      "[65]\tvalid_0's multi_logloss: 1.5827\n",
      "[66]\tvalid_0's multi_logloss: 1.58229\n",
      "[67]\tvalid_0's multi_logloss: 1.58205\n",
      "[68]\tvalid_0's multi_logloss: 1.58172\n",
      "[69]\tvalid_0's multi_logloss: 1.58159\n",
      "[70]\tvalid_0's multi_logloss: 1.58137\n",
      "[71]\tvalid_0's multi_logloss: 1.58104\n",
      "[72]\tvalid_0's multi_logloss: 1.58069\n",
      "[73]\tvalid_0's multi_logloss: 1.58049\n",
      "[74]\tvalid_0's multi_logloss: 1.58023\n",
      "[75]\tvalid_0's multi_logloss: 1.58008\n",
      "[76]\tvalid_0's multi_logloss: 1.57981\n",
      "[77]\tvalid_0's multi_logloss: 1.57942\n",
      "[78]\tvalid_0's multi_logloss: 1.57918\n",
      "[79]\tvalid_0's multi_logloss: 1.57885\n",
      "[80]\tvalid_0's multi_logloss: 1.57857\n",
      "[81]\tvalid_0's multi_logloss: 1.57825\n",
      "[82]\tvalid_0's multi_logloss: 1.57797\n",
      "[83]\tvalid_0's multi_logloss: 1.57759\n",
      "[84]\tvalid_0's multi_logloss: 1.57735\n",
      "[85]\tvalid_0's multi_logloss: 1.57717\n",
      "[86]\tvalid_0's multi_logloss: 1.57688\n",
      "[87]\tvalid_0's multi_logloss: 1.57666\n",
      "[88]\tvalid_0's multi_logloss: 1.57628\n",
      "[89]\tvalid_0's multi_logloss: 1.57616\n",
      "[90]\tvalid_0's multi_logloss: 1.57585\n",
      "[91]\tvalid_0's multi_logloss: 1.57566\n",
      "[92]\tvalid_0's multi_logloss: 1.57528\n",
      "[93]\tvalid_0's multi_logloss: 1.57492\n",
      "[94]\tvalid_0's multi_logloss: 1.57463\n",
      "[95]\tvalid_0's multi_logloss: 1.57445\n",
      "[96]\tvalid_0's multi_logloss: 1.57418\n",
      "[97]\tvalid_0's multi_logloss: 1.57401\n",
      "[98]\tvalid_0's multi_logloss: 1.57386\n",
      "[99]\tvalid_0's multi_logloss: 1.57369\n",
      "[100]\tvalid_0's multi_logloss: 1.57337\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008839 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 7715638, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score -3.388563\n",
      "[LightGBM] [Info] Start training from score -3.286043\n",
      "[LightGBM] [Info] Start training from score -3.265766\n",
      "[LightGBM] [Info] Start training from score -3.814547\n",
      "[LightGBM] [Info] Start training from score -3.310265\n",
      "[LightGBM] [Info] Start training from score -3.206426\n",
      "[LightGBM] [Info] Start training from score -4.264605\n",
      "[LightGBM] [Info] Start training from score -3.385622\n",
      "[LightGBM] [Info] Start training from score -3.678169\n",
      "[LightGBM] [Info] Start training from score -3.401590\n",
      "[LightGBM] [Info] Start training from score -4.879144\n",
      "[LightGBM] [Info] Start training from score -3.027581\n",
      "[LightGBM] [Info] Start training from score -2.985319\n",
      "[LightGBM] [Info] Start training from score -3.251856\n",
      "[LightGBM] [Info] Start training from score -3.294527\n",
      "[LightGBM] [Info] Start training from score -3.372086\n",
      "[LightGBM] [Info] Start training from score -2.973489\n",
      "[LightGBM] [Info] Start training from score -2.489644\n",
      "[LightGBM] [Info] Start training from score -3.403357\n",
      "[LightGBM] [Info] Start training from score -4.161407\n",
      "[LightGBM] [Info] Start training from score -4.219942\n",
      "[LightGBM] [Info] Start training from score -3.454308\n",
      "[LightGBM] [Info] Start training from score -3.414970\n",
      "[LightGBM] [Info] Start training from score -3.160243\n",
      "[LightGBM] [Info] Start training from score -3.113230\n",
      "[LightGBM] [Info] Start training from score -3.209175\n",
      "[LightGBM] [Info] Start training from score -3.282600\n",
      "[LightGBM] [Info] Start training from score -3.180636\n",
      "[1]\tvalid_0's multi_logloss: 2.58254\n",
      "[2]\tvalid_0's multi_logloss: 2.37583\n",
      "[3]\tvalid_0's multi_logloss: 2.26106\n",
      "[4]\tvalid_0's multi_logloss: 2.15187\n",
      "[5]\tvalid_0's multi_logloss: 2.08547\n",
      "[6]\tvalid_0's multi_logloss: 2.01639\n",
      "[7]\tvalid_0's multi_logloss: 1.96271\n",
      "[8]\tvalid_0's multi_logloss: 1.91752\n",
      "[9]\tvalid_0's multi_logloss: 1.87814\n",
      "[10]\tvalid_0's multi_logloss: 1.8447\n",
      "[11]\tvalid_0's multi_logloss: 1.81685\n",
      "[12]\tvalid_0's multi_logloss: 1.79137\n",
      "[13]\tvalid_0's multi_logloss: 1.76931\n",
      "[14]\tvalid_0's multi_logloss: 1.75014\n",
      "[15]\tvalid_0's multi_logloss: 1.73235\n",
      "[16]\tvalid_0's multi_logloss: 1.7168\n",
      "[17]\tvalid_0's multi_logloss: 1.70574\n",
      "[18]\tvalid_0's multi_logloss: 1.69006\n",
      "[19]\tvalid_0's multi_logloss: 1.67807\n",
      "[20]\tvalid_0's multi_logloss: 1.66751\n",
      "[21]\tvalid_0's multi_logloss: 1.65782\n",
      "[22]\tvalid_0's multi_logloss: 1.64881\n",
      "[23]\tvalid_0's multi_logloss: 1.64042\n",
      "[24]\tvalid_0's multi_logloss: 1.63273\n",
      "[25]\tvalid_0's multi_logloss: 1.62573\n",
      "[26]\tvalid_0's multi_logloss: 1.6184\n",
      "[27]\tvalid_0's multi_logloss: 1.61204\n",
      "[28]\tvalid_0's multi_logloss: 1.60598\n",
      "[29]\tvalid_0's multi_logloss: 1.60019\n",
      "[30]\tvalid_0's multi_logloss: 1.59511\n",
      "[31]\tvalid_0's multi_logloss: 1.58986\n",
      "[32]\tvalid_0's multi_logloss: 1.58536\n",
      "[33]\tvalid_0's multi_logloss: 1.58083\n",
      "[34]\tvalid_0's multi_logloss: 1.57667\n",
      "[35]\tvalid_0's multi_logloss: 1.57305\n",
      "[36]\tvalid_0's multi_logloss: 1.56945\n",
      "[37]\tvalid_0's multi_logloss: 1.56573\n",
      "[38]\tvalid_0's multi_logloss: 1.56257\n",
      "[39]\tvalid_0's multi_logloss: 1.55931\n",
      "[40]\tvalid_0's multi_logloss: 1.55634\n",
      "[41]\tvalid_0's multi_logloss: 1.55342\n",
      "[42]\tvalid_0's multi_logloss: 1.55\n",
      "[43]\tvalid_0's multi_logloss: 1.54731\n",
      "[44]\tvalid_0's multi_logloss: 1.54494\n",
      "[45]\tvalid_0's multi_logloss: 1.54242\n",
      "[46]\tvalid_0's multi_logloss: 1.54019\n",
      "[47]\tvalid_0's multi_logloss: 1.53743\n",
      "[48]\tvalid_0's multi_logloss: 1.53522\n",
      "[49]\tvalid_0's multi_logloss: 1.53282\n",
      "[50]\tvalid_0's multi_logloss: 1.53049\n",
      "[51]\tvalid_0's multi_logloss: 1.52843\n",
      "[52]\tvalid_0's multi_logloss: 1.52662\n",
      "[53]\tvalid_0's multi_logloss: 1.52426\n",
      "[54]\tvalid_0's multi_logloss: 1.52205\n",
      "[55]\tvalid_0's multi_logloss: 1.52011\n",
      "[56]\tvalid_0's multi_logloss: 1.51835\n",
      "[57]\tvalid_0's multi_logloss: 1.51662\n",
      "[58]\tvalid_0's multi_logloss: 1.51463\n",
      "[59]\tvalid_0's multi_logloss: 1.51338\n",
      "[60]\tvalid_0's multi_logloss: 1.51176\n",
      "[61]\tvalid_0's multi_logloss: 1.51044\n",
      "[62]\tvalid_0's multi_logloss: 1.50874\n",
      "[63]\tvalid_0's multi_logloss: 1.50717\n",
      "[64]\tvalid_0's multi_logloss: 1.50564\n",
      "[65]\tvalid_0's multi_logloss: 1.50406\n",
      "[66]\tvalid_0's multi_logloss: 1.50225\n",
      "[67]\tvalid_0's multi_logloss: 1.50093\n",
      "[68]\tvalid_0's multi_logloss: 1.49931\n",
      "[69]\tvalid_0's multi_logloss: 1.49802\n",
      "[70]\tvalid_0's multi_logloss: 1.49667\n",
      "[71]\tvalid_0's multi_logloss: 1.49531\n",
      "[72]\tvalid_0's multi_logloss: 1.49409\n",
      "[73]\tvalid_0's multi_logloss: 1.49275\n",
      "[74]\tvalid_0's multi_logloss: 1.49178\n",
      "[75]\tvalid_0's multi_logloss: 1.49058\n",
      "[76]\tvalid_0's multi_logloss: 1.48917\n",
      "[77]\tvalid_0's multi_logloss: 1.48792\n",
      "[78]\tvalid_0's multi_logloss: 1.48704\n",
      "[79]\tvalid_0's multi_logloss: 1.48583\n",
      "[80]\tvalid_0's multi_logloss: 1.48459\n",
      "[81]\tvalid_0's multi_logloss: 1.48327\n",
      "[82]\tvalid_0's multi_logloss: 1.48228\n",
      "[83]\tvalid_0's multi_logloss: 1.48097\n",
      "[84]\tvalid_0's multi_logloss: 1.4802\n",
      "[85]\tvalid_0's multi_logloss: 1.47896\n",
      "[86]\tvalid_0's multi_logloss: 1.47743\n",
      "[87]\tvalid_0's multi_logloss: 1.47626\n",
      "[88]\tvalid_0's multi_logloss: 1.47534\n",
      "[89]\tvalid_0's multi_logloss: 1.47455\n",
      "[90]\tvalid_0's multi_logloss: 1.47348\n",
      "[91]\tvalid_0's multi_logloss: 1.47267\n",
      "[92]\tvalid_0's multi_logloss: 1.47139\n",
      "[93]\tvalid_0's multi_logloss: 1.47025\n",
      "[94]\tvalid_0's multi_logloss: 1.46914\n",
      "[95]\tvalid_0's multi_logloss: 1.46796\n",
      "[96]\tvalid_0's multi_logloss: 1.46705\n",
      "[97]\tvalid_0's multi_logloss: 1.46576\n",
      "[98]\tvalid_0's multi_logloss: 1.46499\n",
      "[99]\tvalid_0's multi_logloss: 1.46424\n",
      "[100]\tvalid_0's multi_logloss: 1.46361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [40:38, 123.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001548 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 820733, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score -0.683185\n",
      "[LightGBM] [Info] Start training from score -2.382997\n",
      "[LightGBM] [Info] Start training from score -2.734975\n",
      "[LightGBM] [Info] Start training from score -3.826068\n",
      "[LightGBM] [Info] Start training from score -1.583719\n",
      "[LightGBM] [Info] Start training from score -2.199855\n",
      "[1]\tvalid_0's multi_logloss: 1.16889\n",
      "[2]\tvalid_0's multi_logloss: 1.05545\n",
      "[3]\tvalid_0's multi_logloss: 0.970176\n",
      "[4]\tvalid_0's multi_logloss: 0.902548\n",
      "[5]\tvalid_0's multi_logloss: 0.847959\n",
      "[6]\tvalid_0's multi_logloss: 0.802055\n",
      "[7]\tvalid_0's multi_logloss: 0.763385\n",
      "[8]\tvalid_0's multi_logloss: 0.731042\n",
      "[9]\tvalid_0's multi_logloss: 0.702522\n",
      "[10]\tvalid_0's multi_logloss: 0.678532\n",
      "[11]\tvalid_0's multi_logloss: 0.657633\n",
      "[12]\tvalid_0's multi_logloss: 0.639315\n",
      "[13]\tvalid_0's multi_logloss: 0.622995\n",
      "[14]\tvalid_0's multi_logloss: 0.608502\n",
      "[15]\tvalid_0's multi_logloss: 0.596249\n",
      "[16]\tvalid_0's multi_logloss: 0.585286\n",
      "[17]\tvalid_0's multi_logloss: 0.575459\n",
      "[18]\tvalid_0's multi_logloss: 0.566478\n",
      "[19]\tvalid_0's multi_logloss: 0.5587\n",
      "[20]\tvalid_0's multi_logloss: 0.550885\n",
      "[21]\tvalid_0's multi_logloss: 0.544095\n",
      "[22]\tvalid_0's multi_logloss: 0.53824\n",
      "[23]\tvalid_0's multi_logloss: 0.532637\n",
      "[24]\tvalid_0's multi_logloss: 0.527528\n",
      "[25]\tvalid_0's multi_logloss: 0.523351\n",
      "[26]\tvalid_0's multi_logloss: 0.519043\n",
      "[27]\tvalid_0's multi_logloss: 0.515067\n",
      "[28]\tvalid_0's multi_logloss: 0.511352\n",
      "[29]\tvalid_0's multi_logloss: 0.508025\n",
      "[30]\tvalid_0's multi_logloss: 0.504955\n",
      "[31]\tvalid_0's multi_logloss: 0.501873\n",
      "[32]\tvalid_0's multi_logloss: 0.499154\n",
      "[33]\tvalid_0's multi_logloss: 0.496613\n",
      "[34]\tvalid_0's multi_logloss: 0.494215\n",
      "[35]\tvalid_0's multi_logloss: 0.491863\n",
      "[36]\tvalid_0's multi_logloss: 0.490018\n",
      "[37]\tvalid_0's multi_logloss: 0.487813\n",
      "[38]\tvalid_0's multi_logloss: 0.485892\n",
      "[39]\tvalid_0's multi_logloss: 0.48424\n",
      "[40]\tvalid_0's multi_logloss: 0.482284\n",
      "[41]\tvalid_0's multi_logloss: 0.480645\n",
      "[42]\tvalid_0's multi_logloss: 0.479374\n",
      "[43]\tvalid_0's multi_logloss: 0.477591\n",
      "[44]\tvalid_0's multi_logloss: 0.476608\n",
      "[45]\tvalid_0's multi_logloss: 0.475108\n",
      "[46]\tvalid_0's multi_logloss: 0.475291\n",
      "[47]\tvalid_0's multi_logloss: 0.472853\n",
      "[48]\tvalid_0's multi_logloss: 0.472455\n",
      "[49]\tvalid_0's multi_logloss: 0.471759\n",
      "[50]\tvalid_0's multi_logloss: 0.470124\n",
      "[51]\tvalid_0's multi_logloss: 0.470522\n",
      "[52]\tvalid_0's multi_logloss: 0.468469\n",
      "[53]\tvalid_0's multi_logloss: 0.47188\n",
      "[54]\tvalid_0's multi_logloss: 0.468662\n",
      "[55]\tvalid_0's multi_logloss: 0.468369\n",
      "[56]\tvalid_0's multi_logloss: 0.46698\n",
      "[57]\tvalid_0's multi_logloss: 0.467637\n",
      "[58]\tvalid_0's multi_logloss: 0.466294\n",
      "[59]\tvalid_0's multi_logloss: 0.464802\n",
      "[60]\tvalid_0's multi_logloss: 0.466536\n",
      "[61]\tvalid_0's multi_logloss: 0.463495\n",
      "[62]\tvalid_0's multi_logloss: 0.465599\n",
      "[63]\tvalid_0's multi_logloss: 0.465311\n",
      "[64]\tvalid_0's multi_logloss: 0.464878\n",
      "[65]\tvalid_0's multi_logloss: 0.463442\n",
      "[66]\tvalid_0's multi_logloss: 0.46547\n",
      "[67]\tvalid_0's multi_logloss: 0.464286\n",
      "[68]\tvalid_0's multi_logloss: 0.461072\n",
      "[69]\tvalid_0's multi_logloss: 0.460569\n",
      "[70]\tvalid_0's multi_logloss: 0.461129\n",
      "[71]\tvalid_0's multi_logloss: 0.45949\n",
      "[72]\tvalid_0's multi_logloss: 0.45996\n",
      "[73]\tvalid_0's multi_logloss: 0.465875\n",
      "[74]\tvalid_0's multi_logloss: 0.459375\n",
      "[75]\tvalid_0's multi_logloss: 0.458584\n",
      "[76]\tvalid_0's multi_logloss: 0.465129\n",
      "[77]\tvalid_0's multi_logloss: 0.461108\n",
      "[78]\tvalid_0's multi_logloss: 0.464932\n",
      "[79]\tvalid_0's multi_logloss: 0.461986\n",
      "[80]\tvalid_0's multi_logloss: 0.462633\n",
      "[81]\tvalid_0's multi_logloss: 0.458384\n",
      "[82]\tvalid_0's multi_logloss: 0.467555\n",
      "[83]\tvalid_0's multi_logloss: 0.461647\n",
      "[84]\tvalid_0's multi_logloss: 0.460387\n",
      "[85]\tvalid_0's multi_logloss: 0.467761\n",
      "[86]\tvalid_0's multi_logloss: 0.459242\n",
      "[87]\tvalid_0's multi_logloss: 0.459127\n",
      "[88]\tvalid_0's multi_logloss: 0.466523\n",
      "[89]\tvalid_0's multi_logloss: 0.464097\n",
      "[90]\tvalid_0's multi_logloss: 0.479555\n",
      "[91]\tvalid_0's multi_logloss: 0.454846\n",
      "[92]\tvalid_0's multi_logloss: 0.470978\n",
      "[93]\tvalid_0's multi_logloss: 0.460812\n",
      "[94]\tvalid_0's multi_logloss: 0.463076\n",
      "[95]\tvalid_0's multi_logloss: 0.453544\n",
      "[96]\tvalid_0's multi_logloss: 0.479592\n",
      "[97]\tvalid_0's multi_logloss: 0.463389\n",
      "[98]\tvalid_0's multi_logloss: 0.493397\n",
      "[99]\tvalid_0's multi_logloss: 0.463667\n",
      "[100]\tvalid_0's multi_logloss: 0.462908\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001592 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 820733, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score -2.163833\n",
      "[LightGBM] [Info] Start training from score -1.796397\n",
      "[LightGBM] [Info] Start training from score -1.843741\n",
      "[LightGBM] [Info] Start training from score -1.989576\n",
      "[LightGBM] [Info] Start training from score -1.941218\n",
      "[LightGBM] [Info] Start training from score -1.949016\n",
      "[LightGBM] [Info] Start training from score -1.978333\n",
      "[1]\tvalid_0's multi_logloss: 1.90468\n",
      "[2]\tvalid_0's multi_logloss: 1.87704\n",
      "[3]\tvalid_0's multi_logloss: 1.85476\n",
      "[4]\tvalid_0's multi_logloss: 1.83643\n",
      "[5]\tvalid_0's multi_logloss: 1.82139\n",
      "[6]\tvalid_0's multi_logloss: 1.80891\n",
      "[7]\tvalid_0's multi_logloss: 1.79853\n",
      "[8]\tvalid_0's multi_logloss: 1.78966\n",
      "[9]\tvalid_0's multi_logloss: 1.78204\n",
      "[10]\tvalid_0's multi_logloss: 1.77566\n",
      "[11]\tvalid_0's multi_logloss: 1.7701\n",
      "[12]\tvalid_0's multi_logloss: 1.76521\n",
      "[13]\tvalid_0's multi_logloss: 1.76115\n",
      "[14]\tvalid_0's multi_logloss: 1.75736\n",
      "[15]\tvalid_0's multi_logloss: 1.7542\n",
      "[16]\tvalid_0's multi_logloss: 1.75134\n",
      "[17]\tvalid_0's multi_logloss: 1.74886\n",
      "[18]\tvalid_0's multi_logloss: 1.74646\n",
      "[19]\tvalid_0's multi_logloss: 1.74437\n",
      "[20]\tvalid_0's multi_logloss: 1.74243\n",
      "[21]\tvalid_0's multi_logloss: 1.74067\n",
      "[22]\tvalid_0's multi_logloss: 1.7391\n",
      "[23]\tvalid_0's multi_logloss: 1.73767\n",
      "[24]\tvalid_0's multi_logloss: 1.73626\n",
      "[25]\tvalid_0's multi_logloss: 1.73505\n",
      "[26]\tvalid_0's multi_logloss: 1.73397\n",
      "[27]\tvalid_0's multi_logloss: 1.73291\n",
      "[28]\tvalid_0's multi_logloss: 1.73203\n",
      "[29]\tvalid_0's multi_logloss: 1.7311\n",
      "[30]\tvalid_0's multi_logloss: 1.73036\n",
      "[31]\tvalid_0's multi_logloss: 1.7296\n",
      "[32]\tvalid_0's multi_logloss: 1.72881\n",
      "[33]\tvalid_0's multi_logloss: 1.72808\n",
      "[34]\tvalid_0's multi_logloss: 1.72746\n",
      "[35]\tvalid_0's multi_logloss: 1.72688\n",
      "[36]\tvalid_0's multi_logloss: 1.72632\n",
      "[37]\tvalid_0's multi_logloss: 1.72579\n",
      "[38]\tvalid_0's multi_logloss: 1.72537\n",
      "[39]\tvalid_0's multi_logloss: 1.72489\n",
      "[40]\tvalid_0's multi_logloss: 1.72446\n",
      "[41]\tvalid_0's multi_logloss: 1.72414\n",
      "[42]\tvalid_0's multi_logloss: 1.72376\n",
      "[43]\tvalid_0's multi_logloss: 1.72336\n",
      "[44]\tvalid_0's multi_logloss: 1.723\n",
      "[45]\tvalid_0's multi_logloss: 1.72263\n",
      "[46]\tvalid_0's multi_logloss: 1.72231\n",
      "[47]\tvalid_0's multi_logloss: 1.72198\n",
      "[48]\tvalid_0's multi_logloss: 1.72168\n",
      "[49]\tvalid_0's multi_logloss: 1.72146\n",
      "[50]\tvalid_0's multi_logloss: 1.72111\n",
      "[51]\tvalid_0's multi_logloss: 1.72088\n",
      "[52]\tvalid_0's multi_logloss: 1.72063\n",
      "[53]\tvalid_0's multi_logloss: 1.72048\n",
      "[54]\tvalid_0's multi_logloss: 1.72025\n",
      "[55]\tvalid_0's multi_logloss: 1.72005\n",
      "[56]\tvalid_0's multi_logloss: 1.71983\n",
      "[57]\tvalid_0's multi_logloss: 1.71966\n",
      "[58]\tvalid_0's multi_logloss: 1.71949\n",
      "[59]\tvalid_0's multi_logloss: 1.71918\n",
      "[60]\tvalid_0's multi_logloss: 1.71901\n",
      "[61]\tvalid_0's multi_logloss: 1.71869\n",
      "[62]\tvalid_0's multi_logloss: 1.71855\n",
      "[63]\tvalid_0's multi_logloss: 1.7183\n",
      "[64]\tvalid_0's multi_logloss: 1.71802\n",
      "[65]\tvalid_0's multi_logloss: 1.71788\n",
      "[66]\tvalid_0's multi_logloss: 1.71767\n",
      "[67]\tvalid_0's multi_logloss: 1.71747\n",
      "[68]\tvalid_0's multi_logloss: 1.71731\n",
      "[69]\tvalid_0's multi_logloss: 1.71714\n",
      "[70]\tvalid_0's multi_logloss: 1.71707\n",
      "[71]\tvalid_0's multi_logloss: 1.71684\n",
      "[72]\tvalid_0's multi_logloss: 1.71661\n",
      "[73]\tvalid_0's multi_logloss: 1.71636\n",
      "[74]\tvalid_0's multi_logloss: 1.71612\n",
      "[75]\tvalid_0's multi_logloss: 1.71584\n",
      "[76]\tvalid_0's multi_logloss: 1.71563\n",
      "[77]\tvalid_0's multi_logloss: 1.71553\n",
      "[78]\tvalid_0's multi_logloss: 1.71538\n",
      "[79]\tvalid_0's multi_logloss: 1.7153\n",
      "[80]\tvalid_0's multi_logloss: 1.7152\n",
      "[81]\tvalid_0's multi_logloss: 1.715\n",
      "[82]\tvalid_0's multi_logloss: 1.71492\n",
      "[83]\tvalid_0's multi_logloss: 1.71467\n",
      "[84]\tvalid_0's multi_logloss: 1.71455\n",
      "[85]\tvalid_0's multi_logloss: 1.7144\n",
      "[86]\tvalid_0's multi_logloss: 1.71428\n",
      "[87]\tvalid_0's multi_logloss: 1.71416\n",
      "[88]\tvalid_0's multi_logloss: 1.71395\n",
      "[89]\tvalid_0's multi_logloss: 1.7138\n",
      "[90]\tvalid_0's multi_logloss: 1.71376\n",
      "[91]\tvalid_0's multi_logloss: 1.71365\n",
      "[92]\tvalid_0's multi_logloss: 1.7134\n",
      "[93]\tvalid_0's multi_logloss: 1.71321\n",
      "[94]\tvalid_0's multi_logloss: 1.713\n",
      "[95]\tvalid_0's multi_logloss: 1.7128\n",
      "[96]\tvalid_0's multi_logloss: 1.71263\n",
      "[97]\tvalid_0's multi_logloss: 1.71234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [40:47, 88.61s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[98]\tvalid_0's multi_logloss: 1.71216\n",
      "[99]\tvalid_0's multi_logloss: 1.71199\n",
      "[100]\tvalid_0's multi_logloss: 1.7118\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017262 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -1.853404\n",
      "[LightGBM] [Info] Start training from score -2.123202\n",
      "[LightGBM] [Info] Start training from score -2.391862\n",
      "[LightGBM] [Info] Start training from score -2.719639\n",
      "[LightGBM] [Info] Start training from score -2.078311\n",
      "[LightGBM] [Info] Start training from score -2.161447\n",
      "[LightGBM] [Info] Start training from score -2.497610\n",
      "[LightGBM] [Info] Start training from score -2.232530\n",
      "[LightGBM] [Info] Start training from score -2.689447\n",
      "[LightGBM] [Info] Start training from score -2.680407\n",
      "[1]\tvalid_0's multi_logloss: 1.98841\n",
      "[2]\tvalid_0's multi_logloss: 1.83519\n",
      "[3]\tvalid_0's multi_logloss: 1.72317\n",
      "[4]\tvalid_0's multi_logloss: 1.63826\n",
      "[5]\tvalid_0's multi_logloss: 1.57073\n",
      "[6]\tvalid_0's multi_logloss: 1.51472\n",
      "[7]\tvalid_0's multi_logloss: 1.46909\n",
      "[8]\tvalid_0's multi_logloss: 1.42847\n",
      "[9]\tvalid_0's multi_logloss: 1.39419\n",
      "[10]\tvalid_0's multi_logloss: 1.36428\n",
      "[11]\tvalid_0's multi_logloss: 1.3364\n",
      "[12]\tvalid_0's multi_logloss: 1.31262\n",
      "[13]\tvalid_0's multi_logloss: 1.29046\n",
      "[14]\tvalid_0's multi_logloss: 1.26976\n",
      "[15]\tvalid_0's multi_logloss: 1.25176\n",
      "[16]\tvalid_0's multi_logloss: 1.23503\n",
      "[17]\tvalid_0's multi_logloss: 1.22125\n",
      "[18]\tvalid_0's multi_logloss: 1.20857\n",
      "[19]\tvalid_0's multi_logloss: 1.19662\n",
      "[20]\tvalid_0's multi_logloss: 1.18569\n",
      "[21]\tvalid_0's multi_logloss: 1.17548\n",
      "[22]\tvalid_0's multi_logloss: 1.16644\n",
      "[23]\tvalid_0's multi_logloss: 1.15796\n",
      "[24]\tvalid_0's multi_logloss: 1.14967\n",
      "[25]\tvalid_0's multi_logloss: 1.1415\n",
      "[26]\tvalid_0's multi_logloss: 1.13514\n",
      "[27]\tvalid_0's multi_logloss: 1.12881\n",
      "[28]\tvalid_0's multi_logloss: 1.12157\n",
      "[29]\tvalid_0's multi_logloss: 1.11537\n",
      "[30]\tvalid_0's multi_logloss: 1.10985\n",
      "[31]\tvalid_0's multi_logloss: 1.10453\n",
      "[32]\tvalid_0's multi_logloss: 1.09966\n",
      "[33]\tvalid_0's multi_logloss: 1.09508\n",
      "[34]\tvalid_0's multi_logloss: 1.09116\n",
      "[35]\tvalid_0's multi_logloss: 1.08731\n",
      "[36]\tvalid_0's multi_logloss: 1.08302\n",
      "[37]\tvalid_0's multi_logloss: 1.0797\n",
      "[38]\tvalid_0's multi_logloss: 1.07555\n",
      "[39]\tvalid_0's multi_logloss: 1.07207\n",
      "[40]\tvalid_0's multi_logloss: 1.06895\n",
      "[41]\tvalid_0's multi_logloss: 1.06598\n",
      "[42]\tvalid_0's multi_logloss: 1.06318\n",
      "[43]\tvalid_0's multi_logloss: 1.06005\n",
      "[44]\tvalid_0's multi_logloss: 1.05671\n",
      "[45]\tvalid_0's multi_logloss: 1.05392\n",
      "[46]\tvalid_0's multi_logloss: 1.05148\n",
      "[47]\tvalid_0's multi_logloss: 1.04886\n",
      "[48]\tvalid_0's multi_logloss: 1.04667\n",
      "[49]\tvalid_0's multi_logloss: 1.04463\n",
      "[50]\tvalid_0's multi_logloss: 1.04234\n",
      "[51]\tvalid_0's multi_logloss: 1.04044\n",
      "[52]\tvalid_0's multi_logloss: 1.03839\n",
      "[53]\tvalid_0's multi_logloss: 1.03672\n",
      "[54]\tvalid_0's multi_logloss: 1.0346\n",
      "[55]\tvalid_0's multi_logloss: 1.03262\n",
      "[56]\tvalid_0's multi_logloss: 1.03078\n",
      "[57]\tvalid_0's multi_logloss: 1.02879\n",
      "[58]\tvalid_0's multi_logloss: 1.02698\n",
      "[59]\tvalid_0's multi_logloss: 1.02536\n",
      "[60]\tvalid_0's multi_logloss: 1.02374\n",
      "[61]\tvalid_0's multi_logloss: 1.02218\n",
      "[62]\tvalid_0's multi_logloss: 1.02025\n",
      "[63]\tvalid_0's multi_logloss: 1.01856\n",
      "[64]\tvalid_0's multi_logloss: 1.01707\n",
      "[65]\tvalid_0's multi_logloss: 1.01544\n",
      "[66]\tvalid_0's multi_logloss: 1.01426\n",
      "[67]\tvalid_0's multi_logloss: 1.01262\n",
      "[68]\tvalid_0's multi_logloss: 1.01097\n",
      "[69]\tvalid_0's multi_logloss: 1.00939\n",
      "[70]\tvalid_0's multi_logloss: 1.0081\n",
      "[71]\tvalid_0's multi_logloss: 1.00676\n",
      "[72]\tvalid_0's multi_logloss: 1.00533\n",
      "[73]\tvalid_0's multi_logloss: 1.00403\n",
      "[74]\tvalid_0's multi_logloss: 1.00282\n",
      "[75]\tvalid_0's multi_logloss: 1.00158\n",
      "[76]\tvalid_0's multi_logloss: 1\n",
      "[77]\tvalid_0's multi_logloss: 0.998747\n",
      "[78]\tvalid_0's multi_logloss: 0.997385\n",
      "[79]\tvalid_0's multi_logloss: 0.99636\n",
      "[80]\tvalid_0's multi_logloss: 0.994914\n",
      "[81]\tvalid_0's multi_logloss: 0.994031\n",
      "[82]\tvalid_0's multi_logloss: 0.992946\n",
      "[83]\tvalid_0's multi_logloss: 0.991853\n",
      "[84]\tvalid_0's multi_logloss: 0.990717\n",
      "[85]\tvalid_0's multi_logloss: 0.989758\n",
      "[86]\tvalid_0's multi_logloss: 0.989029\n",
      "[87]\tvalid_0's multi_logloss: 0.98824\n",
      "[88]\tvalid_0's multi_logloss: 0.987297\n",
      "[89]\tvalid_0's multi_logloss: 0.986122\n",
      "[90]\tvalid_0's multi_logloss: 0.985135\n",
      "[91]\tvalid_0's multi_logloss: 0.984069\n",
      "[92]\tvalid_0's multi_logloss: 0.983004\n",
      "[93]\tvalid_0's multi_logloss: 0.982091\n",
      "[94]\tvalid_0's multi_logloss: 0.981067\n",
      "[95]\tvalid_0's multi_logloss: 0.980113\n",
      "[96]\tvalid_0's multi_logloss: 0.979301\n",
      "[97]\tvalid_0's multi_logloss: 0.978475\n",
      "[98]\tvalid_0's multi_logloss: 0.977334\n",
      "[99]\tvalid_0's multi_logloss: 0.976547\n",
      "[100]\tvalid_0's multi_logloss: 0.975743\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017414 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -1.047228\n",
      "[LightGBM] [Info] Start training from score -1.516216\n",
      "[LightGBM] [Info] Start training from score -0.845018\n",
      "[1]\tvalid_0's multi_logloss: 1.01195\n",
      "[2]\tvalid_0's multi_logloss: 0.969913\n",
      "[3]\tvalid_0's multi_logloss: 0.934846\n",
      "[4]\tvalid_0's multi_logloss: 0.905133\n",
      "[5]\tvalid_0's multi_logloss: 0.879736\n",
      "[6]\tvalid_0's multi_logloss: 0.857926\n",
      "[7]\tvalid_0's multi_logloss: 0.839108\n",
      "[8]\tvalid_0's multi_logloss: 0.822679\n",
      "[9]\tvalid_0's multi_logloss: 0.808089\n",
      "[10]\tvalid_0's multi_logloss: 0.795185\n",
      "[11]\tvalid_0's multi_logloss: 0.783687\n",
      "[12]\tvalid_0's multi_logloss: 0.773482\n",
      "[13]\tvalid_0's multi_logloss: 0.764357\n",
      "[14]\tvalid_0's multi_logloss: 0.756199\n",
      "[15]\tvalid_0's multi_logloss: 0.74875\n",
      "[16]\tvalid_0's multi_logloss: 0.741992\n",
      "[17]\tvalid_0's multi_logloss: 0.735904\n",
      "[18]\tvalid_0's multi_logloss: 0.730421\n",
      "[19]\tvalid_0's multi_logloss: 0.725375\n",
      "[20]\tvalid_0's multi_logloss: 0.720661\n",
      "[21]\tvalid_0's multi_logloss: 0.716372\n",
      "[22]\tvalid_0's multi_logloss: 0.712538\n",
      "[23]\tvalid_0's multi_logloss: 0.70888\n",
      "[24]\tvalid_0's multi_logloss: 0.705493\n",
      "[25]\tvalid_0's multi_logloss: 0.702471\n",
      "[26]\tvalid_0's multi_logloss: 0.699671\n",
      "[27]\tvalid_0's multi_logloss: 0.697032\n",
      "[28]\tvalid_0's multi_logloss: 0.69456\n",
      "[29]\tvalid_0's multi_logloss: 0.692347\n",
      "[30]\tvalid_0's multi_logloss: 0.69034\n",
      "[31]\tvalid_0's multi_logloss: 0.688391\n",
      "[32]\tvalid_0's multi_logloss: 0.686583\n",
      "[33]\tvalid_0's multi_logloss: 0.684889\n",
      "[34]\tvalid_0's multi_logloss: 0.683295\n",
      "[35]\tvalid_0's multi_logloss: 0.681893\n",
      "[36]\tvalid_0's multi_logloss: 0.680557\n",
      "[37]\tvalid_0's multi_logloss: 0.679284\n",
      "[38]\tvalid_0's multi_logloss: 0.678076\n",
      "[39]\tvalid_0's multi_logloss: 0.676946\n",
      "[40]\tvalid_0's multi_logloss: 0.675847\n",
      "[41]\tvalid_0's multi_logloss: 0.674839\n",
      "[42]\tvalid_0's multi_logloss: 0.673866\n",
      "[43]\tvalid_0's multi_logloss: 0.672964\n",
      "[44]\tvalid_0's multi_logloss: 0.672126\n",
      "[45]\tvalid_0's multi_logloss: 0.671337\n",
      "[46]\tvalid_0's multi_logloss: 0.670629\n",
      "[47]\tvalid_0's multi_logloss: 0.669927\n",
      "[48]\tvalid_0's multi_logloss: 0.66933\n",
      "[49]\tvalid_0's multi_logloss: 0.668688\n",
      "[50]\tvalid_0's multi_logloss: 0.668009\n",
      "[51]\tvalid_0's multi_logloss: 0.667377\n",
      "[52]\tvalid_0's multi_logloss: 0.66677\n",
      "[53]\tvalid_0's multi_logloss: 0.666248\n",
      "[54]\tvalid_0's multi_logloss: 0.665629\n",
      "[55]\tvalid_0's multi_logloss: 0.665148\n",
      "[56]\tvalid_0's multi_logloss: 0.664721\n",
      "[57]\tvalid_0's multi_logloss: 0.664186\n",
      "[58]\tvalid_0's multi_logloss: 0.663766\n",
      "[59]\tvalid_0's multi_logloss: 0.663408\n",
      "[60]\tvalid_0's multi_logloss: 0.663038\n",
      "[61]\tvalid_0's multi_logloss: 0.662713\n",
      "[62]\tvalid_0's multi_logloss: 0.662324\n",
      "[63]\tvalid_0's multi_logloss: 0.662063\n",
      "[64]\tvalid_0's multi_logloss: 0.661777\n",
      "[65]\tvalid_0's multi_logloss: 0.661541\n",
      "[66]\tvalid_0's multi_logloss: 0.661234\n",
      "[67]\tvalid_0's multi_logloss: 0.660984\n",
      "[68]\tvalid_0's multi_logloss: 0.660736\n",
      "[69]\tvalid_0's multi_logloss: 0.660446\n",
      "[70]\tvalid_0's multi_logloss: 0.660227\n",
      "[71]\tvalid_0's multi_logloss: 0.660062\n",
      "[72]\tvalid_0's multi_logloss: 0.659862\n",
      "[73]\tvalid_0's multi_logloss: 0.659677\n",
      "[74]\tvalid_0's multi_logloss: 0.659529\n",
      "[75]\tvalid_0's multi_logloss: 0.659313\n",
      "[76]\tvalid_0's multi_logloss: 0.659134\n",
      "[77]\tvalid_0's multi_logloss: 0.658959\n",
      "[78]\tvalid_0's multi_logloss: 0.658735\n",
      "[79]\tvalid_0's multi_logloss: 0.658565\n",
      "[80]\tvalid_0's multi_logloss: 0.658378\n",
      "[81]\tvalid_0's multi_logloss: 0.658167\n",
      "[82]\tvalid_0's multi_logloss: 0.658007\n",
      "[83]\tvalid_0's multi_logloss: 0.657817\n",
      "[84]\tvalid_0's multi_logloss: 0.657639\n",
      "[85]\tvalid_0's multi_logloss: 0.657473\n",
      "[86]\tvalid_0's multi_logloss: 0.65734\n",
      "[87]\tvalid_0's multi_logloss: 0.657176\n",
      "[88]\tvalid_0's multi_logloss: 0.657037\n",
      "[89]\tvalid_0's multi_logloss: 0.656913\n",
      "[90]\tvalid_0's multi_logloss: 0.656792\n",
      "[91]\tvalid_0's multi_logloss: 0.656705\n",
      "[92]\tvalid_0's multi_logloss: 0.656625\n",
      "[93]\tvalid_0's multi_logloss: 0.656508\n",
      "[94]\tvalid_0's multi_logloss: 0.656378\n",
      "[95]\tvalid_0's multi_logloss: 0.656362\n",
      "[96]\tvalid_0's multi_logloss: 0.656257\n",
      "[97]\tvalid_0's multi_logloss: 0.65623\n",
      "[98]\tvalid_0's multi_logloss: 0.656169\n",
      "[99]\tvalid_0's multi_logloss: 0.65611\n",
      "[100]\tvalid_0's multi_logloss: 0.655996\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017599 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -3.244539\n",
      "[LightGBM] [Info] Start training from score -3.224920\n",
      "[LightGBM] [Info] Start training from score -3.369880\n",
      "[LightGBM] [Info] Start training from score -3.326941\n",
      "[LightGBM] [Info] Start training from score -3.378266\n",
      "[LightGBM] [Info] Start training from score -2.568017\n",
      "[LightGBM] [Info] Start training from score -1.914747\n",
      "[LightGBM] [Info] Start training from score -3.469579\n",
      "[LightGBM] [Info] Start training from score -1.919436\n",
      "[LightGBM] [Info] Start training from score -2.291576\n",
      "[LightGBM] [Info] Start training from score -2.007538\n",
      "[LightGBM] [Info] Start training from score -3.402200\n",
      "[LightGBM] [Info] Start training from score -3.212376\n",
      "[LightGBM] [Info] Start training from score -2.244521\n",
      "[1]\tvalid_0's multi_logloss: 2.4079\n",
      "[2]\tvalid_0's multi_logloss: 2.37409\n",
      "[3]\tvalid_0's multi_logloss: 2.34708\n",
      "[4]\tvalid_0's multi_logloss: 2.32494\n",
      "[5]\tvalid_0's multi_logloss: 2.30705\n",
      "[6]\tvalid_0's multi_logloss: 2.29135\n",
      "[7]\tvalid_0's multi_logloss: 2.27821\n",
      "[8]\tvalid_0's multi_logloss: 2.26676\n",
      "[9]\tvalid_0's multi_logloss: 2.25668\n",
      "[10]\tvalid_0's multi_logloss: 2.24727\n",
      "[11]\tvalid_0's multi_logloss: 2.2394\n",
      "[12]\tvalid_0's multi_logloss: 2.23267\n",
      "[13]\tvalid_0's multi_logloss: 2.22637\n",
      "[14]\tvalid_0's multi_logloss: 2.22072\n",
      "[15]\tvalid_0's multi_logloss: 2.21495\n",
      "[16]\tvalid_0's multi_logloss: 2.2101\n",
      "[17]\tvalid_0's multi_logloss: 2.20547\n",
      "[18]\tvalid_0's multi_logloss: 2.20125\n",
      "[19]\tvalid_0's multi_logloss: 2.19735\n",
      "[20]\tvalid_0's multi_logloss: 2.19404\n",
      "[21]\tvalid_0's multi_logloss: 2.19074\n",
      "[22]\tvalid_0's multi_logloss: 2.18744\n",
      "[23]\tvalid_0's multi_logloss: 2.18448\n",
      "[24]\tvalid_0's multi_logloss: 2.18192\n",
      "[25]\tvalid_0's multi_logloss: 2.17955\n",
      "[26]\tvalid_0's multi_logloss: 2.17681\n",
      "[27]\tvalid_0's multi_logloss: 2.17452\n",
      "[28]\tvalid_0's multi_logloss: 2.17219\n",
      "[29]\tvalid_0's multi_logloss: 2.17019\n",
      "[30]\tvalid_0's multi_logloss: 2.16833\n",
      "[31]\tvalid_0's multi_logloss: 2.16638\n",
      "[32]\tvalid_0's multi_logloss: 2.16467\n",
      "[33]\tvalid_0's multi_logloss: 2.16312\n",
      "[34]\tvalid_0's multi_logloss: 2.16142\n",
      "[35]\tvalid_0's multi_logloss: 2.15985\n",
      "[36]\tvalid_0's multi_logloss: 2.15822\n",
      "[37]\tvalid_0's multi_logloss: 2.15691\n",
      "[38]\tvalid_0's multi_logloss: 2.15557\n",
      "[39]\tvalid_0's multi_logloss: 2.15436\n",
      "[40]\tvalid_0's multi_logloss: 2.1531\n",
      "[41]\tvalid_0's multi_logloss: 2.15184\n",
      "[42]\tvalid_0's multi_logloss: 2.1507\n",
      "[43]\tvalid_0's multi_logloss: 2.14954\n",
      "[44]\tvalid_0's multi_logloss: 2.14843\n",
      "[45]\tvalid_0's multi_logloss: 2.14741\n",
      "[46]\tvalid_0's multi_logloss: 2.14637\n",
      "[47]\tvalid_0's multi_logloss: 2.14536\n",
      "[48]\tvalid_0's multi_logloss: 2.14435\n",
      "[49]\tvalid_0's multi_logloss: 2.14357\n",
      "[50]\tvalid_0's multi_logloss: 2.14264\n",
      "[51]\tvalid_0's multi_logloss: 2.14186\n",
      "[52]\tvalid_0's multi_logloss: 2.14084\n",
      "[53]\tvalid_0's multi_logloss: 2.14008\n",
      "[54]\tvalid_0's multi_logloss: 2.13938\n",
      "[55]\tvalid_0's multi_logloss: 2.13851\n",
      "[56]\tvalid_0's multi_logloss: 2.13774\n",
      "[57]\tvalid_0's multi_logloss: 2.13692\n",
      "[58]\tvalid_0's multi_logloss: 2.13615\n",
      "[59]\tvalid_0's multi_logloss: 2.13564\n",
      "[60]\tvalid_0's multi_logloss: 2.13488\n",
      "[61]\tvalid_0's multi_logloss: 2.13418\n",
      "[62]\tvalid_0's multi_logloss: 2.13371\n",
      "[63]\tvalid_0's multi_logloss: 2.13291\n",
      "[64]\tvalid_0's multi_logloss: 2.1322\n",
      "[65]\tvalid_0's multi_logloss: 2.1316\n",
      "[66]\tvalid_0's multi_logloss: 2.13103\n",
      "[67]\tvalid_0's multi_logloss: 2.13058\n",
      "[68]\tvalid_0's multi_logloss: 2.12996\n",
      "[69]\tvalid_0's multi_logloss: 2.12941\n",
      "[70]\tvalid_0's multi_logloss: 2.12872\n",
      "[71]\tvalid_0's multi_logloss: 2.12813\n",
      "[72]\tvalid_0's multi_logloss: 2.12754\n",
      "[73]\tvalid_0's multi_logloss: 2.12699\n",
      "[74]\tvalid_0's multi_logloss: 2.12641\n",
      "[75]\tvalid_0's multi_logloss: 2.12599\n",
      "[76]\tvalid_0's multi_logloss: 2.12553\n",
      "[77]\tvalid_0's multi_logloss: 2.12499\n",
      "[78]\tvalid_0's multi_logloss: 2.12448\n",
      "[79]\tvalid_0's multi_logloss: 2.12395\n",
      "[80]\tvalid_0's multi_logloss: 2.12349\n",
      "[81]\tvalid_0's multi_logloss: 2.12305\n",
      "[82]\tvalid_0's multi_logloss: 2.12254\n",
      "[83]\tvalid_0's multi_logloss: 2.12206\n",
      "[84]\tvalid_0's multi_logloss: 2.12153\n",
      "[85]\tvalid_0's multi_logloss: 2.121\n",
      "[86]\tvalid_0's multi_logloss: 2.12063\n",
      "[87]\tvalid_0's multi_logloss: 2.12009\n",
      "[88]\tvalid_0's multi_logloss: 2.1196\n",
      "[89]\tvalid_0's multi_logloss: 2.11921\n",
      "[90]\tvalid_0's multi_logloss: 2.1189\n",
      "[91]\tvalid_0's multi_logloss: 2.11848\n",
      "[92]\tvalid_0's multi_logloss: 2.11815\n",
      "[93]\tvalid_0's multi_logloss: 2.11782\n",
      "[94]\tvalid_0's multi_logloss: 2.11738\n",
      "[95]\tvalid_0's multi_logloss: 2.11706\n",
      "[96]\tvalid_0's multi_logloss: 2.11658\n",
      "[97]\tvalid_0's multi_logloss: 2.11621\n",
      "[98]\tvalid_0's multi_logloss: 2.11586\n",
      "[99]\tvalid_0's multi_logloss: 2.11552\n",
      "[100]\tvalid_0's multi_logloss: 2.11502\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017560 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -0.501622\n",
      "[LightGBM] [Info] Start training from score -0.930257\n",
      "[1]\tvalid_0's multi_logloss: 0.578075\n",
      "[2]\tvalid_0's multi_logloss: 0.503123\n",
      "[3]\tvalid_0's multi_logloss: 0.441168\n",
      "[4]\tvalid_0's multi_logloss: 0.389101\n",
      "[5]\tvalid_0's multi_logloss: 0.34457\n",
      "[6]\tvalid_0's multi_logloss: 0.306276\n",
      "[7]\tvalid_0's multi_logloss: 0.273256\n",
      "[8]\tvalid_0's multi_logloss: 0.244238\n",
      "[9]\tvalid_0's multi_logloss: 0.218806\n",
      "[10]\tvalid_0's multi_logloss: 0.196475\n",
      "[11]\tvalid_0's multi_logloss: 0.176672\n",
      "[12]\tvalid_0's multi_logloss: 0.158999\n",
      "[13]\tvalid_0's multi_logloss: 0.143343\n",
      "[14]\tvalid_0's multi_logloss: 0.129359\n",
      "[15]\tvalid_0's multi_logloss: 0.116905\n",
      "[16]\tvalid_0's multi_logloss: 0.105905\n",
      "[17]\tvalid_0's multi_logloss: 0.0958897\n",
      "[18]\tvalid_0's multi_logloss: 0.0869298\n",
      "[19]\tvalid_0's multi_logloss: 0.0789082\n",
      "[20]\tvalid_0's multi_logloss: 0.0717462\n",
      "[21]\tvalid_0's multi_logloss: 0.0653376\n",
      "[22]\tvalid_0's multi_logloss: 0.0595157\n",
      "[23]\tvalid_0's multi_logloss: 0.0540877\n",
      "[24]\tvalid_0's multi_logloss: 0.0492346\n",
      "[25]\tvalid_0's multi_logloss: 0.0448349\n",
      "[26]\tvalid_0's multi_logloss: 0.0409102\n",
      "[27]\tvalid_0's multi_logloss: 0.0373461\n",
      "[28]\tvalid_0's multi_logloss: 0.0341461\n",
      "[29]\tvalid_0's multi_logloss: 0.0312301\n",
      "[30]\tvalid_0's multi_logloss: 0.0285811\n",
      "[31]\tvalid_0's multi_logloss: 0.0261933\n",
      "[32]\tvalid_0's multi_logloss: 0.0240158\n",
      "[33]\tvalid_0's multi_logloss: 0.0220371\n",
      "[34]\tvalid_0's multi_logloss: 0.0202285\n",
      "[35]\tvalid_0's multi_logloss: 0.018601\n",
      "[36]\tvalid_0's multi_logloss: 0.0171002\n",
      "[37]\tvalid_0's multi_logloss: 0.015736\n",
      "[38]\tvalid_0's multi_logloss: 0.0145347\n",
      "[39]\tvalid_0's multi_logloss: 0.0134046\n",
      "[40]\tvalid_0's multi_logloss: 0.0123812\n",
      "[41]\tvalid_0's multi_logloss: 0.0114553\n",
      "[42]\tvalid_0's multi_logloss: 0.0105746\n",
      "[43]\tvalid_0's multi_logloss: 0.00975369\n",
      "[44]\tvalid_0's multi_logloss: 0.00902997\n",
      "[45]\tvalid_0's multi_logloss: 0.00839633\n",
      "[46]\tvalid_0's multi_logloss: 0.00779437\n",
      "[47]\tvalid_0's multi_logloss: 0.00727075\n",
      "[48]\tvalid_0's multi_logloss: 0.00677695\n",
      "[49]\tvalid_0's multi_logloss: 0.00633493\n",
      "[50]\tvalid_0's multi_logloss: 0.00591567\n",
      "[51]\tvalid_0's multi_logloss: 0.00554484\n",
      "[52]\tvalid_0's multi_logloss: 0.00521275\n",
      "[53]\tvalid_0's multi_logloss: 0.00488917\n",
      "[54]\tvalid_0's multi_logloss: 0.00460941\n",
      "[55]\tvalid_0's multi_logloss: 0.00434209\n",
      "[56]\tvalid_0's multi_logloss: 0.00411505\n",
      "[57]\tvalid_0's multi_logloss: 0.00388521\n",
      "[58]\tvalid_0's multi_logloss: 0.00369532\n",
      "[59]\tvalid_0's multi_logloss: 0.00350999\n",
      "[60]\tvalid_0's multi_logloss: 0.0033468\n",
      "[61]\tvalid_0's multi_logloss: 0.00319434\n",
      "[62]\tvalid_0's multi_logloss: 0.00305182\n",
      "[63]\tvalid_0's multi_logloss: 0.00292003\n",
      "[64]\tvalid_0's multi_logloss: 0.00280315\n",
      "[65]\tvalid_0's multi_logloss: 0.00269088\n",
      "[66]\tvalid_0's multi_logloss: 0.0025929\n",
      "[67]\tvalid_0's multi_logloss: 0.00249644\n",
      "[68]\tvalid_0's multi_logloss: 0.00241386\n",
      "[69]\tvalid_0's multi_logloss: 0.00233625\n",
      "[70]\tvalid_0's multi_logloss: 0.00226456\n",
      "[71]\tvalid_0's multi_logloss: 0.00219585\n",
      "[72]\tvalid_0's multi_logloss: 0.00213121\n",
      "[73]\tvalid_0's multi_logloss: 0.00207295\n",
      "[74]\tvalid_0's multi_logloss: 0.00202012\n",
      "[75]\tvalid_0's multi_logloss: 0.0019683\n",
      "[76]\tvalid_0's multi_logloss: 0.00192198\n",
      "[77]\tvalid_0's multi_logloss: 0.00235715\n",
      "[78]\tvalid_0's multi_logloss: 0.00200351\n",
      "[79]\tvalid_0's multi_logloss: 0.00255793\n",
      "[80]\tvalid_0's multi_logloss: 0.00227097\n",
      "[81]\tvalid_0's multi_logloss: 0.00223337\n",
      "[82]\tvalid_0's multi_logloss: 0.00219908\n",
      "[83]\tvalid_0's multi_logloss: 0.00216603\n",
      "[84]\tvalid_0's multi_logloss: 0.00199741\n",
      "[85]\tvalid_0's multi_logloss: 0.00196697\n",
      "[86]\tvalid_0's multi_logloss: 0.00194748\n",
      "[87]\tvalid_0's multi_logloss: 0.00192148\n",
      "[88]\tvalid_0's multi_logloss: 0.00189663\n",
      "[89]\tvalid_0's multi_logloss: 0.0018792\n",
      "[90]\tvalid_0's multi_logloss: 0.00185787\n",
      "[91]\tvalid_0's multi_logloss: 0.0018367\n",
      "[92]\tvalid_0's multi_logloss: 0.00181657\n",
      "[93]\tvalid_0's multi_logloss: 0.00186515\n",
      "[94]\tvalid_0's multi_logloss: 0.00176044\n",
      "[95]\tvalid_0's multi_logloss: 0.00174332\n",
      "[96]\tvalid_0's multi_logloss: 0.00172777\n",
      "[97]\tvalid_0's multi_logloss: 0.00171231\n",
      "[98]\tvalid_0's multi_logloss: 0.00169895\n",
      "[99]\tvalid_0's multi_logloss: 0.00173963\n",
      "[100]\tvalid_0's multi_logloss: 0.0018488\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017874 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -0.141837\n",
      "[LightGBM] [Info] Start training from score -2.023158\n",
      "[1]\tvalid_0's multi_logloss: 0.361569\n",
      "[2]\tvalid_0's multi_logloss: 0.343038\n",
      "[3]\tvalid_0's multi_logloss: 0.328483\n",
      "[4]\tvalid_0's multi_logloss: 0.316126\n",
      "[5]\tvalid_0's multi_logloss: 0.306269\n",
      "[6]\tvalid_0's multi_logloss: 0.297721\n",
      "[7]\tvalid_0's multi_logloss: 0.290232\n",
      "[8]\tvalid_0's multi_logloss: 0.28424\n",
      "[9]\tvalid_0's multi_logloss: 0.278763\n",
      "[10]\tvalid_0's multi_logloss: 0.273784\n",
      "[11]\tvalid_0's multi_logloss: 0.269396\n",
      "[12]\tvalid_0's multi_logloss: 0.265884\n",
      "[13]\tvalid_0's multi_logloss: 0.262524\n",
      "[14]\tvalid_0's multi_logloss: 0.259333\n",
      "[15]\tvalid_0's multi_logloss: 0.256634\n",
      "[16]\tvalid_0's multi_logloss: 0.254177\n",
      "[17]\tvalid_0's multi_logloss: 0.251587\n",
      "[18]\tvalid_0's multi_logloss: 0.249345\n",
      "[19]\tvalid_0's multi_logloss: 0.247468\n",
      "[20]\tvalid_0's multi_logloss: 0.245653\n",
      "[21]\tvalid_0's multi_logloss: 0.243942\n",
      "[22]\tvalid_0's multi_logloss: 0.242439\n",
      "[23]\tvalid_0's multi_logloss: 0.240767\n",
      "[24]\tvalid_0's multi_logloss: 0.239002\n",
      "[25]\tvalid_0's multi_logloss: 0.237634\n",
      "[26]\tvalid_0's multi_logloss: 0.236117\n",
      "[27]\tvalid_0's multi_logloss: 0.234584\n",
      "[28]\tvalid_0's multi_logloss: 0.233483\n",
      "[29]\tvalid_0's multi_logloss: 0.232478\n",
      "[30]\tvalid_0's multi_logloss: 0.231395\n",
      "[31]\tvalid_0's multi_logloss: 0.230235\n",
      "[32]\tvalid_0's multi_logloss: 0.229217\n",
      "[33]\tvalid_0's multi_logloss: 0.228546\n",
      "[34]\tvalid_0's multi_logloss: 0.227648\n",
      "[35]\tvalid_0's multi_logloss: 0.226768\n",
      "[36]\tvalid_0's multi_logloss: 0.226199\n",
      "[37]\tvalid_0's multi_logloss: 0.22558\n",
      "[38]\tvalid_0's multi_logloss: 0.224779\n",
      "[39]\tvalid_0's multi_logloss: 0.224153\n",
      "[40]\tvalid_0's multi_logloss: 0.223433\n",
      "[41]\tvalid_0's multi_logloss: 0.222855\n",
      "[42]\tvalid_0's multi_logloss: 0.222305\n",
      "[43]\tvalid_0's multi_logloss: 0.221673\n",
      "[44]\tvalid_0's multi_logloss: 0.221143\n",
      "[45]\tvalid_0's multi_logloss: 0.220508\n",
      "[46]\tvalid_0's multi_logloss: 0.219959\n",
      "[47]\tvalid_0's multi_logloss: 0.219202\n",
      "[48]\tvalid_0's multi_logloss: 0.218696\n",
      "[49]\tvalid_0's multi_logloss: 0.21816\n",
      "[50]\tvalid_0's multi_logloss: 0.217794\n",
      "[51]\tvalid_0's multi_logloss: 0.217445\n",
      "[52]\tvalid_0's multi_logloss: 0.217052\n",
      "[53]\tvalid_0's multi_logloss: 0.21665\n",
      "[54]\tvalid_0's multi_logloss: 0.216257\n",
      "[55]\tvalid_0's multi_logloss: 0.215891\n",
      "[56]\tvalid_0's multi_logloss: 0.215356\n",
      "[57]\tvalid_0's multi_logloss: 0.215081\n",
      "[58]\tvalid_0's multi_logloss: 0.214709\n",
      "[59]\tvalid_0's multi_logloss: 0.214387\n",
      "[60]\tvalid_0's multi_logloss: 0.214215\n",
      "[61]\tvalid_0's multi_logloss: 0.213921\n",
      "[62]\tvalid_0's multi_logloss: 0.213309\n",
      "[63]\tvalid_0's multi_logloss: 0.212845\n",
      "[64]\tvalid_0's multi_logloss: 0.21255\n",
      "[65]\tvalid_0's multi_logloss: 0.212077\n",
      "[66]\tvalid_0's multi_logloss: 0.211898\n",
      "[67]\tvalid_0's multi_logloss: 0.211681\n",
      "[68]\tvalid_0's multi_logloss: 0.21141\n",
      "[69]\tvalid_0's multi_logloss: 0.211004\n",
      "[70]\tvalid_0's multi_logloss: 0.210717\n",
      "[71]\tvalid_0's multi_logloss: 0.210482\n",
      "[72]\tvalid_0's multi_logloss: 0.209915\n",
      "[73]\tvalid_0's multi_logloss: 0.209594\n",
      "[74]\tvalid_0's multi_logloss: 0.209407\n",
      "[75]\tvalid_0's multi_logloss: 0.209263\n",
      "[76]\tvalid_0's multi_logloss: 0.209137\n",
      "[77]\tvalid_0's multi_logloss: 0.208996\n",
      "[78]\tvalid_0's multi_logloss: 0.208863\n",
      "[79]\tvalid_0's multi_logloss: 0.208341\n",
      "[80]\tvalid_0's multi_logloss: 0.208022\n",
      "[81]\tvalid_0's multi_logloss: 0.207813\n",
      "[82]\tvalid_0's multi_logloss: 0.20769\n",
      "[83]\tvalid_0's multi_logloss: 0.207309\n",
      "[84]\tvalid_0's multi_logloss: 0.207127\n",
      "[85]\tvalid_0's multi_logloss: 0.206925\n",
      "[86]\tvalid_0's multi_logloss: 0.206618\n",
      "[87]\tvalid_0's multi_logloss: 0.206412\n",
      "[88]\tvalid_0's multi_logloss: 0.206257\n",
      "[89]\tvalid_0's multi_logloss: 0.206105\n",
      "[90]\tvalid_0's multi_logloss: 0.205766\n",
      "[91]\tvalid_0's multi_logloss: 0.205584\n",
      "[92]\tvalid_0's multi_logloss: 0.205275\n",
      "[93]\tvalid_0's multi_logloss: 0.205049\n",
      "[94]\tvalid_0's multi_logloss: 0.204849\n",
      "[95]\tvalid_0's multi_logloss: 0.204625\n",
      "[96]\tvalid_0's multi_logloss: 0.204213\n",
      "[97]\tvalid_0's multi_logloss: 0.203985\n",
      "[98]\tvalid_0's multi_logloss: 0.203885\n",
      "[99]\tvalid_0's multi_logloss: 0.203748\n",
      "[100]\tvalid_0's multi_logloss: 0.203605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [44:37, 131.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011284 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 7715638, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -1.249550\n",
      "[LightGBM] [Info] Start training from score -3.165534\n",
      "[LightGBM] [Info] Start training from score -1.726403\n",
      "[LightGBM] [Info] Start training from score -1.902421\n",
      "[LightGBM] [Info] Start training from score -1.667720\n",
      "[LightGBM] [Info] Start training from score -1.861961\n",
      "[1]\tvalid_0's multi_logloss: 1.67875\n",
      "[2]\tvalid_0's multi_logloss: 1.67251\n",
      "[3]\tvalid_0's multi_logloss: 1.6673\n",
      "[4]\tvalid_0's multi_logloss: 1.66284\n",
      "[5]\tvalid_0's multi_logloss: 1.65897\n",
      "[6]\tvalid_0's multi_logloss: 1.65573\n",
      "[7]\tvalid_0's multi_logloss: 1.65285\n",
      "[8]\tvalid_0's multi_logloss: 1.65018\n",
      "[9]\tvalid_0's multi_logloss: 1.64787\n",
      "[10]\tvalid_0's multi_logloss: 1.64598\n",
      "[11]\tvalid_0's multi_logloss: 1.64406\n",
      "[12]\tvalid_0's multi_logloss: 1.64242\n",
      "[13]\tvalid_0's multi_logloss: 1.64087\n",
      "[14]\tvalid_0's multi_logloss: 1.63945\n",
      "[15]\tvalid_0's multi_logloss: 1.63819\n",
      "[16]\tvalid_0's multi_logloss: 1.63699\n",
      "[17]\tvalid_0's multi_logloss: 1.63601\n",
      "[18]\tvalid_0's multi_logloss: 1.63503\n",
      "[19]\tvalid_0's multi_logloss: 1.6341\n",
      "[20]\tvalid_0's multi_logloss: 1.63334\n",
      "[21]\tvalid_0's multi_logloss: 1.63257\n",
      "[22]\tvalid_0's multi_logloss: 1.63189\n",
      "[23]\tvalid_0's multi_logloss: 1.63126\n",
      "[24]\tvalid_0's multi_logloss: 1.63069\n",
      "[25]\tvalid_0's multi_logloss: 1.62992\n",
      "[26]\tvalid_0's multi_logloss: 1.62933\n",
      "[27]\tvalid_0's multi_logloss: 1.62887\n",
      "[28]\tvalid_0's multi_logloss: 1.6284\n",
      "[29]\tvalid_0's multi_logloss: 1.62794\n",
      "[30]\tvalid_0's multi_logloss: 1.6274\n",
      "[31]\tvalid_0's multi_logloss: 1.62697\n",
      "[32]\tvalid_0's multi_logloss: 1.62654\n",
      "[33]\tvalid_0's multi_logloss: 1.62615\n",
      "[34]\tvalid_0's multi_logloss: 1.6258\n",
      "[35]\tvalid_0's multi_logloss: 1.62549\n",
      "[36]\tvalid_0's multi_logloss: 1.6252\n",
      "[37]\tvalid_0's multi_logloss: 1.6246\n",
      "[38]\tvalid_0's multi_logloss: 1.62387\n",
      "[39]\tvalid_0's multi_logloss: 1.62353\n",
      "[40]\tvalid_0's multi_logloss: 1.6232\n",
      "[41]\tvalid_0's multi_logloss: 1.6229\n",
      "[42]\tvalid_0's multi_logloss: 1.62264\n",
      "[43]\tvalid_0's multi_logloss: 1.62237\n",
      "[44]\tvalid_0's multi_logloss: 1.62196\n",
      "[45]\tvalid_0's multi_logloss: 1.62142\n",
      "[46]\tvalid_0's multi_logloss: 1.62117\n",
      "[47]\tvalid_0's multi_logloss: 1.6209\n",
      "[48]\tvalid_0's multi_logloss: 1.62058\n",
      "[49]\tvalid_0's multi_logloss: 1.62027\n",
      "[50]\tvalid_0's multi_logloss: 1.61989\n",
      "[51]\tvalid_0's multi_logloss: 1.61961\n",
      "[52]\tvalid_0's multi_logloss: 1.61939\n",
      "[53]\tvalid_0's multi_logloss: 1.61911\n",
      "[54]\tvalid_0's multi_logloss: 1.61886\n",
      "[55]\tvalid_0's multi_logloss: 1.61862\n",
      "[56]\tvalid_0's multi_logloss: 1.61815\n",
      "[57]\tvalid_0's multi_logloss: 1.61797\n",
      "[58]\tvalid_0's multi_logloss: 1.6178\n",
      "[59]\tvalid_0's multi_logloss: 1.61734\n",
      "[60]\tvalid_0's multi_logloss: 1.61707\n",
      "[61]\tvalid_0's multi_logloss: 1.61661\n",
      "[62]\tvalid_0's multi_logloss: 1.61612\n",
      "[63]\tvalid_0's multi_logloss: 1.61578\n",
      "[64]\tvalid_0's multi_logloss: 1.6153\n",
      "[65]\tvalid_0's multi_logloss: 1.61513\n",
      "[66]\tvalid_0's multi_logloss: 1.61497\n",
      "[67]\tvalid_0's multi_logloss: 1.61466\n",
      "[68]\tvalid_0's multi_logloss: 1.61451\n",
      "[69]\tvalid_0's multi_logloss: 1.61428\n",
      "[70]\tvalid_0's multi_logloss: 1.61413\n",
      "[71]\tvalid_0's multi_logloss: 1.61385\n",
      "[72]\tvalid_0's multi_logloss: 1.61369\n",
      "[73]\tvalid_0's multi_logloss: 1.61349\n",
      "[74]\tvalid_0's multi_logloss: 1.61336\n",
      "[75]\tvalid_0's multi_logloss: 1.61312\n",
      "[76]\tvalid_0's multi_logloss: 1.61295\n",
      "[77]\tvalid_0's multi_logloss: 1.61263\n",
      "[78]\tvalid_0's multi_logloss: 1.61227\n",
      "[79]\tvalid_0's multi_logloss: 1.61212\n",
      "[80]\tvalid_0's multi_logloss: 1.61178\n",
      "[81]\tvalid_0's multi_logloss: 1.61159\n",
      "[82]\tvalid_0's multi_logloss: 1.61138\n",
      "[83]\tvalid_0's multi_logloss: 1.61117\n",
      "[84]\tvalid_0's multi_logloss: 1.61106\n",
      "[85]\tvalid_0's multi_logloss: 1.61083\n",
      "[86]\tvalid_0's multi_logloss: 1.6107\n",
      "[87]\tvalid_0's multi_logloss: 1.6106\n",
      "[88]\tvalid_0's multi_logloss: 1.61049\n",
      "[89]\tvalid_0's multi_logloss: 1.61011\n",
      "[90]\tvalid_0's multi_logloss: 1.6099\n",
      "[91]\tvalid_0's multi_logloss: 1.60971\n",
      "[92]\tvalid_0's multi_logloss: 1.60957\n",
      "[93]\tvalid_0's multi_logloss: 1.60942\n",
      "[94]\tvalid_0's multi_logloss: 1.60923\n",
      "[95]\tvalid_0's multi_logloss: 1.60904\n",
      "[96]\tvalid_0's multi_logloss: 1.60872\n",
      "[97]\tvalid_0's multi_logloss: 1.60861\n",
      "[98]\tvalid_0's multi_logloss: 1.60847\n",
      "[99]\tvalid_0's multi_logloss: 1.60839\n",
      "[100]\tvalid_0's multi_logloss: 1.60823\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007770 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 7715638, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -3.388563\n",
      "[LightGBM] [Info] Start training from score -3.286043\n",
      "[LightGBM] [Info] Start training from score -3.265766\n",
      "[LightGBM] [Info] Start training from score -3.814547\n",
      "[LightGBM] [Info] Start training from score -3.310265\n",
      "[LightGBM] [Info] Start training from score -3.206426\n",
      "[LightGBM] [Info] Start training from score -4.264605\n",
      "[LightGBM] [Info] Start training from score -3.385622\n",
      "[LightGBM] [Info] Start training from score -3.678169\n",
      "[LightGBM] [Info] Start training from score -3.401590\n",
      "[LightGBM] [Info] Start training from score -4.879144\n",
      "[LightGBM] [Info] Start training from score -3.027581\n",
      "[LightGBM] [Info] Start training from score -2.985319\n",
      "[LightGBM] [Info] Start training from score -3.251856\n",
      "[LightGBM] [Info] Start training from score -3.294527\n",
      "[LightGBM] [Info] Start training from score -3.372086\n",
      "[LightGBM] [Info] Start training from score -2.973489\n",
      "[LightGBM] [Info] Start training from score -2.489644\n",
      "[LightGBM] [Info] Start training from score -3.403357\n",
      "[LightGBM] [Info] Start training from score -4.161407\n",
      "[LightGBM] [Info] Start training from score -4.219942\n",
      "[LightGBM] [Info] Start training from score -3.454308\n",
      "[LightGBM] [Info] Start training from score -3.414970\n",
      "[LightGBM] [Info] Start training from score -3.160243\n",
      "[LightGBM] [Info] Start training from score -3.113230\n",
      "[LightGBM] [Info] Start training from score -3.209175\n",
      "[LightGBM] [Info] Start training from score -3.282600\n",
      "[LightGBM] [Info] Start training from score -3.180636\n",
      "[1]\tvalid_0's multi_logloss: 2.78547\n",
      "[2]\tvalid_0's multi_logloss: 2.62099\n",
      "[3]\tvalid_0's multi_logloss: 2.50459\n",
      "[4]\tvalid_0's multi_logloss: 2.41722\n",
      "[5]\tvalid_0's multi_logloss: 2.34228\n",
      "[6]\tvalid_0's multi_logloss: 2.28777\n",
      "[7]\tvalid_0's multi_logloss: 2.2342\n",
      "[8]\tvalid_0's multi_logloss: 2.19059\n",
      "[9]\tvalid_0's multi_logloss: 2.15473\n",
      "[10]\tvalid_0's multi_logloss: 2.12447\n",
      "[11]\tvalid_0's multi_logloss: 2.09747\n",
      "[12]\tvalid_0's multi_logloss: 2.07269\n",
      "[13]\tvalid_0's multi_logloss: 2.05138\n",
      "[14]\tvalid_0's multi_logloss: 2.0316\n",
      "[15]\tvalid_0's multi_logloss: 2.01352\n",
      "[16]\tvalid_0's multi_logloss: 1.99851\n",
      "[17]\tvalid_0's multi_logloss: 1.98399\n",
      "[18]\tvalid_0's multi_logloss: 1.97076\n",
      "[19]\tvalid_0's multi_logloss: 1.95879\n",
      "[20]\tvalid_0's multi_logloss: 1.94694\n",
      "[21]\tvalid_0's multi_logloss: 1.93689\n",
      "[22]\tvalid_0's multi_logloss: 1.92745\n",
      "[23]\tvalid_0's multi_logloss: 1.9196\n",
      "[24]\tvalid_0's multi_logloss: 1.91091\n",
      "[25]\tvalid_0's multi_logloss: 1.90392\n",
      "[26]\tvalid_0's multi_logloss: 1.89603\n",
      "[27]\tvalid_0's multi_logloss: 1.88968\n",
      "[28]\tvalid_0's multi_logloss: 1.88426\n",
      "[29]\tvalid_0's multi_logloss: 1.87792\n",
      "[30]\tvalid_0's multi_logloss: 1.87137\n",
      "[31]\tvalid_0's multi_logloss: 1.86593\n",
      "[32]\tvalid_0's multi_logloss: 1.86071\n",
      "[33]\tvalid_0's multi_logloss: 1.8558\n",
      "[34]\tvalid_0's multi_logloss: 1.85097\n",
      "[35]\tvalid_0's multi_logloss: 1.84633\n",
      "[36]\tvalid_0's multi_logloss: 1.84082\n",
      "[37]\tvalid_0's multi_logloss: 1.83805\n",
      "[38]\tvalid_0's multi_logloss: 1.83308\n",
      "[39]\tvalid_0's multi_logloss: 1.83002\n",
      "[40]\tvalid_0's multi_logloss: 1.82626\n",
      "[41]\tvalid_0's multi_logloss: 1.82119\n",
      "[42]\tvalid_0's multi_logloss: 1.81804\n",
      "[43]\tvalid_0's multi_logloss: 1.81487\n",
      "[44]\tvalid_0's multi_logloss: 1.81133\n",
      "[45]\tvalid_0's multi_logloss: 1.80802\n",
      "[46]\tvalid_0's multi_logloss: 1.80545\n",
      "[47]\tvalid_0's multi_logloss: 1.80183\n",
      "[48]\tvalid_0's multi_logloss: 1.8\n",
      "[49]\tvalid_0's multi_logloss: 1.79571\n",
      "[50]\tvalid_0's multi_logloss: 1.79495\n",
      "[51]\tvalid_0's multi_logloss: 1.79246\n",
      "[52]\tvalid_0's multi_logloss: 1.78823\n",
      "[53]\tvalid_0's multi_logloss: 1.78595\n",
      "[54]\tvalid_0's multi_logloss: 1.78474\n",
      "[55]\tvalid_0's multi_logloss: 1.78227\n",
      "[56]\tvalid_0's multi_logloss: 1.78145\n",
      "[57]\tvalid_0's multi_logloss: 1.77504\n",
      "[58]\tvalid_0's multi_logloss: 1.77764\n",
      "[59]\tvalid_0's multi_logloss: 1.77111\n",
      "[60]\tvalid_0's multi_logloss: 1.77103\n",
      "[61]\tvalid_0's multi_logloss: 1.76997\n",
      "[62]\tvalid_0's multi_logloss: 1.76546\n",
      "[63]\tvalid_0's multi_logloss: 1.76287\n",
      "[64]\tvalid_0's multi_logloss: 1.7651\n",
      "[65]\tvalid_0's multi_logloss: 1.76255\n",
      "[66]\tvalid_0's multi_logloss: 1.75958\n",
      "[67]\tvalid_0's multi_logloss: 1.75803\n",
      "[68]\tvalid_0's multi_logloss: 1.75369\n",
      "[69]\tvalid_0's multi_logloss: 1.75328\n",
      "[70]\tvalid_0's multi_logloss: 1.75013\n",
      "[71]\tvalid_0's multi_logloss: 1.75082\n",
      "[72]\tvalid_0's multi_logloss: 1.74576\n",
      "[73]\tvalid_0's multi_logloss: 1.74746\n",
      "[74]\tvalid_0's multi_logloss: 1.74433\n",
      "[75]\tvalid_0's multi_logloss: 1.74325\n",
      "[76]\tvalid_0's multi_logloss: 1.74209\n",
      "[77]\tvalid_0's multi_logloss: 1.738\n",
      "[78]\tvalid_0's multi_logloss: 1.73748\n",
      "[79]\tvalid_0's multi_logloss: 1.73638\n",
      "[80]\tvalid_0's multi_logloss: 1.73157\n",
      "[81]\tvalid_0's multi_logloss: 1.73043\n",
      "[82]\tvalid_0's multi_logloss: 1.73166\n",
      "[83]\tvalid_0's multi_logloss: 1.72776\n",
      "[84]\tvalid_0's multi_logloss: 1.72845\n",
      "[85]\tvalid_0's multi_logloss: 1.72457\n",
      "[86]\tvalid_0's multi_logloss: 1.72855\n",
      "[87]\tvalid_0's multi_logloss: 1.72245\n",
      "[88]\tvalid_0's multi_logloss: 1.72674\n",
      "[89]\tvalid_0's multi_logloss: 1.72486\n",
      "[90]\tvalid_0's multi_logloss: 1.72393\n",
      "[91]\tvalid_0's multi_logloss: 1.71744\n",
      "[92]\tvalid_0's multi_logloss: 1.7167\n",
      "[93]\tvalid_0's multi_logloss: 1.71777\n",
      "[94]\tvalid_0's multi_logloss: 1.71355\n",
      "[95]\tvalid_0's multi_logloss: 1.71415\n",
      "[96]\tvalid_0's multi_logloss: 1.71172\n",
      "[97]\tvalid_0's multi_logloss: 1.71334\n",
      "[98]\tvalid_0's multi_logloss: 1.7156\n",
      "[99]\tvalid_0's multi_logloss: 1.70734\n",
      "[100]\tvalid_0's multi_logloss: 1.7076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [46:16, 121.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001212 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 820733, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -0.683185\n",
      "[LightGBM] [Info] Start training from score -2.382997\n",
      "[LightGBM] [Info] Start training from score -2.734975\n",
      "[LightGBM] [Info] Start training from score -3.826068\n",
      "[LightGBM] [Info] Start training from score -1.583719\n",
      "[LightGBM] [Info] Start training from score -2.199855\n",
      "[1]\tvalid_0's multi_logloss: 1.14944\n",
      "[2]\tvalid_0's multi_logloss: 1.02924\n",
      "[3]\tvalid_0's multi_logloss: 0.938235\n",
      "[4]\tvalid_0's multi_logloss: 0.866785\n",
      "[5]\tvalid_0's multi_logloss: 0.809369\n",
      "[6]\tvalid_0's multi_logloss: 0.761987\n",
      "[7]\tvalid_0's multi_logloss: 0.722944\n",
      "[8]\tvalid_0's multi_logloss: 0.689677\n",
      "[9]\tvalid_0's multi_logloss: 0.661865\n",
      "[10]\tvalid_0's multi_logloss: 0.63828\n",
      "[11]\tvalid_0's multi_logloss: 0.617821\n",
      "[12]\tvalid_0's multi_logloss: 0.600235\n",
      "[13]\tvalid_0's multi_logloss: 0.585011\n",
      "[14]\tvalid_0's multi_logloss: 0.571566\n",
      "[15]\tvalid_0's multi_logloss: 0.560214\n",
      "[16]\tvalid_0's multi_logloss: 0.550299\n",
      "[17]\tvalid_0's multi_logloss: 0.541495\n",
      "[18]\tvalid_0's multi_logloss: 0.53303\n",
      "[19]\tvalid_0's multi_logloss: 0.526011\n",
      "[20]\tvalid_0's multi_logloss: 0.519437\n",
      "[21]\tvalid_0's multi_logloss: 0.513426\n",
      "[22]\tvalid_0's multi_logloss: 0.50833\n",
      "[23]\tvalid_0's multi_logloss: 0.503736\n",
      "[24]\tvalid_0's multi_logloss: 0.499552\n",
      "[25]\tvalid_0's multi_logloss: 0.495738\n",
      "[26]\tvalid_0's multi_logloss: 0.492232\n",
      "[27]\tvalid_0's multi_logloss: 0.4892\n",
      "[28]\tvalid_0's multi_logloss: 0.486441\n",
      "[29]\tvalid_0's multi_logloss: 0.4838\n",
      "[30]\tvalid_0's multi_logloss: 0.481374\n",
      "[31]\tvalid_0's multi_logloss: 0.47922\n",
      "[32]\tvalid_0's multi_logloss: 0.477112\n",
      "[33]\tvalid_0's multi_logloss: 0.475219\n",
      "[34]\tvalid_0's multi_logloss: 0.473504\n",
      "[35]\tvalid_0's multi_logloss: 0.47178\n",
      "[36]\tvalid_0's multi_logloss: 0.470347\n",
      "[37]\tvalid_0's multi_logloss: 0.46894\n",
      "[38]\tvalid_0's multi_logloss: 0.467506\n",
      "[39]\tvalid_0's multi_logloss: 0.466301\n",
      "[40]\tvalid_0's multi_logloss: 0.465426\n",
      "[41]\tvalid_0's multi_logloss: 0.464546\n",
      "[42]\tvalid_0's multi_logloss: 0.46317\n",
      "[43]\tvalid_0's multi_logloss: 0.462195\n",
      "[44]\tvalid_0's multi_logloss: 0.46131\n",
      "[45]\tvalid_0's multi_logloss: 0.460327\n",
      "[46]\tvalid_0's multi_logloss: 0.459536\n",
      "[47]\tvalid_0's multi_logloss: 0.458845\n",
      "[48]\tvalid_0's multi_logloss: 0.458094\n",
      "[49]\tvalid_0's multi_logloss: 0.457564\n",
      "[50]\tvalid_0's multi_logloss: 0.456831\n",
      "[51]\tvalid_0's multi_logloss: 0.456185\n",
      "[52]\tvalid_0's multi_logloss: 0.455611\n",
      "[53]\tvalid_0's multi_logloss: 0.455136\n",
      "[54]\tvalid_0's multi_logloss: 0.454536\n",
      "[55]\tvalid_0's multi_logloss: 0.454096\n",
      "[56]\tvalid_0's multi_logloss: 0.453565\n",
      "[57]\tvalid_0's multi_logloss: 0.453076\n",
      "[58]\tvalid_0's multi_logloss: 0.452668\n",
      "[59]\tvalid_0's multi_logloss: 0.452524\n",
      "[60]\tvalid_0's multi_logloss: 0.451883\n",
      "[61]\tvalid_0's multi_logloss: 0.452354\n",
      "[62]\tvalid_0's multi_logloss: 0.451171\n",
      "[63]\tvalid_0's multi_logloss: 0.450807\n",
      "[64]\tvalid_0's multi_logloss: 0.450354\n",
      "[65]\tvalid_0's multi_logloss: 0.450964\n",
      "[66]\tvalid_0's multi_logloss: 0.452334\n",
      "[67]\tvalid_0's multi_logloss: 0.45035\n",
      "[68]\tvalid_0's multi_logloss: 0.450974\n",
      "[69]\tvalid_0's multi_logloss: 0.454671\n",
      "[70]\tvalid_0's multi_logloss: 0.44929\n",
      "[71]\tvalid_0's multi_logloss: 0.449846\n",
      "[72]\tvalid_0's multi_logloss: 0.454595\n",
      "[73]\tvalid_0's multi_logloss: 0.450072\n",
      "[74]\tvalid_0's multi_logloss: 0.449914\n",
      "[75]\tvalid_0's multi_logloss: 0.452312\n",
      "[76]\tvalid_0's multi_logloss: 0.448614\n",
      "[77]\tvalid_0's multi_logloss: 0.448066\n",
      "[78]\tvalid_0's multi_logloss: 0.447861\n",
      "[79]\tvalid_0's multi_logloss: 0.447659\n",
      "[80]\tvalid_0's multi_logloss: 0.456435\n",
      "[81]\tvalid_0's multi_logloss: 0.45215\n",
      "[82]\tvalid_0's multi_logloss: 0.446846\n",
      "[83]\tvalid_0's multi_logloss: 0.459796\n",
      "[84]\tvalid_0's multi_logloss: 0.453741\n",
      "[85]\tvalid_0's multi_logloss: 0.446661\n",
      "[86]\tvalid_0's multi_logloss: 0.446524\n",
      "[87]\tvalid_0's multi_logloss: 0.450299\n",
      "[88]\tvalid_0's multi_logloss: 0.445758\n",
      "[89]\tvalid_0's multi_logloss: 0.445646\n",
      "[90]\tvalid_0's multi_logloss: 0.447207\n",
      "[91]\tvalid_0's multi_logloss: 0.445455\n",
      "[92]\tvalid_0's multi_logloss: 0.445563\n",
      "[93]\tvalid_0's multi_logloss: 0.470804\n",
      "[94]\tvalid_0's multi_logloss: 0.462522\n",
      "[95]\tvalid_0's multi_logloss: 0.457703\n",
      "[96]\tvalid_0's multi_logloss: 0.445552\n",
      "[97]\tvalid_0's multi_logloss: 0.444855\n",
      "[98]\tvalid_0's multi_logloss: 0.444561\n",
      "[99]\tvalid_0's multi_logloss: 0.444439\n",
      "[100]\tvalid_0's multi_logloss: 0.444291\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001329 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 820733, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -2.163833\n",
      "[LightGBM] [Info] Start training from score -1.796397\n",
      "[LightGBM] [Info] Start training from score -1.843741\n",
      "[LightGBM] [Info] Start training from score -1.989576\n",
      "[LightGBM] [Info] Start training from score -1.941218\n",
      "[LightGBM] [Info] Start training from score -1.949016\n",
      "[LightGBM] [Info] Start training from score -1.978333\n",
      "[1]\tvalid_0's multi_logloss: 1.89931\n",
      "[2]\tvalid_0's multi_logloss: 1.86786\n",
      "[3]\tvalid_0's multi_logloss: 1.84293\n",
      "[4]\tvalid_0's multi_logloss: 1.8225\n",
      "[5]\tvalid_0's multi_logloss: 1.80577\n",
      "[6]\tvalid_0's multi_logloss: 1.7919\n",
      "[7]\tvalid_0's multi_logloss: 1.78038\n",
      "[8]\tvalid_0's multi_logloss: 1.77083\n",
      "[9]\tvalid_0's multi_logloss: 1.76274\n",
      "[10]\tvalid_0's multi_logloss: 1.75589\n",
      "[11]\tvalid_0's multi_logloss: 1.75007\n",
      "[12]\tvalid_0's multi_logloss: 1.74492\n",
      "[13]\tvalid_0's multi_logloss: 1.74046\n",
      "[14]\tvalid_0's multi_logloss: 1.73674\n",
      "[15]\tvalid_0's multi_logloss: 1.73348\n",
      "[16]\tvalid_0's multi_logloss: 1.7307\n",
      "[17]\tvalid_0's multi_logloss: 1.72816\n",
      "[18]\tvalid_0's multi_logloss: 1.72595\n",
      "[19]\tvalid_0's multi_logloss: 1.72394\n",
      "[20]\tvalid_0's multi_logloss: 1.72222\n",
      "[21]\tvalid_0's multi_logloss: 1.72058\n",
      "[22]\tvalid_0's multi_logloss: 1.71913\n",
      "[23]\tvalid_0's multi_logloss: 1.71788\n",
      "[24]\tvalid_0's multi_logloss: 1.71662\n",
      "[25]\tvalid_0's multi_logloss: 1.71551\n",
      "[26]\tvalid_0's multi_logloss: 1.71453\n",
      "[27]\tvalid_0's multi_logloss: 1.71357\n",
      "[28]\tvalid_0's multi_logloss: 1.71271\n",
      "[29]\tvalid_0's multi_logloss: 1.71195\n",
      "[30]\tvalid_0's multi_logloss: 1.71132\n",
      "[31]\tvalid_0's multi_logloss: 1.71061\n",
      "[32]\tvalid_0's multi_logloss: 1.70993\n",
      "[33]\tvalid_0's multi_logloss: 1.70935\n",
      "[34]\tvalid_0's multi_logloss: 1.7087\n",
      "[35]\tvalid_0's multi_logloss: 1.70817\n",
      "[36]\tvalid_0's multi_logloss: 1.70758\n",
      "[37]\tvalid_0's multi_logloss: 1.70715\n",
      "[38]\tvalid_0's multi_logloss: 1.70669\n",
      "[39]\tvalid_0's multi_logloss: 1.70622\n",
      "[40]\tvalid_0's multi_logloss: 1.70591\n",
      "[41]\tvalid_0's multi_logloss: 1.70547\n",
      "[42]\tvalid_0's multi_logloss: 1.70508\n",
      "[43]\tvalid_0's multi_logloss: 1.70467\n",
      "[44]\tvalid_0's multi_logloss: 1.70437\n",
      "[45]\tvalid_0's multi_logloss: 1.70412\n",
      "[46]\tvalid_0's multi_logloss: 1.70376\n",
      "[47]\tvalid_0's multi_logloss: 1.7034\n",
      "[48]\tvalid_0's multi_logloss: 1.70308\n",
      "[49]\tvalid_0's multi_logloss: 1.70276\n",
      "[50]\tvalid_0's multi_logloss: 1.70252\n",
      "[51]\tvalid_0's multi_logloss: 1.70228\n",
      "[52]\tvalid_0's multi_logloss: 1.70205\n",
      "[53]\tvalid_0's multi_logloss: 1.70178\n",
      "[54]\tvalid_0's multi_logloss: 1.70156\n",
      "[55]\tvalid_0's multi_logloss: 1.70144\n",
      "[56]\tvalid_0's multi_logloss: 1.70129\n",
      "[57]\tvalid_0's multi_logloss: 1.70107\n",
      "[58]\tvalid_0's multi_logloss: 1.70086\n",
      "[59]\tvalid_0's multi_logloss: 1.70068\n",
      "[60]\tvalid_0's multi_logloss: 1.70053\n",
      "[61]\tvalid_0's multi_logloss: 1.70041\n",
      "[62]\tvalid_0's multi_logloss: 1.70028\n",
      "[63]\tvalid_0's multi_logloss: 1.70001\n",
      "[64]\tvalid_0's multi_logloss: 1.69983\n",
      "[65]\tvalid_0's multi_logloss: 1.69965\n",
      "[66]\tvalid_0's multi_logloss: 1.69948\n",
      "[67]\tvalid_0's multi_logloss: 1.69929\n",
      "[68]\tvalid_0's multi_logloss: 1.69912\n",
      "[69]\tvalid_0's multi_logloss: 1.69901\n",
      "[70]\tvalid_0's multi_logloss: 1.69886\n",
      "[71]\tvalid_0's multi_logloss: 1.69867\n",
      "[72]\tvalid_0's multi_logloss: 1.69858\n",
      "[73]\tvalid_0's multi_logloss: 1.69849\n",
      "[74]\tvalid_0's multi_logloss: 1.69834\n",
      "[75]\tvalid_0's multi_logloss: 1.69822\n",
      "[76]\tvalid_0's multi_logloss: 1.69809\n",
      "[77]\tvalid_0's multi_logloss: 1.69788\n",
      "[78]\tvalid_0's multi_logloss: 1.6978\n",
      "[79]\tvalid_0's multi_logloss: 1.69767\n",
      "[80]\tvalid_0's multi_logloss: 1.69756\n",
      "[81]\tvalid_0's multi_logloss: 1.69745\n",
      "[82]\tvalid_0's multi_logloss: 1.69739\n",
      "[83]\tvalid_0's multi_logloss: 1.69725\n",
      "[84]\tvalid_0's multi_logloss: 1.69714\n",
      "[85]\tvalid_0's multi_logloss: 1.69703\n",
      "[86]\tvalid_0's multi_logloss: 1.69691\n",
      "[87]\tvalid_0's multi_logloss: 1.69676\n",
      "[88]\tvalid_0's multi_logloss: 1.69667\n",
      "[89]\tvalid_0's multi_logloss: 1.69653\n",
      "[90]\tvalid_0's multi_logloss: 1.69642\n",
      "[91]\tvalid_0's multi_logloss: 1.69631\n",
      "[92]\tvalid_0's multi_logloss: 1.6962\n",
      "[93]\tvalid_0's multi_logloss: 1.69607\n",
      "[94]\tvalid_0's multi_logloss: 1.696\n",
      "[95]\tvalid_0's multi_logloss: 1.69589\n",
      "[96]\tvalid_0's multi_logloss: 1.69579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [46:24, 87.38s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[97]\tvalid_0's multi_logloss: 1.6957\n",
      "[98]\tvalid_0's multi_logloss: 1.69558\n",
      "[99]\tvalid_0's multi_logloss: 1.69547\n",
      "[100]\tvalid_0's multi_logloss: 1.69538\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027372 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -1.853404\n",
      "[LightGBM] [Info] Start training from score -2.123202\n",
      "[LightGBM] [Info] Start training from score -2.391862\n",
      "[LightGBM] [Info] Start training from score -2.719639\n",
      "[LightGBM] [Info] Start training from score -2.078311\n",
      "[LightGBM] [Info] Start training from score -2.161447\n",
      "[LightGBM] [Info] Start training from score -2.497610\n",
      "[LightGBM] [Info] Start training from score -2.232530\n",
      "[LightGBM] [Info] Start training from score -2.689447\n",
      "[LightGBM] [Info] Start training from score -2.680407\n",
      "[1]\tvalid_0's multi_logloss: 1.83797\n",
      "[2]\tvalid_0's multi_logloss: 1.62775\n",
      "[3]\tvalid_0's multi_logloss: 1.48254\n",
      "[4]\tvalid_0's multi_logloss: 1.37376\n",
      "[5]\tvalid_0's multi_logloss: 1.28726\n",
      "[6]\tvalid_0's multi_logloss: 1.21677\n",
      "[7]\tvalid_0's multi_logloss: 1.1593\n",
      "[8]\tvalid_0's multi_logloss: 1.11108\n",
      "[9]\tvalid_0's multi_logloss: 1.07063\n",
      "[10]\tvalid_0's multi_logloss: 1.03731\n",
      "[11]\tvalid_0's multi_logloss: 1.0065\n",
      "[12]\tvalid_0's multi_logloss: 0.980049\n",
      "[13]\tvalid_0's multi_logloss: 0.957662\n",
      "[14]\tvalid_0's multi_logloss: 0.938432\n",
      "[15]\tvalid_0's multi_logloss: 0.920999\n",
      "[16]\tvalid_0's multi_logloss: 0.905722\n",
      "[17]\tvalid_0's multi_logloss: 0.891789\n",
      "[18]\tvalid_0's multi_logloss: 0.87935\n",
      "[19]\tvalid_0's multi_logloss: 0.868336\n",
      "[20]\tvalid_0's multi_logloss: 0.858129\n",
      "[21]\tvalid_0's multi_logloss: 0.849263\n",
      "[22]\tvalid_0's multi_logloss: 0.841363\n",
      "[23]\tvalid_0's multi_logloss: 0.833903\n",
      "[24]\tvalid_0's multi_logloss: 0.826808\n",
      "[25]\tvalid_0's multi_logloss: 0.82039\n",
      "[26]\tvalid_0's multi_logloss: 0.814326\n",
      "[27]\tvalid_0's multi_logloss: 0.808813\n",
      "[28]\tvalid_0's multi_logloss: 0.803263\n",
      "[29]\tvalid_0's multi_logloss: 0.798407\n",
      "[30]\tvalid_0's multi_logloss: 0.794075\n",
      "[31]\tvalid_0's multi_logloss: 0.789303\n",
      "[32]\tvalid_0's multi_logloss: 0.78543\n",
      "[33]\tvalid_0's multi_logloss: 0.781627\n",
      "[34]\tvalid_0's multi_logloss: 0.777867\n",
      "[35]\tvalid_0's multi_logloss: 0.774463\n",
      "[36]\tvalid_0's multi_logloss: 0.770991\n",
      "[37]\tvalid_0's multi_logloss: 0.768094\n",
      "[38]\tvalid_0's multi_logloss: 0.764975\n",
      "[39]\tvalid_0's multi_logloss: 0.762168\n",
      "[40]\tvalid_0's multi_logloss: 0.759438\n",
      "[41]\tvalid_0's multi_logloss: 0.756698\n",
      "[42]\tvalid_0's multi_logloss: 0.75455\n",
      "[43]\tvalid_0's multi_logloss: 0.751976\n",
      "[44]\tvalid_0's multi_logloss: 0.749848\n",
      "[45]\tvalid_0's multi_logloss: 0.747777\n",
      "[46]\tvalid_0's multi_logloss: 0.745722\n",
      "[47]\tvalid_0's multi_logloss: 0.743674\n",
      "[48]\tvalid_0's multi_logloss: 0.741674\n",
      "[49]\tvalid_0's multi_logloss: 0.739806\n",
      "[50]\tvalid_0's multi_logloss: 0.737918\n",
      "[51]\tvalid_0's multi_logloss: 0.73631\n",
      "[52]\tvalid_0's multi_logloss: 0.734671\n",
      "[53]\tvalid_0's multi_logloss: 0.733115\n",
      "[54]\tvalid_0's multi_logloss: 0.731439\n",
      "[55]\tvalid_0's multi_logloss: 0.729987\n",
      "[56]\tvalid_0's multi_logloss: 0.728649\n",
      "[57]\tvalid_0's multi_logloss: 0.727325\n",
      "[58]\tvalid_0's multi_logloss: 0.725957\n",
      "[59]\tvalid_0's multi_logloss: 0.724597\n",
      "[60]\tvalid_0's multi_logloss: 0.723274\n",
      "[61]\tvalid_0's multi_logloss: 0.722051\n",
      "[62]\tvalid_0's multi_logloss: 0.720873\n",
      "[63]\tvalid_0's multi_logloss: 0.719545\n",
      "[64]\tvalid_0's multi_logloss: 0.718482\n",
      "[65]\tvalid_0's multi_logloss: 0.717448\n",
      "[66]\tvalid_0's multi_logloss: 0.716321\n",
      "[67]\tvalid_0's multi_logloss: 0.715401\n",
      "[68]\tvalid_0's multi_logloss: 0.714347\n",
      "[69]\tvalid_0's multi_logloss: 0.713327\n",
      "[70]\tvalid_0's multi_logloss: 0.712376\n",
      "[71]\tvalid_0's multi_logloss: 0.711374\n",
      "[72]\tvalid_0's multi_logloss: 0.710394\n",
      "[73]\tvalid_0's multi_logloss: 0.709471\n",
      "[74]\tvalid_0's multi_logloss: 0.708582\n",
      "[75]\tvalid_0's multi_logloss: 0.707756\n",
      "[76]\tvalid_0's multi_logloss: 0.706876\n",
      "[77]\tvalid_0's multi_logloss: 0.70608\n",
      "[78]\tvalid_0's multi_logloss: 0.705251\n",
      "[79]\tvalid_0's multi_logloss: 0.704454\n",
      "[80]\tvalid_0's multi_logloss: 0.703777\n",
      "[81]\tvalid_0's multi_logloss: 0.703023\n",
      "[82]\tvalid_0's multi_logloss: 0.702389\n",
      "[83]\tvalid_0's multi_logloss: 0.701713\n",
      "[84]\tvalid_0's multi_logloss: 0.70102\n",
      "[85]\tvalid_0's multi_logloss: 0.700358\n",
      "[86]\tvalid_0's multi_logloss: 0.699678\n",
      "[87]\tvalid_0's multi_logloss: 0.69908\n",
      "[88]\tvalid_0's multi_logloss: 0.698314\n",
      "[89]\tvalid_0's multi_logloss: 0.697635\n",
      "[90]\tvalid_0's multi_logloss: 0.69703\n",
      "[91]\tvalid_0's multi_logloss: 0.696425\n",
      "[92]\tvalid_0's multi_logloss: 0.695793\n",
      "[93]\tvalid_0's multi_logloss: 0.695274\n",
      "[94]\tvalid_0's multi_logloss: 0.694718\n",
      "[95]\tvalid_0's multi_logloss: 0.694094\n",
      "[96]\tvalid_0's multi_logloss: 0.693528\n",
      "[97]\tvalid_0's multi_logloss: 0.693018\n",
      "[98]\tvalid_0's multi_logloss: 0.692523\n",
      "[99]\tvalid_0's multi_logloss: 0.692058\n",
      "[100]\tvalid_0's multi_logloss: 0.691542\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026760 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -1.047228\n",
      "[LightGBM] [Info] Start training from score -1.516216\n",
      "[LightGBM] [Info] Start training from score -0.845018\n",
      "[1]\tvalid_0's multi_logloss: 1.0073\n",
      "[2]\tvalid_0's multi_logloss: 0.961591\n",
      "[3]\tvalid_0's multi_logloss: 0.923893\n",
      "[4]\tvalid_0's multi_logloss: 0.892204\n",
      "[5]\tvalid_0's multi_logloss: 0.865209\n",
      "[6]\tvalid_0's multi_logloss: 0.842155\n",
      "[7]\tvalid_0's multi_logloss: 0.822108\n",
      "[8]\tvalid_0's multi_logloss: 0.804723\n",
      "[9]\tvalid_0's multi_logloss: 0.78947\n",
      "[10]\tvalid_0's multi_logloss: 0.776019\n",
      "[11]\tvalid_0's multi_logloss: 0.764087\n",
      "[12]\tvalid_0's multi_logloss: 0.7535\n",
      "[13]\tvalid_0's multi_logloss: 0.743956\n",
      "[14]\tvalid_0's multi_logloss: 0.73542\n",
      "[15]\tvalid_0's multi_logloss: 0.727672\n",
      "[16]\tvalid_0's multi_logloss: 0.720615\n",
      "[17]\tvalid_0's multi_logloss: 0.714086\n",
      "[18]\tvalid_0's multi_logloss: 0.70812\n",
      "[19]\tvalid_0's multi_logloss: 0.70277\n",
      "[20]\tvalid_0's multi_logloss: 0.697899\n",
      "[21]\tvalid_0's multi_logloss: 0.693399\n",
      "[22]\tvalid_0's multi_logloss: 0.689239\n",
      "[23]\tvalid_0's multi_logloss: 0.685382\n",
      "[24]\tvalid_0's multi_logloss: 0.681685\n",
      "[25]\tvalid_0's multi_logloss: 0.678364\n",
      "[26]\tvalid_0's multi_logloss: 0.675348\n",
      "[27]\tvalid_0's multi_logloss: 0.672428\n",
      "[28]\tvalid_0's multi_logloss: 0.669761\n",
      "[29]\tvalid_0's multi_logloss: 0.667333\n",
      "[30]\tvalid_0's multi_logloss: 0.665043\n",
      "[31]\tvalid_0's multi_logloss: 0.66293\n",
      "[32]\tvalid_0's multi_logloss: 0.660927\n",
      "[33]\tvalid_0's multi_logloss: 0.659132\n",
      "[34]\tvalid_0's multi_logloss: 0.657453\n",
      "[35]\tvalid_0's multi_logloss: 0.655837\n",
      "[36]\tvalid_0's multi_logloss: 0.654365\n",
      "[37]\tvalid_0's multi_logloss: 0.652984\n",
      "[38]\tvalid_0's multi_logloss: 0.651721\n",
      "[39]\tvalid_0's multi_logloss: 0.650492\n",
      "[40]\tvalid_0's multi_logloss: 0.649283\n",
      "[41]\tvalid_0's multi_logloss: 0.648232\n",
      "[42]\tvalid_0's multi_logloss: 0.647259\n",
      "[43]\tvalid_0's multi_logloss: 0.646328\n",
      "[44]\tvalid_0's multi_logloss: 0.645362\n",
      "[45]\tvalid_0's multi_logloss: 0.644553\n",
      "[46]\tvalid_0's multi_logloss: 0.643748\n",
      "[47]\tvalid_0's multi_logloss: 0.642985\n",
      "[48]\tvalid_0's multi_logloss: 0.642209\n",
      "[49]\tvalid_0's multi_logloss: 0.641537\n",
      "[50]\tvalid_0's multi_logloss: 0.64089\n",
      "[51]\tvalid_0's multi_logloss: 0.640274\n",
      "[52]\tvalid_0's multi_logloss: 0.639745\n",
      "[53]\tvalid_0's multi_logloss: 0.639196\n",
      "[54]\tvalid_0's multi_logloss: 0.638695\n",
      "[55]\tvalid_0's multi_logloss: 0.638238\n",
      "[56]\tvalid_0's multi_logloss: 0.637764\n",
      "[57]\tvalid_0's multi_logloss: 0.637258\n",
      "[58]\tvalid_0's multi_logloss: 0.636838\n",
      "[59]\tvalid_0's multi_logloss: 0.636436\n",
      "[60]\tvalid_0's multi_logloss: 0.63604\n",
      "[61]\tvalid_0's multi_logloss: 0.635682\n",
      "[62]\tvalid_0's multi_logloss: 0.635324\n",
      "[63]\tvalid_0's multi_logloss: 0.634975\n",
      "[64]\tvalid_0's multi_logloss: 0.63464\n",
      "[65]\tvalid_0's multi_logloss: 0.634342\n",
      "[66]\tvalid_0's multi_logloss: 0.634012\n",
      "[67]\tvalid_0's multi_logloss: 0.633728\n",
      "[68]\tvalid_0's multi_logloss: 0.633479\n",
      "[69]\tvalid_0's multi_logloss: 0.633208\n",
      "[70]\tvalid_0's multi_logloss: 0.632988\n",
      "[71]\tvalid_0's multi_logloss: 0.632734\n",
      "[72]\tvalid_0's multi_logloss: 0.632511\n",
      "[73]\tvalid_0's multi_logloss: 0.632302\n",
      "[74]\tvalid_0's multi_logloss: 0.63211\n",
      "[75]\tvalid_0's multi_logloss: 0.631881\n",
      "[76]\tvalid_0's multi_logloss: 0.631676\n",
      "[77]\tvalid_0's multi_logloss: 0.631461\n",
      "[78]\tvalid_0's multi_logloss: 0.631279\n",
      "[79]\tvalid_0's multi_logloss: 0.631063\n",
      "[80]\tvalid_0's multi_logloss: 0.630884\n",
      "[81]\tvalid_0's multi_logloss: 0.630701\n",
      "[82]\tvalid_0's multi_logloss: 0.630548\n",
      "[83]\tvalid_0's multi_logloss: 0.630412\n",
      "[84]\tvalid_0's multi_logloss: 0.630266\n",
      "[85]\tvalid_0's multi_logloss: 0.630129\n",
      "[86]\tvalid_0's multi_logloss: 0.629981\n",
      "[87]\tvalid_0's multi_logloss: 0.629849\n",
      "[88]\tvalid_0's multi_logloss: 0.62975\n",
      "[89]\tvalid_0's multi_logloss: 0.62962\n",
      "[90]\tvalid_0's multi_logloss: 0.629476\n",
      "[91]\tvalid_0's multi_logloss: 0.629336\n",
      "[92]\tvalid_0's multi_logloss: 0.629218\n",
      "[93]\tvalid_0's multi_logloss: 0.629099\n",
      "[94]\tvalid_0's multi_logloss: 0.628987\n",
      "[95]\tvalid_0's multi_logloss: 0.628844\n",
      "[96]\tvalid_0's multi_logloss: 0.628741\n",
      "[97]\tvalid_0's multi_logloss: 0.628657\n",
      "[98]\tvalid_0's multi_logloss: 0.628533\n",
      "[99]\tvalid_0's multi_logloss: 0.628435\n",
      "[100]\tvalid_0's multi_logloss: 0.628346\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028014 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -3.244539\n",
      "[LightGBM] [Info] Start training from score -3.224920\n",
      "[LightGBM] [Info] Start training from score -3.369880\n",
      "[LightGBM] [Info] Start training from score -3.326941\n",
      "[LightGBM] [Info] Start training from score -3.378266\n",
      "[LightGBM] [Info] Start training from score -2.568017\n",
      "[LightGBM] [Info] Start training from score -1.914747\n",
      "[LightGBM] [Info] Start training from score -3.469579\n",
      "[LightGBM] [Info] Start training from score -1.919436\n",
      "[LightGBM] [Info] Start training from score -2.291576\n",
      "[LightGBM] [Info] Start training from score -2.007538\n",
      "[LightGBM] [Info] Start training from score -3.402200\n",
      "[LightGBM] [Info] Start training from score -3.212376\n",
      "[LightGBM] [Info] Start training from score -2.244521\n",
      "[1]\tvalid_0's multi_logloss: 2.38413\n",
      "[2]\tvalid_0's multi_logloss: 2.33781\n",
      "[3]\tvalid_0's multi_logloss: 2.3007\n",
      "[4]\tvalid_0's multi_logloss: 2.27138\n",
      "[5]\tvalid_0's multi_logloss: 2.24727\n",
      "[6]\tvalid_0's multi_logloss: 2.22693\n",
      "[7]\tvalid_0's multi_logloss: 2.21006\n",
      "[8]\tvalid_0's multi_logloss: 2.19477\n",
      "[9]\tvalid_0's multi_logloss: 2.18115\n",
      "[10]\tvalid_0's multi_logloss: 2.16816\n",
      "[11]\tvalid_0's multi_logloss: 2.1572\n",
      "[12]\tvalid_0's multi_logloss: 2.14816\n",
      "[13]\tvalid_0's multi_logloss: 2.13946\n",
      "[14]\tvalid_0's multi_logloss: 2.13133\n",
      "[15]\tvalid_0's multi_logloss: 2.12411\n",
      "[16]\tvalid_0's multi_logloss: 2.11812\n",
      "[17]\tvalid_0's multi_logloss: 2.11193\n",
      "[18]\tvalid_0's multi_logloss: 2.10575\n",
      "[19]\tvalid_0's multi_logloss: 2.10086\n",
      "[20]\tvalid_0's multi_logloss: 2.09657\n",
      "[21]\tvalid_0's multi_logloss: 2.09188\n",
      "[22]\tvalid_0's multi_logloss: 2.08749\n",
      "[23]\tvalid_0's multi_logloss: 2.08375\n",
      "[24]\tvalid_0's multi_logloss: 2.07976\n",
      "[25]\tvalid_0's multi_logloss: 2.07693\n",
      "[26]\tvalid_0's multi_logloss: 2.07365\n",
      "[27]\tvalid_0's multi_logloss: 2.0704\n",
      "[28]\tvalid_0's multi_logloss: 2.06753\n",
      "[29]\tvalid_0's multi_logloss: 2.06505\n",
      "[30]\tvalid_0's multi_logloss: 2.06265\n",
      "[31]\tvalid_0's multi_logloss: 2.06048\n",
      "[32]\tvalid_0's multi_logloss: 2.05852\n",
      "[33]\tvalid_0's multi_logloss: 2.05678\n",
      "[34]\tvalid_0's multi_logloss: 2.05487\n",
      "[35]\tvalid_0's multi_logloss: 2.05261\n",
      "[36]\tvalid_0's multi_logloss: 2.05079\n",
      "[37]\tvalid_0's multi_logloss: 2.0493\n",
      "[38]\tvalid_0's multi_logloss: 2.04745\n",
      "[39]\tvalid_0's multi_logloss: 2.04573\n",
      "[40]\tvalid_0's multi_logloss: 2.04445\n",
      "[41]\tvalid_0's multi_logloss: 2.0428\n",
      "[42]\tvalid_0's multi_logloss: 2.04136\n",
      "[43]\tvalid_0's multi_logloss: 2.03999\n",
      "[44]\tvalid_0's multi_logloss: 2.03895\n",
      "[45]\tvalid_0's multi_logloss: 2.03783\n",
      "[46]\tvalid_0's multi_logloss: 2.03678\n",
      "[47]\tvalid_0's multi_logloss: 2.03558\n",
      "[48]\tvalid_0's multi_logloss: 2.03451\n",
      "[49]\tvalid_0's multi_logloss: 2.03337\n",
      "[50]\tvalid_0's multi_logloss: 2.03242\n",
      "[51]\tvalid_0's multi_logloss: 2.03134\n",
      "[52]\tvalid_0's multi_logloss: 2.03025\n",
      "[53]\tvalid_0's multi_logloss: 2.02913\n",
      "[54]\tvalid_0's multi_logloss: 2.02831\n",
      "[55]\tvalid_0's multi_logloss: 2.02737\n",
      "[56]\tvalid_0's multi_logloss: 2.02658\n",
      "[57]\tvalid_0's multi_logloss: 2.02564\n",
      "[58]\tvalid_0's multi_logloss: 2.02476\n",
      "[59]\tvalid_0's multi_logloss: 2.02379\n",
      "[60]\tvalid_0's multi_logloss: 2.02312\n",
      "[61]\tvalid_0's multi_logloss: 2.02235\n",
      "[62]\tvalid_0's multi_logloss: 2.0215\n",
      "[63]\tvalid_0's multi_logloss: 2.02081\n",
      "[64]\tvalid_0's multi_logloss: 2.0201\n",
      "[65]\tvalid_0's multi_logloss: 2.01934\n",
      "[66]\tvalid_0's multi_logloss: 2.01872\n",
      "[67]\tvalid_0's multi_logloss: 2.01813\n",
      "[68]\tvalid_0's multi_logloss: 2.01754\n",
      "[69]\tvalid_0's multi_logloss: 2.01682\n",
      "[70]\tvalid_0's multi_logloss: 2.01618\n",
      "[71]\tvalid_0's multi_logloss: 2.01552\n",
      "[72]\tvalid_0's multi_logloss: 2.01487\n",
      "[73]\tvalid_0's multi_logloss: 2.01426\n",
      "[74]\tvalid_0's multi_logloss: 2.01365\n",
      "[75]\tvalid_0's multi_logloss: 2.01311\n",
      "[76]\tvalid_0's multi_logloss: 2.01256\n",
      "[77]\tvalid_0's multi_logloss: 2.01213\n",
      "[78]\tvalid_0's multi_logloss: 2.01169\n",
      "[79]\tvalid_0's multi_logloss: 2.01118\n",
      "[80]\tvalid_0's multi_logloss: 2.01065\n",
      "[81]\tvalid_0's multi_logloss: 2.01013\n",
      "[82]\tvalid_0's multi_logloss: 2.00959\n",
      "[83]\tvalid_0's multi_logloss: 2.00916\n",
      "[84]\tvalid_0's multi_logloss: 2.00874\n",
      "[85]\tvalid_0's multi_logloss: 2.00823\n",
      "[86]\tvalid_0's multi_logloss: 2.0078\n",
      "[87]\tvalid_0's multi_logloss: 2.00739\n",
      "[88]\tvalid_0's multi_logloss: 2.00701\n",
      "[89]\tvalid_0's multi_logloss: 2.00664\n",
      "[90]\tvalid_0's multi_logloss: 2.00613\n",
      "[91]\tvalid_0's multi_logloss: 2.00578\n",
      "[92]\tvalid_0's multi_logloss: 2.00542\n",
      "[93]\tvalid_0's multi_logloss: 2.00508\n",
      "[94]\tvalid_0's multi_logloss: 2.00461\n",
      "[95]\tvalid_0's multi_logloss: 2.00415\n",
      "[96]\tvalid_0's multi_logloss: 2.00381\n",
      "[97]\tvalid_0's multi_logloss: 2.00343\n",
      "[98]\tvalid_0's multi_logloss: 2.00307\n",
      "[99]\tvalid_0's multi_logloss: 2.0027\n",
      "[100]\tvalid_0's multi_logloss: 2.00243\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019054 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -0.501622\n",
      "[LightGBM] [Info] Start training from score -0.930257\n",
      "[1]\tvalid_0's multi_logloss: 0.575798\n",
      "[2]\tvalid_0's multi_logloss: 0.499412\n",
      "[3]\tvalid_0's multi_logloss: 0.436358\n",
      "[4]\tvalid_0's multi_logloss: 0.38339\n",
      "[5]\tvalid_0's multi_logloss: 0.338326\n",
      "[6]\tvalid_0's multi_logloss: 0.299612\n",
      "[7]\tvalid_0's multi_logloss: 0.266095\n",
      "[8]\tvalid_0's multi_logloss: 0.236898\n",
      "[9]\tvalid_0's multi_logloss: 0.211337\n",
      "[10]\tvalid_0's multi_logloss: 0.188864\n",
      "[11]\tvalid_0's multi_logloss: 0.169034\n",
      "[12]\tvalid_0's multi_logloss: 0.15147\n",
      "[13]\tvalid_0's multi_logloss: 0.135884\n",
      "[14]\tvalid_0's multi_logloss: 0.122027\n",
      "[15]\tvalid_0's multi_logloss: 0.109686\n",
      "[16]\tvalid_0's multi_logloss: 0.098664\n",
      "[17]\tvalid_0's multi_logloss: 0.0888125\n",
      "[18]\tvalid_0's multi_logloss: 0.0799964\n",
      "[19]\tvalid_0's multi_logloss: 0.0720965\n",
      "[20]\tvalid_0's multi_logloss: 0.0650109\n",
      "[21]\tvalid_0's multi_logloss: 0.0586485\n",
      "[22]\tvalid_0's multi_logloss: 0.0529349\n",
      "[23]\tvalid_0's multi_logloss: 0.0477992\n",
      "[24]\tvalid_0's multi_logloss: 0.0431762\n",
      "[25]\tvalid_0's multi_logloss: 0.0390148\n",
      "[26]\tvalid_0's multi_logloss: 0.0352669\n",
      "[27]\tvalid_0's multi_logloss: 0.0318904\n",
      "[28]\tvalid_0's multi_logloss: 0.0288471\n",
      "[29]\tvalid_0's multi_logloss: 0.0261047\n",
      "[30]\tvalid_0's multi_logloss: 0.023629\n",
      "[31]\tvalid_0's multi_logloss: 0.0213932\n",
      "[32]\tvalid_0's multi_logloss: 0.0193772\n",
      "[33]\tvalid_0's multi_logloss: 0.0175575\n",
      "[34]\tvalid_0's multi_logloss: 0.0159144\n",
      "[35]\tvalid_0's multi_logloss: 0.0143984\n",
      "[36]\tvalid_0's multi_logloss: 0.0130565\n",
      "[37]\tvalid_0's multi_logloss: 0.0118444\n",
      "[38]\tvalid_0's multi_logloss: 0.0107478\n",
      "[39]\tvalid_0's multi_logloss: 0.00975709\n",
      "[40]\tvalid_0's multi_logloss: 0.00886015\n",
      "[41]\tvalid_0's multi_logloss: 0.00804821\n",
      "[42]\tvalid_0's multi_logloss: 0.00731799\n",
      "[43]\tvalid_0's multi_logloss: 0.00665743\n",
      "[44]\tvalid_0's multi_logloss: 0.00605959\n",
      "[45]\tvalid_0's multi_logloss: 0.00551888\n",
      "[46]\tvalid_0's multi_logloss: 0.00503116\n",
      "[47]\tvalid_0's multi_logloss: 0.00459016\n",
      "[48]\tvalid_0's multi_logloss: 0.00419184\n",
      "[49]\tvalid_0's multi_logloss: 0.00383195\n",
      "[50]\tvalid_0's multi_logloss: 0.00350645\n",
      "[51]\tvalid_0's multi_logloss: 0.00321134\n",
      "[52]\tvalid_0's multi_logloss: 0.00295208\n",
      "[53]\tvalid_0's multi_logloss: 0.00271132\n",
      "[54]\tvalid_0's multi_logloss: 0.00249342\n",
      "[55]\tvalid_0's multi_logloss: 0.00229542\n",
      "[56]\tvalid_0's multi_logloss: 0.00211608\n",
      "[57]\tvalid_0's multi_logloss: 0.00195473\n",
      "[58]\tvalid_0's multi_logloss: 0.00180856\n",
      "[59]\tvalid_0's multi_logloss: 0.00167624\n",
      "[60]\tvalid_0's multi_logloss: 0.0015597\n",
      "[61]\tvalid_0's multi_logloss: 0.00145031\n",
      "[62]\tvalid_0's multi_logloss: 0.00135265\n",
      "[63]\tvalid_0's multi_logloss: 0.00126409\n",
      "[64]\tvalid_0's multi_logloss: 0.00118284\n",
      "[65]\tvalid_0's multi_logloss: 0.00111431\n",
      "[66]\tvalid_0's multi_logloss: 0.00105357\n",
      "[67]\tvalid_0's multi_logloss: 0.000994799\n",
      "[68]\tvalid_0's multi_logloss: 0.000942097\n",
      "[69]\tvalid_0's multi_logloss: 0.000899306\n",
      "[70]\tvalid_0's multi_logloss: 0.000850056\n",
      "[71]\tvalid_0's multi_logloss: 0.00083183\n",
      "[72]\tvalid_0's multi_logloss: 0.000802843\n",
      "[73]\tvalid_0's multi_logloss: 0.000770624\n",
      "[74]\tvalid_0's multi_logloss: 0.000732157\n",
      "[75]\tvalid_0's multi_logloss: 0.000711157\n",
      "[76]\tvalid_0's multi_logloss: 0.000689029\n",
      "[77]\tvalid_0's multi_logloss: 0.000663109\n",
      "[78]\tvalid_0's multi_logloss: 0.000645784\n",
      "[79]\tvalid_0's multi_logloss: 0.000628406\n",
      "[80]\tvalid_0's multi_logloss: 0.000617714\n",
      "[81]\tvalid_0's multi_logloss: 0.000650786\n",
      "[82]\tvalid_0's multi_logloss: 0.000637439\n",
      "[83]\tvalid_0's multi_logloss: 0.000623928\n",
      "[84]\tvalid_0's multi_logloss: 0.000614952\n",
      "[85]\tvalid_0's multi_logloss: 0.000680798\n",
      "[86]\tvalid_0's multi_logloss: 0.000633563\n",
      "[87]\tvalid_0's multi_logloss: 0.000671025\n",
      "[88]\tvalid_0's multi_logloss: 0.000714587\n",
      "[89]\tvalid_0's multi_logloss: 0.000631463\n",
      "[90]\tvalid_0's multi_logloss: 0.000634476\n",
      "[91]\tvalid_0's multi_logloss: 0.00062433\n",
      "[92]\tvalid_0's multi_logloss: 0.000701532\n",
      "[93]\tvalid_0's multi_logloss: 0.00058512\n",
      "[94]\tvalid_0's multi_logloss: 0.000636694\n",
      "[95]\tvalid_0's multi_logloss: 0.000575297\n",
      "[96]\tvalid_0's multi_logloss: 0.000615251\n",
      "[97]\tvalid_0's multi_logloss: 0.000611378\n",
      "[98]\tvalid_0's multi_logloss: 0.00058621\n",
      "[99]\tvalid_0's multi_logloss: 0.000788974\n",
      "[100]\tvalid_0's multi_logloss: 0.000598646\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018412 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -0.141837\n",
      "[LightGBM] [Info] Start training from score -2.023158\n",
      "[1]\tvalid_0's multi_logloss: 0.34179\n",
      "[2]\tvalid_0's multi_logloss: 0.313416\n",
      "[3]\tvalid_0's multi_logloss: 0.291413\n",
      "[4]\tvalid_0's multi_logloss: 0.274714\n",
      "[5]\tvalid_0's multi_logloss: 0.261205\n",
      "[6]\tvalid_0's multi_logloss: 0.249953\n",
      "[7]\tvalid_0's multi_logloss: 0.240795\n",
      "[8]\tvalid_0's multi_logloss: 0.232868\n",
      "[9]\tvalid_0's multi_logloss: 0.225546\n",
      "[10]\tvalid_0's multi_logloss: 0.21882\n",
      "[11]\tvalid_0's multi_logloss: 0.210931\n",
      "[12]\tvalid_0's multi_logloss: 0.203969\n",
      "[13]\tvalid_0's multi_logloss: 0.198709\n",
      "[14]\tvalid_0's multi_logloss: 0.19441\n",
      "[15]\tvalid_0's multi_logloss: 0.189692\n",
      "[16]\tvalid_0's multi_logloss: 0.184992\n",
      "[17]\tvalid_0's multi_logloss: 0.180655\n",
      "[18]\tvalid_0's multi_logloss: 0.17701\n",
      "[19]\tvalid_0's multi_logloss: 0.173493\n",
      "[20]\tvalid_0's multi_logloss: 0.169474\n",
      "[21]\tvalid_0's multi_logloss: 0.167546\n",
      "[22]\tvalid_0's multi_logloss: 0.165764\n",
      "[23]\tvalid_0's multi_logloss: 0.16406\n",
      "[24]\tvalid_0's multi_logloss: 0.161784\n",
      "[25]\tvalid_0's multi_logloss: 0.16004\n",
      "[26]\tvalid_0's multi_logloss: 0.157556\n",
      "[27]\tvalid_0's multi_logloss: 0.156098\n",
      "[28]\tvalid_0's multi_logloss: 0.15494\n",
      "[29]\tvalid_0's multi_logloss: 0.152926\n",
      "[30]\tvalid_0's multi_logloss: 0.151743\n",
      "[31]\tvalid_0's multi_logloss: 0.150924\n",
      "[32]\tvalid_0's multi_logloss: 0.149357\n",
      "[33]\tvalid_0's multi_logloss: 0.147858\n",
      "[34]\tvalid_0's multi_logloss: 0.146365\n",
      "[35]\tvalid_0's multi_logloss: 0.145417\n",
      "[36]\tvalid_0's multi_logloss: 0.143967\n",
      "[37]\tvalid_0's multi_logloss: 0.142834\n",
      "[38]\tvalid_0's multi_logloss: 0.142264\n",
      "[39]\tvalid_0's multi_logloss: 0.141574\n",
      "[40]\tvalid_0's multi_logloss: 0.140501\n",
      "[41]\tvalid_0's multi_logloss: 0.139945\n",
      "[42]\tvalid_0's multi_logloss: 0.139037\n",
      "[43]\tvalid_0's multi_logloss: 0.138219\n",
      "[44]\tvalid_0's multi_logloss: 0.137576\n",
      "[45]\tvalid_0's multi_logloss: 0.136871\n",
      "[46]\tvalid_0's multi_logloss: 0.136029\n",
      "[47]\tvalid_0's multi_logloss: 0.135425\n",
      "[48]\tvalid_0's multi_logloss: 0.134814\n",
      "[49]\tvalid_0's multi_logloss: 0.134362\n",
      "[50]\tvalid_0's multi_logloss: 0.13374\n",
      "[51]\tvalid_0's multi_logloss: 0.133266\n",
      "[52]\tvalid_0's multi_logloss: 0.132926\n",
      "[53]\tvalid_0's multi_logloss: 0.132441\n",
      "[54]\tvalid_0's multi_logloss: 0.131873\n",
      "[55]\tvalid_0's multi_logloss: 0.131227\n",
      "[56]\tvalid_0's multi_logloss: 0.130831\n",
      "[57]\tvalid_0's multi_logloss: 0.13049\n",
      "[58]\tvalid_0's multi_logloss: 0.12997\n",
      "[59]\tvalid_0's multi_logloss: 0.129514\n",
      "[60]\tvalid_0's multi_logloss: 0.129219\n",
      "[61]\tvalid_0's multi_logloss: 0.128845\n",
      "[62]\tvalid_0's multi_logloss: 0.128197\n",
      "[63]\tvalid_0's multi_logloss: 0.127889\n",
      "[64]\tvalid_0's multi_logloss: 0.127555\n",
      "[65]\tvalid_0's multi_logloss: 0.127181\n",
      "[66]\tvalid_0's multi_logloss: 0.126951\n",
      "[67]\tvalid_0's multi_logloss: 0.126428\n",
      "[68]\tvalid_0's multi_logloss: 0.126134\n",
      "[69]\tvalid_0's multi_logloss: 0.125917\n",
      "[70]\tvalid_0's multi_logloss: 0.125542\n",
      "[71]\tvalid_0's multi_logloss: 0.125241\n",
      "[72]\tvalid_0's multi_logloss: 0.124948\n",
      "[73]\tvalid_0's multi_logloss: 0.124725\n",
      "[74]\tvalid_0's multi_logloss: 0.12453\n",
      "[75]\tvalid_0's multi_logloss: 0.124292\n",
      "[76]\tvalid_0's multi_logloss: 0.123828\n",
      "[77]\tvalid_0's multi_logloss: 0.12365\n",
      "[78]\tvalid_0's multi_logloss: 0.123493\n",
      "[79]\tvalid_0's multi_logloss: 0.123262\n",
      "[80]\tvalid_0's multi_logloss: 0.122896\n",
      "[81]\tvalid_0's multi_logloss: 0.12272\n",
      "[82]\tvalid_0's multi_logloss: 0.122409\n",
      "[83]\tvalid_0's multi_logloss: 0.122257\n",
      "[84]\tvalid_0's multi_logloss: 0.122067\n",
      "[85]\tvalid_0's multi_logloss: 0.121919\n",
      "[86]\tvalid_0's multi_logloss: 0.121812\n",
      "[87]\tvalid_0's multi_logloss: 0.121414\n",
      "[88]\tvalid_0's multi_logloss: 0.121193\n",
      "[89]\tvalid_0's multi_logloss: 0.121021\n",
      "[90]\tvalid_0's multi_logloss: 0.12071\n",
      "[91]\tvalid_0's multi_logloss: 0.120555\n",
      "[92]\tvalid_0's multi_logloss: 0.12033\n",
      "[93]\tvalid_0's multi_logloss: 0.120121\n",
      "[94]\tvalid_0's multi_logloss: 0.11994\n",
      "[95]\tvalid_0's multi_logloss: 0.119748\n",
      "[96]\tvalid_0's multi_logloss: 0.119494\n",
      "[97]\tvalid_0's multi_logloss: 0.119318\n",
      "[98]\tvalid_0's multi_logloss: 0.119105\n",
      "[99]\tvalid_0's multi_logloss: 0.118818\n",
      "[100]\tvalid_0's multi_logloss: 0.118501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [51:00, 144.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012253 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 7715638, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -1.249550\n",
      "[LightGBM] [Info] Start training from score -3.165534\n",
      "[LightGBM] [Info] Start training from score -1.726403\n",
      "[LightGBM] [Info] Start training from score -1.902421\n",
      "[LightGBM] [Info] Start training from score -1.667720\n",
      "[LightGBM] [Info] Start training from score -1.861961\n",
      "[1]\tvalid_0's multi_logloss: 1.65839\n",
      "[2]\tvalid_0's multi_logloss: 1.63754\n",
      "[3]\tvalid_0's multi_logloss: 1.62095\n",
      "[4]\tvalid_0's multi_logloss: 1.60732\n",
      "[5]\tvalid_0's multi_logloss: 1.5962\n",
      "[6]\tvalid_0's multi_logloss: 1.58683\n",
      "[7]\tvalid_0's multi_logloss: 1.57889\n",
      "[8]\tvalid_0's multi_logloss: 1.57212\n",
      "[9]\tvalid_0's multi_logloss: 1.56615\n",
      "[10]\tvalid_0's multi_logloss: 1.56113\n",
      "[11]\tvalid_0's multi_logloss: 1.55674\n",
      "[12]\tvalid_0's multi_logloss: 1.55261\n",
      "[13]\tvalid_0's multi_logloss: 1.54911\n",
      "[14]\tvalid_0's multi_logloss: 1.54583\n",
      "[15]\tvalid_0's multi_logloss: 1.54297\n",
      "[16]\tvalid_0's multi_logloss: 1.54042\n",
      "[17]\tvalid_0's multi_logloss: 1.53797\n",
      "[18]\tvalid_0's multi_logloss: 1.53582\n",
      "[19]\tvalid_0's multi_logloss: 1.5338\n",
      "[20]\tvalid_0's multi_logloss: 1.53159\n",
      "[21]\tvalid_0's multi_logloss: 1.52985\n",
      "[22]\tvalid_0's multi_logloss: 1.52805\n",
      "[23]\tvalid_0's multi_logloss: 1.52651\n",
      "[24]\tvalid_0's multi_logloss: 1.52495\n",
      "[25]\tvalid_0's multi_logloss: 1.52353\n",
      "[26]\tvalid_0's multi_logloss: 1.52217\n",
      "[27]\tvalid_0's multi_logloss: 1.52079\n",
      "[28]\tvalid_0's multi_logloss: 1.5196\n",
      "[29]\tvalid_0's multi_logloss: 1.51833\n",
      "[30]\tvalid_0's multi_logloss: 1.51721\n",
      "[31]\tvalid_0's multi_logloss: 1.5161\n",
      "[32]\tvalid_0's multi_logloss: 1.51508\n",
      "[33]\tvalid_0's multi_logloss: 1.5141\n",
      "[34]\tvalid_0's multi_logloss: 1.51308\n",
      "[35]\tvalid_0's multi_logloss: 1.51216\n",
      "[36]\tvalid_0's multi_logloss: 1.51129\n",
      "[37]\tvalid_0's multi_logloss: 1.51038\n",
      "[38]\tvalid_0's multi_logloss: 1.50951\n",
      "[39]\tvalid_0's multi_logloss: 1.50877\n",
      "[40]\tvalid_0's multi_logloss: 1.50793\n",
      "[41]\tvalid_0's multi_logloss: 1.50713\n",
      "[42]\tvalid_0's multi_logloss: 1.50639\n",
      "[43]\tvalid_0's multi_logloss: 1.50566\n",
      "[44]\tvalid_0's multi_logloss: 1.505\n",
      "[45]\tvalid_0's multi_logloss: 1.50434\n",
      "[46]\tvalid_0's multi_logloss: 1.50365\n",
      "[47]\tvalid_0's multi_logloss: 1.50303\n",
      "[48]\tvalid_0's multi_logloss: 1.50241\n",
      "[49]\tvalid_0's multi_logloss: 1.50177\n",
      "[50]\tvalid_0's multi_logloss: 1.50118\n",
      "[51]\tvalid_0's multi_logloss: 1.50065\n",
      "[52]\tvalid_0's multi_logloss: 1.50012\n",
      "[53]\tvalid_0's multi_logloss: 1.49958\n",
      "[54]\tvalid_0's multi_logloss: 1.4991\n",
      "[55]\tvalid_0's multi_logloss: 1.49859\n",
      "[56]\tvalid_0's multi_logloss: 1.49808\n",
      "[57]\tvalid_0's multi_logloss: 1.49763\n",
      "[58]\tvalid_0's multi_logloss: 1.49711\n",
      "[59]\tvalid_0's multi_logloss: 1.49664\n",
      "[60]\tvalid_0's multi_logloss: 1.49615\n",
      "[61]\tvalid_0's multi_logloss: 1.49577\n",
      "[62]\tvalid_0's multi_logloss: 1.4954\n",
      "[63]\tvalid_0's multi_logloss: 1.49493\n",
      "[64]\tvalid_0's multi_logloss: 1.49446\n",
      "[65]\tvalid_0's multi_logloss: 1.49403\n",
      "[66]\tvalid_0's multi_logloss: 1.49365\n",
      "[67]\tvalid_0's multi_logloss: 1.49324\n",
      "[68]\tvalid_0's multi_logloss: 1.49286\n",
      "[69]\tvalid_0's multi_logloss: 1.49245\n",
      "[70]\tvalid_0's multi_logloss: 1.49207\n",
      "[71]\tvalid_0's multi_logloss: 1.49173\n",
      "[72]\tvalid_0's multi_logloss: 1.49139\n",
      "[73]\tvalid_0's multi_logloss: 1.49107\n",
      "[74]\tvalid_0's multi_logloss: 1.49076\n",
      "[75]\tvalid_0's multi_logloss: 1.49037\n",
      "[76]\tvalid_0's multi_logloss: 1.49007\n",
      "[77]\tvalid_0's multi_logloss: 1.4897\n",
      "[78]\tvalid_0's multi_logloss: 1.48943\n",
      "[79]\tvalid_0's multi_logloss: 1.48909\n",
      "[80]\tvalid_0's multi_logloss: 1.48882\n",
      "[81]\tvalid_0's multi_logloss: 1.48847\n",
      "[82]\tvalid_0's multi_logloss: 1.48818\n",
      "[83]\tvalid_0's multi_logloss: 1.48795\n",
      "[84]\tvalid_0's multi_logloss: 1.48762\n",
      "[85]\tvalid_0's multi_logloss: 1.48728\n",
      "[86]\tvalid_0's multi_logloss: 1.48703\n",
      "[87]\tvalid_0's multi_logloss: 1.4867\n",
      "[88]\tvalid_0's multi_logloss: 1.48639\n",
      "[89]\tvalid_0's multi_logloss: 1.48611\n",
      "[90]\tvalid_0's multi_logloss: 1.48584\n",
      "[91]\tvalid_0's multi_logloss: 1.48554\n",
      "[92]\tvalid_0's multi_logloss: 1.48526\n",
      "[93]\tvalid_0's multi_logloss: 1.485\n",
      "[94]\tvalid_0's multi_logloss: 1.48476\n",
      "[95]\tvalid_0's multi_logloss: 1.48448\n",
      "[96]\tvalid_0's multi_logloss: 1.48426\n",
      "[97]\tvalid_0's multi_logloss: 1.48401\n",
      "[98]\tvalid_0's multi_logloss: 1.48373\n",
      "[99]\tvalid_0's multi_logloss: 1.48351\n",
      "[100]\tvalid_0's multi_logloss: 1.48329\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012122 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 7715638, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -3.388563\n",
      "[LightGBM] [Info] Start training from score -3.286043\n",
      "[LightGBM] [Info] Start training from score -3.265766\n",
      "[LightGBM] [Info] Start training from score -3.814547\n",
      "[LightGBM] [Info] Start training from score -3.310265\n",
      "[LightGBM] [Info] Start training from score -3.206426\n",
      "[LightGBM] [Info] Start training from score -4.264605\n",
      "[LightGBM] [Info] Start training from score -3.385622\n",
      "[LightGBM] [Info] Start training from score -3.678169\n",
      "[LightGBM] [Info] Start training from score -3.401590\n",
      "[LightGBM] [Info] Start training from score -4.879144\n",
      "[LightGBM] [Info] Start training from score -3.027581\n",
      "[LightGBM] [Info] Start training from score -2.985319\n",
      "[LightGBM] [Info] Start training from score -3.251856\n",
      "[LightGBM] [Info] Start training from score -3.294527\n",
      "[LightGBM] [Info] Start training from score -3.372086\n",
      "[LightGBM] [Info] Start training from score -2.973489\n",
      "[LightGBM] [Info] Start training from score -2.489644\n",
      "[LightGBM] [Info] Start training from score -3.403357\n",
      "[LightGBM] [Info] Start training from score -4.161407\n",
      "[LightGBM] [Info] Start training from score -4.219942\n",
      "[LightGBM] [Info] Start training from score -3.454308\n",
      "[LightGBM] [Info] Start training from score -3.414970\n",
      "[LightGBM] [Info] Start training from score -3.160243\n",
      "[LightGBM] [Info] Start training from score -3.113230\n",
      "[LightGBM] [Info] Start training from score -3.209175\n",
      "[LightGBM] [Info] Start training from score -3.282600\n",
      "[LightGBM] [Info] Start training from score -3.180636\n",
      "[1]\tvalid_0's multi_logloss: 2.37372\n",
      "[2]\tvalid_0's multi_logloss: 2.1735\n",
      "[3]\tvalid_0's multi_logloss: 2.02473\n",
      "[4]\tvalid_0's multi_logloss: 1.91693\n",
      "[5]\tvalid_0's multi_logloss: 1.83097\n",
      "[6]\tvalid_0's multi_logloss: 1.76097\n",
      "[7]\tvalid_0's multi_logloss: 1.70142\n",
      "[8]\tvalid_0's multi_logloss: 1.65236\n",
      "[9]\tvalid_0's multi_logloss: 1.61024\n",
      "[10]\tvalid_0's multi_logloss: 1.57288\n",
      "[11]\tvalid_0's multi_logloss: 1.54124\n",
      "[12]\tvalid_0's multi_logloss: 1.51227\n",
      "[13]\tvalid_0's multi_logloss: 1.48672\n",
      "[14]\tvalid_0's multi_logloss: 1.46467\n",
      "[15]\tvalid_0's multi_logloss: 1.44475\n",
      "[16]\tvalid_0's multi_logloss: 1.42656\n",
      "[17]\tvalid_0's multi_logloss: 1.41052\n",
      "[18]\tvalid_0's multi_logloss: 1.3959\n",
      "[19]\tvalid_0's multi_logloss: 1.38232\n",
      "[20]\tvalid_0's multi_logloss: 1.36988\n",
      "[21]\tvalid_0's multi_logloss: 1.35807\n",
      "[22]\tvalid_0's multi_logloss: 1.34737\n",
      "[23]\tvalid_0's multi_logloss: 1.33725\n",
      "[24]\tvalid_0's multi_logloss: 1.32814\n",
      "[25]\tvalid_0's multi_logloss: 1.31955\n",
      "[26]\tvalid_0's multi_logloss: 1.31152\n",
      "[27]\tvalid_0's multi_logloss: 1.30392\n",
      "[28]\tvalid_0's multi_logloss: 1.29685\n",
      "[29]\tvalid_0's multi_logloss: 1.29005\n",
      "[30]\tvalid_0's multi_logloss: 1.28363\n",
      "[31]\tvalid_0's multi_logloss: 1.27766\n",
      "[32]\tvalid_0's multi_logloss: 1.27196\n",
      "[33]\tvalid_0's multi_logloss: 1.26663\n",
      "[34]\tvalid_0's multi_logloss: 1.26159\n",
      "[35]\tvalid_0's multi_logloss: 1.2567\n",
      "[36]\tvalid_0's multi_logloss: 1.25184\n",
      "[37]\tvalid_0's multi_logloss: 1.24734\n",
      "[38]\tvalid_0's multi_logloss: 1.24298\n",
      "[39]\tvalid_0's multi_logloss: 1.23908\n",
      "[40]\tvalid_0's multi_logloss: 1.23513\n",
      "[41]\tvalid_0's multi_logloss: 1.2313\n",
      "[42]\tvalid_0's multi_logloss: 1.22878\n",
      "[43]\tvalid_0's multi_logloss: 1.22442\n",
      "[44]\tvalid_0's multi_logloss: 1.22108\n",
      "[45]\tvalid_0's multi_logloss: 1.21779\n",
      "[46]\tvalid_0's multi_logloss: 1.21503\n",
      "[47]\tvalid_0's multi_logloss: 1.21206\n",
      "[48]\tvalid_0's multi_logloss: 1.20907\n",
      "[49]\tvalid_0's multi_logloss: 1.20641\n",
      "[50]\tvalid_0's multi_logloss: 1.20381\n",
      "[51]\tvalid_0's multi_logloss: 1.20106\n",
      "[52]\tvalid_0's multi_logloss: 1.19851\n",
      "[53]\tvalid_0's multi_logloss: 1.19618\n",
      "[54]\tvalid_0's multi_logloss: 1.19373\n",
      "[55]\tvalid_0's multi_logloss: 1.19193\n",
      "[56]\tvalid_0's multi_logloss: 1.18982\n",
      "[57]\tvalid_0's multi_logloss: 1.18905\n",
      "[58]\tvalid_0's multi_logloss: 1.18654\n",
      "[59]\tvalid_0's multi_logloss: 1.18484\n",
      "[60]\tvalid_0's multi_logloss: 1.18264\n",
      "[61]\tvalid_0's multi_logloss: 1.18027\n",
      "[62]\tvalid_0's multi_logloss: 1.17913\n",
      "[63]\tvalid_0's multi_logloss: 1.17635\n",
      "[64]\tvalid_0's multi_logloss: 1.17513\n",
      "[65]\tvalid_0's multi_logloss: 1.173\n",
      "[66]\tvalid_0's multi_logloss: 1.17155\n",
      "[67]\tvalid_0's multi_logloss: 1.16988\n",
      "[68]\tvalid_0's multi_logloss: 1.16943\n",
      "[69]\tvalid_0's multi_logloss: 1.1674\n",
      "[70]\tvalid_0's multi_logloss: 1.16579\n",
      "[71]\tvalid_0's multi_logloss: 1.16453\n",
      "[72]\tvalid_0's multi_logloss: 1.16302\n",
      "[73]\tvalid_0's multi_logloss: 1.16153\n",
      "[74]\tvalid_0's multi_logloss: 1.16024\n",
      "[75]\tvalid_0's multi_logloss: 1.15899\n",
      "[76]\tvalid_0's multi_logloss: 1.15835\n",
      "[77]\tvalid_0's multi_logloss: 1.15728\n",
      "[78]\tvalid_0's multi_logloss: 1.15718\n",
      "[79]\tvalid_0's multi_logloss: 1.15618\n",
      "[80]\tvalid_0's multi_logloss: 1.15414\n",
      "[81]\tvalid_0's multi_logloss: 1.15318\n",
      "[82]\tvalid_0's multi_logloss: 1.15218\n",
      "[83]\tvalid_0's multi_logloss: 1.15079\n",
      "[84]\tvalid_0's multi_logloss: 1.15176\n",
      "[85]\tvalid_0's multi_logloss: 1.15174\n",
      "[86]\tvalid_0's multi_logloss: 1.14903\n",
      "[87]\tvalid_0's multi_logloss: 1.14895\n",
      "[88]\tvalid_0's multi_logloss: 1.14847\n",
      "[89]\tvalid_0's multi_logloss: 1.14889\n",
      "[90]\tvalid_0's multi_logloss: 1.14621\n",
      "[91]\tvalid_0's multi_logloss: 1.14506\n",
      "[92]\tvalid_0's multi_logloss: 1.14455\n",
      "[93]\tvalid_0's multi_logloss: 1.14538\n",
      "[94]\tvalid_0's multi_logloss: 1.14478\n",
      "[95]\tvalid_0's multi_logloss: 1.14275\n",
      "[96]\tvalid_0's multi_logloss: 1.14227\n",
      "[97]\tvalid_0's multi_logloss: 1.14097\n",
      "[98]\tvalid_0's multi_logloss: 1.14064\n",
      "[99]\tvalid_0's multi_logloss: 1.14491\n",
      "[100]\tvalid_0's multi_logloss: 1.13915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [53:01, 137.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 820733, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -0.683185\n",
      "[LightGBM] [Info] Start training from score -2.382997\n",
      "[LightGBM] [Info] Start training from score -2.734975\n",
      "[LightGBM] [Info] Start training from score -3.826068\n",
      "[LightGBM] [Info] Start training from score -1.583719\n",
      "[LightGBM] [Info] Start training from score -2.199855\n",
      "[1]\tvalid_0's multi_logloss: 1.12466\n",
      "[2]\tvalid_0's multi_logloss: 0.990024\n",
      "[3]\tvalid_0's multi_logloss: 0.890828\n",
      "[4]\tvalid_0's multi_logloss: 0.813143\n",
      "[5]\tvalid_0's multi_logloss: 0.751035\n",
      "[6]\tvalid_0's multi_logloss: 0.699739\n",
      "[7]\tvalid_0's multi_logloss: 0.657777\n",
      "[8]\tvalid_0's multi_logloss: 0.622396\n",
      "[9]\tvalid_0's multi_logloss: 0.592154\n",
      "[10]\tvalid_0's multi_logloss: 0.566601\n",
      "[11]\tvalid_0's multi_logloss: 0.54481\n",
      "[12]\tvalid_0's multi_logloss: 0.525132\n",
      "[13]\tvalid_0's multi_logloss: 0.508371\n",
      "[14]\tvalid_0's multi_logloss: 0.493857\n",
      "[15]\tvalid_0's multi_logloss: 0.481221\n",
      "[16]\tvalid_0's multi_logloss: 0.470232\n",
      "[17]\tvalid_0's multi_logloss: 0.460557\n",
      "[18]\tvalid_0's multi_logloss: 0.452467\n",
      "[19]\tvalid_0's multi_logloss: 0.44478\n",
      "[20]\tvalid_0's multi_logloss: 0.438027\n",
      "[21]\tvalid_0's multi_logloss: 0.431953\n",
      "[22]\tvalid_0's multi_logloss: 0.426499\n",
      "[23]\tvalid_0's multi_logloss: 0.421686\n",
      "[24]\tvalid_0's multi_logloss: 0.416578\n",
      "[25]\tvalid_0's multi_logloss: 0.412344\n",
      "[26]\tvalid_0's multi_logloss: 0.408236\n",
      "[27]\tvalid_0's multi_logloss: 0.404578\n",
      "[28]\tvalid_0's multi_logloss: 0.401177\n",
      "[29]\tvalid_0's multi_logloss: 0.398368\n",
      "[30]\tvalid_0's multi_logloss: 0.395593\n",
      "[31]\tvalid_0's multi_logloss: 0.39319\n",
      "[32]\tvalid_0's multi_logloss: 0.391097\n",
      "[33]\tvalid_0's multi_logloss: 0.388609\n",
      "[34]\tvalid_0's multi_logloss: 0.386824\n",
      "[35]\tvalid_0's multi_logloss: 0.385211\n",
      "[36]\tvalid_0's multi_logloss: 0.383273\n",
      "[37]\tvalid_0's multi_logloss: 0.381746\n",
      "[38]\tvalid_0's multi_logloss: 0.380184\n",
      "[39]\tvalid_0's multi_logloss: 0.378951\n",
      "[40]\tvalid_0's multi_logloss: 0.377408\n",
      "[41]\tvalid_0's multi_logloss: 0.376354\n",
      "[42]\tvalid_0's multi_logloss: 0.375198\n",
      "[43]\tvalid_0's multi_logloss: 0.374176\n",
      "[44]\tvalid_0's multi_logloss: 0.373123\n",
      "[45]\tvalid_0's multi_logloss: 0.372228\n",
      "[46]\tvalid_0's multi_logloss: 0.371592\n",
      "[47]\tvalid_0's multi_logloss: 0.372447\n",
      "[48]\tvalid_0's multi_logloss: 0.370691\n",
      "[49]\tvalid_0's multi_logloss: 0.369914\n",
      "[50]\tvalid_0's multi_logloss: 0.369125\n",
      "[51]\tvalid_0's multi_logloss: 0.369508\n",
      "[52]\tvalid_0's multi_logloss: 0.368374\n",
      "[53]\tvalid_0's multi_logloss: 0.367655\n",
      "[54]\tvalid_0's multi_logloss: 0.367183\n",
      "[55]\tvalid_0's multi_logloss: 0.366244\n",
      "[56]\tvalid_0's multi_logloss: 0.365872\n",
      "[57]\tvalid_0's multi_logloss: 0.365148\n",
      "[58]\tvalid_0's multi_logloss: 0.366956\n",
      "[59]\tvalid_0's multi_logloss: 0.364733\n",
      "[60]\tvalid_0's multi_logloss: 0.364564\n",
      "[61]\tvalid_0's multi_logloss: 0.363927\n",
      "[62]\tvalid_0's multi_logloss: 0.364139\n",
      "[63]\tvalid_0's multi_logloss: 0.363839\n",
      "[64]\tvalid_0's multi_logloss: 0.365304\n",
      "[65]\tvalid_0's multi_logloss: 0.363526\n",
      "[66]\tvalid_0's multi_logloss: 0.366683\n",
      "[67]\tvalid_0's multi_logloss: 0.363025\n",
      "[68]\tvalid_0's multi_logloss: 0.362801\n",
      "[69]\tvalid_0's multi_logloss: 0.362539\n",
      "[70]\tvalid_0's multi_logloss: 0.362531\n",
      "[71]\tvalid_0's multi_logloss: 0.362002\n",
      "[72]\tvalid_0's multi_logloss: 0.364921\n",
      "[73]\tvalid_0's multi_logloss: 0.364608\n",
      "[74]\tvalid_0's multi_logloss: 0.363563\n",
      "[75]\tvalid_0's multi_logloss: 0.364394\n",
      "[76]\tvalid_0's multi_logloss: 0.364148\n",
      "[77]\tvalid_0's multi_logloss: 0.364404\n",
      "[78]\tvalid_0's multi_logloss: 0.374735\n",
      "[79]\tvalid_0's multi_logloss: 0.363428\n",
      "[80]\tvalid_0's multi_logloss: 0.363439\n",
      "[81]\tvalid_0's multi_logloss: 0.362327\n",
      "[82]\tvalid_0's multi_logloss: 0.362974\n",
      "[83]\tvalid_0's multi_logloss: 0.364594\n",
      "[84]\tvalid_0's multi_logloss: 0.363127\n",
      "[85]\tvalid_0's multi_logloss: 0.363383\n",
      "[86]\tvalid_0's multi_logloss: 0.364898\n",
      "[87]\tvalid_0's multi_logloss: 0.363946\n",
      "[88]\tvalid_0's multi_logloss: 0.3649\n",
      "[89]\tvalid_0's multi_logloss: 0.379232\n",
      "[90]\tvalid_0's multi_logloss: 0.371113\n",
      "[91]\tvalid_0's multi_logloss: 0.365915\n",
      "[92]\tvalid_0's multi_logloss: 0.375138\n",
      "[93]\tvalid_0's multi_logloss: 0.370159\n",
      "[94]\tvalid_0's multi_logloss: 0.363543\n",
      "[95]\tvalid_0's multi_logloss: 0.374113\n",
      "[96]\tvalid_0's multi_logloss: 0.376377\n",
      "[97]\tvalid_0's multi_logloss: 0.372946\n",
      "[98]\tvalid_0's multi_logloss: 0.378633\n",
      "[99]\tvalid_0's multi_logloss: 0.377231\n",
      "[100]\tvalid_0's multi_logloss: 0.374713\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001526 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 820733, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -2.163833\n",
      "[LightGBM] [Info] Start training from score -1.796397\n",
      "[LightGBM] [Info] Start training from score -1.843741\n",
      "[LightGBM] [Info] Start training from score -1.989576\n",
      "[LightGBM] [Info] Start training from score -1.941218\n",
      "[LightGBM] [Info] Start training from score -1.949016\n",
      "[LightGBM] [Info] Start training from score -1.978333\n",
      "[1]\tvalid_0's multi_logloss: 1.89542\n",
      "[2]\tvalid_0's multi_logloss: 1.86102\n",
      "[3]\tvalid_0's multi_logloss: 1.83364\n",
      "[4]\tvalid_0's multi_logloss: 1.81126\n",
      "[5]\tvalid_0's multi_logloss: 1.79269\n",
      "[6]\tvalid_0's multi_logloss: 1.77738\n",
      "[7]\tvalid_0's multi_logloss: 1.76424\n",
      "[8]\tvalid_0's multi_logloss: 1.7532\n",
      "[9]\tvalid_0's multi_logloss: 1.74377\n",
      "[10]\tvalid_0's multi_logloss: 1.73563\n",
      "[11]\tvalid_0's multi_logloss: 1.72885\n",
      "[12]\tvalid_0's multi_logloss: 1.72299\n",
      "[13]\tvalid_0's multi_logloss: 1.71765\n",
      "[14]\tvalid_0's multi_logloss: 1.71286\n",
      "[15]\tvalid_0's multi_logloss: 1.70872\n",
      "[16]\tvalid_0's multi_logloss: 1.70513\n",
      "[17]\tvalid_0's multi_logloss: 1.70177\n",
      "[18]\tvalid_0's multi_logloss: 1.6989\n",
      "[19]\tvalid_0's multi_logloss: 1.69624\n",
      "[20]\tvalid_0's multi_logloss: 1.69389\n",
      "[21]\tvalid_0's multi_logloss: 1.69162\n",
      "[22]\tvalid_0's multi_logloss: 1.68954\n",
      "[23]\tvalid_0's multi_logloss: 1.6878\n",
      "[24]\tvalid_0's multi_logloss: 1.68603\n",
      "[25]\tvalid_0's multi_logloss: 1.68447\n",
      "[26]\tvalid_0's multi_logloss: 1.68281\n",
      "[27]\tvalid_0's multi_logloss: 1.68127\n",
      "[28]\tvalid_0's multi_logloss: 1.68002\n",
      "[29]\tvalid_0's multi_logloss: 1.67871\n",
      "[30]\tvalid_0's multi_logloss: 1.67752\n",
      "[31]\tvalid_0's multi_logloss: 1.6764\n",
      "[32]\tvalid_0's multi_logloss: 1.67541\n",
      "[33]\tvalid_0's multi_logloss: 1.67436\n",
      "[34]\tvalid_0's multi_logloss: 1.67315\n",
      "[35]\tvalid_0's multi_logloss: 1.67226\n",
      "[36]\tvalid_0's multi_logloss: 1.67126\n",
      "[37]\tvalid_0's multi_logloss: 1.6704\n",
      "[38]\tvalid_0's multi_logloss: 1.66961\n",
      "[39]\tvalid_0's multi_logloss: 1.66885\n",
      "[40]\tvalid_0's multi_logloss: 1.66803\n",
      "[41]\tvalid_0's multi_logloss: 1.66734\n",
      "[42]\tvalid_0's multi_logloss: 1.66666\n",
      "[43]\tvalid_0's multi_logloss: 1.66593\n",
      "[44]\tvalid_0's multi_logloss: 1.66526\n",
      "[45]\tvalid_0's multi_logloss: 1.66468\n",
      "[46]\tvalid_0's multi_logloss: 1.66403\n",
      "[47]\tvalid_0's multi_logloss: 1.66341\n",
      "[48]\tvalid_0's multi_logloss: 1.66294\n",
      "[49]\tvalid_0's multi_logloss: 1.66244\n",
      "[50]\tvalid_0's multi_logloss: 1.66178\n",
      "[51]\tvalid_0's multi_logloss: 1.6613\n",
      "[52]\tvalid_0's multi_logloss: 1.66077\n",
      "[53]\tvalid_0's multi_logloss: 1.66034\n",
      "[54]\tvalid_0's multi_logloss: 1.65984\n",
      "[55]\tvalid_0's multi_logloss: 1.65941\n",
      "[56]\tvalid_0's multi_logloss: 1.65903\n",
      "[57]\tvalid_0's multi_logloss: 1.65862\n",
      "[58]\tvalid_0's multi_logloss: 1.65827\n",
      "[59]\tvalid_0's multi_logloss: 1.65785\n",
      "[60]\tvalid_0's multi_logloss: 1.65753\n",
      "[61]\tvalid_0's multi_logloss: 1.65723\n",
      "[62]\tvalid_0's multi_logloss: 1.65696\n",
      "[63]\tvalid_0's multi_logloss: 1.6566\n",
      "[64]\tvalid_0's multi_logloss: 1.65619\n",
      "[65]\tvalid_0's multi_logloss: 1.65598\n",
      "[66]\tvalid_0's multi_logloss: 1.65566\n",
      "[67]\tvalid_0's multi_logloss: 1.65534\n",
      "[68]\tvalid_0's multi_logloss: 1.65505\n",
      "[69]\tvalid_0's multi_logloss: 1.65486\n",
      "[70]\tvalid_0's multi_logloss: 1.65455\n",
      "[71]\tvalid_0's multi_logloss: 1.6543\n",
      "[72]\tvalid_0's multi_logloss: 1.65409\n",
      "[73]\tvalid_0's multi_logloss: 1.6539\n",
      "[74]\tvalid_0's multi_logloss: 1.65372\n",
      "[75]\tvalid_0's multi_logloss: 1.65347\n",
      "[76]\tvalid_0's multi_logloss: 1.65317\n",
      "[77]\tvalid_0's multi_logloss: 1.65301\n",
      "[78]\tvalid_0's multi_logloss: 1.65282\n",
      "[79]\tvalid_0's multi_logloss: 1.65266\n",
      "[80]\tvalid_0's multi_logloss: 1.65244\n",
      "[81]\tvalid_0's multi_logloss: 1.65229\n",
      "[82]\tvalid_0's multi_logloss: 1.65209\n",
      "[83]\tvalid_0's multi_logloss: 1.65193\n",
      "[84]\tvalid_0's multi_logloss: 1.65167\n",
      "[85]\tvalid_0's multi_logloss: 1.6515\n",
      "[86]\tvalid_0's multi_logloss: 1.65137\n",
      "[87]\tvalid_0's multi_logloss: 1.65123\n",
      "[88]\tvalid_0's multi_logloss: 1.65102\n",
      "[89]\tvalid_0's multi_logloss: 1.6509\n",
      "[90]\tvalid_0's multi_logloss: 1.65073\n",
      "[91]\tvalid_0's multi_logloss: 1.65059\n",
      "[92]\tvalid_0's multi_logloss: 1.65039\n",
      "[93]\tvalid_0's multi_logloss: 1.65024\n",
      "[94]\tvalid_0's multi_logloss: 1.65008\n",
      "[95]\tvalid_0's multi_logloss: 1.6499\n",
      "[96]\tvalid_0's multi_logloss: 1.64974\n",
      "[97]\tvalid_0's multi_logloss: 1.64959\n",
      "[98]\tvalid_0's multi_logloss: 1.6494\n",
      "[99]\tvalid_0's multi_logloss: 1.64916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [53:10, 98.74s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's multi_logloss: 1.64906\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025889 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -1.853404\n",
      "[LightGBM] [Info] Start training from score -2.123202\n",
      "[LightGBM] [Info] Start training from score -2.391862\n",
      "[LightGBM] [Info] Start training from score -2.719639\n",
      "[LightGBM] [Info] Start training from score -2.078311\n",
      "[LightGBM] [Info] Start training from score -2.161447\n",
      "[LightGBM] [Info] Start training from score -2.497610\n",
      "[LightGBM] [Info] Start training from score -2.232530\n",
      "[LightGBM] [Info] Start training from score -2.689447\n",
      "[LightGBM] [Info] Start training from score -2.680407\n",
      "[1]\tvalid_0's multi_logloss: 1.97915\n",
      "[2]\tvalid_0's multi_logloss: 1.81796\n",
      "[3]\tvalid_0's multi_logloss: 1.70018\n",
      "[4]\tvalid_0's multi_logloss: 1.6083\n",
      "[5]\tvalid_0's multi_logloss: 1.53268\n",
      "[6]\tvalid_0's multi_logloss: 1.46858\n",
      "[7]\tvalid_0's multi_logloss: 1.41467\n",
      "[8]\tvalid_0's multi_logloss: 1.36817\n",
      "[9]\tvalid_0's multi_logloss: 1.32804\n",
      "[10]\tvalid_0's multi_logloss: 1.29452\n",
      "[11]\tvalid_0's multi_logloss: 1.26467\n",
      "[12]\tvalid_0's multi_logloss: 1.23805\n",
      "[13]\tvalid_0's multi_logloss: 1.21422\n",
      "[14]\tvalid_0's multi_logloss: 1.19377\n",
      "[15]\tvalid_0's multi_logloss: 1.175\n",
      "[16]\tvalid_0's multi_logloss: 1.1585\n",
      "[17]\tvalid_0's multi_logloss: 1.14305\n",
      "[18]\tvalid_0's multi_logloss: 1.12928\n",
      "[19]\tvalid_0's multi_logloss: 1.11675\n",
      "[20]\tvalid_0's multi_logloss: 1.10517\n",
      "[21]\tvalid_0's multi_logloss: 1.09447\n",
      "[22]\tvalid_0's multi_logloss: 1.08519\n",
      "[23]\tvalid_0's multi_logloss: 1.07678\n",
      "[24]\tvalid_0's multi_logloss: 1.0686\n",
      "[25]\tvalid_0's multi_logloss: 1.06092\n",
      "[26]\tvalid_0's multi_logloss: 1.05389\n",
      "[27]\tvalid_0's multi_logloss: 1.04697\n",
      "[28]\tvalid_0's multi_logloss: 1.04062\n",
      "[29]\tvalid_0's multi_logloss: 1.03502\n",
      "[30]\tvalid_0's multi_logloss: 1.02958\n",
      "[31]\tvalid_0's multi_logloss: 1.02442\n",
      "[32]\tvalid_0's multi_logloss: 1.0195\n",
      "[33]\tvalid_0's multi_logloss: 1.01507\n",
      "[34]\tvalid_0's multi_logloss: 1.011\n",
      "[35]\tvalid_0's multi_logloss: 1.00717\n",
      "[36]\tvalid_0's multi_logloss: 1.00302\n",
      "[37]\tvalid_0's multi_logloss: 0.99923\n",
      "[38]\tvalid_0's multi_logloss: 0.995461\n",
      "[39]\tvalid_0's multi_logloss: 0.992097\n",
      "[40]\tvalid_0's multi_logloss: 0.988816\n",
      "[41]\tvalid_0's multi_logloss: 0.985662\n",
      "[42]\tvalid_0's multi_logloss: 0.98285\n",
      "[43]\tvalid_0's multi_logloss: 0.980064\n",
      "[44]\tvalid_0's multi_logloss: 0.977389\n",
      "[45]\tvalid_0's multi_logloss: 0.974984\n",
      "[46]\tvalid_0's multi_logloss: 0.972335\n",
      "[47]\tvalid_0's multi_logloss: 0.969816\n",
      "[48]\tvalid_0's multi_logloss: 0.967549\n",
      "[49]\tvalid_0's multi_logloss: 0.965305\n",
      "[50]\tvalid_0's multi_logloss: 0.963243\n",
      "[51]\tvalid_0's multi_logloss: 0.961114\n",
      "[52]\tvalid_0's multi_logloss: 0.959079\n",
      "[53]\tvalid_0's multi_logloss: 0.957252\n",
      "[54]\tvalid_0's multi_logloss: 0.955402\n",
      "[55]\tvalid_0's multi_logloss: 0.953611\n",
      "[56]\tvalid_0's multi_logloss: 0.951526\n",
      "[57]\tvalid_0's multi_logloss: 0.949717\n",
      "[58]\tvalid_0's multi_logloss: 0.947816\n",
      "[59]\tvalid_0's multi_logloss: 0.945894\n",
      "[60]\tvalid_0's multi_logloss: 0.944339\n",
      "[61]\tvalid_0's multi_logloss: 0.942733\n",
      "[62]\tvalid_0's multi_logloss: 0.9414\n",
      "[63]\tvalid_0's multi_logloss: 0.939943\n",
      "[64]\tvalid_0's multi_logloss: 0.938304\n",
      "[65]\tvalid_0's multi_logloss: 0.9368\n",
      "[66]\tvalid_0's multi_logloss: 0.935433\n",
      "[67]\tvalid_0's multi_logloss: 0.934059\n",
      "[68]\tvalid_0's multi_logloss: 0.932674\n",
      "[69]\tvalid_0's multi_logloss: 0.931199\n",
      "[70]\tvalid_0's multi_logloss: 0.929867\n",
      "[71]\tvalid_0's multi_logloss: 0.928774\n",
      "[72]\tvalid_0's multi_logloss: 0.92755\n",
      "[73]\tvalid_0's multi_logloss: 0.926249\n",
      "[74]\tvalid_0's multi_logloss: 0.92465\n",
      "[75]\tvalid_0's multi_logloss: 0.923212\n",
      "[76]\tvalid_0's multi_logloss: 0.922044\n",
      "[77]\tvalid_0's multi_logloss: 0.920745\n",
      "[78]\tvalid_0's multi_logloss: 0.919811\n",
      "[79]\tvalid_0's multi_logloss: 0.918704\n",
      "[80]\tvalid_0's multi_logloss: 0.917739\n",
      "[81]\tvalid_0's multi_logloss: 0.916537\n",
      "[82]\tvalid_0's multi_logloss: 0.915365\n",
      "[83]\tvalid_0's multi_logloss: 0.91429\n",
      "[84]\tvalid_0's multi_logloss: 0.913279\n",
      "[85]\tvalid_0's multi_logloss: 0.912351\n",
      "[86]\tvalid_0's multi_logloss: 0.91135\n",
      "[87]\tvalid_0's multi_logloss: 0.910489\n",
      "[88]\tvalid_0's multi_logloss: 0.909603\n",
      "[89]\tvalid_0's multi_logloss: 0.908607\n",
      "[90]\tvalid_0's multi_logloss: 0.907737\n",
      "[91]\tvalid_0's multi_logloss: 0.906826\n",
      "[92]\tvalid_0's multi_logloss: 0.905904\n",
      "[93]\tvalid_0's multi_logloss: 0.905174\n",
      "[94]\tvalid_0's multi_logloss: 0.904069\n",
      "[95]\tvalid_0's multi_logloss: 0.903071\n",
      "[96]\tvalid_0's multi_logloss: 0.902237\n",
      "[97]\tvalid_0's multi_logloss: 0.901533\n",
      "[98]\tvalid_0's multi_logloss: 0.90054\n",
      "[99]\tvalid_0's multi_logloss: 0.89976\n",
      "[100]\tvalid_0's multi_logloss: 0.898918\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027047 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -1.047228\n",
      "[LightGBM] [Info] Start training from score -1.516216\n",
      "[LightGBM] [Info] Start training from score -0.845018\n",
      "[1]\tvalid_0's multi_logloss: 1.01271\n",
      "[2]\tvalid_0's multi_logloss: 0.971243\n",
      "[3]\tvalid_0's multi_logloss: 0.936641\n",
      "[4]\tvalid_0's multi_logloss: 0.907325\n",
      "[5]\tvalid_0's multi_logloss: 0.882313\n",
      "[6]\tvalid_0's multi_logloss: 0.860672\n",
      "[7]\tvalid_0's multi_logloss: 0.841931\n",
      "[8]\tvalid_0's multi_logloss: 0.825365\n",
      "[9]\tvalid_0's multi_logloss: 0.81099\n",
      "[10]\tvalid_0's multi_logloss: 0.798179\n",
      "[11]\tvalid_0's multi_logloss: 0.786891\n",
      "[12]\tvalid_0's multi_logloss: 0.776752\n",
      "[13]\tvalid_0's multi_logloss: 0.767606\n",
      "[14]\tvalid_0's multi_logloss: 0.759315\n",
      "[15]\tvalid_0's multi_logloss: 0.751957\n",
      "[16]\tvalid_0's multi_logloss: 0.745261\n",
      "[17]\tvalid_0's multi_logloss: 0.739127\n",
      "[18]\tvalid_0's multi_logloss: 0.733601\n",
      "[19]\tvalid_0's multi_logloss: 0.728566\n",
      "[20]\tvalid_0's multi_logloss: 0.723939\n",
      "[21]\tvalid_0's multi_logloss: 0.719689\n",
      "[22]\tvalid_0's multi_logloss: 0.715739\n",
      "[23]\tvalid_0's multi_logloss: 0.712031\n",
      "[24]\tvalid_0's multi_logloss: 0.708509\n",
      "[25]\tvalid_0's multi_logloss: 0.705346\n",
      "[26]\tvalid_0's multi_logloss: 0.702377\n",
      "[27]\tvalid_0's multi_logloss: 0.699725\n",
      "[28]\tvalid_0's multi_logloss: 0.697237\n",
      "[29]\tvalid_0's multi_logloss: 0.694907\n",
      "[30]\tvalid_0's multi_logloss: 0.692753\n",
      "[31]\tvalid_0's multi_logloss: 0.690776\n",
      "[32]\tvalid_0's multi_logloss: 0.688864\n",
      "[33]\tvalid_0's multi_logloss: 0.687051\n",
      "[34]\tvalid_0's multi_logloss: 0.685285\n",
      "[35]\tvalid_0's multi_logloss: 0.683791\n",
      "[36]\tvalid_0's multi_logloss: 0.682384\n",
      "[37]\tvalid_0's multi_logloss: 0.681002\n",
      "[38]\tvalid_0's multi_logloss: 0.67975\n",
      "[39]\tvalid_0's multi_logloss: 0.678545\n",
      "[40]\tvalid_0's multi_logloss: 0.677458\n",
      "[41]\tvalid_0's multi_logloss: 0.676396\n",
      "[42]\tvalid_0's multi_logloss: 0.675397\n",
      "[43]\tvalid_0's multi_logloss: 0.674489\n",
      "[44]\tvalid_0's multi_logloss: 0.673595\n",
      "[45]\tvalid_0's multi_logloss: 0.672801\n",
      "[46]\tvalid_0's multi_logloss: 0.672047\n",
      "[47]\tvalid_0's multi_logloss: 0.671358\n",
      "[48]\tvalid_0's multi_logloss: 0.670692\n",
      "[49]\tvalid_0's multi_logloss: 0.670042\n",
      "[50]\tvalid_0's multi_logloss: 0.669409\n",
      "[51]\tvalid_0's multi_logloss: 0.668878\n",
      "[52]\tvalid_0's multi_logloss: 0.668244\n",
      "[53]\tvalid_0's multi_logloss: 0.667734\n",
      "[54]\tvalid_0's multi_logloss: 0.667198\n",
      "[55]\tvalid_0's multi_logloss: 0.666703\n",
      "[56]\tvalid_0's multi_logloss: 0.666314\n",
      "[57]\tvalid_0's multi_logloss: 0.665917\n",
      "[58]\tvalid_0's multi_logloss: 0.665489\n",
      "[59]\tvalid_0's multi_logloss: 0.665001\n",
      "[60]\tvalid_0's multi_logloss: 0.664634\n",
      "[61]\tvalid_0's multi_logloss: 0.664263\n",
      "[62]\tvalid_0's multi_logloss: 0.663976\n",
      "[63]\tvalid_0's multi_logloss: 0.663654\n",
      "[64]\tvalid_0's multi_logloss: 0.663362\n",
      "[65]\tvalid_0's multi_logloss: 0.66308\n",
      "[66]\tvalid_0's multi_logloss: 0.662735\n",
      "[67]\tvalid_0's multi_logloss: 0.66247\n",
      "[68]\tvalid_0's multi_logloss: 0.662221\n",
      "[69]\tvalid_0's multi_logloss: 0.661965\n",
      "[70]\tvalid_0's multi_logloss: 0.661718\n",
      "[71]\tvalid_0's multi_logloss: 0.661465\n",
      "[72]\tvalid_0's multi_logloss: 0.661307\n",
      "[73]\tvalid_0's multi_logloss: 0.661019\n",
      "[74]\tvalid_0's multi_logloss: 0.660715\n",
      "[75]\tvalid_0's multi_logloss: 0.660531\n",
      "[76]\tvalid_0's multi_logloss: 0.660319\n",
      "[77]\tvalid_0's multi_logloss: 0.660114\n",
      "[78]\tvalid_0's multi_logloss: 0.659907\n",
      "[79]\tvalid_0's multi_logloss: 0.659734\n",
      "[80]\tvalid_0's multi_logloss: 0.659572\n",
      "[81]\tvalid_0's multi_logloss: 0.659332\n",
      "[82]\tvalid_0's multi_logloss: 0.659159\n",
      "[83]\tvalid_0's multi_logloss: 0.658982\n",
      "[84]\tvalid_0's multi_logloss: 0.65876\n",
      "[85]\tvalid_0's multi_logloss: 0.658609\n",
      "[86]\tvalid_0's multi_logloss: 0.658449\n",
      "[87]\tvalid_0's multi_logloss: 0.658294\n",
      "[88]\tvalid_0's multi_logloss: 0.658153\n",
      "[89]\tvalid_0's multi_logloss: 0.65801\n",
      "[90]\tvalid_0's multi_logloss: 0.657881\n",
      "[91]\tvalid_0's multi_logloss: 0.657713\n",
      "[92]\tvalid_0's multi_logloss: 0.657588\n",
      "[93]\tvalid_0's multi_logloss: 0.657441\n",
      "[94]\tvalid_0's multi_logloss: 0.657315\n",
      "[95]\tvalid_0's multi_logloss: 0.657181\n",
      "[96]\tvalid_0's multi_logloss: 0.657043\n",
      "[97]\tvalid_0's multi_logloss: 0.656859\n",
      "[98]\tvalid_0's multi_logloss: 0.656755\n",
      "[99]\tvalid_0's multi_logloss: 0.656594\n",
      "[100]\tvalid_0's multi_logloss: 0.656434\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027324 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -3.244539\n",
      "[LightGBM] [Info] Start training from score -3.224920\n",
      "[LightGBM] [Info] Start training from score -3.369880\n",
      "[LightGBM] [Info] Start training from score -3.326941\n",
      "[LightGBM] [Info] Start training from score -3.378266\n",
      "[LightGBM] [Info] Start training from score -2.568017\n",
      "[LightGBM] [Info] Start training from score -1.914747\n",
      "[LightGBM] [Info] Start training from score -3.469579\n",
      "[LightGBM] [Info] Start training from score -1.919436\n",
      "[LightGBM] [Info] Start training from score -2.291576\n",
      "[LightGBM] [Info] Start training from score -2.007538\n",
      "[LightGBM] [Info] Start training from score -3.402200\n",
      "[LightGBM] [Info] Start training from score -3.212376\n",
      "[LightGBM] [Info] Start training from score -2.244521\n",
      "[1]\tvalid_0's multi_logloss: 2.40849\n",
      "[2]\tvalid_0's multi_logloss: 2.37492\n",
      "[3]\tvalid_0's multi_logloss: 2.3479\n",
      "[4]\tvalid_0's multi_logloss: 2.32603\n",
      "[5]\tvalid_0's multi_logloss: 2.30733\n",
      "[6]\tvalid_0's multi_logloss: 2.29116\n",
      "[7]\tvalid_0's multi_logloss: 2.27699\n",
      "[8]\tvalid_0's multi_logloss: 2.26478\n",
      "[9]\tvalid_0's multi_logloss: 2.2537\n",
      "[10]\tvalid_0's multi_logloss: 2.24413\n",
      "[11]\tvalid_0's multi_logloss: 2.2354\n",
      "[12]\tvalid_0's multi_logloss: 2.2274\n",
      "[13]\tvalid_0's multi_logloss: 2.22025\n",
      "[14]\tvalid_0's multi_logloss: 2.21398\n",
      "[15]\tvalid_0's multi_logloss: 2.20751\n",
      "[16]\tvalid_0's multi_logloss: 2.20217\n",
      "[17]\tvalid_0's multi_logloss: 2.19712\n",
      "[18]\tvalid_0's multi_logloss: 2.19237\n",
      "[19]\tvalid_0's multi_logloss: 2.18778\n",
      "[20]\tvalid_0's multi_logloss: 2.18359\n",
      "[21]\tvalid_0's multi_logloss: 2.17965\n",
      "[22]\tvalid_0's multi_logloss: 2.17604\n",
      "[23]\tvalid_0's multi_logloss: 2.17272\n",
      "[24]\tvalid_0's multi_logloss: 2.16955\n",
      "[25]\tvalid_0's multi_logloss: 2.16623\n",
      "[26]\tvalid_0's multi_logloss: 2.16335\n",
      "[27]\tvalid_0's multi_logloss: 2.16065\n",
      "[28]\tvalid_0's multi_logloss: 2.15812\n",
      "[29]\tvalid_0's multi_logloss: 2.15554\n",
      "[30]\tvalid_0's multi_logloss: 2.15347\n",
      "[31]\tvalid_0's multi_logloss: 2.1513\n",
      "[32]\tvalid_0's multi_logloss: 2.14938\n",
      "[33]\tvalid_0's multi_logloss: 2.14742\n",
      "[34]\tvalid_0's multi_logloss: 2.14579\n",
      "[35]\tvalid_0's multi_logloss: 2.14419\n",
      "[36]\tvalid_0's multi_logloss: 2.14258\n",
      "[37]\tvalid_0's multi_logloss: 2.14125\n",
      "[38]\tvalid_0's multi_logloss: 2.13958\n",
      "[39]\tvalid_0's multi_logloss: 2.13818\n",
      "[40]\tvalid_0's multi_logloss: 2.13685\n",
      "[41]\tvalid_0's multi_logloss: 2.13555\n",
      "[42]\tvalid_0's multi_logloss: 2.13434\n",
      "[43]\tvalid_0's multi_logloss: 2.13298\n",
      "[44]\tvalid_0's multi_logloss: 2.13165\n",
      "[45]\tvalid_0's multi_logloss: 2.13065\n",
      "[46]\tvalid_0's multi_logloss: 2.12957\n",
      "[47]\tvalid_0's multi_logloss: 2.12836\n",
      "[48]\tvalid_0's multi_logloss: 2.12741\n",
      "[49]\tvalid_0's multi_logloss: 2.12631\n",
      "[50]\tvalid_0's multi_logloss: 2.12538\n",
      "[51]\tvalid_0's multi_logloss: 2.12437\n",
      "[52]\tvalid_0's multi_logloss: 2.12339\n",
      "[53]\tvalid_0's multi_logloss: 2.12214\n",
      "[54]\tvalid_0's multi_logloss: 2.12129\n",
      "[55]\tvalid_0's multi_logloss: 2.1205\n",
      "[56]\tvalid_0's multi_logloss: 2.11949\n",
      "[57]\tvalid_0's multi_logloss: 2.11836\n",
      "[58]\tvalid_0's multi_logloss: 2.11766\n",
      "[59]\tvalid_0's multi_logloss: 2.11682\n",
      "[60]\tvalid_0's multi_logloss: 2.11612\n",
      "[61]\tvalid_0's multi_logloss: 2.1151\n",
      "[62]\tvalid_0's multi_logloss: 2.11432\n",
      "[63]\tvalid_0's multi_logloss: 2.11351\n",
      "[64]\tvalid_0's multi_logloss: 2.11293\n",
      "[65]\tvalid_0's multi_logloss: 2.11225\n",
      "[66]\tvalid_0's multi_logloss: 2.11142\n",
      "[67]\tvalid_0's multi_logloss: 2.11046\n",
      "[68]\tvalid_0's multi_logloss: 2.1096\n",
      "[69]\tvalid_0's multi_logloss: 2.1088\n",
      "[70]\tvalid_0's multi_logloss: 2.10823\n",
      "[71]\tvalid_0's multi_logloss: 2.10756\n",
      "[72]\tvalid_0's multi_logloss: 2.10688\n",
      "[73]\tvalid_0's multi_logloss: 2.10625\n",
      "[74]\tvalid_0's multi_logloss: 2.10556\n",
      "[75]\tvalid_0's multi_logloss: 2.10484\n",
      "[76]\tvalid_0's multi_logloss: 2.10433\n",
      "[77]\tvalid_0's multi_logloss: 2.10374\n",
      "[78]\tvalid_0's multi_logloss: 2.103\n",
      "[79]\tvalid_0's multi_logloss: 2.10242\n",
      "[80]\tvalid_0's multi_logloss: 2.10183\n",
      "[81]\tvalid_0's multi_logloss: 2.1013\n",
      "[82]\tvalid_0's multi_logloss: 2.10069\n",
      "[83]\tvalid_0's multi_logloss: 2.10011\n",
      "[84]\tvalid_0's multi_logloss: 2.09964\n",
      "[85]\tvalid_0's multi_logloss: 2.09893\n",
      "[86]\tvalid_0's multi_logloss: 2.09832\n",
      "[87]\tvalid_0's multi_logloss: 2.09798\n",
      "[88]\tvalid_0's multi_logloss: 2.0976\n",
      "[89]\tvalid_0's multi_logloss: 2.09692\n",
      "[90]\tvalid_0's multi_logloss: 2.09659\n",
      "[91]\tvalid_0's multi_logloss: 2.09612\n",
      "[92]\tvalid_0's multi_logloss: 2.09572\n",
      "[93]\tvalid_0's multi_logloss: 2.0953\n",
      "[94]\tvalid_0's multi_logloss: 2.0948\n",
      "[95]\tvalid_0's multi_logloss: 2.09443\n",
      "[96]\tvalid_0's multi_logloss: 2.09408\n",
      "[97]\tvalid_0's multi_logloss: 2.09382\n",
      "[98]\tvalid_0's multi_logloss: 2.09329\n",
      "[99]\tvalid_0's multi_logloss: 2.09288\n",
      "[100]\tvalid_0's multi_logloss: 2.09255\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027128 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -0.501622\n",
      "[LightGBM] [Info] Start training from score -0.930257\n",
      "[1]\tvalid_0's multi_logloss: 0.579284\n",
      "[2]\tvalid_0's multi_logloss: 0.504973\n",
      "[3]\tvalid_0's multi_logloss: 0.443362\n",
      "[4]\tvalid_0's multi_logloss: 0.391662\n",
      "[5]\tvalid_0's multi_logloss: 0.347739\n",
      "[6]\tvalid_0's multi_logloss: 0.309505\n",
      "[7]\tvalid_0's multi_logloss: 0.276512\n",
      "[8]\tvalid_0's multi_logloss: 0.247567\n",
      "[9]\tvalid_0's multi_logloss: 0.222074\n",
      "[10]\tvalid_0's multi_logloss: 0.199551\n",
      "[11]\tvalid_0's multi_logloss: 0.179684\n",
      "[12]\tvalid_0's multi_logloss: 0.161957\n",
      "[13]\tvalid_0's multi_logloss: 0.146121\n",
      "[14]\tvalid_0's multi_logloss: 0.131966\n",
      "[15]\tvalid_0's multi_logloss: 0.119305\n",
      "[16]\tvalid_0's multi_logloss: 0.108023\n",
      "[17]\tvalid_0's multi_logloss: 0.0978571\n",
      "[18]\tvalid_0's multi_logloss: 0.0887597\n",
      "[19]\tvalid_0's multi_logloss: 0.0804902\n",
      "[20]\tvalid_0's multi_logloss: 0.0731141\n",
      "[21]\tvalid_0's multi_logloss: 0.0664485\n",
      "[22]\tvalid_0's multi_logloss: 0.0603948\n",
      "[23]\tvalid_0's multi_logloss: 0.0549734\n",
      "[24]\tvalid_0's multi_logloss: 0.0500313\n",
      "[25]\tvalid_0's multi_logloss: 0.0455244\n",
      "[26]\tvalid_0's multi_logloss: 0.041482\n",
      "[27]\tvalid_0's multi_logloss: 0.037836\n",
      "[28]\tvalid_0's multi_logloss: 0.034472\n",
      "[29]\tvalid_0's multi_logloss: 0.0314786\n",
      "[30]\tvalid_0's multi_logloss: 0.02873\n",
      "[31]\tvalid_0's multi_logloss: 0.0262353\n",
      "[32]\tvalid_0's multi_logloss: 0.0239456\n",
      "[33]\tvalid_0's multi_logloss: 0.0219166\n",
      "[34]\tvalid_0's multi_logloss: 0.0200511\n",
      "[35]\tvalid_0's multi_logloss: 0.0183531\n",
      "[36]\tvalid_0's multi_logloss: 0.0168153\n",
      "[37]\tvalid_0's multi_logloss: 0.0154126\n",
      "[38]\tvalid_0's multi_logloss: 0.0141322\n",
      "[39]\tvalid_0's multi_logloss: 0.0129564\n",
      "[40]\tvalid_0's multi_logloss: 0.0119011\n",
      "[41]\tvalid_0's multi_logloss: 0.0109262\n",
      "[42]\tvalid_0's multi_logloss: 0.0100435\n",
      "[43]\tvalid_0's multi_logloss: 0.0092616\n",
      "[44]\tvalid_0's multi_logloss: 0.00852385\n",
      "[45]\tvalid_0's multi_logloss: 0.00786526\n",
      "[46]\tvalid_0's multi_logloss: 0.00725668\n",
      "[47]\tvalid_0's multi_logloss: 0.00670321\n",
      "[48]\tvalid_0's multi_logloss: 0.00619618\n",
      "[49]\tvalid_0's multi_logloss: 0.00573188\n",
      "[50]\tvalid_0's multi_logloss: 0.00530774\n",
      "[51]\tvalid_0's multi_logloss: 0.00492106\n",
      "[52]\tvalid_0's multi_logloss: 0.00456672\n",
      "[53]\tvalid_0's multi_logloss: 0.00423874\n",
      "[54]\tvalid_0's multi_logloss: 0.00394977\n",
      "[55]\tvalid_0's multi_logloss: 0.00368161\n",
      "[56]\tvalid_0's multi_logloss: 0.00343151\n",
      "[57]\tvalid_0's multi_logloss: 0.00320434\n",
      "[58]\tvalid_0's multi_logloss: 0.00299649\n",
      "[59]\tvalid_0's multi_logloss: 0.00280464\n",
      "[60]\tvalid_0's multi_logloss: 0.00262723\n",
      "[61]\tvalid_0's multi_logloss: 0.00246961\n",
      "[62]\tvalid_0's multi_logloss: 0.00231765\n",
      "[63]\tvalid_0's multi_logloss: 0.00217645\n",
      "[64]\tvalid_0's multi_logloss: 0.00205094\n",
      "[65]\tvalid_0's multi_logloss: 0.00193818\n",
      "[66]\tvalid_0's multi_logloss: 0.00183454\n",
      "[67]\tvalid_0's multi_logloss: 0.00173768\n",
      "[68]\tvalid_0's multi_logloss: 0.00164727\n",
      "[69]\tvalid_0's multi_logloss: 0.00156176\n",
      "[70]\tvalid_0's multi_logloss: 0.00148529\n",
      "[71]\tvalid_0's multi_logloss: 0.00141723\n",
      "[72]\tvalid_0's multi_logloss: 0.00135198\n",
      "[73]\tvalid_0's multi_logloss: 0.0012937\n",
      "[74]\tvalid_0's multi_logloss: 0.00129516\n",
      "[75]\tvalid_0's multi_logloss: 0.00124515\n",
      "[76]\tvalid_0's multi_logloss: 0.00119829\n",
      "[77]\tvalid_0's multi_logloss: 0.00115303\n",
      "[78]\tvalid_0's multi_logloss: 0.00111126\n",
      "[79]\tvalid_0's multi_logloss: 0.00107424\n",
      "[80]\tvalid_0's multi_logloss: 0.00104008\n",
      "[81]\tvalid_0's multi_logloss: 0.00100631\n",
      "[82]\tvalid_0's multi_logloss: 0.000974941\n",
      "[83]\tvalid_0's multi_logloss: 0.000945868\n",
      "[84]\tvalid_0's multi_logloss: 0.000920397\n",
      "[85]\tvalid_0's multi_logloss: 0.000862423\n",
      "[86]\tvalid_0's multi_logloss: 0.000839413\n",
      "[87]\tvalid_0's multi_logloss: 0.000816882\n",
      "[88]\tvalid_0's multi_logloss: 0.000795727\n",
      "[89]\tvalid_0's multi_logloss: 0.000779914\n",
      "[90]\tvalid_0's multi_logloss: 0.000826967\n",
      "[91]\tvalid_0's multi_logloss: 0.000810716\n",
      "[92]\tvalid_0's multi_logloss: 0.0007949\n",
      "[93]\tvalid_0's multi_logloss: 0.000779547\n",
      "[94]\tvalid_0's multi_logloss: 0.000765771\n",
      "[95]\tvalid_0's multi_logloss: 0.000739016\n",
      "[96]\tvalid_0's multi_logloss: 0.000724446\n",
      "[97]\tvalid_0's multi_logloss: 0.000707822\n",
      "[98]\tvalid_0's multi_logloss: 0.000696922\n",
      "[99]\tvalid_0's multi_logloss: 0.000737113\n",
      "[100]\tvalid_0's multi_logloss: 0.00071049\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027517 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -0.141837\n",
      "[LightGBM] [Info] Start training from score -2.023158\n",
      "[1]\tvalid_0's multi_logloss: 0.360518\n",
      "[2]\tvalid_0's multi_logloss: 0.339456\n",
      "[3]\tvalid_0's multi_logloss: 0.323978\n",
      "[4]\tvalid_0's multi_logloss: 0.311701\n",
      "[5]\tvalid_0's multi_logloss: 0.300656\n",
      "[6]\tvalid_0's multi_logloss: 0.291512\n",
      "[7]\tvalid_0's multi_logloss: 0.283578\n",
      "[8]\tvalid_0's multi_logloss: 0.276144\n",
      "[9]\tvalid_0's multi_logloss: 0.269795\n",
      "[10]\tvalid_0's multi_logloss: 0.264286\n",
      "[11]\tvalid_0's multi_logloss: 0.259061\n",
      "[12]\tvalid_0's multi_logloss: 0.254351\n",
      "[13]\tvalid_0's multi_logloss: 0.250396\n",
      "[14]\tvalid_0's multi_logloss: 0.246044\n",
      "[15]\tvalid_0's multi_logloss: 0.242385\n",
      "[16]\tvalid_0's multi_logloss: 0.239295\n",
      "[17]\tvalid_0's multi_logloss: 0.236222\n",
      "[18]\tvalid_0's multi_logloss: 0.233223\n",
      "[19]\tvalid_0's multi_logloss: 0.230533\n",
      "[20]\tvalid_0's multi_logloss: 0.228173\n",
      "[21]\tvalid_0's multi_logloss: 0.226076\n",
      "[22]\tvalid_0's multi_logloss: 0.223918\n",
      "[23]\tvalid_0's multi_logloss: 0.221906\n",
      "[24]\tvalid_0's multi_logloss: 0.219821\n",
      "[25]\tvalid_0's multi_logloss: 0.218265\n",
      "[26]\tvalid_0's multi_logloss: 0.216445\n",
      "[27]\tvalid_0's multi_logloss: 0.214897\n",
      "[28]\tvalid_0's multi_logloss: 0.21361\n",
      "[29]\tvalid_0's multi_logloss: 0.21226\n",
      "[30]\tvalid_0's multi_logloss: 0.211286\n",
      "[31]\tvalid_0's multi_logloss: 0.210107\n",
      "[32]\tvalid_0's multi_logloss: 0.209059\n",
      "[33]\tvalid_0's multi_logloss: 0.208233\n",
      "[34]\tvalid_0's multi_logloss: 0.207039\n",
      "[35]\tvalid_0's multi_logloss: 0.206303\n",
      "[36]\tvalid_0's multi_logloss: 0.205154\n",
      "[37]\tvalid_0's multi_logloss: 0.204316\n",
      "[38]\tvalid_0's multi_logloss: 0.203316\n",
      "[39]\tvalid_0's multi_logloss: 0.202821\n",
      "[40]\tvalid_0's multi_logloss: 0.201844\n",
      "[41]\tvalid_0's multi_logloss: 0.201102\n",
      "[42]\tvalid_0's multi_logloss: 0.200604\n",
      "[43]\tvalid_0's multi_logloss: 0.199685\n",
      "[44]\tvalid_0's multi_logloss: 0.199275\n",
      "[45]\tvalid_0's multi_logloss: 0.198622\n",
      "[46]\tvalid_0's multi_logloss: 0.197614\n",
      "[47]\tvalid_0's multi_logloss: 0.196462\n",
      "[48]\tvalid_0's multi_logloss: 0.195906\n",
      "[49]\tvalid_0's multi_logloss: 0.195055\n",
      "[50]\tvalid_0's multi_logloss: 0.194585\n",
      "[51]\tvalid_0's multi_logloss: 0.193733\n",
      "[52]\tvalid_0's multi_logloss: 0.193266\n",
      "[53]\tvalid_0's multi_logloss: 0.192464\n",
      "[54]\tvalid_0's multi_logloss: 0.192048\n",
      "[55]\tvalid_0's multi_logloss: 0.191814\n",
      "[56]\tvalid_0's multi_logloss: 0.191164\n",
      "[57]\tvalid_0's multi_logloss: 0.190936\n",
      "[58]\tvalid_0's multi_logloss: 0.190522\n",
      "[59]\tvalid_0's multi_logloss: 0.190027\n",
      "[60]\tvalid_0's multi_logloss: 0.189598\n",
      "[61]\tvalid_0's multi_logloss: 0.189034\n",
      "[62]\tvalid_0's multi_logloss: 0.188533\n",
      "[63]\tvalid_0's multi_logloss: 0.188216\n",
      "[64]\tvalid_0's multi_logloss: 0.187636\n",
      "[65]\tvalid_0's multi_logloss: 0.187406\n",
      "[66]\tvalid_0's multi_logloss: 0.186871\n",
      "[67]\tvalid_0's multi_logloss: 0.186692\n",
      "[68]\tvalid_0's multi_logloss: 0.18629\n",
      "[69]\tvalid_0's multi_logloss: 0.186037\n",
      "[70]\tvalid_0's multi_logloss: 0.185514\n",
      "[71]\tvalid_0's multi_logloss: 0.185167\n",
      "[72]\tvalid_0's multi_logloss: 0.184893\n",
      "[73]\tvalid_0's multi_logloss: 0.184374\n",
      "[74]\tvalid_0's multi_logloss: 0.184064\n",
      "[75]\tvalid_0's multi_logloss: 0.183837\n",
      "[76]\tvalid_0's multi_logloss: 0.183482\n",
      "[77]\tvalid_0's multi_logloss: 0.183128\n",
      "[78]\tvalid_0's multi_logloss: 0.182831\n",
      "[79]\tvalid_0's multi_logloss: 0.182592\n",
      "[80]\tvalid_0's multi_logloss: 0.182419\n",
      "[81]\tvalid_0's multi_logloss: 0.182083\n",
      "[82]\tvalid_0's multi_logloss: 0.181743\n",
      "[83]\tvalid_0's multi_logloss: 0.181445\n",
      "[84]\tvalid_0's multi_logloss: 0.180834\n",
      "[85]\tvalid_0's multi_logloss: 0.180314\n",
      "[86]\tvalid_0's multi_logloss: 0.179896\n",
      "[87]\tvalid_0's multi_logloss: 0.179704\n",
      "[88]\tvalid_0's multi_logloss: 0.179439\n",
      "[89]\tvalid_0's multi_logloss: 0.178883\n",
      "[90]\tvalid_0's multi_logloss: 0.178618\n",
      "[91]\tvalid_0's multi_logloss: 0.178241\n",
      "[92]\tvalid_0's multi_logloss: 0.178056\n",
      "[93]\tvalid_0's multi_logloss: 0.177924\n",
      "[94]\tvalid_0's multi_logloss: 0.177436\n",
      "[95]\tvalid_0's multi_logloss: 0.177077\n",
      "[96]\tvalid_0's multi_logloss: 0.176882\n",
      "[97]\tvalid_0's multi_logloss: 0.176674\n",
      "[98]\tvalid_0's multi_logloss: 0.176481\n",
      "[99]\tvalid_0's multi_logloss: 0.176339\n",
      "[100]\tvalid_0's multi_logloss: 0.176199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [57:35, 148.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012810 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 7715638, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -1.249550\n",
      "[LightGBM] [Info] Start training from score -3.165534\n",
      "[LightGBM] [Info] Start training from score -1.726403\n",
      "[LightGBM] [Info] Start training from score -1.902421\n",
      "[LightGBM] [Info] Start training from score -1.667720\n",
      "[LightGBM] [Info] Start training from score -1.861961\n",
      "[1]\tvalid_0's multi_logloss: 1.67571\n",
      "[2]\tvalid_0's multi_logloss: 1.66716\n",
      "[3]\tvalid_0's multi_logloss: 1.65926\n",
      "[4]\tvalid_0's multi_logloss: 1.65313\n",
      "[5]\tvalid_0's multi_logloss: 1.64768\n",
      "[6]\tvalid_0's multi_logloss: 1.64253\n",
      "[7]\tvalid_0's multi_logloss: 1.63855\n",
      "[8]\tvalid_0's multi_logloss: 1.63404\n",
      "[9]\tvalid_0's multi_logloss: 1.63085\n",
      "[10]\tvalid_0's multi_logloss: 1.62718\n",
      "[11]\tvalid_0's multi_logloss: 1.62468\n",
      "[12]\tvalid_0's multi_logloss: 1.62249\n",
      "[13]\tvalid_0's multi_logloss: 1.61981\n",
      "[14]\tvalid_0's multi_logloss: 1.61779\n",
      "[15]\tvalid_0's multi_logloss: 1.61596\n",
      "[16]\tvalid_0's multi_logloss: 1.61374\n",
      "[17]\tvalid_0's multi_logloss: 1.61207\n",
      "[18]\tvalid_0's multi_logloss: 1.61006\n",
      "[19]\tvalid_0's multi_logloss: 1.60814\n",
      "[20]\tvalid_0's multi_logloss: 1.60691\n",
      "[21]\tvalid_0's multi_logloss: 1.60494\n",
      "[22]\tvalid_0's multi_logloss: 1.6035\n",
      "[23]\tvalid_0's multi_logloss: 1.6024\n",
      "[24]\tvalid_0's multi_logloss: 1.60126\n",
      "[25]\tvalid_0's multi_logloss: 1.60031\n",
      "[26]\tvalid_0's multi_logloss: 1.59918\n",
      "[27]\tvalid_0's multi_logloss: 1.59749\n",
      "[28]\tvalid_0's multi_logloss: 1.59593\n",
      "[29]\tvalid_0's multi_logloss: 1.59462\n",
      "[30]\tvalid_0's multi_logloss: 1.59377\n",
      "[31]\tvalid_0's multi_logloss: 1.59294\n",
      "[32]\tvalid_0's multi_logloss: 1.59175\n",
      "[33]\tvalid_0's multi_logloss: 1.59076\n",
      "[34]\tvalid_0's multi_logloss: 1.59009\n",
      "[35]\tvalid_0's multi_logloss: 1.58893\n",
      "[36]\tvalid_0's multi_logloss: 1.58818\n",
      "[37]\tvalid_0's multi_logloss: 1.58722\n",
      "[38]\tvalid_0's multi_logloss: 1.58669\n",
      "[39]\tvalid_0's multi_logloss: 1.58561\n",
      "[40]\tvalid_0's multi_logloss: 1.58475\n",
      "[41]\tvalid_0's multi_logloss: 1.58426\n",
      "[42]\tvalid_0's multi_logloss: 1.58356\n",
      "[43]\tvalid_0's multi_logloss: 1.58297\n",
      "[44]\tvalid_0's multi_logloss: 1.58208\n",
      "[45]\tvalid_0's multi_logloss: 1.58131\n",
      "[46]\tvalid_0's multi_logloss: 1.58066\n",
      "[47]\tvalid_0's multi_logloss: 1.58005\n",
      "[48]\tvalid_0's multi_logloss: 1.57952\n",
      "[49]\tvalid_0's multi_logloss: 1.57885\n",
      "[50]\tvalid_0's multi_logloss: 1.57842\n",
      "[51]\tvalid_0's multi_logloss: 1.5778\n",
      "[52]\tvalid_0's multi_logloss: 1.57724\n",
      "[53]\tvalid_0's multi_logloss: 1.57648\n",
      "[54]\tvalid_0's multi_logloss: 1.57609\n",
      "[55]\tvalid_0's multi_logloss: 1.57559\n",
      "[56]\tvalid_0's multi_logloss: 1.57508\n",
      "[57]\tvalid_0's multi_logloss: 1.5746\n",
      "[58]\tvalid_0's multi_logloss: 1.57392\n",
      "[59]\tvalid_0's multi_logloss: 1.5736\n",
      "[60]\tvalid_0's multi_logloss: 1.57311\n",
      "[61]\tvalid_0's multi_logloss: 1.5727\n",
      "[62]\tvalid_0's multi_logloss: 1.57231\n",
      "[63]\tvalid_0's multi_logloss: 1.57193\n",
      "[64]\tvalid_0's multi_logloss: 1.57161\n",
      "[65]\tvalid_0's multi_logloss: 1.57126\n",
      "[66]\tvalid_0's multi_logloss: 1.5709\n",
      "[67]\tvalid_0's multi_logloss: 1.5706\n",
      "[68]\tvalid_0's multi_logloss: 1.57024\n",
      "[69]\tvalid_0's multi_logloss: 1.56995\n",
      "[70]\tvalid_0's multi_logloss: 1.56956\n",
      "[71]\tvalid_0's multi_logloss: 1.56922\n",
      "[72]\tvalid_0's multi_logloss: 1.56888\n",
      "[73]\tvalid_0's multi_logloss: 1.56857\n",
      "[74]\tvalid_0's multi_logloss: 1.56795\n",
      "[75]\tvalid_0's multi_logloss: 1.5677\n",
      "[76]\tvalid_0's multi_logloss: 1.56746\n",
      "[77]\tvalid_0's multi_logloss: 1.56717\n",
      "[78]\tvalid_0's multi_logloss: 1.56665\n",
      "[79]\tvalid_0's multi_logloss: 1.56578\n",
      "[80]\tvalid_0's multi_logloss: 1.5656\n",
      "[81]\tvalid_0's multi_logloss: 1.56522\n",
      "[82]\tvalid_0's multi_logloss: 1.56495\n",
      "[83]\tvalid_0's multi_logloss: 1.56464\n",
      "[84]\tvalid_0's multi_logloss: 1.56403\n",
      "[85]\tvalid_0's multi_logloss: 1.56372\n",
      "[86]\tvalid_0's multi_logloss: 1.56343\n",
      "[87]\tvalid_0's multi_logloss: 1.56275\n",
      "[88]\tvalid_0's multi_logloss: 1.56218\n",
      "[89]\tvalid_0's multi_logloss: 1.56177\n",
      "[90]\tvalid_0's multi_logloss: 1.56152\n",
      "[91]\tvalid_0's multi_logloss: 1.56128\n",
      "[92]\tvalid_0's multi_logloss: 1.56096\n",
      "[93]\tvalid_0's multi_logloss: 1.56067\n",
      "[94]\tvalid_0's multi_logloss: 1.56037\n",
      "[95]\tvalid_0's multi_logloss: 1.56008\n",
      "[96]\tvalid_0's multi_logloss: 1.55982\n",
      "[97]\tvalid_0's multi_logloss: 1.55961\n",
      "[98]\tvalid_0's multi_logloss: 1.55932\n",
      "[99]\tvalid_0's multi_logloss: 1.55909\n",
      "[100]\tvalid_0's multi_logloss: 1.55881\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008526 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 7715638, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -3.388563\n",
      "[LightGBM] [Info] Start training from score -3.286043\n",
      "[LightGBM] [Info] Start training from score -3.265766\n",
      "[LightGBM] [Info] Start training from score -3.814547\n",
      "[LightGBM] [Info] Start training from score -3.310265\n",
      "[LightGBM] [Info] Start training from score -3.206426\n",
      "[LightGBM] [Info] Start training from score -4.264605\n",
      "[LightGBM] [Info] Start training from score -3.385622\n",
      "[LightGBM] [Info] Start training from score -3.678169\n",
      "[LightGBM] [Info] Start training from score -3.401590\n",
      "[LightGBM] [Info] Start training from score -4.879144\n",
      "[LightGBM] [Info] Start training from score -3.027581\n",
      "[LightGBM] [Info] Start training from score -2.985319\n",
      "[LightGBM] [Info] Start training from score -3.251856\n",
      "[LightGBM] [Info] Start training from score -3.294527\n",
      "[LightGBM] [Info] Start training from score -3.372086\n",
      "[LightGBM] [Info] Start training from score -2.973489\n",
      "[LightGBM] [Info] Start training from score -2.489644\n",
      "[LightGBM] [Info] Start training from score -3.403357\n",
      "[LightGBM] [Info] Start training from score -4.161407\n",
      "[LightGBM] [Info] Start training from score -4.219942\n",
      "[LightGBM] [Info] Start training from score -3.454308\n",
      "[LightGBM] [Info] Start training from score -3.414970\n",
      "[LightGBM] [Info] Start training from score -3.160243\n",
      "[LightGBM] [Info] Start training from score -3.113230\n",
      "[LightGBM] [Info] Start training from score -3.209175\n",
      "[LightGBM] [Info] Start training from score -3.282600\n",
      "[LightGBM] [Info] Start training from score -3.180636\n",
      "[1]\tvalid_0's multi_logloss: 2.5216\n",
      "[2]\tvalid_0's multi_logloss: 2.32876\n",
      "[3]\tvalid_0's multi_logloss: 2.19444\n",
      "[4]\tvalid_0's multi_logloss: 2.09654\n",
      "[5]\tvalid_0's multi_logloss: 2.01743\n",
      "[6]\tvalid_0's multi_logloss: 1.95047\n",
      "[7]\tvalid_0's multi_logloss: 1.8955\n",
      "[8]\tvalid_0's multi_logloss: 1.84919\n",
      "[9]\tvalid_0's multi_logloss: 1.8101\n",
      "[10]\tvalid_0's multi_logloss: 1.77485\n",
      "[11]\tvalid_0's multi_logloss: 1.74513\n",
      "[12]\tvalid_0's multi_logloss: 1.71814\n",
      "[13]\tvalid_0's multi_logloss: 1.69407\n",
      "[14]\tvalid_0's multi_logloss: 1.67283\n",
      "[15]\tvalid_0's multi_logloss: 1.65423\n",
      "[16]\tvalid_0's multi_logloss: 1.63718\n",
      "[17]\tvalid_0's multi_logloss: 1.62189\n",
      "[18]\tvalid_0's multi_logloss: 1.60773\n",
      "[19]\tvalid_0's multi_logloss: 1.59678\n",
      "[20]\tvalid_0's multi_logloss: 1.5845\n",
      "[21]\tvalid_0's multi_logloss: 1.57436\n",
      "[22]\tvalid_0's multi_logloss: 1.56437\n",
      "[23]\tvalid_0's multi_logloss: 1.55513\n",
      "[24]\tvalid_0's multi_logloss: 1.54661\n",
      "[25]\tvalid_0's multi_logloss: 1.53811\n",
      "[26]\tvalid_0's multi_logloss: 1.53063\n",
      "[27]\tvalid_0's multi_logloss: 1.52334\n",
      "[28]\tvalid_0's multi_logloss: 1.51683\n",
      "[29]\tvalid_0's multi_logloss: 1.50975\n",
      "[30]\tvalid_0's multi_logloss: 1.50366\n",
      "[31]\tvalid_0's multi_logloss: 1.49799\n",
      "[32]\tvalid_0's multi_logloss: 1.49242\n",
      "[33]\tvalid_0's multi_logloss: 1.48708\n",
      "[34]\tvalid_0's multi_logloss: 1.48252\n",
      "[35]\tvalid_0's multi_logloss: 1.47724\n",
      "[36]\tvalid_0's multi_logloss: 1.47307\n",
      "[37]\tvalid_0's multi_logloss: 1.46905\n",
      "[38]\tvalid_0's multi_logloss: 1.46522\n",
      "[39]\tvalid_0's multi_logloss: 1.46056\n",
      "[40]\tvalid_0's multi_logloss: 1.45687\n",
      "[41]\tvalid_0's multi_logloss: 1.45312\n",
      "[42]\tvalid_0's multi_logloss: 1.44953\n",
      "[43]\tvalid_0's multi_logloss: 1.44609\n",
      "[44]\tvalid_0's multi_logloss: 1.44292\n",
      "[45]\tvalid_0's multi_logloss: 1.43966\n",
      "[46]\tvalid_0's multi_logloss: 1.43688\n",
      "[47]\tvalid_0's multi_logloss: 1.43353\n",
      "[48]\tvalid_0's multi_logloss: 1.43024\n",
      "[49]\tvalid_0's multi_logloss: 1.42731\n",
      "[50]\tvalid_0's multi_logloss: 1.42543\n",
      "[51]\tvalid_0's multi_logloss: 1.42241\n",
      "[52]\tvalid_0's multi_logloss: 1.42007\n",
      "[53]\tvalid_0's multi_logloss: 1.41779\n",
      "[54]\tvalid_0's multi_logloss: 1.41516\n",
      "[55]\tvalid_0's multi_logloss: 1.41289\n",
      "[56]\tvalid_0's multi_logloss: 1.41083\n",
      "[57]\tvalid_0's multi_logloss: 1.40894\n",
      "[58]\tvalid_0's multi_logloss: 1.40655\n",
      "[59]\tvalid_0's multi_logloss: 1.4051\n",
      "[60]\tvalid_0's multi_logloss: 1.40272\n",
      "[61]\tvalid_0's multi_logloss: 1.40106\n",
      "[62]\tvalid_0's multi_logloss: 1.39893\n",
      "[63]\tvalid_0's multi_logloss: 1.39795\n",
      "[64]\tvalid_0's multi_logloss: 1.39524\n",
      "[65]\tvalid_0's multi_logloss: 1.39348\n",
      "[66]\tvalid_0's multi_logloss: 1.39188\n",
      "[67]\tvalid_0's multi_logloss: 1.39022\n",
      "[68]\tvalid_0's multi_logloss: 1.38938\n",
      "[69]\tvalid_0's multi_logloss: 1.38724\n",
      "[70]\tvalid_0's multi_logloss: 1.38554\n",
      "[71]\tvalid_0's multi_logloss: 1.38525\n",
      "[72]\tvalid_0's multi_logloss: 1.38365\n",
      "[73]\tvalid_0's multi_logloss: 1.38337\n",
      "[74]\tvalid_0's multi_logloss: 1.38329\n",
      "[75]\tvalid_0's multi_logloss: 1.38018\n",
      "[76]\tvalid_0's multi_logloss: 1.37943\n",
      "[77]\tvalid_0's multi_logloss: 1.37814\n",
      "[78]\tvalid_0's multi_logloss: 1.37773\n",
      "[79]\tvalid_0's multi_logloss: 1.37573\n",
      "[80]\tvalid_0's multi_logloss: 1.37573\n",
      "[81]\tvalid_0's multi_logloss: 1.37386\n",
      "[82]\tvalid_0's multi_logloss: 1.37178\n",
      "[83]\tvalid_0's multi_logloss: 1.37122\n",
      "[84]\tvalid_0's multi_logloss: 1.36996\n",
      "[85]\tvalid_0's multi_logloss: 1.36914\n",
      "[86]\tvalid_0's multi_logloss: 1.36732\n",
      "[87]\tvalid_0's multi_logloss: 1.37244\n",
      "[88]\tvalid_0's multi_logloss: 1.36596\n",
      "[89]\tvalid_0's multi_logloss: 1.36797\n",
      "[90]\tvalid_0's multi_logloss: 1.36359\n",
      "[91]\tvalid_0's multi_logloss: 1.36308\n",
      "[92]\tvalid_0's multi_logloss: 1.3649\n",
      "[93]\tvalid_0's multi_logloss: 1.36167\n",
      "[94]\tvalid_0's multi_logloss: 1.36156\n",
      "[95]\tvalid_0's multi_logloss: 1.35887\n",
      "[96]\tvalid_0's multi_logloss: 1.3577\n",
      "[97]\tvalid_0's multi_logloss: 1.35887\n",
      "[98]\tvalid_0's multi_logloss: 1.35785\n",
      "[99]\tvalid_0's multi_logloss: 1.35986\n",
      "[100]\tvalid_0's multi_logloss: 1.35301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29it [59:30, 138.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001515 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 820733, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -0.683185\n",
      "[LightGBM] [Info] Start training from score -2.382997\n",
      "[LightGBM] [Info] Start training from score -2.734975\n",
      "[LightGBM] [Info] Start training from score -3.826068\n",
      "[LightGBM] [Info] Start training from score -1.583719\n",
      "[LightGBM] [Info] Start training from score -2.199855\n",
      "[1]\tvalid_0's multi_logloss: 1.16347\n",
      "[2]\tvalid_0's multi_logloss: 1.04896\n",
      "[3]\tvalid_0's multi_logloss: 0.960953\n",
      "[4]\tvalid_0's multi_logloss: 0.891438\n",
      "[5]\tvalid_0's multi_logloss: 0.83482\n",
      "[6]\tvalid_0's multi_logloss: 0.786995\n",
      "[7]\tvalid_0's multi_logloss: 0.746867\n",
      "[8]\tvalid_0's multi_logloss: 0.712881\n",
      "[9]\tvalid_0's multi_logloss: 0.684345\n",
      "[10]\tvalid_0's multi_logloss: 0.659606\n",
      "[11]\tvalid_0's multi_logloss: 0.637692\n",
      "[12]\tvalid_0's multi_logloss: 0.618982\n",
      "[13]\tvalid_0's multi_logloss: 0.602588\n",
      "[14]\tvalid_0's multi_logloss: 0.588289\n",
      "[15]\tvalid_0's multi_logloss: 0.575481\n",
      "[16]\tvalid_0's multi_logloss: 0.564274\n",
      "[17]\tvalid_0's multi_logloss: 0.553854\n",
      "[18]\tvalid_0's multi_logloss: 0.544731\n",
      "[19]\tvalid_0's multi_logloss: 0.536089\n",
      "[20]\tvalid_0's multi_logloss: 0.528824\n",
      "[21]\tvalid_0's multi_logloss: 0.522174\n",
      "[22]\tvalid_0's multi_logloss: 0.515616\n",
      "[23]\tvalid_0's multi_logloss: 0.510139\n",
      "[24]\tvalid_0's multi_logloss: 0.50493\n",
      "[25]\tvalid_0's multi_logloss: 0.499986\n",
      "[26]\tvalid_0's multi_logloss: 0.495924\n",
      "[27]\tvalid_0's multi_logloss: 0.491818\n",
      "[28]\tvalid_0's multi_logloss: 0.487637\n",
      "[29]\tvalid_0's multi_logloss: 0.484051\n",
      "[30]\tvalid_0's multi_logloss: 0.480938\n",
      "[31]\tvalid_0's multi_logloss: 0.477867\n",
      "[32]\tvalid_0's multi_logloss: 0.474942\n",
      "[33]\tvalid_0's multi_logloss: 0.47254\n",
      "[34]\tvalid_0's multi_logloss: 0.470108\n",
      "[35]\tvalid_0's multi_logloss: 0.467332\n",
      "[36]\tvalid_0's multi_logloss: 0.46539\n",
      "[37]\tvalid_0's multi_logloss: 0.463166\n",
      "[38]\tvalid_0's multi_logloss: 0.460995\n",
      "[39]\tvalid_0's multi_logloss: 0.459208\n",
      "[40]\tvalid_0's multi_logloss: 0.457969\n",
      "[41]\tvalid_0's multi_logloss: 0.456287\n",
      "[42]\tvalid_0's multi_logloss: 0.454599\n",
      "[43]\tvalid_0's multi_logloss: 0.452776\n",
      "[44]\tvalid_0's multi_logloss: 0.451521\n",
      "[45]\tvalid_0's multi_logloss: 0.450312\n",
      "[46]\tvalid_0's multi_logloss: 0.448766\n",
      "[47]\tvalid_0's multi_logloss: 0.447546\n",
      "[48]\tvalid_0's multi_logloss: 0.446175\n",
      "[49]\tvalid_0's multi_logloss: 0.445333\n",
      "[50]\tvalid_0's multi_logloss: 0.444222\n",
      "[51]\tvalid_0's multi_logloss: 0.443485\n",
      "[52]\tvalid_0's multi_logloss: 0.442314\n",
      "[53]\tvalid_0's multi_logloss: 0.441242\n",
      "[54]\tvalid_0's multi_logloss: 0.44046\n",
      "[55]\tvalid_0's multi_logloss: 0.439523\n",
      "[56]\tvalid_0's multi_logloss: 0.438485\n",
      "[57]\tvalid_0's multi_logloss: 0.438138\n",
      "[58]\tvalid_0's multi_logloss: 0.437698\n",
      "[59]\tvalid_0's multi_logloss: 0.437351\n",
      "[60]\tvalid_0's multi_logloss: 0.436212\n",
      "[61]\tvalid_0's multi_logloss: 0.435972\n",
      "[62]\tvalid_0's multi_logloss: 0.436346\n",
      "[63]\tvalid_0's multi_logloss: 0.434397\n",
      "[64]\tvalid_0's multi_logloss: 0.436697\n",
      "[65]\tvalid_0's multi_logloss: 0.432798\n",
      "[66]\tvalid_0's multi_logloss: 0.43278\n",
      "[67]\tvalid_0's multi_logloss: 0.431801\n",
      "[68]\tvalid_0's multi_logloss: 0.435472\n",
      "[69]\tvalid_0's multi_logloss: 0.431062\n",
      "[70]\tvalid_0's multi_logloss: 0.431453\n",
      "[71]\tvalid_0's multi_logloss: 0.42984\n",
      "[72]\tvalid_0's multi_logloss: 0.431391\n",
      "[73]\tvalid_0's multi_logloss: 0.43054\n",
      "[74]\tvalid_0's multi_logloss: 0.429102\n",
      "[75]\tvalid_0's multi_logloss: 0.430533\n",
      "[76]\tvalid_0's multi_logloss: 0.429229\n",
      "[77]\tvalid_0's multi_logloss: 0.427912\n",
      "[78]\tvalid_0's multi_logloss: 0.430263\n",
      "[79]\tvalid_0's multi_logloss: 0.429606\n",
      "[80]\tvalid_0's multi_logloss: 0.431071\n",
      "[81]\tvalid_0's multi_logloss: 0.431027\n",
      "[82]\tvalid_0's multi_logloss: 0.433338\n",
      "[83]\tvalid_0's multi_logloss: 0.431094\n",
      "[84]\tvalid_0's multi_logloss: 0.439345\n",
      "[85]\tvalid_0's multi_logloss: 0.436183\n",
      "[86]\tvalid_0's multi_logloss: 0.430623\n",
      "[87]\tvalid_0's multi_logloss: 0.432652\n",
      "[88]\tvalid_0's multi_logloss: 0.433552\n",
      "[89]\tvalid_0's multi_logloss: 0.431229\n",
      "[90]\tvalid_0's multi_logloss: 0.435791\n",
      "[91]\tvalid_0's multi_logloss: 0.432336\n",
      "[92]\tvalid_0's multi_logloss: 0.432027\n",
      "[93]\tvalid_0's multi_logloss: 0.431891\n",
      "[94]\tvalid_0's multi_logloss: 0.431797\n",
      "[95]\tvalid_0's multi_logloss: 0.43658\n",
      "[96]\tvalid_0's multi_logloss: 0.429665\n",
      "[97]\tvalid_0's multi_logloss: 0.432182\n",
      "[98]\tvalid_0's multi_logloss: 0.43344\n",
      "[99]\tvalid_0's multi_logloss: 0.430668\n",
      "[100]\tvalid_0's multi_logloss: 0.427348\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001763 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 820733, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -2.163833\n",
      "[LightGBM] [Info] Start training from score -1.796397\n",
      "[LightGBM] [Info] Start training from score -1.843741\n",
      "[LightGBM] [Info] Start training from score -1.989576\n",
      "[LightGBM] [Info] Start training from score -1.941218\n",
      "[LightGBM] [Info] Start training from score -1.949016\n",
      "[LightGBM] [Info] Start training from score -1.978333\n",
      "[1]\tvalid_0's multi_logloss: 1.90158\n",
      "[2]\tvalid_0's multi_logloss: 1.87154\n",
      "[3]\tvalid_0's multi_logloss: 1.84757\n",
      "[4]\tvalid_0's multi_logloss: 1.82796\n",
      "[5]\tvalid_0's multi_logloss: 1.81194\n",
      "[6]\tvalid_0's multi_logloss: 1.79855\n",
      "[7]\tvalid_0's multi_logloss: 1.7874\n",
      "[8]\tvalid_0's multi_logloss: 1.77789\n",
      "[9]\tvalid_0's multi_logloss: 1.76985\n",
      "[10]\tvalid_0's multi_logloss: 1.76295\n",
      "[11]\tvalid_0's multi_logloss: 1.75685\n",
      "[12]\tvalid_0's multi_logloss: 1.75165\n",
      "[13]\tvalid_0's multi_logloss: 1.74706\n",
      "[14]\tvalid_0's multi_logloss: 1.74321\n",
      "[15]\tvalid_0's multi_logloss: 1.73958\n",
      "[16]\tvalid_0's multi_logloss: 1.73639\n",
      "[17]\tvalid_0's multi_logloss: 1.73364\n",
      "[18]\tvalid_0's multi_logloss: 1.73123\n",
      "[19]\tvalid_0's multi_logloss: 1.72896\n",
      "[20]\tvalid_0's multi_logloss: 1.72689\n",
      "[21]\tvalid_0's multi_logloss: 1.72505\n",
      "[22]\tvalid_0's multi_logloss: 1.72335\n",
      "[23]\tvalid_0's multi_logloss: 1.72186\n",
      "[24]\tvalid_0's multi_logloss: 1.72054\n",
      "[25]\tvalid_0's multi_logloss: 1.71925\n",
      "[26]\tvalid_0's multi_logloss: 1.71808\n",
      "[27]\tvalid_0's multi_logloss: 1.71693\n",
      "[28]\tvalid_0's multi_logloss: 1.71595\n",
      "[29]\tvalid_0's multi_logloss: 1.71489\n",
      "[30]\tvalid_0's multi_logloss: 1.71399\n",
      "[31]\tvalid_0's multi_logloss: 1.71323\n",
      "[32]\tvalid_0's multi_logloss: 1.71243\n",
      "[33]\tvalid_0's multi_logloss: 1.71141\n",
      "[34]\tvalid_0's multi_logloss: 1.71069\n",
      "[35]\tvalid_0's multi_logloss: 1.70985\n",
      "[36]\tvalid_0's multi_logloss: 1.70915\n",
      "[37]\tvalid_0's multi_logloss: 1.70854\n",
      "[38]\tvalid_0's multi_logloss: 1.70794\n",
      "[39]\tvalid_0's multi_logloss: 1.70742\n",
      "[40]\tvalid_0's multi_logloss: 1.70684\n",
      "[41]\tvalid_0's multi_logloss: 1.70628\n",
      "[42]\tvalid_0's multi_logloss: 1.7057\n",
      "[43]\tvalid_0's multi_logloss: 1.70516\n",
      "[44]\tvalid_0's multi_logloss: 1.70457\n",
      "[45]\tvalid_0's multi_logloss: 1.70408\n",
      "[46]\tvalid_0's multi_logloss: 1.70364\n",
      "[47]\tvalid_0's multi_logloss: 1.70321\n",
      "[48]\tvalid_0's multi_logloss: 1.70277\n",
      "[49]\tvalid_0's multi_logloss: 1.70246\n",
      "[50]\tvalid_0's multi_logloss: 1.70218\n",
      "[51]\tvalid_0's multi_logloss: 1.7017\n",
      "[52]\tvalid_0's multi_logloss: 1.70145\n",
      "[53]\tvalid_0's multi_logloss: 1.70118\n",
      "[54]\tvalid_0's multi_logloss: 1.70083\n",
      "[55]\tvalid_0's multi_logloss: 1.70053\n",
      "[56]\tvalid_0's multi_logloss: 1.70035\n",
      "[57]\tvalid_0's multi_logloss: 1.70013\n",
      "[58]\tvalid_0's multi_logloss: 1.69986\n",
      "[59]\tvalid_0's multi_logloss: 1.69961\n",
      "[60]\tvalid_0's multi_logloss: 1.69925\n",
      "[61]\tvalid_0's multi_logloss: 1.69894\n",
      "[62]\tvalid_0's multi_logloss: 1.6988\n",
      "[63]\tvalid_0's multi_logloss: 1.69868\n",
      "[64]\tvalid_0's multi_logloss: 1.69846\n",
      "[65]\tvalid_0's multi_logloss: 1.69825\n",
      "[66]\tvalid_0's multi_logloss: 1.69814\n",
      "[67]\tvalid_0's multi_logloss: 1.69785\n",
      "[68]\tvalid_0's multi_logloss: 1.69759\n",
      "[69]\tvalid_0's multi_logloss: 1.69743\n",
      "[70]\tvalid_0's multi_logloss: 1.69721\n",
      "[71]\tvalid_0's multi_logloss: 1.69702\n",
      "[72]\tvalid_0's multi_logloss: 1.69678\n",
      "[73]\tvalid_0's multi_logloss: 1.69671\n",
      "[74]\tvalid_0's multi_logloss: 1.69638\n",
      "[75]\tvalid_0's multi_logloss: 1.69623\n",
      "[76]\tvalid_0's multi_logloss: 1.69614\n",
      "[77]\tvalid_0's multi_logloss: 1.69598\n",
      "[78]\tvalid_0's multi_logloss: 1.69581\n",
      "[79]\tvalid_0's multi_logloss: 1.69568\n",
      "[80]\tvalid_0's multi_logloss: 1.69558\n",
      "[81]\tvalid_0's multi_logloss: 1.69547\n",
      "[82]\tvalid_0's multi_logloss: 1.69536\n",
      "[83]\tvalid_0's multi_logloss: 1.69518\n",
      "[84]\tvalid_0's multi_logloss: 1.69507\n",
      "[85]\tvalid_0's multi_logloss: 1.69492\n",
      "[86]\tvalid_0's multi_logloss: 1.69483\n",
      "[87]\tvalid_0's multi_logloss: 1.69457\n",
      "[88]\tvalid_0's multi_logloss: 1.69438\n",
      "[89]\tvalid_0's multi_logloss: 1.69427\n",
      "[90]\tvalid_0's multi_logloss: 1.69399\n",
      "[91]\tvalid_0's multi_logloss: 1.69378\n",
      "[92]\tvalid_0's multi_logloss: 1.69368\n",
      "[93]\tvalid_0's multi_logloss: 1.69344\n",
      "[94]\tvalid_0's multi_logloss: 1.69333\n",
      "[95]\tvalid_0's multi_logloss: 1.69318\n",
      "[96]\tvalid_0's multi_logloss: 1.69302\n",
      "[97]\tvalid_0's multi_logloss: 1.69285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [59:39, 99.70s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[98]\tvalid_0's multi_logloss: 1.6927\n",
      "[99]\tvalid_0's multi_logloss: 1.69253\n",
      "[100]\tvalid_0's multi_logloss: 1.69231\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019306 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1530\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score -1.853404\n",
      "[LightGBM] [Info] Start training from score -2.123202\n",
      "[LightGBM] [Info] Start training from score -2.391862\n",
      "[LightGBM] [Info] Start training from score -2.719639\n",
      "[LightGBM] [Info] Start training from score -2.078311\n",
      "[LightGBM] [Info] Start training from score -2.161447\n",
      "[LightGBM] [Info] Start training from score -2.497610\n",
      "[LightGBM] [Info] Start training from score -2.232530\n",
      "[LightGBM] [Info] Start training from score -2.689447\n",
      "[LightGBM] [Info] Start training from score -2.680407\n",
      "[1]\tvalid_0's multi_logloss: 2.02915\n",
      "[2]\tvalid_0's multi_logloss: 1.88064\n",
      "[3]\tvalid_0's multi_logloss: 1.76844\n",
      "[4]\tvalid_0's multi_logloss: 1.68021\n",
      "[5]\tvalid_0's multi_logloss: 1.60944\n",
      "[6]\tvalid_0's multi_logloss: 1.54936\n",
      "[7]\tvalid_0's multi_logloss: 1.49742\n",
      "[8]\tvalid_0's multi_logloss: 1.45294\n",
      "[9]\tvalid_0's multi_logloss: 1.41471\n",
      "[10]\tvalid_0's multi_logloss: 1.38133\n",
      "[11]\tvalid_0's multi_logloss: 1.35216\n",
      "[12]\tvalid_0's multi_logloss: 1.32585\n",
      "[13]\tvalid_0's multi_logloss: 1.30151\n",
      "[14]\tvalid_0's multi_logloss: 1.27959\n",
      "[15]\tvalid_0's multi_logloss: 1.2593\n",
      "[16]\tvalid_0's multi_logloss: 1.24192\n",
      "[17]\tvalid_0's multi_logloss: 1.22543\n",
      "[18]\tvalid_0's multi_logloss: 1.21038\n",
      "[19]\tvalid_0's multi_logloss: 1.1964\n",
      "[20]\tvalid_0's multi_logloss: 1.18465\n",
      "[21]\tvalid_0's multi_logloss: 1.17342\n",
      "[22]\tvalid_0's multi_logloss: 1.16259\n",
      "[23]\tvalid_0's multi_logloss: 1.15232\n",
      "[24]\tvalid_0's multi_logloss: 1.14289\n",
      "[25]\tvalid_0's multi_logloss: 1.13444\n",
      "[26]\tvalid_0's multi_logloss: 1.12613\n",
      "[27]\tvalid_0's multi_logloss: 1.11877\n",
      "[28]\tvalid_0's multi_logloss: 1.11136\n",
      "[29]\tvalid_0's multi_logloss: 1.10477\n",
      "[30]\tvalid_0's multi_logloss: 1.09854\n",
      "[31]\tvalid_0's multi_logloss: 1.0925\n",
      "[32]\tvalid_0's multi_logloss: 1.08682\n",
      "[33]\tvalid_0's multi_logloss: 1.08143\n",
      "[34]\tvalid_0's multi_logloss: 1.07639\n",
      "[35]\tvalid_0's multi_logloss: 1.07209\n",
      "[36]\tvalid_0's multi_logloss: 1.0668\n",
      "[37]\tvalid_0's multi_logloss: 1.06278\n",
      "[38]\tvalid_0's multi_logloss: 1.05863\n",
      "[39]\tvalid_0's multi_logloss: 1.05442\n",
      "[40]\tvalid_0's multi_logloss: 1.05043\n",
      "[41]\tvalid_0's multi_logloss: 1.04667\n",
      "[42]\tvalid_0's multi_logloss: 1.04347\n",
      "[43]\tvalid_0's multi_logloss: 1.04009\n",
      "[44]\tvalid_0's multi_logloss: 1.03619\n",
      "[45]\tvalid_0's multi_logloss: 1.0328\n",
      "[46]\tvalid_0's multi_logloss: 1.02995\n",
      "[47]\tvalid_0's multi_logloss: 1.02717\n",
      "[48]\tvalid_0's multi_logloss: 1.0248\n",
      "[49]\tvalid_0's multi_logloss: 1.02176\n",
      "[50]\tvalid_0's multi_logloss: 1.01847\n",
      "[51]\tvalid_0's multi_logloss: 1.01604\n",
      "[52]\tvalid_0's multi_logloss: 1.01358\n",
      "[53]\tvalid_0's multi_logloss: 1.01113\n",
      "[54]\tvalid_0's multi_logloss: 1.00885\n",
      "[55]\tvalid_0's multi_logloss: 1.00675\n",
      "[56]\tvalid_0's multi_logloss: 1.00468\n",
      "[57]\tvalid_0's multi_logloss: 1.00254\n",
      "[58]\tvalid_0's multi_logloss: 1.00048\n",
      "[59]\tvalid_0's multi_logloss: 0.99864\n",
      "[60]\tvalid_0's multi_logloss: 0.99675\n",
      "[61]\tvalid_0's multi_logloss: 0.99496\n",
      "[62]\tvalid_0's multi_logloss: 0.99332\n",
      "[63]\tvalid_0's multi_logloss: 0.991555\n",
      "[64]\tvalid_0's multi_logloss: 0.989609\n",
      "[65]\tvalid_0's multi_logloss: 0.987684\n",
      "[66]\tvalid_0's multi_logloss: 0.986394\n",
      "[67]\tvalid_0's multi_logloss: 0.985185\n",
      "[68]\tvalid_0's multi_logloss: 0.983458\n",
      "[69]\tvalid_0's multi_logloss: 0.981814\n",
      "[70]\tvalid_0's multi_logloss: 0.979929\n",
      "[71]\tvalid_0's multi_logloss: 0.978499\n",
      "[72]\tvalid_0's multi_logloss: 0.976972\n",
      "[73]\tvalid_0's multi_logloss: 0.975383\n",
      "[74]\tvalid_0's multi_logloss: 0.973611\n",
      "[75]\tvalid_0's multi_logloss: 0.972267\n",
      "[76]\tvalid_0's multi_logloss: 0.970545\n",
      "[77]\tvalid_0's multi_logloss: 0.969028\n",
      "[78]\tvalid_0's multi_logloss: 0.967824\n",
      "[79]\tvalid_0's multi_logloss: 0.96662\n",
      "[80]\tvalid_0's multi_logloss: 0.965652\n",
      "[81]\tvalid_0's multi_logloss: 0.964626\n",
      "[82]\tvalid_0's multi_logloss: 0.96312\n",
      "[83]\tvalid_0's multi_logloss: 0.962133\n",
      "[84]\tvalid_0's multi_logloss: 0.961141\n",
      "[85]\tvalid_0's multi_logloss: 0.959936\n",
      "[86]\tvalid_0's multi_logloss: 0.958867\n",
      "[87]\tvalid_0's multi_logloss: 0.95793\n",
      "[88]\tvalid_0's multi_logloss: 0.956997\n",
      "[89]\tvalid_0's multi_logloss: 0.956256\n",
      "[90]\tvalid_0's multi_logloss: 0.954941\n",
      "[91]\tvalid_0's multi_logloss: 0.953758\n",
      "[92]\tvalid_0's multi_logloss: 0.952855\n",
      "[93]\tvalid_0's multi_logloss: 0.951957\n",
      "[94]\tvalid_0's multi_logloss: 0.950876\n",
      "[95]\tvalid_0's multi_logloss: 0.950202\n",
      "[96]\tvalid_0's multi_logloss: 0.94898\n",
      "[97]\tvalid_0's multi_logloss: 0.947979\n",
      "[98]\tvalid_0's multi_logloss: 0.947145\n",
      "[99]\tvalid_0's multi_logloss: 0.946369\n",
      "[100]\tvalid_0's multi_logloss: 0.945651\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028423 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1530\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score -1.047228\n",
      "[LightGBM] [Info] Start training from score -1.516216\n",
      "[LightGBM] [Info] Start training from score -0.845018\n",
      "[1]\tvalid_0's multi_logloss: 1.01527\n",
      "[2]\tvalid_0's multi_logloss: 0.975532\n",
      "[3]\tvalid_0's multi_logloss: 0.941975\n",
      "[4]\tvalid_0's multi_logloss: 0.913612\n",
      "[5]\tvalid_0's multi_logloss: 0.889522\n",
      "[6]\tvalid_0's multi_logloss: 0.868453\n",
      "[7]\tvalid_0's multi_logloss: 0.850278\n",
      "[8]\tvalid_0's multi_logloss: 0.834188\n",
      "[9]\tvalid_0's multi_logloss: 0.820142\n",
      "[10]\tvalid_0's multi_logloss: 0.807533\n",
      "[11]\tvalid_0's multi_logloss: 0.796253\n",
      "[12]\tvalid_0's multi_logloss: 0.785987\n",
      "[13]\tvalid_0's multi_logloss: 0.776686\n",
      "[14]\tvalid_0's multi_logloss: 0.768426\n",
      "[15]\tvalid_0's multi_logloss: 0.760902\n",
      "[16]\tvalid_0's multi_logloss: 0.75424\n",
      "[17]\tvalid_0's multi_logloss: 0.748029\n",
      "[18]\tvalid_0's multi_logloss: 0.742197\n",
      "[19]\tvalid_0's multi_logloss: 0.736871\n",
      "[20]\tvalid_0's multi_logloss: 0.732117\n",
      "[21]\tvalid_0's multi_logloss: 0.727769\n",
      "[22]\tvalid_0's multi_logloss: 0.72369\n",
      "[23]\tvalid_0's multi_logloss: 0.719982\n",
      "[24]\tvalid_0's multi_logloss: 0.716443\n",
      "[25]\tvalid_0's multi_logloss: 0.713173\n",
      "[26]\tvalid_0's multi_logloss: 0.710179\n",
      "[27]\tvalid_0's multi_logloss: 0.707361\n",
      "[28]\tvalid_0's multi_logloss: 0.704648\n",
      "[29]\tvalid_0's multi_logloss: 0.70227\n",
      "[30]\tvalid_0's multi_logloss: 0.700006\n",
      "[31]\tvalid_0's multi_logloss: 0.697823\n",
      "[32]\tvalid_0's multi_logloss: 0.695793\n",
      "[33]\tvalid_0's multi_logloss: 0.693917\n",
      "[34]\tvalid_0's multi_logloss: 0.692177\n",
      "[35]\tvalid_0's multi_logloss: 0.690515\n",
      "[36]\tvalid_0's multi_logloss: 0.688966\n",
      "[37]\tvalid_0's multi_logloss: 0.687496\n",
      "[38]\tvalid_0's multi_logloss: 0.68611\n",
      "[39]\tvalid_0's multi_logloss: 0.684781\n",
      "[40]\tvalid_0's multi_logloss: 0.683443\n",
      "[41]\tvalid_0's multi_logloss: 0.682348\n",
      "[42]\tvalid_0's multi_logloss: 0.681227\n",
      "[43]\tvalid_0's multi_logloss: 0.680121\n",
      "[44]\tvalid_0's multi_logloss: 0.679154\n",
      "[45]\tvalid_0's multi_logloss: 0.678195\n",
      "[46]\tvalid_0's multi_logloss: 0.677418\n",
      "[47]\tvalid_0's multi_logloss: 0.676628\n",
      "[48]\tvalid_0's multi_logloss: 0.675809\n",
      "[49]\tvalid_0's multi_logloss: 0.67503\n",
      "[50]\tvalid_0's multi_logloss: 0.674303\n",
      "[51]\tvalid_0's multi_logloss: 0.673703\n",
      "[52]\tvalid_0's multi_logloss: 0.673114\n",
      "[53]\tvalid_0's multi_logloss: 0.672481\n",
      "[54]\tvalid_0's multi_logloss: 0.671967\n",
      "[55]\tvalid_0's multi_logloss: 0.671252\n",
      "[56]\tvalid_0's multi_logloss: 0.670722\n",
      "[57]\tvalid_0's multi_logloss: 0.670232\n",
      "[58]\tvalid_0's multi_logloss: 0.669807\n",
      "[59]\tvalid_0's multi_logloss: 0.66934\n",
      "[60]\tvalid_0's multi_logloss: 0.668859\n",
      "[61]\tvalid_0's multi_logloss: 0.668461\n",
      "[62]\tvalid_0's multi_logloss: 0.66809\n",
      "[63]\tvalid_0's multi_logloss: 0.667653\n",
      "[64]\tvalid_0's multi_logloss: 0.667263\n",
      "[65]\tvalid_0's multi_logloss: 0.666909\n",
      "[66]\tvalid_0's multi_logloss: 0.666511\n",
      "[67]\tvalid_0's multi_logloss: 0.666244\n",
      "[68]\tvalid_0's multi_logloss: 0.66596\n",
      "[69]\tvalid_0's multi_logloss: 0.665629\n",
      "[70]\tvalid_0's multi_logloss: 0.665236\n",
      "[71]\tvalid_0's multi_logloss: 0.664981\n",
      "[72]\tvalid_0's multi_logloss: 0.664747\n",
      "[73]\tvalid_0's multi_logloss: 0.664473\n",
      "[74]\tvalid_0's multi_logloss: 0.664182\n",
      "[75]\tvalid_0's multi_logloss: 0.663976\n",
      "[76]\tvalid_0's multi_logloss: 0.663726\n",
      "[77]\tvalid_0's multi_logloss: 0.663522\n",
      "[78]\tvalid_0's multi_logloss: 0.663182\n",
      "[79]\tvalid_0's multi_logloss: 0.662966\n",
      "[80]\tvalid_0's multi_logloss: 0.662742\n",
      "[81]\tvalid_0's multi_logloss: 0.662462\n",
      "[82]\tvalid_0's multi_logloss: 0.662264\n",
      "[83]\tvalid_0's multi_logloss: 0.662139\n",
      "[84]\tvalid_0's multi_logloss: 0.661823\n",
      "[85]\tvalid_0's multi_logloss: 0.661664\n",
      "[86]\tvalid_0's multi_logloss: 0.661513\n",
      "[87]\tvalid_0's multi_logloss: 0.661291\n",
      "[88]\tvalid_0's multi_logloss: 0.66113\n",
      "[89]\tvalid_0's multi_logloss: 0.660983\n",
      "[90]\tvalid_0's multi_logloss: 0.660845\n",
      "[91]\tvalid_0's multi_logloss: 0.66069\n",
      "[92]\tvalid_0's multi_logloss: 0.660532\n",
      "[93]\tvalid_0's multi_logloss: 0.660331\n",
      "[94]\tvalid_0's multi_logloss: 0.660221\n",
      "[95]\tvalid_0's multi_logloss: 0.660084\n",
      "[96]\tvalid_0's multi_logloss: 0.659962\n",
      "[97]\tvalid_0's multi_logloss: 0.659767\n",
      "[98]\tvalid_0's multi_logloss: 0.659598\n",
      "[99]\tvalid_0's multi_logloss: 0.659447\n",
      "[100]\tvalid_0's multi_logloss: 0.659413\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018980 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1530\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score -3.244539\n",
      "[LightGBM] [Info] Start training from score -3.224920\n",
      "[LightGBM] [Info] Start training from score -3.369880\n",
      "[LightGBM] [Info] Start training from score -3.326941\n",
      "[LightGBM] [Info] Start training from score -3.378266\n",
      "[LightGBM] [Info] Start training from score -2.568017\n",
      "[LightGBM] [Info] Start training from score -1.914747\n",
      "[LightGBM] [Info] Start training from score -3.469579\n",
      "[LightGBM] [Info] Start training from score -1.919436\n",
      "[LightGBM] [Info] Start training from score -2.291576\n",
      "[LightGBM] [Info] Start training from score -2.007538\n",
      "[LightGBM] [Info] Start training from score -3.402200\n",
      "[LightGBM] [Info] Start training from score -3.212376\n",
      "[LightGBM] [Info] Start training from score -2.244521\n",
      "[1]\tvalid_0's multi_logloss: 2.40033\n",
      "[2]\tvalid_0's multi_logloss: 2.36113\n",
      "[3]\tvalid_0's multi_logloss: 2.33099\n",
      "[4]\tvalid_0's multi_logloss: 2.306\n",
      "[5]\tvalid_0's multi_logloss: 2.28529\n",
      "[6]\tvalid_0's multi_logloss: 2.26701\n",
      "[7]\tvalid_0's multi_logloss: 2.2516\n",
      "[8]\tvalid_0's multi_logloss: 2.23761\n",
      "[9]\tvalid_0's multi_logloss: 2.22543\n",
      "[10]\tvalid_0's multi_logloss: 2.21465\n",
      "[11]\tvalid_0's multi_logloss: 2.20523\n",
      "[12]\tvalid_0's multi_logloss: 2.19691\n",
      "[13]\tvalid_0's multi_logloss: 2.18914\n",
      "[14]\tvalid_0's multi_logloss: 2.18201\n",
      "[15]\tvalid_0's multi_logloss: 2.17543\n",
      "[16]\tvalid_0's multi_logloss: 2.16957\n",
      "[17]\tvalid_0's multi_logloss: 2.16416\n",
      "[18]\tvalid_0's multi_logloss: 2.15915\n",
      "[19]\tvalid_0's multi_logloss: 2.15479\n",
      "[20]\tvalid_0's multi_logloss: 2.15056\n",
      "[21]\tvalid_0's multi_logloss: 2.14668\n",
      "[22]\tvalid_0's multi_logloss: 2.14308\n",
      "[23]\tvalid_0's multi_logloss: 2.13953\n",
      "[24]\tvalid_0's multi_logloss: 2.13615\n",
      "[25]\tvalid_0's multi_logloss: 2.13321\n",
      "[26]\tvalid_0's multi_logloss: 2.1306\n",
      "[27]\tvalid_0's multi_logloss: 2.12798\n",
      "[28]\tvalid_0's multi_logloss: 2.12562\n",
      "[29]\tvalid_0's multi_logloss: 2.12343\n",
      "[30]\tvalid_0's multi_logloss: 2.12116\n",
      "[31]\tvalid_0's multi_logloss: 2.11902\n",
      "[32]\tvalid_0's multi_logloss: 2.11719\n",
      "[33]\tvalid_0's multi_logloss: 2.11526\n",
      "[34]\tvalid_0's multi_logloss: 2.1135\n",
      "[35]\tvalid_0's multi_logloss: 2.11181\n",
      "[36]\tvalid_0's multi_logloss: 2.11029\n",
      "[37]\tvalid_0's multi_logloss: 2.10867\n",
      "[38]\tvalid_0's multi_logloss: 2.10733\n",
      "[39]\tvalid_0's multi_logloss: 2.10591\n",
      "[40]\tvalid_0's multi_logloss: 2.10462\n",
      "[41]\tvalid_0's multi_logloss: 2.10318\n",
      "[42]\tvalid_0's multi_logloss: 2.10208\n",
      "[43]\tvalid_0's multi_logloss: 2.1008\n",
      "[44]\tvalid_0's multi_logloss: 2.09985\n",
      "[45]\tvalid_0's multi_logloss: 2.09863\n",
      "[46]\tvalid_0's multi_logloss: 2.09754\n",
      "[47]\tvalid_0's multi_logloss: 2.09653\n",
      "[48]\tvalid_0's multi_logloss: 2.09568\n",
      "[49]\tvalid_0's multi_logloss: 2.09448\n",
      "[50]\tvalid_0's multi_logloss: 2.09356\n",
      "[51]\tvalid_0's multi_logloss: 2.09265\n",
      "[52]\tvalid_0's multi_logloss: 2.09184\n",
      "[53]\tvalid_0's multi_logloss: 2.0911\n",
      "[54]\tvalid_0's multi_logloss: 2.09014\n",
      "[55]\tvalid_0's multi_logloss: 2.08935\n",
      "[56]\tvalid_0's multi_logloss: 2.08854\n",
      "[57]\tvalid_0's multi_logloss: 2.08786\n",
      "[58]\tvalid_0's multi_logloss: 2.08713\n",
      "[59]\tvalid_0's multi_logloss: 2.08631\n",
      "[60]\tvalid_0's multi_logloss: 2.08561\n",
      "[61]\tvalid_0's multi_logloss: 2.08491\n",
      "[62]\tvalid_0's multi_logloss: 2.08432\n",
      "[63]\tvalid_0's multi_logloss: 2.0837\n",
      "[64]\tvalid_0's multi_logloss: 2.08304\n",
      "[65]\tvalid_0's multi_logloss: 2.08239\n",
      "[66]\tvalid_0's multi_logloss: 2.08173\n",
      "[67]\tvalid_0's multi_logloss: 2.08112\n",
      "[68]\tvalid_0's multi_logloss: 2.08046\n",
      "[69]\tvalid_0's multi_logloss: 2.07997\n",
      "[70]\tvalid_0's multi_logloss: 2.07941\n",
      "[71]\tvalid_0's multi_logloss: 2.07883\n",
      "[72]\tvalid_0's multi_logloss: 2.07831\n",
      "[73]\tvalid_0's multi_logloss: 2.07782\n",
      "[74]\tvalid_0's multi_logloss: 2.07747\n",
      "[75]\tvalid_0's multi_logloss: 2.0769\n",
      "[76]\tvalid_0's multi_logloss: 2.07646\n",
      "[77]\tvalid_0's multi_logloss: 2.07599\n",
      "[78]\tvalid_0's multi_logloss: 2.07561\n",
      "[79]\tvalid_0's multi_logloss: 2.0752\n",
      "[80]\tvalid_0's multi_logloss: 2.07478\n",
      "[81]\tvalid_0's multi_logloss: 2.07431\n",
      "[82]\tvalid_0's multi_logloss: 2.07389\n",
      "[83]\tvalid_0's multi_logloss: 2.07351\n",
      "[84]\tvalid_0's multi_logloss: 2.07317\n",
      "[85]\tvalid_0's multi_logloss: 2.07286\n",
      "[86]\tvalid_0's multi_logloss: 2.07253\n",
      "[87]\tvalid_0's multi_logloss: 2.07216\n",
      "[88]\tvalid_0's multi_logloss: 2.07178\n",
      "[89]\tvalid_0's multi_logloss: 2.07148\n",
      "[90]\tvalid_0's multi_logloss: 2.07106\n",
      "[91]\tvalid_0's multi_logloss: 2.07075\n",
      "[92]\tvalid_0's multi_logloss: 2.07041\n",
      "[93]\tvalid_0's multi_logloss: 2.07005\n",
      "[94]\tvalid_0's multi_logloss: 2.06955\n",
      "[95]\tvalid_0's multi_logloss: 2.06914\n",
      "[96]\tvalid_0's multi_logloss: 2.06883\n",
      "[97]\tvalid_0's multi_logloss: 2.06848\n",
      "[98]\tvalid_0's multi_logloss: 2.06821\n",
      "[99]\tvalid_0's multi_logloss: 2.06787\n",
      "[100]\tvalid_0's multi_logloss: 2.06745\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1530\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score -0.501622\n",
      "[LightGBM] [Info] Start training from score -0.930257\n",
      "[1]\tvalid_0's multi_logloss: 0.583345\n",
      "[2]\tvalid_0's multi_logloss: 0.512675\n",
      "[3]\tvalid_0's multi_logloss: 0.453894\n",
      "[4]\tvalid_0's multi_logloss: 0.4043\n",
      "[5]\tvalid_0's multi_logloss: 0.36158\n",
      "[6]\tvalid_0's multi_logloss: 0.324539\n",
      "[7]\tvalid_0's multi_logloss: 0.291598\n",
      "[8]\tvalid_0's multi_logloss: 0.262694\n",
      "[9]\tvalid_0's multi_logloss: 0.237177\n",
      "[10]\tvalid_0's multi_logloss: 0.214671\n",
      "[11]\tvalid_0's multi_logloss: 0.194101\n",
      "[12]\tvalid_0's multi_logloss: 0.176027\n",
      "[13]\tvalid_0's multi_logloss: 0.160045\n",
      "[14]\tvalid_0's multi_logloss: 0.1454\n",
      "[15]\tvalid_0's multi_logloss: 0.132127\n",
      "[16]\tvalid_0's multi_logloss: 0.120291\n",
      "[17]\tvalid_0's multi_logloss: 0.109549\n",
      "[18]\tvalid_0's multi_logloss: 0.0998235\n",
      "[19]\tvalid_0's multi_logloss: 0.0913486\n",
      "[20]\tvalid_0's multi_logloss: 0.0833931\n",
      "[21]\tvalid_0's multi_logloss: 0.0764238\n",
      "[22]\tvalid_0's multi_logloss: 0.069952\n",
      "[23]\tvalid_0's multi_logloss: 0.0641113\n",
      "[24]\tvalid_0's multi_logloss: 0.0589685\n",
      "[25]\tvalid_0's multi_logloss: 0.0540936\n",
      "[26]\tvalid_0's multi_logloss: 0.0496603\n",
      "[27]\tvalid_0's multi_logloss: 0.0458217\n",
      "[28]\tvalid_0's multi_logloss: 0.0420463\n",
      "[29]\tvalid_0's multi_logloss: 0.0386598\n",
      "[30]\tvalid_0's multi_logloss: 0.035592\n",
      "[31]\tvalid_0's multi_logloss: 0.0327824\n",
      "[32]\tvalid_0's multi_logloss: 0.0302623\n",
      "[33]\tvalid_0's multi_logloss: 0.0279406\n",
      "[34]\tvalid_0's multi_logloss: 0.0257983\n",
      "[35]\tvalid_0's multi_logloss: 0.0238711\n",
      "[36]\tvalid_0's multi_logloss: 0.0220771\n",
      "[37]\tvalid_0's multi_logloss: 0.0204428\n",
      "[38]\tvalid_0's multi_logloss: 0.0189864\n",
      "[39]\tvalid_0's multi_logloss: 0.0176247\n",
      "[40]\tvalid_0's multi_logloss: 0.0163489\n",
      "[41]\tvalid_0's multi_logloss: 0.0152202\n",
      "[42]\tvalid_0's multi_logloss: 0.0141517\n",
      "[43]\tvalid_0's multi_logloss: 0.0131556\n",
      "[44]\tvalid_0's multi_logloss: 0.0122341\n",
      "[45]\tvalid_0's multi_logloss: 0.0114205\n",
      "[46]\tvalid_0's multi_logloss: 0.0106731\n",
      "[47]\tvalid_0's multi_logloss: 0.0099942\n",
      "[48]\tvalid_0's multi_logloss: 0.00934382\n",
      "[49]\tvalid_0's multi_logloss: 0.00873525\n",
      "[50]\tvalid_0's multi_logloss: 0.00818051\n",
      "[51]\tvalid_0's multi_logloss: 0.00767239\n",
      "[52]\tvalid_0's multi_logloss: 0.00723252\n",
      "[53]\tvalid_0's multi_logloss: 0.00680924\n",
      "[54]\tvalid_0's multi_logloss: 0.0063958\n",
      "[55]\tvalid_0's multi_logloss: 0.00602583\n",
      "[56]\tvalid_0's multi_logloss: 0.00567622\n",
      "[57]\tvalid_0's multi_logloss: 0.00536665\n",
      "[58]\tvalid_0's multi_logloss: 0.00505822\n",
      "[59]\tvalid_0's multi_logloss: 0.00479335\n",
      "[60]\tvalid_0's multi_logloss: 0.00453577\n",
      "[61]\tvalid_0's multi_logloss: 0.00431844\n",
      "[62]\tvalid_0's multi_logloss: 0.00409021\n",
      "[63]\tvalid_0's multi_logloss: 0.00388248\n",
      "[64]\tvalid_0's multi_logloss: 0.00368278\n",
      "[65]\tvalid_0's multi_logloss: 0.00352065\n",
      "[66]\tvalid_0's multi_logloss: 0.00335277\n",
      "[67]\tvalid_0's multi_logloss: 0.003194\n",
      "[68]\tvalid_0's multi_logloss: 0.00304799\n",
      "[69]\tvalid_0's multi_logloss: 0.0030015\n",
      "[70]\tvalid_0's multi_logloss: 0.00287434\n",
      "[71]\tvalid_0's multi_logloss: 0.00275185\n",
      "[72]\tvalid_0's multi_logloss: 0.00264273\n",
      "[73]\tvalid_0's multi_logloss: 0.00254623\n",
      "[74]\tvalid_0's multi_logloss: 0.00245128\n",
      "[75]\tvalid_0's multi_logloss: 0.00236009\n",
      "[76]\tvalid_0's multi_logloss: 0.00226663\n",
      "[77]\tvalid_0's multi_logloss: 0.00218357\n",
      "[78]\tvalid_0's multi_logloss: 0.0021079\n",
      "[79]\tvalid_0's multi_logloss: 0.00203373\n",
      "[80]\tvalid_0's multi_logloss: 0.00197013\n",
      "[81]\tvalid_0's multi_logloss: 0.00190987\n",
      "[82]\tvalid_0's multi_logloss: 0.00184961\n",
      "[83]\tvalid_0's multi_logloss: 0.0017933\n",
      "[84]\tvalid_0's multi_logloss: 0.00174549\n",
      "[85]\tvalid_0's multi_logloss: 0.00169367\n",
      "[86]\tvalid_0's multi_logloss: 0.0016491\n",
      "[87]\tvalid_0's multi_logloss: 0.00160495\n",
      "[88]\tvalid_0's multi_logloss: 0.00155901\n",
      "[89]\tvalid_0's multi_logloss: 0.00151841\n",
      "[90]\tvalid_0's multi_logloss: 0.00150463\n",
      "[91]\tvalid_0's multi_logloss: 0.00146764\n",
      "[92]\tvalid_0's multi_logloss: 0.00143642\n",
      "[93]\tvalid_0's multi_logloss: 0.00140578\n",
      "[94]\tvalid_0's multi_logloss: 0.00147279\n",
      "[95]\tvalid_0's multi_logloss: 0.00144443\n",
      "[96]\tvalid_0's multi_logloss: 0.00144691\n",
      "[97]\tvalid_0's multi_logloss: 0.00142244\n",
      "[98]\tvalid_0's multi_logloss: 0.00154572\n",
      "[99]\tvalid_0's multi_logloss: 0.00170257\n",
      "[100]\tvalid_0's multi_logloss: 0.00163073\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019074 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1530\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score -0.141837\n",
      "[LightGBM] [Info] Start training from score -2.023158\n",
      "[1]\tvalid_0's multi_logloss: 0.352608\n",
      "[2]\tvalid_0's multi_logloss: 0.327493\n",
      "[3]\tvalid_0's multi_logloss: 0.307268\n",
      "[4]\tvalid_0's multi_logloss: 0.291937\n",
      "[5]\tvalid_0's multi_logloss: 0.278216\n",
      "[6]\tvalid_0's multi_logloss: 0.266118\n",
      "[7]\tvalid_0's multi_logloss: 0.25639\n",
      "[8]\tvalid_0's multi_logloss: 0.247301\n",
      "[9]\tvalid_0's multi_logloss: 0.239618\n",
      "[10]\tvalid_0's multi_logloss: 0.232929\n",
      "[11]\tvalid_0's multi_logloss: 0.226918\n",
      "[12]\tvalid_0's multi_logloss: 0.221259\n",
      "[13]\tvalid_0's multi_logloss: 0.216009\n",
      "[14]\tvalid_0's multi_logloss: 0.211652\n",
      "[15]\tvalid_0's multi_logloss: 0.20721\n",
      "[16]\tvalid_0's multi_logloss: 0.203429\n",
      "[17]\tvalid_0's multi_logloss: 0.199927\n",
      "[18]\tvalid_0's multi_logloss: 0.196751\n",
      "[19]\tvalid_0's multi_logloss: 0.193996\n",
      "[20]\tvalid_0's multi_logloss: 0.19143\n",
      "[21]\tvalid_0's multi_logloss: 0.189148\n",
      "[22]\tvalid_0's multi_logloss: 0.186792\n",
      "[23]\tvalid_0's multi_logloss: 0.184915\n",
      "[24]\tvalid_0's multi_logloss: 0.182822\n",
      "[25]\tvalid_0's multi_logloss: 0.181191\n",
      "[26]\tvalid_0's multi_logloss: 0.179598\n",
      "[27]\tvalid_0's multi_logloss: 0.177913\n",
      "[28]\tvalid_0's multi_logloss: 0.176618\n",
      "[29]\tvalid_0's multi_logloss: 0.17533\n",
      "[30]\tvalid_0's multi_logloss: 0.174003\n",
      "[31]\tvalid_0's multi_logloss: 0.172891\n",
      "[32]\tvalid_0's multi_logloss: 0.171671\n",
      "[33]\tvalid_0's multi_logloss: 0.170564\n",
      "[34]\tvalid_0's multi_logloss: 0.169668\n",
      "[35]\tvalid_0's multi_logloss: 0.168924\n",
      "[36]\tvalid_0's multi_logloss: 0.167643\n",
      "[37]\tvalid_0's multi_logloss: 0.166922\n",
      "[38]\tvalid_0's multi_logloss: 0.166292\n",
      "[39]\tvalid_0's multi_logloss: 0.165451\n",
      "[40]\tvalid_0's multi_logloss: 0.164472\n",
      "[41]\tvalid_0's multi_logloss: 0.163658\n",
      "[42]\tvalid_0's multi_logloss: 0.162828\n",
      "[43]\tvalid_0's multi_logloss: 0.161891\n",
      "[44]\tvalid_0's multi_logloss: 0.161301\n",
      "[45]\tvalid_0's multi_logloss: 0.160552\n",
      "[46]\tvalid_0's multi_logloss: 0.159932\n",
      "[47]\tvalid_0's multi_logloss: 0.15956\n",
      "[48]\tvalid_0's multi_logloss: 0.159171\n",
      "[49]\tvalid_0's multi_logloss: 0.158668\n",
      "[50]\tvalid_0's multi_logloss: 0.158163\n",
      "[51]\tvalid_0's multi_logloss: 0.157581\n",
      "[52]\tvalid_0's multi_logloss: 0.156963\n",
      "[53]\tvalid_0's multi_logloss: 0.156682\n",
      "[54]\tvalid_0's multi_logloss: 0.156044\n",
      "[55]\tvalid_0's multi_logloss: 0.155554\n",
      "[56]\tvalid_0's multi_logloss: 0.155148\n",
      "[57]\tvalid_0's multi_logloss: 0.154895\n",
      "[58]\tvalid_0's multi_logloss: 0.154683\n",
      "[59]\tvalid_0's multi_logloss: 0.154144\n",
      "[60]\tvalid_0's multi_logloss: 0.15357\n",
      "[61]\tvalid_0's multi_logloss: 0.153228\n",
      "[62]\tvalid_0's multi_logloss: 0.152912\n",
      "[63]\tvalid_0's multi_logloss: 0.15272\n",
      "[64]\tvalid_0's multi_logloss: 0.152334\n",
      "[65]\tvalid_0's multi_logloss: 0.151964\n",
      "[66]\tvalid_0's multi_logloss: 0.15176\n",
      "[67]\tvalid_0's multi_logloss: 0.151447\n",
      "[68]\tvalid_0's multi_logloss: 0.151288\n",
      "[69]\tvalid_0's multi_logloss: 0.150914\n",
      "[70]\tvalid_0's multi_logloss: 0.150405\n",
      "[71]\tvalid_0's multi_logloss: 0.150258\n",
      "[72]\tvalid_0's multi_logloss: 0.150081\n",
      "[73]\tvalid_0's multi_logloss: 0.149941\n",
      "[74]\tvalid_0's multi_logloss: 0.149512\n",
      "[75]\tvalid_0's multi_logloss: 0.149213\n",
      "[76]\tvalid_0's multi_logloss: 0.148952\n",
      "[77]\tvalid_0's multi_logloss: 0.148697\n",
      "[78]\tvalid_0's multi_logloss: 0.148477\n",
      "[79]\tvalid_0's multi_logloss: 0.148225\n",
      "[80]\tvalid_0's multi_logloss: 0.147947\n",
      "[81]\tvalid_0's multi_logloss: 0.147549\n",
      "[82]\tvalid_0's multi_logloss: 0.147462\n",
      "[83]\tvalid_0's multi_logloss: 0.147168\n",
      "[84]\tvalid_0's multi_logloss: 0.146947\n",
      "[85]\tvalid_0's multi_logloss: 0.146692\n",
      "[86]\tvalid_0's multi_logloss: 0.146312\n",
      "[87]\tvalid_0's multi_logloss: 0.146169\n",
      "[88]\tvalid_0's multi_logloss: 0.145978\n",
      "[89]\tvalid_0's multi_logloss: 0.145698\n",
      "[90]\tvalid_0's multi_logloss: 0.145531\n",
      "[91]\tvalid_0's multi_logloss: 0.145322\n",
      "[92]\tvalid_0's multi_logloss: 0.145164\n",
      "[93]\tvalid_0's multi_logloss: 0.144789\n",
      "[94]\tvalid_0's multi_logloss: 0.144515\n",
      "[95]\tvalid_0's multi_logloss: 0.144244\n",
      "[96]\tvalid_0's multi_logloss: 0.144146\n",
      "[97]\tvalid_0's multi_logloss: 0.144039\n",
      "[98]\tvalid_0's multi_logloss: 0.143955\n",
      "[99]\tvalid_0's multi_logloss: 0.143678\n",
      "[100]\tvalid_0's multi_logloss: 0.143546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [1:04:14, 152.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011360 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1530\n",
      "[LightGBM] [Info] Number of data points in the train set: 7715638, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score -1.249550\n",
      "[LightGBM] [Info] Start training from score -3.165534\n",
      "[LightGBM] [Info] Start training from score -1.726403\n",
      "[LightGBM] [Info] Start training from score -1.902421\n",
      "[LightGBM] [Info] Start training from score -1.667720\n",
      "[LightGBM] [Info] Start training from score -1.861961\n",
      "[1]\tvalid_0's multi_logloss: 1.67084\n",
      "[2]\tvalid_0's multi_logloss: 1.65851\n",
      "[3]\tvalid_0's multi_logloss: 1.64822\n",
      "[4]\tvalid_0's multi_logloss: 1.63984\n",
      "[5]\tvalid_0's multi_logloss: 1.63238\n",
      "[6]\tvalid_0's multi_logloss: 1.62592\n",
      "[7]\tvalid_0's multi_logloss: 1.62058\n",
      "[8]\tvalid_0's multi_logloss: 1.61559\n",
      "[9]\tvalid_0's multi_logloss: 1.61141\n",
      "[10]\tvalid_0's multi_logloss: 1.60777\n",
      "[11]\tvalid_0's multi_logloss: 1.60446\n",
      "[12]\tvalid_0's multi_logloss: 1.60149\n",
      "[13]\tvalid_0's multi_logloss: 1.59876\n",
      "[14]\tvalid_0's multi_logloss: 1.59619\n",
      "[15]\tvalid_0's multi_logloss: 1.5939\n",
      "[16]\tvalid_0's multi_logloss: 1.5918\n",
      "[17]\tvalid_0's multi_logloss: 1.58986\n",
      "[18]\tvalid_0's multi_logloss: 1.58795\n",
      "[19]\tvalid_0's multi_logloss: 1.58622\n",
      "[20]\tvalid_0's multi_logloss: 1.58463\n",
      "[21]\tvalid_0's multi_logloss: 1.58294\n",
      "[22]\tvalid_0's multi_logloss: 1.58162\n",
      "[23]\tvalid_0's multi_logloss: 1.58027\n",
      "[24]\tvalid_0's multi_logloss: 1.57901\n",
      "[25]\tvalid_0's multi_logloss: 1.57779\n",
      "[26]\tvalid_0's multi_logloss: 1.57656\n",
      "[27]\tvalid_0's multi_logloss: 1.57555\n",
      "[28]\tvalid_0's multi_logloss: 1.57466\n",
      "[29]\tvalid_0's multi_logloss: 1.57359\n",
      "[30]\tvalid_0's multi_logloss: 1.57278\n",
      "[31]\tvalid_0's multi_logloss: 1.57199\n",
      "[32]\tvalid_0's multi_logloss: 1.5711\n",
      "[33]\tvalid_0's multi_logloss: 1.57039\n",
      "[34]\tvalid_0's multi_logloss: 1.56959\n",
      "[35]\tvalid_0's multi_logloss: 1.56895\n",
      "[36]\tvalid_0's multi_logloss: 1.56818\n",
      "[37]\tvalid_0's multi_logloss: 1.56762\n",
      "[38]\tvalid_0's multi_logloss: 1.56695\n",
      "[39]\tvalid_0's multi_logloss: 1.56635\n",
      "[40]\tvalid_0's multi_logloss: 1.56571\n",
      "[41]\tvalid_0's multi_logloss: 1.56503\n",
      "[42]\tvalid_0's multi_logloss: 1.56433\n",
      "[43]\tvalid_0's multi_logloss: 1.56379\n",
      "[44]\tvalid_0's multi_logloss: 1.56316\n",
      "[45]\tvalid_0's multi_logloss: 1.56271\n",
      "[46]\tvalid_0's multi_logloss: 1.56215\n",
      "[47]\tvalid_0's multi_logloss: 1.56168\n",
      "[48]\tvalid_0's multi_logloss: 1.56113\n",
      "[49]\tvalid_0's multi_logloss: 1.56071\n",
      "[50]\tvalid_0's multi_logloss: 1.56021\n",
      "[51]\tvalid_0's multi_logloss: 1.55987\n",
      "[52]\tvalid_0's multi_logloss: 1.55934\n",
      "[53]\tvalid_0's multi_logloss: 1.55888\n",
      "[54]\tvalid_0's multi_logloss: 1.55848\n",
      "[55]\tvalid_0's multi_logloss: 1.55811\n",
      "[56]\tvalid_0's multi_logloss: 1.55774\n",
      "[57]\tvalid_0's multi_logloss: 1.55732\n",
      "[58]\tvalid_0's multi_logloss: 1.55694\n",
      "[59]\tvalid_0's multi_logloss: 1.5565\n",
      "[60]\tvalid_0's multi_logloss: 1.55616\n",
      "[61]\tvalid_0's multi_logloss: 1.55585\n",
      "[62]\tvalid_0's multi_logloss: 1.55549\n",
      "[63]\tvalid_0's multi_logloss: 1.55503\n",
      "[64]\tvalid_0's multi_logloss: 1.55458\n",
      "[65]\tvalid_0's multi_logloss: 1.55424\n",
      "[66]\tvalid_0's multi_logloss: 1.55385\n",
      "[67]\tvalid_0's multi_logloss: 1.55356\n",
      "[68]\tvalid_0's multi_logloss: 1.55326\n",
      "[69]\tvalid_0's multi_logloss: 1.55301\n",
      "[70]\tvalid_0's multi_logloss: 1.55267\n",
      "[71]\tvalid_0's multi_logloss: 1.55218\n",
      "[72]\tvalid_0's multi_logloss: 1.5519\n",
      "[73]\tvalid_0's multi_logloss: 1.55148\n",
      "[74]\tvalid_0's multi_logloss: 1.55119\n",
      "[75]\tvalid_0's multi_logloss: 1.55095\n",
      "[76]\tvalid_0's multi_logloss: 1.55069\n",
      "[77]\tvalid_0's multi_logloss: 1.55045\n",
      "[78]\tvalid_0's multi_logloss: 1.55019\n",
      "[79]\tvalid_0's multi_logloss: 1.54986\n",
      "[80]\tvalid_0's multi_logloss: 1.54959\n",
      "[81]\tvalid_0's multi_logloss: 1.54934\n",
      "[82]\tvalid_0's multi_logloss: 1.54904\n",
      "[83]\tvalid_0's multi_logloss: 1.54882\n",
      "[84]\tvalid_0's multi_logloss: 1.54853\n",
      "[85]\tvalid_0's multi_logloss: 1.54835\n",
      "[86]\tvalid_0's multi_logloss: 1.54805\n",
      "[87]\tvalid_0's multi_logloss: 1.54787\n",
      "[88]\tvalid_0's multi_logloss: 1.54757\n",
      "[89]\tvalid_0's multi_logloss: 1.5473\n",
      "[90]\tvalid_0's multi_logloss: 1.5471\n",
      "[91]\tvalid_0's multi_logloss: 1.54689\n",
      "[92]\tvalid_0's multi_logloss: 1.54673\n",
      "[93]\tvalid_0's multi_logloss: 1.5464\n",
      "[94]\tvalid_0's multi_logloss: 1.54624\n",
      "[95]\tvalid_0's multi_logloss: 1.54599\n",
      "[96]\tvalid_0's multi_logloss: 1.54579\n",
      "[97]\tvalid_0's multi_logloss: 1.54567\n",
      "[98]\tvalid_0's multi_logloss: 1.54544\n",
      "[99]\tvalid_0's multi_logloss: 1.54514\n",
      "[100]\tvalid_0's multi_logloss: 1.54481\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012570 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1530\n",
      "[LightGBM] [Info] Number of data points in the train set: 7715638, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score -3.388563\n",
      "[LightGBM] [Info] Start training from score -3.286043\n",
      "[LightGBM] [Info] Start training from score -3.265766\n",
      "[LightGBM] [Info] Start training from score -3.814547\n",
      "[LightGBM] [Info] Start training from score -3.310265\n",
      "[LightGBM] [Info] Start training from score -3.206426\n",
      "[LightGBM] [Info] Start training from score -4.264605\n",
      "[LightGBM] [Info] Start training from score -3.385622\n",
      "[LightGBM] [Info] Start training from score -3.678169\n",
      "[LightGBM] [Info] Start training from score -3.401590\n",
      "[LightGBM] [Info] Start training from score -4.879144\n",
      "[LightGBM] [Info] Start training from score -3.027581\n",
      "[LightGBM] [Info] Start training from score -2.985319\n",
      "[LightGBM] [Info] Start training from score -3.251856\n",
      "[LightGBM] [Info] Start training from score -3.294527\n",
      "[LightGBM] [Info] Start training from score -3.372086\n",
      "[LightGBM] [Info] Start training from score -2.973489\n",
      "[LightGBM] [Info] Start training from score -2.489644\n",
      "[LightGBM] [Info] Start training from score -3.403357\n",
      "[LightGBM] [Info] Start training from score -4.161407\n",
      "[LightGBM] [Info] Start training from score -4.219942\n",
      "[LightGBM] [Info] Start training from score -3.454308\n",
      "[LightGBM] [Info] Start training from score -3.414970\n",
      "[LightGBM] [Info] Start training from score -3.160243\n",
      "[LightGBM] [Info] Start training from score -3.113230\n",
      "[LightGBM] [Info] Start training from score -3.209175\n",
      "[LightGBM] [Info] Start training from score -3.282600\n",
      "[LightGBM] [Info] Start training from score -3.180636\n",
      "[1]\tvalid_0's multi_logloss: 2.66164\n",
      "[2]\tvalid_0's multi_logloss: 2.45089\n",
      "[3]\tvalid_0's multi_logloss: 2.31296\n",
      "[4]\tvalid_0's multi_logloss: 2.20751\n",
      "[5]\tvalid_0's multi_logloss: 2.124\n",
      "[6]\tvalid_0's multi_logloss: 2.05408\n",
      "[7]\tvalid_0's multi_logloss: 1.99194\n",
      "[8]\tvalid_0's multi_logloss: 1.93979\n",
      "[9]\tvalid_0's multi_logloss: 1.89467\n",
      "[10]\tvalid_0's multi_logloss: 1.856\n",
      "[11]\tvalid_0's multi_logloss: 1.82\n",
      "[12]\tvalid_0's multi_logloss: 1.78902\n",
      "[13]\tvalid_0's multi_logloss: 1.76223\n",
      "[14]\tvalid_0's multi_logloss: 1.73652\n",
      "[15]\tvalid_0's multi_logloss: 1.71338\n",
      "[16]\tvalid_0's multi_logloss: 1.69299\n",
      "[17]\tvalid_0's multi_logloss: 1.67431\n",
      "[18]\tvalid_0's multi_logloss: 1.65625\n",
      "[19]\tvalid_0's multi_logloss: 1.6395\n",
      "[20]\tvalid_0's multi_logloss: 1.62451\n",
      "[21]\tvalid_0's multi_logloss: 1.61102\n",
      "[22]\tvalid_0's multi_logloss: 1.59825\n",
      "[23]\tvalid_0's multi_logloss: 1.58597\n",
      "[24]\tvalid_0's multi_logloss: 1.57483\n",
      "[25]\tvalid_0's multi_logloss: 1.56493\n",
      "[26]\tvalid_0's multi_logloss: 1.5556\n",
      "[27]\tvalid_0's multi_logloss: 1.54665\n",
      "[28]\tvalid_0's multi_logloss: 1.538\n",
      "[29]\tvalid_0's multi_logloss: 1.53058\n",
      "[30]\tvalid_0's multi_logloss: 1.52352\n",
      "[31]\tvalid_0's multi_logloss: 1.51668\n",
      "[32]\tvalid_0's multi_logloss: 1.51037\n",
      "[33]\tvalid_0's multi_logloss: 1.5036\n",
      "[34]\tvalid_0's multi_logloss: 1.49768\n",
      "[35]\tvalid_0's multi_logloss: 1.49186\n",
      "[36]\tvalid_0's multi_logloss: 1.48668\n",
      "[37]\tvalid_0's multi_logloss: 1.48137\n",
      "[38]\tvalid_0's multi_logloss: 1.47917\n",
      "[39]\tvalid_0's multi_logloss: 1.47175\n",
      "[40]\tvalid_0's multi_logloss: 1.4674\n",
      "[41]\tvalid_0's multi_logloss: 1.46376\n",
      "[42]\tvalid_0's multi_logloss: 1.459\n",
      "[43]\tvalid_0's multi_logloss: 1.45522\n",
      "[44]\tvalid_0's multi_logloss: 1.45102\n",
      "[45]\tvalid_0's multi_logloss: 1.44733\n",
      "[46]\tvalid_0's multi_logloss: 1.44449\n",
      "[47]\tvalid_0's multi_logloss: 1.44091\n",
      "[48]\tvalid_0's multi_logloss: 1.43733\n",
      "[49]\tvalid_0's multi_logloss: 1.43405\n",
      "[50]\tvalid_0's multi_logloss: 1.4314\n",
      "[51]\tvalid_0's multi_logloss: 1.4285\n",
      "[52]\tvalid_0's multi_logloss: 1.42594\n",
      "[53]\tvalid_0's multi_logloss: 1.4229\n",
      "[54]\tvalid_0's multi_logloss: 1.42001\n",
      "[55]\tvalid_0's multi_logloss: 1.41735\n",
      "[56]\tvalid_0's multi_logloss: 1.41495\n",
      "[57]\tvalid_0's multi_logloss: 1.41226\n",
      "[58]\tvalid_0's multi_logloss: 1.40989\n",
      "[59]\tvalid_0's multi_logloss: 1.40775\n",
      "[60]\tvalid_0's multi_logloss: 1.40512\n",
      "[61]\tvalid_0's multi_logloss: 1.40272\n",
      "[62]\tvalid_0's multi_logloss: 1.40066\n",
      "[63]\tvalid_0's multi_logloss: 1.39903\n",
      "[64]\tvalid_0's multi_logloss: 1.39709\n",
      "[65]\tvalid_0's multi_logloss: 1.39519\n",
      "[66]\tvalid_0's multi_logloss: 1.39341\n",
      "[67]\tvalid_0's multi_logloss: 1.39192\n",
      "[68]\tvalid_0's multi_logloss: 1.3897\n",
      "[69]\tvalid_0's multi_logloss: 1.38779\n",
      "[70]\tvalid_0's multi_logloss: 1.38631\n",
      "[71]\tvalid_0's multi_logloss: 1.38503\n",
      "[72]\tvalid_0's multi_logloss: 1.38219\n",
      "[73]\tvalid_0's multi_logloss: 1.38071\n",
      "[74]\tvalid_0's multi_logloss: 1.37939\n",
      "[75]\tvalid_0's multi_logloss: 1.37766\n",
      "[76]\tvalid_0's multi_logloss: 1.37547\n",
      "[77]\tvalid_0's multi_logloss: 1.37411\n",
      "[78]\tvalid_0's multi_logloss: 1.37248\n",
      "[79]\tvalid_0's multi_logloss: 1.37058\n",
      "[80]\tvalid_0's multi_logloss: 1.36896\n",
      "[81]\tvalid_0's multi_logloss: 1.36747\n",
      "[82]\tvalid_0's multi_logloss: 1.36603\n",
      "[83]\tvalid_0's multi_logloss: 1.36431\n",
      "[84]\tvalid_0's multi_logloss: 1.36325\n",
      "[85]\tvalid_0's multi_logloss: 1.36158\n",
      "[86]\tvalid_0's multi_logloss: 1.3599\n",
      "[87]\tvalid_0's multi_logloss: 1.3585\n",
      "[88]\tvalid_0's multi_logloss: 1.35846\n",
      "[89]\tvalid_0's multi_logloss: 1.35598\n",
      "[90]\tvalid_0's multi_logloss: 1.35461\n",
      "[91]\tvalid_0's multi_logloss: 1.35325\n",
      "[92]\tvalid_0's multi_logloss: 1.35163\n",
      "[93]\tvalid_0's multi_logloss: 1.35079\n",
      "[94]\tvalid_0's multi_logloss: 1.34987\n",
      "[95]\tvalid_0's multi_logloss: 1.34916\n",
      "[96]\tvalid_0's multi_logloss: 1.34866\n",
      "[97]\tvalid_0's multi_logloss: 1.34676\n",
      "[98]\tvalid_0's multi_logloss: 1.34601\n",
      "[99]\tvalid_0's multi_logloss: 1.3447\n",
      "[100]\tvalid_0's multi_logloss: 1.34389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [1:06:08, 140.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001622 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1530\n",
      "[LightGBM] [Info] Number of data points in the train set: 820733, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score -0.683185\n",
      "[LightGBM] [Info] Start training from score -2.382997\n",
      "[LightGBM] [Info] Start training from score -2.734975\n",
      "[LightGBM] [Info] Start training from score -3.826068\n",
      "[LightGBM] [Info] Start training from score -1.583719\n",
      "[LightGBM] [Info] Start training from score -2.199855\n",
      "[1]\tvalid_0's multi_logloss: 1.21225\n",
      "[2]\tvalid_0's multi_logloss: 1.11672\n",
      "[3]\tvalid_0's multi_logloss: 1.04239\n",
      "[4]\tvalid_0's multi_logloss: 0.98447\n",
      "[5]\tvalid_0's multi_logloss: 0.935746\n",
      "[6]\tvalid_0's multi_logloss: 0.894356\n",
      "[7]\tvalid_0's multi_logloss: 0.858678\n",
      "[8]\tvalid_0's multi_logloss: 0.829511\n",
      "[9]\tvalid_0's multi_logloss: 0.803497\n",
      "[10]\tvalid_0's multi_logloss: 0.779555\n",
      "[11]\tvalid_0's multi_logloss: 0.758731\n",
      "[12]\tvalid_0's multi_logloss: 0.740772\n",
      "[13]\tvalid_0's multi_logloss: 0.72422\n",
      "[14]\tvalid_0's multi_logloss: 0.709164\n",
      "[15]\tvalid_0's multi_logloss: 0.696361\n",
      "[16]\tvalid_0's multi_logloss: 0.684418\n",
      "[17]\tvalid_0's multi_logloss: 0.673931\n",
      "[18]\tvalid_0's multi_logloss: 0.664\n",
      "[19]\tvalid_0's multi_logloss: 0.653753\n",
      "[20]\tvalid_0's multi_logloss: 0.645269\n",
      "[21]\tvalid_0's multi_logloss: 0.637916\n",
      "[22]\tvalid_0's multi_logloss: 0.630056\n",
      "[23]\tvalid_0's multi_logloss: 0.623324\n",
      "[24]\tvalid_0's multi_logloss: 0.616938\n",
      "[25]\tvalid_0's multi_logloss: 0.611572\n",
      "[26]\tvalid_0's multi_logloss: 0.605997\n",
      "[27]\tvalid_0's multi_logloss: 0.600781\n",
      "[28]\tvalid_0's multi_logloss: 0.596152\n",
      "[29]\tvalid_0's multi_logloss: 0.591937\n",
      "[30]\tvalid_0's multi_logloss: 0.58792\n",
      "[31]\tvalid_0's multi_logloss: 0.583656\n",
      "[32]\tvalid_0's multi_logloss: 0.580139\n",
      "[33]\tvalid_0's multi_logloss: 0.576675\n",
      "[34]\tvalid_0's multi_logloss: 0.573611\n",
      "[35]\tvalid_0's multi_logloss: 0.570956\n",
      "[36]\tvalid_0's multi_logloss: 0.568273\n",
      "[37]\tvalid_0's multi_logloss: 0.565631\n",
      "[38]\tvalid_0's multi_logloss: 0.5629\n",
      "[39]\tvalid_0's multi_logloss: 0.560192\n",
      "[40]\tvalid_0's multi_logloss: 0.558197\n",
      "[41]\tvalid_0's multi_logloss: 0.556624\n",
      "[42]\tvalid_0's multi_logloss: 0.554716\n",
      "[43]\tvalid_0's multi_logloss: 0.55247\n",
      "[44]\tvalid_0's multi_logloss: 0.550436\n",
      "[45]\tvalid_0's multi_logloss: 0.548541\n",
      "[46]\tvalid_0's multi_logloss: 0.546782\n",
      "[47]\tvalid_0's multi_logloss: 0.544987\n",
      "[48]\tvalid_0's multi_logloss: 0.543523\n",
      "[49]\tvalid_0's multi_logloss: 0.542863\n",
      "[50]\tvalid_0's multi_logloss: 0.541098\n",
      "[51]\tvalid_0's multi_logloss: 0.539872\n",
      "[52]\tvalid_0's multi_logloss: 0.538743\n",
      "[53]\tvalid_0's multi_logloss: 0.537266\n",
      "[54]\tvalid_0's multi_logloss: 0.536328\n",
      "[55]\tvalid_0's multi_logloss: 0.534967\n",
      "[56]\tvalid_0's multi_logloss: 0.533798\n",
      "[57]\tvalid_0's multi_logloss: 0.533736\n",
      "[58]\tvalid_0's multi_logloss: 0.531961\n",
      "[59]\tvalid_0's multi_logloss: 0.531207\n",
      "[60]\tvalid_0's multi_logloss: 0.533716\n",
      "[61]\tvalid_0's multi_logloss: 0.529767\n",
      "[62]\tvalid_0's multi_logloss: 0.532559\n",
      "[63]\tvalid_0's multi_logloss: 0.528485\n",
      "[64]\tvalid_0's multi_logloss: 0.529139\n",
      "[65]\tvalid_0's multi_logloss: 0.52769\n",
      "[66]\tvalid_0's multi_logloss: 0.526613\n",
      "[67]\tvalid_0's multi_logloss: 0.525405\n",
      "[68]\tvalid_0's multi_logloss: 0.524627\n",
      "[69]\tvalid_0's multi_logloss: 0.524162\n",
      "[70]\tvalid_0's multi_logloss: 0.523603\n",
      "[71]\tvalid_0's multi_logloss: 0.523095\n",
      "[72]\tvalid_0's multi_logloss: 0.52199\n",
      "[73]\tvalid_0's multi_logloss: 0.521603\n",
      "[74]\tvalid_0's multi_logloss: 0.523369\n",
      "[75]\tvalid_0's multi_logloss: 0.521589\n",
      "[76]\tvalid_0's multi_logloss: 0.520846\n",
      "[77]\tvalid_0's multi_logloss: 0.522302\n",
      "[78]\tvalid_0's multi_logloss: 0.519528\n",
      "[79]\tvalid_0's multi_logloss: 0.520096\n",
      "[80]\tvalid_0's multi_logloss: 0.51868\n",
      "[81]\tvalid_0's multi_logloss: 0.518979\n",
      "[82]\tvalid_0's multi_logloss: 0.519462\n",
      "[83]\tvalid_0's multi_logloss: 0.519571\n",
      "[84]\tvalid_0's multi_logloss: 0.519967\n",
      "[85]\tvalid_0's multi_logloss: 0.518052\n",
      "[86]\tvalid_0's multi_logloss: 0.517539\n",
      "[87]\tvalid_0's multi_logloss: 0.516949\n",
      "[88]\tvalid_0's multi_logloss: 0.517873\n",
      "[89]\tvalid_0's multi_logloss: 0.518049\n",
      "[90]\tvalid_0's multi_logloss: 0.516246\n",
      "[91]\tvalid_0's multi_logloss: 0.517148\n",
      "[92]\tvalid_0's multi_logloss: 0.515788\n",
      "[93]\tvalid_0's multi_logloss: 0.51656\n",
      "[94]\tvalid_0's multi_logloss: 0.519235\n",
      "[95]\tvalid_0's multi_logloss: 0.520971\n",
      "[96]\tvalid_0's multi_logloss: 0.517332\n",
      "[97]\tvalid_0's multi_logloss: 0.518435\n",
      "[98]\tvalid_0's multi_logloss: 0.518039\n",
      "[99]\tvalid_0's multi_logloss: 0.517148\n",
      "[100]\tvalid_0's multi_logloss: 0.521817\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001722 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1530\n",
      "[LightGBM] [Info] Number of data points in the train set: 820733, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score -2.163833\n",
      "[LightGBM] [Info] Start training from score -1.796397\n",
      "[LightGBM] [Info] Start training from score -1.843741\n",
      "[LightGBM] [Info] Start training from score -1.989576\n",
      "[LightGBM] [Info] Start training from score -1.941218\n",
      "[LightGBM] [Info] Start training from score -1.949016\n",
      "[LightGBM] [Info] Start training from score -1.978333\n",
      "[1]\tvalid_0's multi_logloss: 1.90925\n",
      "[2]\tvalid_0's multi_logloss: 1.88491\n",
      "[3]\tvalid_0's multi_logloss: 1.865\n",
      "[4]\tvalid_0's multi_logloss: 1.84842\n",
      "[5]\tvalid_0's multi_logloss: 1.8346\n",
      "[6]\tvalid_0's multi_logloss: 1.82243\n",
      "[7]\tvalid_0's multi_logloss: 1.81193\n",
      "[8]\tvalid_0's multi_logloss: 1.80322\n",
      "[9]\tvalid_0's multi_logloss: 1.79565\n",
      "[10]\tvalid_0's multi_logloss: 1.78894\n",
      "[11]\tvalid_0's multi_logloss: 1.78306\n",
      "[12]\tvalid_0's multi_logloss: 1.77786\n",
      "[13]\tvalid_0's multi_logloss: 1.77322\n",
      "[14]\tvalid_0's multi_logloss: 1.76908\n",
      "[15]\tvalid_0's multi_logloss: 1.76539\n",
      "[16]\tvalid_0's multi_logloss: 1.76193\n",
      "[17]\tvalid_0's multi_logloss: 1.75912\n",
      "[18]\tvalid_0's multi_logloss: 1.75637\n",
      "[19]\tvalid_0's multi_logloss: 1.75394\n",
      "[20]\tvalid_0's multi_logloss: 1.75172\n",
      "[21]\tvalid_0's multi_logloss: 1.74956\n",
      "[22]\tvalid_0's multi_logloss: 1.74775\n",
      "[23]\tvalid_0's multi_logloss: 1.74598\n",
      "[24]\tvalid_0's multi_logloss: 1.74451\n",
      "[25]\tvalid_0's multi_logloss: 1.74307\n",
      "[26]\tvalid_0's multi_logloss: 1.74169\n",
      "[27]\tvalid_0's multi_logloss: 1.74036\n",
      "[28]\tvalid_0's multi_logloss: 1.73915\n",
      "[29]\tvalid_0's multi_logloss: 1.73798\n",
      "[30]\tvalid_0's multi_logloss: 1.737\n",
      "[31]\tvalid_0's multi_logloss: 1.73612\n",
      "[32]\tvalid_0's multi_logloss: 1.73524\n",
      "[33]\tvalid_0's multi_logloss: 1.73435\n",
      "[34]\tvalid_0's multi_logloss: 1.73357\n",
      "[35]\tvalid_0's multi_logloss: 1.73272\n",
      "[36]\tvalid_0's multi_logloss: 1.73204\n",
      "[37]\tvalid_0's multi_logloss: 1.73141\n",
      "[38]\tvalid_0's multi_logloss: 1.73083\n",
      "[39]\tvalid_0's multi_logloss: 1.73037\n",
      "[40]\tvalid_0's multi_logloss: 1.72977\n",
      "[41]\tvalid_0's multi_logloss: 1.72933\n",
      "[42]\tvalid_0's multi_logloss: 1.72886\n",
      "[43]\tvalid_0's multi_logloss: 1.72839\n",
      "[44]\tvalid_0's multi_logloss: 1.72807\n",
      "[45]\tvalid_0's multi_logloss: 1.72771\n",
      "[46]\tvalid_0's multi_logloss: 1.7273\n",
      "[47]\tvalid_0's multi_logloss: 1.72697\n",
      "[48]\tvalid_0's multi_logloss: 1.72672\n",
      "[49]\tvalid_0's multi_logloss: 1.72641\n",
      "[50]\tvalid_0's multi_logloss: 1.72618\n",
      "[51]\tvalid_0's multi_logloss: 1.726\n",
      "[52]\tvalid_0's multi_logloss: 1.7258\n",
      "[53]\tvalid_0's multi_logloss: 1.72558\n",
      "[54]\tvalid_0's multi_logloss: 1.72534\n",
      "[55]\tvalid_0's multi_logloss: 1.72514\n",
      "[56]\tvalid_0's multi_logloss: 1.72493\n",
      "[57]\tvalid_0's multi_logloss: 1.72473\n",
      "[58]\tvalid_0's multi_logloss: 1.72464\n",
      "[59]\tvalid_0's multi_logloss: 1.72442\n",
      "[60]\tvalid_0's multi_logloss: 1.72427\n",
      "[61]\tvalid_0's multi_logloss: 1.72416\n",
      "[62]\tvalid_0's multi_logloss: 1.72402\n",
      "[63]\tvalid_0's multi_logloss: 1.72389\n",
      "[64]\tvalid_0's multi_logloss: 1.72377\n",
      "[65]\tvalid_0's multi_logloss: 1.72351\n",
      "[66]\tvalid_0's multi_logloss: 1.72338\n",
      "[67]\tvalid_0's multi_logloss: 1.72318\n",
      "[68]\tvalid_0's multi_logloss: 1.72302\n",
      "[69]\tvalid_0's multi_logloss: 1.72286\n",
      "[70]\tvalid_0's multi_logloss: 1.72274\n",
      "[71]\tvalid_0's multi_logloss: 1.72262\n",
      "[72]\tvalid_0's multi_logloss: 1.72251\n",
      "[73]\tvalid_0's multi_logloss: 1.72242\n",
      "[74]\tvalid_0's multi_logloss: 1.72229\n",
      "[75]\tvalid_0's multi_logloss: 1.72211\n",
      "[76]\tvalid_0's multi_logloss: 1.72195\n",
      "[77]\tvalid_0's multi_logloss: 1.72181\n",
      "[78]\tvalid_0's multi_logloss: 1.72167\n",
      "[79]\tvalid_0's multi_logloss: 1.72158\n",
      "[80]\tvalid_0's multi_logloss: 1.72143\n",
      "[81]\tvalid_0's multi_logloss: 1.72134\n",
      "[82]\tvalid_0's multi_logloss: 1.72119\n",
      "[83]\tvalid_0's multi_logloss: 1.72104\n",
      "[84]\tvalid_0's multi_logloss: 1.72088\n",
      "[85]\tvalid_0's multi_logloss: 1.72075\n",
      "[86]\tvalid_0's multi_logloss: 1.72064\n",
      "[87]\tvalid_0's multi_logloss: 1.72061\n",
      "[88]\tvalid_0's multi_logloss: 1.72049\n",
      "[89]\tvalid_0's multi_logloss: 1.7204\n",
      "[90]\tvalid_0's multi_logloss: 1.72035\n",
      "[91]\tvalid_0's multi_logloss: 1.72024\n",
      "[92]\tvalid_0's multi_logloss: 1.72012\n",
      "[93]\tvalid_0's multi_logloss: 1.72\n",
      "[94]\tvalid_0's multi_logloss: 1.71988\n",
      "[95]\tvalid_0's multi_logloss: 1.71978\n",
      "[96]\tvalid_0's multi_logloss: 1.71965\n",
      "[97]\tvalid_0's multi_logloss: 1.71961\n",
      "[98]\tvalid_0's multi_logloss: 1.7194\n",
      "[99]\tvalid_0's multi_logloss: 1.71925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33it [1:06:18, 101.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's multi_logloss: 1.71916\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027692 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -1.853404\n",
      "[LightGBM] [Info] Start training from score -2.123202\n",
      "[LightGBM] [Info] Start training from score -2.391862\n",
      "[LightGBM] [Info] Start training from score -2.719639\n",
      "[LightGBM] [Info] Start training from score -2.078311\n",
      "[LightGBM] [Info] Start training from score -2.161447\n",
      "[LightGBM] [Info] Start training from score -2.497610\n",
      "[LightGBM] [Info] Start training from score -2.232530\n",
      "[LightGBM] [Info] Start training from score -2.689447\n",
      "[LightGBM] [Info] Start training from score -2.680407\n",
      "[1]\tvalid_0's multi_logloss: 2.03498\n",
      "[2]\tvalid_0's multi_logloss: 1.90758\n",
      "[3]\tvalid_0's multi_logloss: 1.81339\n",
      "[4]\tvalid_0's multi_logloss: 1.73855\n",
      "[5]\tvalid_0's multi_logloss: 1.67691\n",
      "[6]\tvalid_0's multi_logloss: 1.62618\n",
      "[7]\tvalid_0's multi_logloss: 1.58337\n",
      "[8]\tvalid_0's multi_logloss: 1.54684\n",
      "[9]\tvalid_0's multi_logloss: 1.51403\n",
      "[10]\tvalid_0's multi_logloss: 1.48647\n",
      "[11]\tvalid_0's multi_logloss: 1.46049\n",
      "[12]\tvalid_0's multi_logloss: 1.43699\n",
      "[13]\tvalid_0's multi_logloss: 1.41738\n",
      "[14]\tvalid_0's multi_logloss: 1.39968\n",
      "[15]\tvalid_0's multi_logloss: 1.38299\n",
      "[16]\tvalid_0's multi_logloss: 1.36874\n",
      "[17]\tvalid_0's multi_logloss: 1.35554\n",
      "[18]\tvalid_0's multi_logloss: 1.34266\n",
      "[19]\tvalid_0's multi_logloss: 1.33132\n",
      "[20]\tvalid_0's multi_logloss: 1.32069\n",
      "[21]\tvalid_0's multi_logloss: 1.31028\n",
      "[22]\tvalid_0's multi_logloss: 1.2996\n",
      "[23]\tvalid_0's multi_logloss: 1.29102\n",
      "[24]\tvalid_0's multi_logloss: 1.28298\n",
      "[25]\tvalid_0's multi_logloss: 1.27435\n",
      "[26]\tvalid_0's multi_logloss: 1.26742\n",
      "[27]\tvalid_0's multi_logloss: 1.26093\n",
      "[28]\tvalid_0's multi_logloss: 1.25355\n",
      "[29]\tvalid_0's multi_logloss: 1.24765\n",
      "[30]\tvalid_0's multi_logloss: 1.24132\n",
      "[31]\tvalid_0's multi_logloss: 1.23613\n",
      "[32]\tvalid_0's multi_logloss: 1.23115\n",
      "[33]\tvalid_0's multi_logloss: 1.22513\n",
      "[34]\tvalid_0's multi_logloss: 1.22032\n",
      "[35]\tvalid_0's multi_logloss: 1.2155\n",
      "[36]\tvalid_0's multi_logloss: 1.21142\n",
      "[37]\tvalid_0's multi_logloss: 1.20778\n",
      "[38]\tvalid_0's multi_logloss: 1.20344\n",
      "[39]\tvalid_0's multi_logloss: 1.19974\n",
      "[40]\tvalid_0's multi_logloss: 1.19541\n",
      "[41]\tvalid_0's multi_logloss: 1.19173\n",
      "[42]\tvalid_0's multi_logloss: 1.18885\n",
      "[43]\tvalid_0's multi_logloss: 1.18561\n",
      "[44]\tvalid_0's multi_logloss: 1.18269\n",
      "[45]\tvalid_0's multi_logloss: 1.17948\n",
      "[46]\tvalid_0's multi_logloss: 1.17642\n",
      "[47]\tvalid_0's multi_logloss: 1.1726\n",
      "[48]\tvalid_0's multi_logloss: 1.16996\n",
      "[49]\tvalid_0's multi_logloss: 1.16701\n",
      "[50]\tvalid_0's multi_logloss: 1.1645\n",
      "[51]\tvalid_0's multi_logloss: 1.16188\n",
      "[52]\tvalid_0's multi_logloss: 1.15894\n",
      "[53]\tvalid_0's multi_logloss: 1.15644\n",
      "[54]\tvalid_0's multi_logloss: 1.15431\n",
      "[55]\tvalid_0's multi_logloss: 1.15178\n",
      "[56]\tvalid_0's multi_logloss: 1.15018\n",
      "[57]\tvalid_0's multi_logloss: 1.14785\n",
      "[58]\tvalid_0's multi_logloss: 1.14591\n",
      "[59]\tvalid_0's multi_logloss: 1.14392\n",
      "[60]\tvalid_0's multi_logloss: 1.14122\n",
      "[61]\tvalid_0's multi_logloss: 1.1393\n",
      "[62]\tvalid_0's multi_logloss: 1.13717\n",
      "[63]\tvalid_0's multi_logloss: 1.13505\n",
      "[64]\tvalid_0's multi_logloss: 1.13285\n",
      "[65]\tvalid_0's multi_logloss: 1.13109\n",
      "[66]\tvalid_0's multi_logloss: 1.12876\n",
      "[67]\tvalid_0's multi_logloss: 1.12688\n",
      "[68]\tvalid_0's multi_logloss: 1.1254\n",
      "[69]\tvalid_0's multi_logloss: 1.12409\n",
      "[70]\tvalid_0's multi_logloss: 1.12204\n",
      "[71]\tvalid_0's multi_logloss: 1.1203\n",
      "[72]\tvalid_0's multi_logloss: 1.11854\n",
      "[73]\tvalid_0's multi_logloss: 1.11668\n",
      "[74]\tvalid_0's multi_logloss: 1.11525\n",
      "[75]\tvalid_0's multi_logloss: 1.11411\n",
      "[76]\tvalid_0's multi_logloss: 1.11288\n",
      "[77]\tvalid_0's multi_logloss: 1.11141\n",
      "[78]\tvalid_0's multi_logloss: 1.11014\n",
      "[79]\tvalid_0's multi_logloss: 1.10873\n",
      "[80]\tvalid_0's multi_logloss: 1.10741\n",
      "[81]\tvalid_0's multi_logloss: 1.10579\n",
      "[82]\tvalid_0's multi_logloss: 1.10438\n",
      "[83]\tvalid_0's multi_logloss: 1.10222\n",
      "[84]\tvalid_0's multi_logloss: 1.10077\n",
      "[85]\tvalid_0's multi_logloss: 1.0995\n",
      "[86]\tvalid_0's multi_logloss: 1.09746\n",
      "[87]\tvalid_0's multi_logloss: 1.09598\n",
      "[88]\tvalid_0's multi_logloss: 1.09519\n",
      "[89]\tvalid_0's multi_logloss: 1.09431\n",
      "[90]\tvalid_0's multi_logloss: 1.09284\n",
      "[91]\tvalid_0's multi_logloss: 1.09109\n",
      "[92]\tvalid_0's multi_logloss: 1.09021\n",
      "[93]\tvalid_0's multi_logloss: 1.08907\n",
      "[94]\tvalid_0's multi_logloss: 1.08782\n",
      "[95]\tvalid_0's multi_logloss: 1.08657\n",
      "[96]\tvalid_0's multi_logloss: 1.08544\n",
      "[97]\tvalid_0's multi_logloss: 1.08433\n",
      "[98]\tvalid_0's multi_logloss: 1.08332\n",
      "[99]\tvalid_0's multi_logloss: 1.0824\n",
      "[100]\tvalid_0's multi_logloss: 1.08155\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027153 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -1.047228\n",
      "[LightGBM] [Info] Start training from score -1.516216\n",
      "[LightGBM] [Info] Start training from score -0.845018\n",
      "[1]\tvalid_0's multi_logloss: 1.01249\n",
      "[2]\tvalid_0's multi_logloss: 0.97063\n",
      "[3]\tvalid_0's multi_logloss: 0.93589\n",
      "[4]\tvalid_0's multi_logloss: 0.906765\n",
      "[5]\tvalid_0's multi_logloss: 0.881688\n",
      "[6]\tvalid_0's multi_logloss: 0.860169\n",
      "[7]\tvalid_0's multi_logloss: 0.841533\n",
      "[8]\tvalid_0's multi_logloss: 0.825239\n",
      "[9]\tvalid_0's multi_logloss: 0.810847\n",
      "[10]\tvalid_0's multi_logloss: 0.798093\n",
      "[11]\tvalid_0's multi_logloss: 0.786822\n",
      "[12]\tvalid_0's multi_logloss: 0.776676\n",
      "[13]\tvalid_0's multi_logloss: 0.76758\n",
      "[14]\tvalid_0's multi_logloss: 0.759528\n",
      "[15]\tvalid_0's multi_logloss: 0.752131\n",
      "[16]\tvalid_0's multi_logloss: 0.745481\n",
      "[17]\tvalid_0's multi_logloss: 0.739316\n",
      "[18]\tvalid_0's multi_logloss: 0.733775\n",
      "[19]\tvalid_0's multi_logloss: 0.72881\n",
      "[20]\tvalid_0's multi_logloss: 0.724133\n",
      "[21]\tvalid_0's multi_logloss: 0.719819\n",
      "[22]\tvalid_0's multi_logloss: 0.715866\n",
      "[23]\tvalid_0's multi_logloss: 0.712354\n",
      "[24]\tvalid_0's multi_logloss: 0.709099\n",
      "[25]\tvalid_0's multi_logloss: 0.706007\n",
      "[26]\tvalid_0's multi_logloss: 0.703117\n",
      "[27]\tvalid_0's multi_logloss: 0.700536\n",
      "[28]\tvalid_0's multi_logloss: 0.698154\n",
      "[29]\tvalid_0's multi_logloss: 0.695808\n",
      "[30]\tvalid_0's multi_logloss: 0.693698\n",
      "[31]\tvalid_0's multi_logloss: 0.691749\n",
      "[32]\tvalid_0's multi_logloss: 0.68978\n",
      "[33]\tvalid_0's multi_logloss: 0.687965\n",
      "[34]\tvalid_0's multi_logloss: 0.686298\n",
      "[35]\tvalid_0's multi_logloss: 0.684806\n",
      "[36]\tvalid_0's multi_logloss: 0.683333\n",
      "[37]\tvalid_0's multi_logloss: 0.6819\n",
      "[38]\tvalid_0's multi_logloss: 0.680522\n",
      "[39]\tvalid_0's multi_logloss: 0.679284\n",
      "[40]\tvalid_0's multi_logloss: 0.678158\n",
      "[41]\tvalid_0's multi_logloss: 0.677102\n",
      "[42]\tvalid_0's multi_logloss: 0.676115\n",
      "[43]\tvalid_0's multi_logloss: 0.675165\n",
      "[44]\tvalid_0's multi_logloss: 0.674301\n",
      "[45]\tvalid_0's multi_logloss: 0.673533\n",
      "[46]\tvalid_0's multi_logloss: 0.672725\n",
      "[47]\tvalid_0's multi_logloss: 0.671955\n",
      "[48]\tvalid_0's multi_logloss: 0.671239\n",
      "[49]\tvalid_0's multi_logloss: 0.670505\n",
      "[50]\tvalid_0's multi_logloss: 0.669891\n",
      "[51]\tvalid_0's multi_logloss: 0.669268\n",
      "[52]\tvalid_0's multi_logloss: 0.668718\n",
      "[53]\tvalid_0's multi_logloss: 0.668231\n",
      "[54]\tvalid_0's multi_logloss: 0.667709\n",
      "[55]\tvalid_0's multi_logloss: 0.667312\n",
      "[56]\tvalid_0's multi_logloss: 0.66683\n",
      "[57]\tvalid_0's multi_logloss: 0.666389\n",
      "[58]\tvalid_0's multi_logloss: 0.665974\n",
      "[59]\tvalid_0's multi_logloss: 0.665589\n",
      "[60]\tvalid_0's multi_logloss: 0.665272\n",
      "[61]\tvalid_0's multi_logloss: 0.664926\n",
      "[62]\tvalid_0's multi_logloss: 0.664571\n",
      "[63]\tvalid_0's multi_logloss: 0.664216\n",
      "[64]\tvalid_0's multi_logloss: 0.663918\n",
      "[65]\tvalid_0's multi_logloss: 0.663571\n",
      "[66]\tvalid_0's multi_logloss: 0.663288\n",
      "[67]\tvalid_0's multi_logloss: 0.662969\n",
      "[68]\tvalid_0's multi_logloss: 0.662691\n",
      "[69]\tvalid_0's multi_logloss: 0.662486\n",
      "[70]\tvalid_0's multi_logloss: 0.662273\n",
      "[71]\tvalid_0's multi_logloss: 0.662057\n",
      "[72]\tvalid_0's multi_logloss: 0.661841\n",
      "[73]\tvalid_0's multi_logloss: 0.661598\n",
      "[74]\tvalid_0's multi_logloss: 0.661361\n",
      "[75]\tvalid_0's multi_logloss: 0.661153\n",
      "[76]\tvalid_0's multi_logloss: 0.660938\n",
      "[77]\tvalid_0's multi_logloss: 0.660727\n",
      "[78]\tvalid_0's multi_logloss: 0.660541\n",
      "[79]\tvalid_0's multi_logloss: 0.660352\n",
      "[80]\tvalid_0's multi_logloss: 0.660188\n",
      "[81]\tvalid_0's multi_logloss: 0.659988\n",
      "[82]\tvalid_0's multi_logloss: 0.65977\n",
      "[83]\tvalid_0's multi_logloss: 0.659597\n",
      "[84]\tvalid_0's multi_logloss: 0.659422\n",
      "[85]\tvalid_0's multi_logloss: 0.659288\n",
      "[86]\tvalid_0's multi_logloss: 0.659076\n",
      "[87]\tvalid_0's multi_logloss: 0.658908\n",
      "[88]\tvalid_0's multi_logloss: 0.658746\n",
      "[89]\tvalid_0's multi_logloss: 0.658653\n",
      "[90]\tvalid_0's multi_logloss: 0.658565\n",
      "[91]\tvalid_0's multi_logloss: 0.65847\n",
      "[92]\tvalid_0's multi_logloss: 0.658402\n",
      "[93]\tvalid_0's multi_logloss: 0.658282\n",
      "[94]\tvalid_0's multi_logloss: 0.658179\n",
      "[95]\tvalid_0's multi_logloss: 0.658008\n",
      "[96]\tvalid_0's multi_logloss: 0.657855\n",
      "[97]\tvalid_0's multi_logloss: 0.657759\n",
      "[98]\tvalid_0's multi_logloss: 0.657654\n",
      "[99]\tvalid_0's multi_logloss: 0.657549\n",
      "[100]\tvalid_0's multi_logloss: 0.657468\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027687 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -3.244539\n",
      "[LightGBM] [Info] Start training from score -3.224920\n",
      "[LightGBM] [Info] Start training from score -3.369880\n",
      "[LightGBM] [Info] Start training from score -3.326941\n",
      "[LightGBM] [Info] Start training from score -3.378266\n",
      "[LightGBM] [Info] Start training from score -2.568017\n",
      "[LightGBM] [Info] Start training from score -1.914747\n",
      "[LightGBM] [Info] Start training from score -3.469579\n",
      "[LightGBM] [Info] Start training from score -1.919436\n",
      "[LightGBM] [Info] Start training from score -2.291576\n",
      "[LightGBM] [Info] Start training from score -2.007538\n",
      "[LightGBM] [Info] Start training from score -3.402200\n",
      "[LightGBM] [Info] Start training from score -3.212376\n",
      "[LightGBM] [Info] Start training from score -2.244521\n",
      "[1]\tvalid_0's multi_logloss: 2.40315\n",
      "[2]\tvalid_0's multi_logloss: 2.36795\n",
      "[3]\tvalid_0's multi_logloss: 2.34037\n",
      "[4]\tvalid_0's multi_logloss: 2.31822\n",
      "[5]\tvalid_0's multi_logloss: 2.29977\n",
      "[6]\tvalid_0's multi_logloss: 2.2845\n",
      "[7]\tvalid_0's multi_logloss: 2.27143\n",
      "[8]\tvalid_0's multi_logloss: 2.26004\n",
      "[9]\tvalid_0's multi_logloss: 2.25027\n",
      "[10]\tvalid_0's multi_logloss: 2.24126\n",
      "[11]\tvalid_0's multi_logloss: 2.23397\n",
      "[12]\tvalid_0's multi_logloss: 2.22677\n",
      "[13]\tvalid_0's multi_logloss: 2.22026\n",
      "[14]\tvalid_0's multi_logloss: 2.21444\n",
      "[15]\tvalid_0's multi_logloss: 2.20932\n",
      "[16]\tvalid_0's multi_logloss: 2.20456\n",
      "[17]\tvalid_0's multi_logloss: 2.19966\n",
      "[18]\tvalid_0's multi_logloss: 2.19529\n",
      "[19]\tvalid_0's multi_logloss: 2.19166\n",
      "[20]\tvalid_0's multi_logloss: 2.18797\n",
      "[21]\tvalid_0's multi_logloss: 2.1848\n",
      "[22]\tvalid_0's multi_logloss: 2.18178\n",
      "[23]\tvalid_0's multi_logloss: 2.17852\n",
      "[24]\tvalid_0's multi_logloss: 2.17578\n",
      "[25]\tvalid_0's multi_logloss: 2.17279\n",
      "[26]\tvalid_0's multi_logloss: 2.17029\n",
      "[27]\tvalid_0's multi_logloss: 2.16801\n",
      "[28]\tvalid_0's multi_logloss: 2.16593\n",
      "[29]\tvalid_0's multi_logloss: 2.16386\n",
      "[30]\tvalid_0's multi_logloss: 2.16168\n",
      "[31]\tvalid_0's multi_logloss: 2.15974\n",
      "[32]\tvalid_0's multi_logloss: 2.15771\n",
      "[33]\tvalid_0's multi_logloss: 2.15577\n",
      "[34]\tvalid_0's multi_logloss: 2.15428\n",
      "[35]\tvalid_0's multi_logloss: 2.15285\n",
      "[36]\tvalid_0's multi_logloss: 2.15134\n",
      "[37]\tvalid_0's multi_logloss: 2.14974\n",
      "[38]\tvalid_0's multi_logloss: 2.14844\n",
      "[39]\tvalid_0's multi_logloss: 2.14712\n",
      "[40]\tvalid_0's multi_logloss: 2.14566\n",
      "[41]\tvalid_0's multi_logloss: 2.14438\n",
      "[42]\tvalid_0's multi_logloss: 2.14323\n",
      "[43]\tvalid_0's multi_logloss: 2.14198\n",
      "[44]\tvalid_0's multi_logloss: 2.14085\n",
      "[45]\tvalid_0's multi_logloss: 2.1395\n",
      "[46]\tvalid_0's multi_logloss: 2.13854\n",
      "[47]\tvalid_0's multi_logloss: 2.13761\n",
      "[48]\tvalid_0's multi_logloss: 2.13666\n",
      "[49]\tvalid_0's multi_logloss: 2.13581\n",
      "[50]\tvalid_0's multi_logloss: 2.13496\n",
      "[51]\tvalid_0's multi_logloss: 2.13411\n",
      "[52]\tvalid_0's multi_logloss: 2.13323\n",
      "[53]\tvalid_0's multi_logloss: 2.13232\n",
      "[54]\tvalid_0's multi_logloss: 2.13166\n",
      "[55]\tvalid_0's multi_logloss: 2.13086\n",
      "[56]\tvalid_0's multi_logloss: 2.1302\n",
      "[57]\tvalid_0's multi_logloss: 2.12955\n",
      "[58]\tvalid_0's multi_logloss: 2.12887\n",
      "[59]\tvalid_0's multi_logloss: 2.12819\n",
      "[60]\tvalid_0's multi_logloss: 2.12764\n",
      "[61]\tvalid_0's multi_logloss: 2.12714\n",
      "[62]\tvalid_0's multi_logloss: 2.12668\n",
      "[63]\tvalid_0's multi_logloss: 2.12601\n",
      "[64]\tvalid_0's multi_logloss: 2.12529\n",
      "[65]\tvalid_0's multi_logloss: 2.12476\n",
      "[66]\tvalid_0's multi_logloss: 2.12429\n",
      "[67]\tvalid_0's multi_logloss: 2.12357\n",
      "[68]\tvalid_0's multi_logloss: 2.12305\n",
      "[69]\tvalid_0's multi_logloss: 2.12254\n",
      "[70]\tvalid_0's multi_logloss: 2.12196\n",
      "[71]\tvalid_0's multi_logloss: 2.12138\n",
      "[72]\tvalid_0's multi_logloss: 2.12087\n",
      "[73]\tvalid_0's multi_logloss: 2.12046\n",
      "[74]\tvalid_0's multi_logloss: 2.11993\n",
      "[75]\tvalid_0's multi_logloss: 2.1195\n",
      "[76]\tvalid_0's multi_logloss: 2.11906\n",
      "[77]\tvalid_0's multi_logloss: 2.11853\n",
      "[78]\tvalid_0's multi_logloss: 2.11811\n",
      "[79]\tvalid_0's multi_logloss: 2.11764\n",
      "[80]\tvalid_0's multi_logloss: 2.11715\n",
      "[81]\tvalid_0's multi_logloss: 2.11649\n",
      "[82]\tvalid_0's multi_logloss: 2.11608\n",
      "[83]\tvalid_0's multi_logloss: 2.11565\n",
      "[84]\tvalid_0's multi_logloss: 2.11531\n",
      "[85]\tvalid_0's multi_logloss: 2.11484\n",
      "[86]\tvalid_0's multi_logloss: 2.11436\n",
      "[87]\tvalid_0's multi_logloss: 2.11402\n",
      "[88]\tvalid_0's multi_logloss: 2.11358\n",
      "[89]\tvalid_0's multi_logloss: 2.11317\n",
      "[90]\tvalid_0's multi_logloss: 2.11275\n",
      "[91]\tvalid_0's multi_logloss: 2.11229\n",
      "[92]\tvalid_0's multi_logloss: 2.1119\n",
      "[93]\tvalid_0's multi_logloss: 2.11164\n",
      "[94]\tvalid_0's multi_logloss: 2.11137\n",
      "[95]\tvalid_0's multi_logloss: 2.111\n",
      "[96]\tvalid_0's multi_logloss: 2.11059\n",
      "[97]\tvalid_0's multi_logloss: 2.11032\n",
      "[98]\tvalid_0's multi_logloss: 2.1099\n",
      "[99]\tvalid_0's multi_logloss: 2.10957\n",
      "[100]\tvalid_0's multi_logloss: 2.10918\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026869 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -0.501622\n",
      "[LightGBM] [Info] Start training from score -0.930257\n",
      "[1]\tvalid_0's multi_logloss: 0.576741\n",
      "[2]\tvalid_0's multi_logloss: 0.501183\n",
      "[3]\tvalid_0's multi_logloss: 0.43877\n",
      "[4]\tvalid_0's multi_logloss: 0.386165\n",
      "[5]\tvalid_0's multi_logloss: 0.341367\n",
      "[6]\tvalid_0's multi_logloss: 0.302895\n",
      "[7]\tvalid_0's multi_logloss: 0.269447\n",
      "[8]\tvalid_0's multi_logloss: 0.240418\n",
      "[9]\tvalid_0's multi_logloss: 0.214995\n",
      "[10]\tvalid_0's multi_logloss: 0.192642\n",
      "[11]\tvalid_0's multi_logloss: 0.172669\n",
      "[12]\tvalid_0's multi_logloss: 0.15502\n",
      "[13]\tvalid_0's multi_logloss: 0.139326\n",
      "[14]\tvalid_0's multi_logloss: 0.12547\n",
      "[15]\tvalid_0's multi_logloss: 0.113056\n",
      "[16]\tvalid_0's multi_logloss: 0.101892\n",
      "[17]\tvalid_0's multi_logloss: 0.0919482\n",
      "[18]\tvalid_0's multi_logloss: 0.0830002\n",
      "[19]\tvalid_0's multi_logloss: 0.0749566\n",
      "[20]\tvalid_0's multi_logloss: 0.0677289\n",
      "[21]\tvalid_0's multi_logloss: 0.0612706\n",
      "[22]\tvalid_0's multi_logloss: 0.0554363\n",
      "[23]\tvalid_0's multi_logloss: 0.0502101\n",
      "[24]\tvalid_0's multi_logloss: 0.045485\n",
      "[25]\tvalid_0's multi_logloss: 0.0412366\n",
      "[26]\tvalid_0's multi_logloss: 0.0373597\n",
      "[27]\tvalid_0's multi_logloss: 0.0338716\n",
      "[28]\tvalid_0's multi_logloss: 0.0307791\n",
      "[29]\tvalid_0's multi_logloss: 0.0279369\n",
      "[30]\tvalid_0's multi_logloss: 0.0253566\n",
      "[31]\tvalid_0's multi_logloss: 0.023031\n",
      "[32]\tvalid_0's multi_logloss: 0.0209156\n",
      "[33]\tvalid_0's multi_logloss: 0.0190237\n",
      "[34]\tvalid_0's multi_logloss: 0.0172869\n",
      "[35]\tvalid_0's multi_logloss: 0.015724\n",
      "[36]\tvalid_0's multi_logloss: 0.0142986\n",
      "[37]\tvalid_0's multi_logloss: 0.0130159\n",
      "[38]\tvalid_0's multi_logloss: 0.0118525\n",
      "[39]\tvalid_0's multi_logloss: 0.0107914\n",
      "[40]\tvalid_0's multi_logloss: 0.00983126\n",
      "[41]\tvalid_0's multi_logloss: 0.00896558\n",
      "[42]\tvalid_0's multi_logloss: 0.00817375\n",
      "[43]\tvalid_0's multi_logloss: 0.00746494\n",
      "[44]\tvalid_0's multi_logloss: 0.0068161\n",
      "[45]\tvalid_0's multi_logloss: 0.00623095\n",
      "[46]\tvalid_0's multi_logloss: 0.00569726\n",
      "[47]\tvalid_0's multi_logloss: 0.005218\n",
      "[48]\tvalid_0's multi_logloss: 0.00477643\n",
      "[49]\tvalid_0's multi_logloss: 0.00437917\n",
      "[50]\tvalid_0's multi_logloss: 0.00401123\n",
      "[51]\tvalid_0's multi_logloss: 0.00368408\n",
      "[52]\tvalid_0's multi_logloss: 0.0033847\n",
      "[53]\tvalid_0's multi_logloss: 0.00311549\n",
      "[54]\tvalid_0's multi_logloss: 0.0028713\n",
      "[55]\tvalid_0's multi_logloss: 0.00264639\n",
      "[56]\tvalid_0's multi_logloss: 0.00244289\n",
      "[57]\tvalid_0's multi_logloss: 0.00226078\n",
      "[58]\tvalid_0's multi_logloss: 0.00209212\n",
      "[59]\tvalid_0's multi_logloss: 0.00193862\n",
      "[60]\tvalid_0's multi_logloss: 0.00179933\n",
      "[61]\tvalid_0's multi_logloss: 0.00167242\n",
      "[62]\tvalid_0's multi_logloss: 0.00155495\n",
      "[63]\tvalid_0's multi_logloss: 0.00145008\n",
      "[64]\tvalid_0's multi_logloss: 0.00135412\n",
      "[65]\tvalid_0's multi_logloss: 0.00126631\n",
      "[66]\tvalid_0's multi_logloss: 0.00118761\n",
      "[67]\tvalid_0's multi_logloss: 0.00111206\n",
      "[68]\tvalid_0's multi_logloss: 0.00104386\n",
      "[69]\tvalid_0's multi_logloss: 0.000984313\n",
      "[70]\tvalid_0's multi_logloss: 0.000929699\n",
      "[71]\tvalid_0's multi_logloss: 0.000879487\n",
      "[72]\tvalid_0's multi_logloss: 0.000834994\n",
      "[73]\tvalid_0's multi_logloss: 0.000794029\n",
      "[74]\tvalid_0's multi_logloss: 0.000755741\n",
      "[75]\tvalid_0's multi_logloss: 0.000722274\n",
      "[76]\tvalid_0's multi_logloss: 0.000691876\n",
      "[77]\tvalid_0's multi_logloss: 0.000662902\n",
      "[78]\tvalid_0's multi_logloss: 0.000637419\n",
      "[79]\tvalid_0's multi_logloss: 0.000614393\n",
      "[80]\tvalid_0's multi_logloss: 0.00059291\n",
      "[81]\tvalid_0's multi_logloss: 0.000573477\n",
      "[82]\tvalid_0's multi_logloss: 0.00055502\n",
      "[83]\tvalid_0's multi_logloss: 0.000538071\n",
      "[84]\tvalid_0's multi_logloss: 0.000521433\n",
      "[85]\tvalid_0's multi_logloss: 0.000507267\n",
      "[86]\tvalid_0's multi_logloss: 0.000494089\n",
      "[87]\tvalid_0's multi_logloss: 0.000482132\n",
      "[88]\tvalid_0's multi_logloss: 0.000470998\n",
      "[89]\tvalid_0's multi_logloss: 0.000461137\n",
      "[90]\tvalid_0's multi_logloss: 0.00045228\n",
      "[91]\tvalid_0's multi_logloss: 0.000486421\n",
      "[92]\tvalid_0's multi_logloss: 0.000439836\n",
      "[93]\tvalid_0's multi_logloss: 0.000479372\n",
      "[94]\tvalid_0's multi_logloss: 0.00049408\n",
      "[95]\tvalid_0's multi_logloss: 0.000487569\n",
      "[96]\tvalid_0's multi_logloss: 0.000541954\n",
      "[97]\tvalid_0's multi_logloss: 0.000465704\n",
      "[98]\tvalid_0's multi_logloss: 0.000460737\n",
      "[99]\tvalid_0's multi_logloss: 0.000456184\n",
      "[100]\tvalid_0's multi_logloss: 0.000447396\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018349 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -0.141837\n",
      "[LightGBM] [Info] Start training from score -2.023158\n",
      "[1]\tvalid_0's multi_logloss: 0.357259\n",
      "[2]\tvalid_0's multi_logloss: 0.336142\n",
      "[3]\tvalid_0's multi_logloss: 0.320203\n",
      "[4]\tvalid_0's multi_logloss: 0.307888\n",
      "[5]\tvalid_0's multi_logloss: 0.298023\n",
      "[6]\tvalid_0's multi_logloss: 0.289611\n",
      "[7]\tvalid_0's multi_logloss: 0.282245\n",
      "[8]\tvalid_0's multi_logloss: 0.276026\n",
      "[9]\tvalid_0's multi_logloss: 0.270342\n",
      "[10]\tvalid_0's multi_logloss: 0.265603\n",
      "[11]\tvalid_0's multi_logloss: 0.261555\n",
      "[12]\tvalid_0's multi_logloss: 0.25741\n",
      "[13]\tvalid_0's multi_logloss: 0.253952\n",
      "[14]\tvalid_0's multi_logloss: 0.250772\n",
      "[15]\tvalid_0's multi_logloss: 0.247409\n",
      "[16]\tvalid_0's multi_logloss: 0.244502\n",
      "[17]\tvalid_0's multi_logloss: 0.24176\n",
      "[18]\tvalid_0's multi_logloss: 0.23956\n",
      "[19]\tvalid_0's multi_logloss: 0.237116\n",
      "[20]\tvalid_0's multi_logloss: 0.234996\n",
      "[21]\tvalid_0's multi_logloss: 0.232996\n",
      "[22]\tvalid_0's multi_logloss: 0.23134\n",
      "[23]\tvalid_0's multi_logloss: 0.229632\n",
      "[24]\tvalid_0's multi_logloss: 0.227617\n",
      "[25]\tvalid_0's multi_logloss: 0.226209\n",
      "[26]\tvalid_0's multi_logloss: 0.224494\n",
      "[27]\tvalid_0's multi_logloss: 0.223091\n",
      "[28]\tvalid_0's multi_logloss: 0.221915\n",
      "[29]\tvalid_0's multi_logloss: 0.220522\n",
      "[30]\tvalid_0's multi_logloss: 0.219547\n",
      "[31]\tvalid_0's multi_logloss: 0.218316\n",
      "[32]\tvalid_0's multi_logloss: 0.217274\n",
      "[33]\tvalid_0's multi_logloss: 0.21617\n",
      "[34]\tvalid_0's multi_logloss: 0.215508\n",
      "[35]\tvalid_0's multi_logloss: 0.214692\n",
      "[36]\tvalid_0's multi_logloss: 0.213831\n",
      "[37]\tvalid_0's multi_logloss: 0.212869\n",
      "[38]\tvalid_0's multi_logloss: 0.211916\n",
      "[39]\tvalid_0's multi_logloss: 0.211185\n",
      "[40]\tvalid_0's multi_logloss: 0.21052\n",
      "[41]\tvalid_0's multi_logloss: 0.209766\n",
      "[42]\tvalid_0's multi_logloss: 0.209044\n",
      "[43]\tvalid_0's multi_logloss: 0.208364\n",
      "[44]\tvalid_0's multi_logloss: 0.20785\n",
      "[45]\tvalid_0's multi_logloss: 0.207416\n",
      "[46]\tvalid_0's multi_logloss: 0.206546\n",
      "[47]\tvalid_0's multi_logloss: 0.206094\n",
      "[48]\tvalid_0's multi_logloss: 0.20533\n",
      "[49]\tvalid_0's multi_logloss: 0.204659\n",
      "[50]\tvalid_0's multi_logloss: 0.204336\n",
      "[51]\tvalid_0's multi_logloss: 0.203971\n",
      "[52]\tvalid_0's multi_logloss: 0.203476\n",
      "[53]\tvalid_0's multi_logloss: 0.203211\n",
      "[54]\tvalid_0's multi_logloss: 0.202726\n",
      "[55]\tvalid_0's multi_logloss: 0.202313\n",
      "[56]\tvalid_0's multi_logloss: 0.202129\n",
      "[57]\tvalid_0's multi_logloss: 0.20159\n",
      "[58]\tvalid_0's multi_logloss: 0.201198\n",
      "[59]\tvalid_0's multi_logloss: 0.200547\n",
      "[60]\tvalid_0's multi_logloss: 0.200114\n",
      "[61]\tvalid_0's multi_logloss: 0.199855\n",
      "[62]\tvalid_0's multi_logloss: 0.199666\n",
      "[63]\tvalid_0's multi_logloss: 0.199172\n",
      "[64]\tvalid_0's multi_logloss: 0.198846\n",
      "[65]\tvalid_0's multi_logloss: 0.198296\n",
      "[66]\tvalid_0's multi_logloss: 0.198073\n",
      "[67]\tvalid_0's multi_logloss: 0.197849\n",
      "[68]\tvalid_0's multi_logloss: 0.197515\n",
      "[69]\tvalid_0's multi_logloss: 0.197115\n",
      "[70]\tvalid_0's multi_logloss: 0.19699\n",
      "[71]\tvalid_0's multi_logloss: 0.196764\n",
      "[72]\tvalid_0's multi_logloss: 0.196526\n",
      "[73]\tvalid_0's multi_logloss: 0.196357\n",
      "[74]\tvalid_0's multi_logloss: 0.19614\n",
      "[75]\tvalid_0's multi_logloss: 0.19583\n",
      "[76]\tvalid_0's multi_logloss: 0.195647\n",
      "[77]\tvalid_0's multi_logloss: 0.195131\n",
      "[78]\tvalid_0's multi_logloss: 0.194989\n",
      "[79]\tvalid_0's multi_logloss: 0.194606\n",
      "[80]\tvalid_0's multi_logloss: 0.194299\n",
      "[81]\tvalid_0's multi_logloss: 0.194073\n",
      "[82]\tvalid_0's multi_logloss: 0.193773\n",
      "[83]\tvalid_0's multi_logloss: 0.193349\n",
      "[84]\tvalid_0's multi_logloss: 0.193178\n",
      "[85]\tvalid_0's multi_logloss: 0.19301\n",
      "[86]\tvalid_0's multi_logloss: 0.192651\n",
      "[87]\tvalid_0's multi_logloss: 0.192342\n",
      "[88]\tvalid_0's multi_logloss: 0.192124\n",
      "[89]\tvalid_0's multi_logloss: 0.191933\n",
      "[90]\tvalid_0's multi_logloss: 0.191747\n",
      "[91]\tvalid_0's multi_logloss: 0.191409\n",
      "[92]\tvalid_0's multi_logloss: 0.191296\n",
      "[93]\tvalid_0's multi_logloss: 0.191077\n",
      "[94]\tvalid_0's multi_logloss: 0.190894\n",
      "[95]\tvalid_0's multi_logloss: 0.190611\n",
      "[96]\tvalid_0's multi_logloss: 0.190493\n",
      "[97]\tvalid_0's multi_logloss: 0.190398\n",
      "[98]\tvalid_0's multi_logloss: 0.19027\n",
      "[99]\tvalid_0's multi_logloss: 0.190079\n",
      "[100]\tvalid_0's multi_logloss: 0.189761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34it [1:10:40, 149.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011742 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 7715638, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -1.249550\n",
      "[LightGBM] [Info] Start training from score -3.165534\n",
      "[LightGBM] [Info] Start training from score -1.726403\n",
      "[LightGBM] [Info] Start training from score -1.902421\n",
      "[LightGBM] [Info] Start training from score -1.667720\n",
      "[LightGBM] [Info] Start training from score -1.861961\n",
      "[1]\tvalid_0's multi_logloss: 1.67549\n",
      "[2]\tvalid_0's multi_logloss: 1.66659\n",
      "[3]\tvalid_0's multi_logloss: 1.65932\n",
      "[4]\tvalid_0's multi_logloss: 1.65293\n",
      "[5]\tvalid_0's multi_logloss: 1.64752\n",
      "[6]\tvalid_0's multi_logloss: 1.64274\n",
      "[7]\tvalid_0's multi_logloss: 1.63842\n",
      "[8]\tvalid_0's multi_logloss: 1.63469\n",
      "[9]\tvalid_0's multi_logloss: 1.6314\n",
      "[10]\tvalid_0's multi_logloss: 1.62838\n",
      "[11]\tvalid_0's multi_logloss: 1.62539\n",
      "[12]\tvalid_0's multi_logloss: 1.62286\n",
      "[13]\tvalid_0's multi_logloss: 1.62048\n",
      "[14]\tvalid_0's multi_logloss: 1.61823\n",
      "[15]\tvalid_0's multi_logloss: 1.61625\n",
      "[16]\tvalid_0's multi_logloss: 1.61438\n",
      "[17]\tvalid_0's multi_logloss: 1.61238\n",
      "[18]\tvalid_0's multi_logloss: 1.61073\n",
      "[19]\tvalid_0's multi_logloss: 1.60899\n",
      "[20]\tvalid_0's multi_logloss: 1.60717\n",
      "[21]\tvalid_0's multi_logloss: 1.60569\n",
      "[22]\tvalid_0's multi_logloss: 1.60434\n",
      "[23]\tvalid_0's multi_logloss: 1.60277\n",
      "[24]\tvalid_0's multi_logloss: 1.6016\n",
      "[25]\tvalid_0's multi_logloss: 1.60053\n",
      "[26]\tvalid_0's multi_logloss: 1.59942\n",
      "[27]\tvalid_0's multi_logloss: 1.59822\n",
      "[28]\tvalid_0's multi_logloss: 1.59717\n",
      "[29]\tvalid_0's multi_logloss: 1.5961\n",
      "[30]\tvalid_0's multi_logloss: 1.59527\n",
      "[31]\tvalid_0's multi_logloss: 1.59451\n",
      "[32]\tvalid_0's multi_logloss: 1.59363\n",
      "[33]\tvalid_0's multi_logloss: 1.59267\n",
      "[34]\tvalid_0's multi_logloss: 1.5916\n",
      "[35]\tvalid_0's multi_logloss: 1.59088\n",
      "[36]\tvalid_0's multi_logloss: 1.59028\n",
      "[37]\tvalid_0's multi_logloss: 1.58941\n",
      "[38]\tvalid_0's multi_logloss: 1.58837\n",
      "[39]\tvalid_0's multi_logloss: 1.58773\n",
      "[40]\tvalid_0's multi_logloss: 1.58714\n",
      "[41]\tvalid_0's multi_logloss: 1.58649\n",
      "[42]\tvalid_0's multi_logloss: 1.58573\n",
      "[43]\tvalid_0's multi_logloss: 1.58525\n",
      "[44]\tvalid_0's multi_logloss: 1.58466\n",
      "[45]\tvalid_0's multi_logloss: 1.58387\n",
      "[46]\tvalid_0's multi_logloss: 1.5834\n",
      "[47]\tvalid_0's multi_logloss: 1.58285\n",
      "[48]\tvalid_0's multi_logloss: 1.58215\n",
      "[49]\tvalid_0's multi_logloss: 1.58173\n",
      "[50]\tvalid_0's multi_logloss: 1.58137\n",
      "[51]\tvalid_0's multi_logloss: 1.58091\n",
      "[52]\tvalid_0's multi_logloss: 1.58052\n",
      "[53]\tvalid_0's multi_logloss: 1.58004\n",
      "[54]\tvalid_0's multi_logloss: 1.57954\n",
      "[55]\tvalid_0's multi_logloss: 1.57883\n",
      "[56]\tvalid_0's multi_logloss: 1.57835\n",
      "[57]\tvalid_0's multi_logloss: 1.57776\n",
      "[58]\tvalid_0's multi_logloss: 1.57735\n",
      "[59]\tvalid_0's multi_logloss: 1.57673\n",
      "[60]\tvalid_0's multi_logloss: 1.576\n",
      "[61]\tvalid_0's multi_logloss: 1.57542\n",
      "[62]\tvalid_0's multi_logloss: 1.57507\n",
      "[63]\tvalid_0's multi_logloss: 1.57439\n",
      "[64]\tvalid_0's multi_logloss: 1.57398\n",
      "[65]\tvalid_0's multi_logloss: 1.5736\n",
      "[66]\tvalid_0's multi_logloss: 1.57311\n",
      "[67]\tvalid_0's multi_logloss: 1.57274\n",
      "[68]\tvalid_0's multi_logloss: 1.5721\n",
      "[69]\tvalid_0's multi_logloss: 1.57165\n",
      "[70]\tvalid_0's multi_logloss: 1.5712\n",
      "[71]\tvalid_0's multi_logloss: 1.57096\n",
      "[72]\tvalid_0's multi_logloss: 1.57067\n",
      "[73]\tvalid_0's multi_logloss: 1.57041\n",
      "[74]\tvalid_0's multi_logloss: 1.57006\n",
      "[75]\tvalid_0's multi_logloss: 1.56965\n",
      "[76]\tvalid_0's multi_logloss: 1.56913\n",
      "[77]\tvalid_0's multi_logloss: 1.56887\n",
      "[78]\tvalid_0's multi_logloss: 1.56857\n",
      "[79]\tvalid_0's multi_logloss: 1.56825\n",
      "[80]\tvalid_0's multi_logloss: 1.56778\n",
      "[81]\tvalid_0's multi_logloss: 1.56751\n",
      "[82]\tvalid_0's multi_logloss: 1.56729\n",
      "[83]\tvalid_0's multi_logloss: 1.56686\n",
      "[84]\tvalid_0's multi_logloss: 1.56663\n",
      "[85]\tvalid_0's multi_logloss: 1.56647\n",
      "[86]\tvalid_0's multi_logloss: 1.56624\n",
      "[87]\tvalid_0's multi_logloss: 1.56601\n",
      "[88]\tvalid_0's multi_logloss: 1.56583\n",
      "[89]\tvalid_0's multi_logloss: 1.5656\n",
      "[90]\tvalid_0's multi_logloss: 1.56537\n",
      "[91]\tvalid_0's multi_logloss: 1.56504\n",
      "[92]\tvalid_0's multi_logloss: 1.56458\n",
      "[93]\tvalid_0's multi_logloss: 1.56434\n",
      "[94]\tvalid_0's multi_logloss: 1.56394\n",
      "[95]\tvalid_0's multi_logloss: 1.56373\n",
      "[96]\tvalid_0's multi_logloss: 1.56334\n",
      "[97]\tvalid_0's multi_logloss: 1.56276\n",
      "[98]\tvalid_0's multi_logloss: 1.56241\n",
      "[99]\tvalid_0's multi_logloss: 1.56221\n",
      "[100]\tvalid_0's multi_logloss: 1.56174\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 7715638, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -3.388563\n",
      "[LightGBM] [Info] Start training from score -3.286043\n",
      "[LightGBM] [Info] Start training from score -3.265766\n",
      "[LightGBM] [Info] Start training from score -3.814547\n",
      "[LightGBM] [Info] Start training from score -3.310265\n",
      "[LightGBM] [Info] Start training from score -3.206426\n",
      "[LightGBM] [Info] Start training from score -4.264605\n",
      "[LightGBM] [Info] Start training from score -3.385622\n",
      "[LightGBM] [Info] Start training from score -3.678169\n",
      "[LightGBM] [Info] Start training from score -3.401590\n",
      "[LightGBM] [Info] Start training from score -4.879144\n",
      "[LightGBM] [Info] Start training from score -3.027581\n",
      "[LightGBM] [Info] Start training from score -2.985319\n",
      "[LightGBM] [Info] Start training from score -3.251856\n",
      "[LightGBM] [Info] Start training from score -3.294527\n",
      "[LightGBM] [Info] Start training from score -3.372086\n",
      "[LightGBM] [Info] Start training from score -2.973489\n",
      "[LightGBM] [Info] Start training from score -2.489644\n",
      "[LightGBM] [Info] Start training from score -3.403357\n",
      "[LightGBM] [Info] Start training from score -4.161407\n",
      "[LightGBM] [Info] Start training from score -4.219942\n",
      "[LightGBM] [Info] Start training from score -3.454308\n",
      "[LightGBM] [Info] Start training from score -3.414970\n",
      "[LightGBM] [Info] Start training from score -3.160243\n",
      "[LightGBM] [Info] Start training from score -3.113230\n",
      "[LightGBM] [Info] Start training from score -3.209175\n",
      "[LightGBM] [Info] Start training from score -3.282600\n",
      "[LightGBM] [Info] Start training from score -3.180636\n",
      "[1]\tvalid_0's multi_logloss: 2.71966\n",
      "[2]\tvalid_0's multi_logloss: 2.5513\n",
      "[3]\tvalid_0's multi_logloss: 2.43368\n",
      "[4]\tvalid_0's multi_logloss: 2.34393\n",
      "[5]\tvalid_0's multi_logloss: 2.27249\n",
      "[6]\tvalid_0's multi_logloss: 2.21244\n",
      "[7]\tvalid_0's multi_logloss: 2.16094\n",
      "[8]\tvalid_0's multi_logloss: 2.11669\n",
      "[9]\tvalid_0's multi_logloss: 2.07906\n",
      "[10]\tvalid_0's multi_logloss: 2.04537\n",
      "[11]\tvalid_0's multi_logloss: 2.01632\n",
      "[12]\tvalid_0's multi_logloss: 1.99058\n",
      "[13]\tvalid_0's multi_logloss: 1.96698\n",
      "[14]\tvalid_0's multi_logloss: 1.94534\n",
      "[15]\tvalid_0's multi_logloss: 1.92622\n",
      "[16]\tvalid_0's multi_logloss: 1.90888\n",
      "[17]\tvalid_0's multi_logloss: 1.89326\n",
      "[18]\tvalid_0's multi_logloss: 1.87861\n",
      "[19]\tvalid_0's multi_logloss: 1.86553\n",
      "[20]\tvalid_0's multi_logloss: 1.85314\n",
      "[21]\tvalid_0's multi_logloss: 1.84147\n",
      "[22]\tvalid_0's multi_logloss: 1.83051\n",
      "[23]\tvalid_0's multi_logloss: 1.82058\n",
      "[24]\tvalid_0's multi_logloss: 1.81143\n",
      "[25]\tvalid_0's multi_logloss: 1.80267\n",
      "[26]\tvalid_0's multi_logloss: 1.79433\n",
      "[27]\tvalid_0's multi_logloss: 1.78669\n",
      "[28]\tvalid_0's multi_logloss: 1.77926\n",
      "[29]\tvalid_0's multi_logloss: 1.77245\n",
      "[30]\tvalid_0's multi_logloss: 1.76624\n",
      "[31]\tvalid_0's multi_logloss: 1.76029\n",
      "[32]\tvalid_0's multi_logloss: 1.75416\n",
      "[33]\tvalid_0's multi_logloss: 1.74814\n",
      "[34]\tvalid_0's multi_logloss: 1.7425\n",
      "[35]\tvalid_0's multi_logloss: 1.73751\n",
      "[36]\tvalid_0's multi_logloss: 1.73257\n",
      "[37]\tvalid_0's multi_logloss: 1.72762\n",
      "[38]\tvalid_0's multi_logloss: 1.72317\n",
      "[39]\tvalid_0's multi_logloss: 1.71864\n",
      "[40]\tvalid_0's multi_logloss: 1.71452\n",
      "[41]\tvalid_0's multi_logloss: 1.71032\n",
      "[42]\tvalid_0's multi_logloss: 1.70652\n",
      "[43]\tvalid_0's multi_logloss: 1.70281\n",
      "[44]\tvalid_0's multi_logloss: 1.69936\n",
      "[45]\tvalid_0's multi_logloss: 1.69677\n",
      "[46]\tvalid_0's multi_logloss: 1.69308\n",
      "[47]\tvalid_0's multi_logloss: 1.68955\n",
      "[48]\tvalid_0's multi_logloss: 1.68627\n",
      "[49]\tvalid_0's multi_logloss: 1.68285\n",
      "[50]\tvalid_0's multi_logloss: 1.68049\n",
      "[51]\tvalid_0's multi_logloss: 1.67743\n",
      "[52]\tvalid_0's multi_logloss: 1.67486\n",
      "[53]\tvalid_0's multi_logloss: 1.67133\n",
      "[54]\tvalid_0's multi_logloss: 1.66931\n",
      "[55]\tvalid_0's multi_logloss: 1.66663\n",
      "[56]\tvalid_0's multi_logloss: 1.66404\n",
      "[57]\tvalid_0's multi_logloss: 1.66122\n",
      "[58]\tvalid_0's multi_logloss: 1.65876\n",
      "[59]\tvalid_0's multi_logloss: 1.65643\n",
      "[60]\tvalid_0's multi_logloss: 1.65399\n",
      "[61]\tvalid_0's multi_logloss: 1.65151\n",
      "[62]\tvalid_0's multi_logloss: 1.64943\n",
      "[63]\tvalid_0's multi_logloss: 1.64782\n",
      "[64]\tvalid_0's multi_logloss: 1.64523\n",
      "[65]\tvalid_0's multi_logloss: 1.64382\n",
      "[66]\tvalid_0's multi_logloss: 1.64208\n",
      "[67]\tvalid_0's multi_logloss: 1.63981\n",
      "[68]\tvalid_0's multi_logloss: 1.63802\n",
      "[69]\tvalid_0's multi_logloss: 1.63631\n",
      "[70]\tvalid_0's multi_logloss: 1.63475\n",
      "[71]\tvalid_0's multi_logloss: 1.63288\n",
      "[72]\tvalid_0's multi_logloss: 1.63157\n",
      "[73]\tvalid_0's multi_logloss: 1.6298\n",
      "[74]\tvalid_0's multi_logloss: 1.62795\n",
      "[75]\tvalid_0's multi_logloss: 1.62676\n",
      "[76]\tvalid_0's multi_logloss: 1.62534\n",
      "[77]\tvalid_0's multi_logloss: 1.6246\n",
      "[78]\tvalid_0's multi_logloss: 1.62139\n",
      "[79]\tvalid_0's multi_logloss: 1.62028\n",
      "[80]\tvalid_0's multi_logloss: 1.61962\n",
      "[81]\tvalid_0's multi_logloss: 1.61771\n",
      "[82]\tvalid_0's multi_logloss: 1.61746\n",
      "[83]\tvalid_0's multi_logloss: 1.6164\n",
      "[84]\tvalid_0's multi_logloss: 1.61411\n",
      "[85]\tvalid_0's multi_logloss: 1.61518\n",
      "[86]\tvalid_0's multi_logloss: 1.61028\n",
      "[87]\tvalid_0's multi_logloss: 1.61284\n",
      "[88]\tvalid_0's multi_logloss: 1.60928\n",
      "[89]\tvalid_0's multi_logloss: 1.60695\n",
      "[90]\tvalid_0's multi_logloss: 1.6086\n",
      "[91]\tvalid_0's multi_logloss: 1.60407\n",
      "[92]\tvalid_0's multi_logloss: 1.60255\n",
      "[93]\tvalid_0's multi_logloss: 1.60175\n",
      "[94]\tvalid_0's multi_logloss: 1.59981\n",
      "[95]\tvalid_0's multi_logloss: 1.59773\n",
      "[96]\tvalid_0's multi_logloss: 1.59697\n",
      "[97]\tvalid_0's multi_logloss: 1.59381\n",
      "[98]\tvalid_0's multi_logloss: 1.59314\n",
      "[99]\tvalid_0's multi_logloss: 1.59216\n",
      "[100]\tvalid_0's multi_logloss: 1.59226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [1:12:33, 138.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001291 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 820733, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -0.683185\n",
      "[LightGBM] [Info] Start training from score -2.382997\n",
      "[LightGBM] [Info] Start training from score -2.734975\n",
      "[LightGBM] [Info] Start training from score -3.826068\n",
      "[LightGBM] [Info] Start training from score -1.583719\n",
      "[LightGBM] [Info] Start training from score -2.199855\n",
      "[1]\tvalid_0's multi_logloss: 1.1771\n",
      "[2]\tvalid_0's multi_logloss: 1.06967\n",
      "[3]\tvalid_0's multi_logloss: 0.986893\n",
      "[4]\tvalid_0's multi_logloss: 0.921675\n",
      "[5]\tvalid_0's multi_logloss: 0.867963\n",
      "[6]\tvalid_0's multi_logloss: 0.823736\n",
      "[7]\tvalid_0's multi_logloss: 0.786229\n",
      "[8]\tvalid_0's multi_logloss: 0.754446\n",
      "[9]\tvalid_0's multi_logloss: 0.727536\n",
      "[10]\tvalid_0's multi_logloss: 0.704384\n",
      "[11]\tvalid_0's multi_logloss: 0.684171\n",
      "[12]\tvalid_0's multi_logloss: 0.666837\n",
      "[13]\tvalid_0's multi_logloss: 0.651277\n",
      "[14]\tvalid_0's multi_logloss: 0.637701\n",
      "[15]\tvalid_0's multi_logloss: 0.62566\n",
      "[16]\tvalid_0's multi_logloss: 0.614916\n",
      "[17]\tvalid_0's multi_logloss: 0.60553\n",
      "[18]\tvalid_0's multi_logloss: 0.597014\n",
      "[19]\tvalid_0's multi_logloss: 0.589252\n",
      "[20]\tvalid_0's multi_logloss: 0.581987\n",
      "[21]\tvalid_0's multi_logloss: 0.575588\n",
      "[22]\tvalid_0's multi_logloss: 0.569456\n",
      "[23]\tvalid_0's multi_logloss: 0.563898\n",
      "[24]\tvalid_0's multi_logloss: 0.558887\n",
      "[25]\tvalid_0's multi_logloss: 0.554271\n",
      "[26]\tvalid_0's multi_logloss: 0.549995\n",
      "[27]\tvalid_0's multi_logloss: 0.54618\n",
      "[28]\tvalid_0's multi_logloss: 0.542619\n",
      "[29]\tvalid_0's multi_logloss: 0.539432\n",
      "[30]\tvalid_0's multi_logloss: 0.53622\n",
      "[31]\tvalid_0's multi_logloss: 0.533261\n",
      "[32]\tvalid_0's multi_logloss: 0.530719\n",
      "[33]\tvalid_0's multi_logloss: 0.528149\n",
      "[34]\tvalid_0's multi_logloss: 0.525912\n",
      "[35]\tvalid_0's multi_logloss: 0.52393\n",
      "[36]\tvalid_0's multi_logloss: 0.521834\n",
      "[37]\tvalid_0's multi_logloss: 0.520183\n",
      "[38]\tvalid_0's multi_logloss: 0.518403\n",
      "[39]\tvalid_0's multi_logloss: 0.51676\n",
      "[40]\tvalid_0's multi_logloss: 0.515204\n",
      "[41]\tvalid_0's multi_logloss: 0.513951\n",
      "[42]\tvalid_0's multi_logloss: 0.51284\n",
      "[43]\tvalid_0's multi_logloss: 0.511596\n",
      "[44]\tvalid_0's multi_logloss: 0.510167\n",
      "[45]\tvalid_0's multi_logloss: 0.509151\n",
      "[46]\tvalid_0's multi_logloss: 0.50788\n",
      "[47]\tvalid_0's multi_logloss: 0.506795\n",
      "[48]\tvalid_0's multi_logloss: 0.505456\n",
      "[49]\tvalid_0's multi_logloss: 0.50443\n",
      "[50]\tvalid_0's multi_logloss: 0.503525\n",
      "[51]\tvalid_0's multi_logloss: 0.502586\n",
      "[52]\tvalid_0's multi_logloss: 0.501974\n",
      "[53]\tvalid_0's multi_logloss: 0.500792\n",
      "[54]\tvalid_0's multi_logloss: 0.500895\n",
      "[55]\tvalid_0's multi_logloss: 0.499344\n",
      "[56]\tvalid_0's multi_logloss: 0.498604\n",
      "[57]\tvalid_0's multi_logloss: 0.501575\n",
      "[58]\tvalid_0's multi_logloss: 0.498725\n",
      "[59]\tvalid_0's multi_logloss: 0.497283\n",
      "[60]\tvalid_0's multi_logloss: 0.496574\n",
      "[61]\tvalid_0's multi_logloss: 0.496167\n",
      "[62]\tvalid_0's multi_logloss: 0.495137\n",
      "[63]\tvalid_0's multi_logloss: 0.49526\n",
      "[64]\tvalid_0's multi_logloss: 0.494066\n",
      "[65]\tvalid_0's multi_logloss: 0.494496\n",
      "[66]\tvalid_0's multi_logloss: 0.494194\n",
      "[67]\tvalid_0's multi_logloss: 0.494886\n",
      "[68]\tvalid_0's multi_logloss: 0.49476\n",
      "[69]\tvalid_0's multi_logloss: 0.491246\n",
      "[70]\tvalid_0's multi_logloss: 0.495786\n",
      "[71]\tvalid_0's multi_logloss: 0.492377\n",
      "[72]\tvalid_0's multi_logloss: 0.492227\n",
      "[73]\tvalid_0's multi_logloss: 0.491453\n",
      "[74]\tvalid_0's multi_logloss: 0.490661\n",
      "[75]\tvalid_0's multi_logloss: 0.49476\n",
      "[76]\tvalid_0's multi_logloss: 0.491151\n",
      "[77]\tvalid_0's multi_logloss: 0.492552\n",
      "[78]\tvalid_0's multi_logloss: 0.489523\n",
      "[79]\tvalid_0's multi_logloss: 0.492221\n",
      "[80]\tvalid_0's multi_logloss: 0.491533\n",
      "[81]\tvalid_0's multi_logloss: 0.489707\n",
      "[82]\tvalid_0's multi_logloss: 0.487605\n",
      "[83]\tvalid_0's multi_logloss: 0.490456\n",
      "[84]\tvalid_0's multi_logloss: 0.487934\n",
      "[85]\tvalid_0's multi_logloss: 0.487192\n",
      "[86]\tvalid_0's multi_logloss: 0.49522\n",
      "[87]\tvalid_0's multi_logloss: 0.48881\n",
      "[88]\tvalid_0's multi_logloss: 0.490679\n",
      "[89]\tvalid_0's multi_logloss: 0.4868\n",
      "[90]\tvalid_0's multi_logloss: 0.485987\n",
      "[91]\tvalid_0's multi_logloss: 0.492627\n",
      "[92]\tvalid_0's multi_logloss: 0.48651\n",
      "[93]\tvalid_0's multi_logloss: 0.486156\n",
      "[94]\tvalid_0's multi_logloss: 0.488377\n",
      "[95]\tvalid_0's multi_logloss: 0.49129\n",
      "[96]\tvalid_0's multi_logloss: 0.488156\n",
      "[97]\tvalid_0's multi_logloss: 0.489211\n",
      "[98]\tvalid_0's multi_logloss: 0.49311\n",
      "[99]\tvalid_0's multi_logloss: 0.485779\n",
      "[100]\tvalid_0's multi_logloss: 0.49476\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001574 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 820733, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -2.163833\n",
      "[LightGBM] [Info] Start training from score -1.796397\n",
      "[LightGBM] [Info] Start training from score -1.843741\n",
      "[LightGBM] [Info] Start training from score -1.989576\n",
      "[LightGBM] [Info] Start training from score -1.941218\n",
      "[LightGBM] [Info] Start training from score -1.949016\n",
      "[LightGBM] [Info] Start training from score -1.978333\n",
      "[1]\tvalid_0's multi_logloss: 1.90433\n",
      "[2]\tvalid_0's multi_logloss: 1.87655\n",
      "[3]\tvalid_0's multi_logloss: 1.85384\n",
      "[4]\tvalid_0's multi_logloss: 1.8355\n",
      "[5]\tvalid_0's multi_logloss: 1.82032\n",
      "[6]\tvalid_0's multi_logloss: 1.80766\n",
      "[7]\tvalid_0's multi_logloss: 1.79699\n",
      "[8]\tvalid_0's multi_logloss: 1.78797\n",
      "[9]\tvalid_0's multi_logloss: 1.78035\n",
      "[10]\tvalid_0's multi_logloss: 1.77382\n",
      "[11]\tvalid_0's multi_logloss: 1.76827\n",
      "[12]\tvalid_0's multi_logloss: 1.7635\n",
      "[13]\tvalid_0's multi_logloss: 1.75935\n",
      "[14]\tvalid_0's multi_logloss: 1.7557\n",
      "[15]\tvalid_0's multi_logloss: 1.75241\n",
      "[16]\tvalid_0's multi_logloss: 1.74956\n",
      "[17]\tvalid_0's multi_logloss: 1.7471\n",
      "[18]\tvalid_0's multi_logloss: 1.74492\n",
      "[19]\tvalid_0's multi_logloss: 1.7428\n",
      "[20]\tvalid_0's multi_logloss: 1.74098\n",
      "[21]\tvalid_0's multi_logloss: 1.73932\n",
      "[22]\tvalid_0's multi_logloss: 1.73789\n",
      "[23]\tvalid_0's multi_logloss: 1.73654\n",
      "[24]\tvalid_0's multi_logloss: 1.73534\n",
      "[25]\tvalid_0's multi_logloss: 1.73423\n",
      "[26]\tvalid_0's multi_logloss: 1.73309\n",
      "[27]\tvalid_0's multi_logloss: 1.73207\n",
      "[28]\tvalid_0's multi_logloss: 1.73114\n",
      "[29]\tvalid_0's multi_logloss: 1.73034\n",
      "[30]\tvalid_0's multi_logloss: 1.72947\n",
      "[31]\tvalid_0's multi_logloss: 1.72879\n",
      "[32]\tvalid_0's multi_logloss: 1.72804\n",
      "[33]\tvalid_0's multi_logloss: 1.72733\n",
      "[34]\tvalid_0's multi_logloss: 1.72665\n",
      "[35]\tvalid_0's multi_logloss: 1.72605\n",
      "[36]\tvalid_0's multi_logloss: 1.72545\n",
      "[37]\tvalid_0's multi_logloss: 1.72488\n",
      "[38]\tvalid_0's multi_logloss: 1.7244\n",
      "[39]\tvalid_0's multi_logloss: 1.72393\n",
      "[40]\tvalid_0's multi_logloss: 1.72347\n",
      "[41]\tvalid_0's multi_logloss: 1.72305\n",
      "[42]\tvalid_0's multi_logloss: 1.72267\n",
      "[43]\tvalid_0's multi_logloss: 1.72233\n",
      "[44]\tvalid_0's multi_logloss: 1.72204\n",
      "[45]\tvalid_0's multi_logloss: 1.72174\n",
      "[46]\tvalid_0's multi_logloss: 1.72138\n",
      "[47]\tvalid_0's multi_logloss: 1.72112\n",
      "[48]\tvalid_0's multi_logloss: 1.72085\n",
      "[49]\tvalid_0's multi_logloss: 1.72062\n",
      "[50]\tvalid_0's multi_logloss: 1.72034\n",
      "[51]\tvalid_0's multi_logloss: 1.72005\n",
      "[52]\tvalid_0's multi_logloss: 1.71978\n",
      "[53]\tvalid_0's multi_logloss: 1.71951\n",
      "[54]\tvalid_0's multi_logloss: 1.7193\n",
      "[55]\tvalid_0's multi_logloss: 1.71911\n",
      "[56]\tvalid_0's multi_logloss: 1.71893\n",
      "[57]\tvalid_0's multi_logloss: 1.71882\n",
      "[58]\tvalid_0's multi_logloss: 1.71849\n",
      "[59]\tvalid_0's multi_logloss: 1.71828\n",
      "[60]\tvalid_0's multi_logloss: 1.71812\n",
      "[61]\tvalid_0's multi_logloss: 1.71798\n",
      "[62]\tvalid_0's multi_logloss: 1.7178\n",
      "[63]\tvalid_0's multi_logloss: 1.71762\n",
      "[64]\tvalid_0's multi_logloss: 1.71745\n",
      "[65]\tvalid_0's multi_logloss: 1.71725\n",
      "[66]\tvalid_0's multi_logloss: 1.71712\n",
      "[67]\tvalid_0's multi_logloss: 1.71691\n",
      "[68]\tvalid_0's multi_logloss: 1.71679\n",
      "[69]\tvalid_0's multi_logloss: 1.71667\n",
      "[70]\tvalid_0's multi_logloss: 1.71659\n",
      "[71]\tvalid_0's multi_logloss: 1.71628\n",
      "[72]\tvalid_0's multi_logloss: 1.71617\n",
      "[73]\tvalid_0's multi_logloss: 1.7161\n",
      "[74]\tvalid_0's multi_logloss: 1.71605\n",
      "[75]\tvalid_0's multi_logloss: 1.71594\n",
      "[76]\tvalid_0's multi_logloss: 1.71577\n",
      "[77]\tvalid_0's multi_logloss: 1.71562\n",
      "[78]\tvalid_0's multi_logloss: 1.71551\n",
      "[79]\tvalid_0's multi_logloss: 1.71533\n",
      "[80]\tvalid_0's multi_logloss: 1.71528\n",
      "[81]\tvalid_0's multi_logloss: 1.7152\n",
      "[82]\tvalid_0's multi_logloss: 1.71508\n",
      "[83]\tvalid_0's multi_logloss: 1.71502\n",
      "[84]\tvalid_0's multi_logloss: 1.71492\n",
      "[85]\tvalid_0's multi_logloss: 1.71476\n",
      "[86]\tvalid_0's multi_logloss: 1.71464\n",
      "[87]\tvalid_0's multi_logloss: 1.71453\n",
      "[88]\tvalid_0's multi_logloss: 1.71439\n",
      "[89]\tvalid_0's multi_logloss: 1.71433\n",
      "[90]\tvalid_0's multi_logloss: 1.71418\n",
      "[91]\tvalid_0's multi_logloss: 1.71409\n",
      "[92]\tvalid_0's multi_logloss: 1.71405\n",
      "[93]\tvalid_0's multi_logloss: 1.71393\n",
      "[94]\tvalid_0's multi_logloss: 1.71384\n",
      "[95]\tvalid_0's multi_logloss: 1.71377\n",
      "[96]\tvalid_0's multi_logloss: 1.71368\n",
      "[97]\tvalid_0's multi_logloss: 1.71351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36it [1:12:42, 121.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[98]\tvalid_0's multi_logloss: 1.71343\n",
      "[99]\tvalid_0's multi_logloss: 1.7133\n",
      "[100]\tvalid_0's multi_logloss: 1.71321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datasets\n",
    "import lightgbm\n",
    "import sklearn\n",
    "\n",
    "result_list = []\n",
    "metadata_dict = dict()\n",
    "save_dir = Path('/data/PycharmProjects/cytof_benchmark/results/classifier_data')\n",
    "for row in latent_data.iterrows():\n",
    "    dim,model_name,dataset_name,test_file,train_file,val_file = list(row[1])\n",
    "\n",
    "    if dataset_name not in metadata_dict:\n",
    "        dataset_class = getattr(datasets, dataset_name)\n",
    "        dataset_dir = dataset_dirs[dataset_name]\n",
    "\n",
    "        dataset = dataset_class(data_dir=dataset_dir)\n",
    "        metadata_dict[dataset_name] = dataset.train[1],dataset.val[1],dataset.test[1]\n",
    "\n",
    "    y_train,y_val,y_test = metadata_dict[dataset_name]\n",
    "\n",
    "    for variable in variables[dataset_name]:\n",
    "        gbm = lightgbm.LGBMClassifier()\n",
    "        params = {'objective': 'multiclass','num_class': y_train[variable].nunique()}\n",
    "\n",
    "        X_train = pd.read_csv(train_file,index_col=0)\n",
    "        X_val = pd.read_csv(val_file,index_col=0)\n",
    "        X_test = pd.read_csv(test_file,index_col=0)\n",
    "\n",
    "        lgb_train = lightgbm.Dataset(X_train, y_train[variable].astype('category').cat.codes)\n",
    "        lgb_eval = lightgbm.Dataset(X_val, y_val[variable].astype('category').cat.codes, reference=lgb_train)\n",
    "\n",
    "        classifier = lightgbm.train(params,\n",
    "                                    train_set=lgb_train,\n",
    "                                    valid_sets=lgb_eval)\n",
    "\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "        acc = sklearn.metrics.accuracy_score(y_test[variable].astype('category').cat.codes, y_pred)\n",
    "\n",
    "        result_list.append((dim,model_name,dataset_name,variable,acc))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    " pd.DataFrame(result_list, columns=['dim','model','dataset','variable','test_acc']).to_csv(save_dir / \"lgbm_latent.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016870 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10455\n",
      "[LightGBM] [Info] Number of data points in the train set: 820733, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score -0.683185\n",
      "[LightGBM] [Info] Start training from score -2.382997\n",
      "[LightGBM] [Info] Start training from score -2.734975\n",
      "[LightGBM] [Info] Start training from score -3.826068\n",
      "[LightGBM] [Info] Start training from score -1.583719\n",
      "[LightGBM] [Info] Start training from score -2.199855\n",
      "[1]\tvalid_0's multi_logloss: 1.087\n",
      "[2]\tvalid_0's multi_logloss: 0.93628\n",
      "[3]\tvalid_0's multi_logloss: 0.824137\n",
      "[4]\tvalid_0's multi_logloss: 0.735327\n",
      "[5]\tvalid_0's multi_logloss: 0.664285\n",
      "[6]\tvalid_0's multi_logloss: 0.606386\n",
      "[7]\tvalid_0's multi_logloss: 0.558273\n",
      "[8]\tvalid_0's multi_logloss: 0.518046\n",
      "[9]\tvalid_0's multi_logloss: 0.483504\n",
      "[10]\tvalid_0's multi_logloss: 0.454185\n",
      "[11]\tvalid_0's multi_logloss: 0.429046\n",
      "[12]\tvalid_0's multi_logloss: 0.407627\n",
      "[13]\tvalid_0's multi_logloss: 0.389209\n",
      "[14]\tvalid_0's multi_logloss: 0.373211\n",
      "[15]\tvalid_0's multi_logloss: 0.359282\n",
      "[16]\tvalid_0's multi_logloss: 0.347291\n",
      "[17]\tvalid_0's multi_logloss: 0.336411\n",
      "[18]\tvalid_0's multi_logloss: 0.326945\n",
      "[19]\tvalid_0's multi_logloss: 0.318589\n",
      "[20]\tvalid_0's multi_logloss: 0.31096\n",
      "[21]\tvalid_0's multi_logloss: 0.304176\n",
      "[22]\tvalid_0's multi_logloss: 0.298194\n",
      "[23]\tvalid_0's multi_logloss: 0.292497\n",
      "[24]\tvalid_0's multi_logloss: 0.287522\n",
      "[25]\tvalid_0's multi_logloss: 0.283144\n",
      "[26]\tvalid_0's multi_logloss: 0.279085\n",
      "[27]\tvalid_0's multi_logloss: 0.275455\n",
      "[28]\tvalid_0's multi_logloss: 0.271999\n",
      "[29]\tvalid_0's multi_logloss: 0.268883\n",
      "[30]\tvalid_0's multi_logloss: 0.265945\n",
      "[31]\tvalid_0's multi_logloss: 0.26325\n",
      "[32]\tvalid_0's multi_logloss: 0.26081\n",
      "[33]\tvalid_0's multi_logloss: 0.258591\n",
      "[34]\tvalid_0's multi_logloss: 0.256549\n",
      "[35]\tvalid_0's multi_logloss: 0.254621\n",
      "[36]\tvalid_0's multi_logloss: 0.252714\n",
      "[37]\tvalid_0's multi_logloss: 0.251033\n",
      "[38]\tvalid_0's multi_logloss: 0.24943\n",
      "[39]\tvalid_0's multi_logloss: 0.247954\n",
      "[40]\tvalid_0's multi_logloss: 0.246564\n",
      "[41]\tvalid_0's multi_logloss: 0.245248\n",
      "[42]\tvalid_0's multi_logloss: 0.244045\n",
      "[43]\tvalid_0's multi_logloss: 0.242802\n",
      "[44]\tvalid_0's multi_logloss: 0.241741\n",
      "[45]\tvalid_0's multi_logloss: 0.24062\n",
      "[46]\tvalid_0's multi_logloss: 0.239628\n",
      "[47]\tvalid_0's multi_logloss: 0.238567\n",
      "[48]\tvalid_0's multi_logloss: 0.237734\n",
      "[49]\tvalid_0's multi_logloss: 0.23689\n",
      "[50]\tvalid_0's multi_logloss: 0.236072\n",
      "[51]\tvalid_0's multi_logloss: 0.235266\n",
      "[52]\tvalid_0's multi_logloss: 0.234553\n",
      "[53]\tvalid_0's multi_logloss: 0.233864\n",
      "[54]\tvalid_0's multi_logloss: 0.233158\n",
      "[55]\tvalid_0's multi_logloss: 0.232509\n",
      "[56]\tvalid_0's multi_logloss: 0.232006\n",
      "[57]\tvalid_0's multi_logloss: 0.231406\n",
      "[58]\tvalid_0's multi_logloss: 0.232597\n",
      "[59]\tvalid_0's multi_logloss: 0.231186\n",
      "[60]\tvalid_0's multi_logloss: 0.230754\n",
      "[61]\tvalid_0's multi_logloss: 0.230206\n",
      "[62]\tvalid_0's multi_logloss: 0.229755\n",
      "[63]\tvalid_0's multi_logloss: 0.229148\n",
      "[64]\tvalid_0's multi_logloss: 0.229012\n",
      "[65]\tvalid_0's multi_logloss: 0.228475\n",
      "[66]\tvalid_0's multi_logloss: 0.22798\n",
      "[67]\tvalid_0's multi_logloss: 0.227631\n",
      "[68]\tvalid_0's multi_logloss: 0.227203\n",
      "[69]\tvalid_0's multi_logloss: 0.228151\n",
      "[70]\tvalid_0's multi_logloss: 0.226575\n",
      "[71]\tvalid_0's multi_logloss: 0.227786\n",
      "[72]\tvalid_0's multi_logloss: 0.225872\n",
      "[73]\tvalid_0's multi_logloss: 0.225489\n",
      "[74]\tvalid_0's multi_logloss: 0.225181\n",
      "[75]\tvalid_0's multi_logloss: 0.2249\n",
      "[76]\tvalid_0's multi_logloss: 0.224543\n",
      "[77]\tvalid_0's multi_logloss: 0.224592\n",
      "[78]\tvalid_0's multi_logloss: 0.223782\n",
      "[79]\tvalid_0's multi_logloss: 0.223485\n",
      "[80]\tvalid_0's multi_logloss: 0.225943\n",
      "[81]\tvalid_0's multi_logloss: 0.223293\n",
      "[82]\tvalid_0's multi_logloss: 0.222917\n",
      "[83]\tvalid_0's multi_logloss: 0.223854\n",
      "[84]\tvalid_0's multi_logloss: 0.222448\n",
      "[85]\tvalid_0's multi_logloss: 0.222258\n",
      "[86]\tvalid_0's multi_logloss: 0.222082\n",
      "[87]\tvalid_0's multi_logloss: 0.222029\n",
      "[88]\tvalid_0's multi_logloss: 0.222994\n",
      "[89]\tvalid_0's multi_logloss: 0.226109\n",
      "[90]\tvalid_0's multi_logloss: 0.221436\n",
      "[91]\tvalid_0's multi_logloss: 0.222632\n",
      "[92]\tvalid_0's multi_logloss: 0.220813\n",
      "[93]\tvalid_0's multi_logloss: 0.220797\n",
      "[94]\tvalid_0's multi_logloss: 0.220406\n",
      "[95]\tvalid_0's multi_logloss: 0.220145\n",
      "[96]\tvalid_0's multi_logloss: 0.219967\n",
      "[97]\tvalid_0's multi_logloss: 0.22056\n",
      "[98]\tvalid_0's multi_logloss: 0.219602\n",
      "[99]\tvalid_0's multi_logloss: 0.222021\n",
      "[100]\tvalid_0's multi_logloss: 0.219352\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016677 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10455\n",
      "[LightGBM] [Info] Number of data points in the train set: 820733, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score -2.163833\n",
      "[LightGBM] [Info] Start training from score -1.796397\n",
      "[LightGBM] [Info] Start training from score -1.843741\n",
      "[LightGBM] [Info] Start training from score -1.989576\n",
      "[LightGBM] [Info] Start training from score -1.941218\n",
      "[LightGBM] [Info] Start training from score -1.949016\n",
      "[LightGBM] [Info] Start training from score -1.978333\n",
      "[1]\tvalid_0's multi_logloss: 1.88299\n",
      "[2]\tvalid_0's multi_logloss: 1.83833\n",
      "[3]\tvalid_0's multi_logloss: 1.80241\n",
      "[4]\tvalid_0's multi_logloss: 1.77235\n",
      "[5]\tvalid_0's multi_logloss: 1.74731\n",
      "[6]\tvalid_0's multi_logloss: 1.72597\n",
      "[7]\tvalid_0's multi_logloss: 1.70749\n",
      "[8]\tvalid_0's multi_logloss: 1.69108\n",
      "[9]\tvalid_0's multi_logloss: 1.67666\n",
      "[10]\tvalid_0's multi_logloss: 1.66386\n",
      "[11]\tvalid_0's multi_logloss: 1.65254\n",
      "[12]\tvalid_0's multi_logloss: 1.64231\n",
      "[13]\tvalid_0's multi_logloss: 1.63288\n",
      "[14]\tvalid_0's multi_logloss: 1.6243\n",
      "[15]\tvalid_0's multi_logloss: 1.61652\n",
      "[16]\tvalid_0's multi_logloss: 1.60912\n",
      "[17]\tvalid_0's multi_logloss: 1.60228\n",
      "[18]\tvalid_0's multi_logloss: 1.59599\n",
      "[19]\tvalid_0's multi_logloss: 1.59006\n",
      "[20]\tvalid_0's multi_logloss: 1.5845\n",
      "[21]\tvalid_0's multi_logloss: 1.5796\n",
      "[22]\tvalid_0's multi_logloss: 1.57462\n",
      "[23]\tvalid_0's multi_logloss: 1.57\n",
      "[24]\tvalid_0's multi_logloss: 1.56561\n",
      "[25]\tvalid_0's multi_logloss: 1.56151\n",
      "[26]\tvalid_0's multi_logloss: 1.55742\n",
      "[27]\tvalid_0's multi_logloss: 1.55367\n",
      "[28]\tvalid_0's multi_logloss: 1.54993\n",
      "[29]\tvalid_0's multi_logloss: 1.54656\n",
      "[30]\tvalid_0's multi_logloss: 1.54306\n",
      "[31]\tvalid_0's multi_logloss: 1.53986\n",
      "[32]\tvalid_0's multi_logloss: 1.53668\n",
      "[33]\tvalid_0's multi_logloss: 1.53361\n",
      "[34]\tvalid_0's multi_logloss: 1.53063\n",
      "[35]\tvalid_0's multi_logloss: 1.52805\n",
      "[36]\tvalid_0's multi_logloss: 1.52525\n",
      "[37]\tvalid_0's multi_logloss: 1.52273\n",
      "[38]\tvalid_0's multi_logloss: 1.52017\n",
      "[39]\tvalid_0's multi_logloss: 1.51774\n",
      "[40]\tvalid_0's multi_logloss: 1.51534\n",
      "[41]\tvalid_0's multi_logloss: 1.51301\n",
      "[42]\tvalid_0's multi_logloss: 1.51065\n",
      "[43]\tvalid_0's multi_logloss: 1.50845\n",
      "[44]\tvalid_0's multi_logloss: 1.50622\n",
      "[45]\tvalid_0's multi_logloss: 1.50411\n",
      "[46]\tvalid_0's multi_logloss: 1.50202\n",
      "[47]\tvalid_0's multi_logloss: 1.49998\n",
      "[48]\tvalid_0's multi_logloss: 1.49781\n",
      "[49]\tvalid_0's multi_logloss: 1.49592\n",
      "[50]\tvalid_0's multi_logloss: 1.49406\n",
      "[51]\tvalid_0's multi_logloss: 1.49233\n",
      "[52]\tvalid_0's multi_logloss: 1.49064\n",
      "[53]\tvalid_0's multi_logloss: 1.48877\n",
      "[54]\tvalid_0's multi_logloss: 1.48702\n",
      "[55]\tvalid_0's multi_logloss: 1.48534\n",
      "[56]\tvalid_0's multi_logloss: 1.48358\n",
      "[57]\tvalid_0's multi_logloss: 1.48202\n",
      "[58]\tvalid_0's multi_logloss: 1.48044\n",
      "[59]\tvalid_0's multi_logloss: 1.47885\n",
      "[60]\tvalid_0's multi_logloss: 1.47727\n",
      "[61]\tvalid_0's multi_logloss: 1.47574\n",
      "[62]\tvalid_0's multi_logloss: 1.47427\n",
      "[63]\tvalid_0's multi_logloss: 1.47272\n",
      "[64]\tvalid_0's multi_logloss: 1.47123\n",
      "[65]\tvalid_0's multi_logloss: 1.4699\n",
      "[66]\tvalid_0's multi_logloss: 1.46855\n",
      "[67]\tvalid_0's multi_logloss: 1.46727\n",
      "[68]\tvalid_0's multi_logloss: 1.46589\n",
      "[69]\tvalid_0's multi_logloss: 1.46448\n",
      "[70]\tvalid_0's multi_logloss: 1.46312\n",
      "[71]\tvalid_0's multi_logloss: 1.46185\n",
      "[72]\tvalid_0's multi_logloss: 1.4606\n",
      "[73]\tvalid_0's multi_logloss: 1.45942\n",
      "[74]\tvalid_0's multi_logloss: 1.45816\n",
      "[75]\tvalid_0's multi_logloss: 1.45692\n",
      "[76]\tvalid_0's multi_logloss: 1.45562\n",
      "[77]\tvalid_0's multi_logloss: 1.45452\n",
      "[78]\tvalid_0's multi_logloss: 1.45334\n",
      "[79]\tvalid_0's multi_logloss: 1.45225\n",
      "[80]\tvalid_0's multi_logloss: 1.45114\n",
      "[81]\tvalid_0's multi_logloss: 1.45003\n",
      "[82]\tvalid_0's multi_logloss: 1.44892\n",
      "[83]\tvalid_0's multi_logloss: 1.44774\n",
      "[84]\tvalid_0's multi_logloss: 1.44665\n",
      "[85]\tvalid_0's multi_logloss: 1.44564\n",
      "[86]\tvalid_0's multi_logloss: 1.44458\n",
      "[87]\tvalid_0's multi_logloss: 1.44349\n",
      "[88]\tvalid_0's multi_logloss: 1.4425\n",
      "[89]\tvalid_0's multi_logloss: 1.44152\n",
      "[90]\tvalid_0's multi_logloss: 1.44055\n",
      "[91]\tvalid_0's multi_logloss: 1.43964\n",
      "[92]\tvalid_0's multi_logloss: 1.43873\n",
      "[93]\tvalid_0's multi_logloss: 1.43777\n",
      "[94]\tvalid_0's multi_logloss: 1.4368\n",
      "[95]\tvalid_0's multi_logloss: 1.43583\n",
      "[96]\tvalid_0's multi_logloss: 1.43488\n",
      "[97]\tvalid_0's multi_logloss: 1.43398\n",
      "[98]\tvalid_0's multi_logloss: 1.4331\n",
      "[99]\tvalid_0's multi_logloss: 1.43219\n",
      "[100]\tvalid_0's multi_logloss: 1.43128\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000997 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 820733, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -0.683185\n",
      "[LightGBM] [Info] Start training from score -2.382997\n",
      "[LightGBM] [Info] Start training from score -2.734975\n",
      "[LightGBM] [Info] Start training from score -3.826068\n",
      "[LightGBM] [Info] Start training from score -1.583719\n",
      "[LightGBM] [Info] Start training from score -2.199855\n",
      "[1]\tvalid_0's multi_logloss: 1.25384\n",
      "[2]\tvalid_0's multi_logloss: 1.1605\n",
      "[3]\tvalid_0's multi_logloss: 1.08954\n",
      "[4]\tvalid_0's multi_logloss: 1.03356\n",
      "[5]\tvalid_0's multi_logloss: 0.988557\n",
      "[6]\tvalid_0's multi_logloss: 0.951672\n",
      "[7]\tvalid_0's multi_logloss: 0.921101\n",
      "[8]\tvalid_0's multi_logloss: 0.895634\n",
      "[9]\tvalid_0's multi_logloss: 0.874189\n",
      "[10]\tvalid_0's multi_logloss: 0.856026\n",
      "[11]\tvalid_0's multi_logloss: 0.840472\n",
      "[12]\tvalid_0's multi_logloss: 0.827084\n",
      "[13]\tvalid_0's multi_logloss: 0.815503\n",
      "[14]\tvalid_0's multi_logloss: 0.805515\n",
      "[15]\tvalid_0's multi_logloss: 0.796763\n",
      "[16]\tvalid_0's multi_logloss: 0.789115\n",
      "[17]\tvalid_0's multi_logloss: 0.782408\n",
      "[18]\tvalid_0's multi_logloss: 0.776449\n",
      "[19]\tvalid_0's multi_logloss: 0.771166\n",
      "[20]\tvalid_0's multi_logloss: 0.76647\n",
      "[21]\tvalid_0's multi_logloss: 0.762274\n",
      "[22]\tvalid_0's multi_logloss: 0.758535\n",
      "[23]\tvalid_0's multi_logloss: 0.755195\n",
      "[24]\tvalid_0's multi_logloss: 0.75215\n",
      "[25]\tvalid_0's multi_logloss: 0.749428\n",
      "[26]\tvalid_0's multi_logloss: 0.746964\n",
      "[27]\tvalid_0's multi_logloss: 0.744739\n",
      "[28]\tvalid_0's multi_logloss: 0.742742\n",
      "[29]\tvalid_0's multi_logloss: 0.740912\n",
      "[30]\tvalid_0's multi_logloss: 0.73926\n",
      "[31]\tvalid_0's multi_logloss: 0.737766\n",
      "[32]\tvalid_0's multi_logloss: 0.736396\n",
      "[33]\tvalid_0's multi_logloss: 0.735127\n",
      "[34]\tvalid_0's multi_logloss: 0.733964\n",
      "[35]\tvalid_0's multi_logloss: 0.732895\n",
      "[36]\tvalid_0's multi_logloss: 0.731927\n",
      "[37]\tvalid_0's multi_logloss: 0.731045\n",
      "[38]\tvalid_0's multi_logloss: 0.730227\n",
      "[39]\tvalid_0's multi_logloss: 0.729494\n",
      "[40]\tvalid_0's multi_logloss: 0.72878\n",
      "[41]\tvalid_0's multi_logloss: 0.728144\n",
      "[42]\tvalid_0's multi_logloss: 0.727561\n",
      "[43]\tvalid_0's multi_logloss: 0.727024\n",
      "[44]\tvalid_0's multi_logloss: 0.726547\n",
      "[45]\tvalid_0's multi_logloss: 0.726116\n",
      "[46]\tvalid_0's multi_logloss: 0.725712\n",
      "[47]\tvalid_0's multi_logloss: 0.725343\n",
      "[48]\tvalid_0's multi_logloss: 0.725018\n",
      "[49]\tvalid_0's multi_logloss: 0.724695\n",
      "[50]\tvalid_0's multi_logloss: 0.724379\n",
      "[51]\tvalid_0's multi_logloss: 0.724097\n",
      "[52]\tvalid_0's multi_logloss: 0.723813\n",
      "[53]\tvalid_0's multi_logloss: 0.723557\n",
      "[54]\tvalid_0's multi_logloss: 0.723316\n",
      "[55]\tvalid_0's multi_logloss: 0.723099\n",
      "[56]\tvalid_0's multi_logloss: 0.722882\n",
      "[57]\tvalid_0's multi_logloss: 0.722699\n",
      "[58]\tvalid_0's multi_logloss: 0.722504\n",
      "[59]\tvalid_0's multi_logloss: 0.722321\n",
      "[60]\tvalid_0's multi_logloss: 0.722164\n",
      "[61]\tvalid_0's multi_logloss: 0.722009\n",
      "[62]\tvalid_0's multi_logloss: 0.721851\n",
      "[63]\tvalid_0's multi_logloss: 0.721778\n",
      "[64]\tvalid_0's multi_logloss: 0.721599\n",
      "[65]\tvalid_0's multi_logloss: 0.721463\n",
      "[66]\tvalid_0's multi_logloss: 0.721709\n",
      "[67]\tvalid_0's multi_logloss: 0.721283\n",
      "[68]\tvalid_0's multi_logloss: 0.721354\n",
      "[69]\tvalid_0's multi_logloss: 0.72112\n",
      "[70]\tvalid_0's multi_logloss: 0.720999\n",
      "[71]\tvalid_0's multi_logloss: 0.720908\n",
      "[72]\tvalid_0's multi_logloss: 0.720958\n",
      "[73]\tvalid_0's multi_logloss: 0.720672\n",
      "[74]\tvalid_0's multi_logloss: 0.720587\n",
      "[75]\tvalid_0's multi_logloss: 0.720729\n",
      "[76]\tvalid_0's multi_logloss: 0.720756\n",
      "[77]\tvalid_0's multi_logloss: 0.720338\n",
      "[78]\tvalid_0's multi_logloss: 0.721191\n",
      "[79]\tvalid_0's multi_logloss: 0.72177\n",
      "[80]\tvalid_0's multi_logloss: 0.721763\n",
      "[81]\tvalid_0's multi_logloss: 0.720666\n",
      "[82]\tvalid_0's multi_logloss: 0.72053\n",
      "[83]\tvalid_0's multi_logloss: 0.720041\n",
      "[84]\tvalid_0's multi_logloss: 0.720508\n",
      "[85]\tvalid_0's multi_logloss: 0.722709\n",
      "[86]\tvalid_0's multi_logloss: 0.723543\n",
      "[87]\tvalid_0's multi_logloss: 0.722331\n",
      "[88]\tvalid_0's multi_logloss: 0.720407\n",
      "[89]\tvalid_0's multi_logloss: 0.722133\n",
      "[90]\tvalid_0's multi_logloss: 0.723879\n",
      "[91]\tvalid_0's multi_logloss: 0.72287\n",
      "[92]\tvalid_0's multi_logloss: 0.724057\n",
      "[93]\tvalid_0's multi_logloss: 0.723265\n",
      "[94]\tvalid_0's multi_logloss: 0.722869\n",
      "[95]\tvalid_0's multi_logloss: 0.719368\n",
      "[96]\tvalid_0's multi_logloss: 0.719653\n",
      "[97]\tvalid_0's multi_logloss: 0.72157\n",
      "[98]\tvalid_0's multi_logloss: 0.728196\n",
      "[99]\tvalid_0's multi_logloss: 0.726275\n",
      "[100]\tvalid_0's multi_logloss: 0.719217\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001052 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 820733, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -2.163833\n",
      "[LightGBM] [Info] Start training from score -1.796397\n",
      "[LightGBM] [Info] Start training from score -1.843741\n",
      "[LightGBM] [Info] Start training from score -1.989576\n",
      "[LightGBM] [Info] Start training from score -1.941218\n",
      "[LightGBM] [Info] Start training from score -1.949016\n",
      "[LightGBM] [Info] Start training from score -1.978333\n",
      "[1]\tvalid_0's multi_logloss: 1.90263\n",
      "[2]\tvalid_0's multi_logloss: 1.87347\n",
      "[3]\tvalid_0's multi_logloss: 1.85029\n",
      "[4]\tvalid_0's multi_logloss: 1.83166\n",
      "[5]\tvalid_0's multi_logloss: 1.8164\n",
      "[6]\tvalid_0's multi_logloss: 1.80391\n",
      "[7]\tvalid_0's multi_logloss: 1.79357\n",
      "[8]\tvalid_0's multi_logloss: 1.78499\n",
      "[9]\tvalid_0's multi_logloss: 1.77786\n",
      "[10]\tvalid_0's multi_logloss: 1.77189\n",
      "[11]\tvalid_0's multi_logloss: 1.76688\n",
      "[12]\tvalid_0's multi_logloss: 1.76261\n",
      "[13]\tvalid_0's multi_logloss: 1.75901\n",
      "[14]\tvalid_0's multi_logloss: 1.75598\n",
      "[15]\tvalid_0's multi_logloss: 1.75339\n",
      "[16]\tvalid_0's multi_logloss: 1.75119\n",
      "[17]\tvalid_0's multi_logloss: 1.74932\n",
      "[18]\tvalid_0's multi_logloss: 1.74772\n",
      "[19]\tvalid_0's multi_logloss: 1.74635\n",
      "[20]\tvalid_0's multi_logloss: 1.74517\n",
      "[21]\tvalid_0's multi_logloss: 1.74414\n",
      "[22]\tvalid_0's multi_logloss: 1.74325\n",
      "[23]\tvalid_0's multi_logloss: 1.74247\n",
      "[24]\tvalid_0's multi_logloss: 1.74181\n",
      "[25]\tvalid_0's multi_logloss: 1.74123\n",
      "[26]\tvalid_0's multi_logloss: 1.74072\n",
      "[27]\tvalid_0's multi_logloss: 1.74027\n",
      "[28]\tvalid_0's multi_logloss: 1.73987\n",
      "[29]\tvalid_0's multi_logloss: 1.73952\n",
      "[30]\tvalid_0's multi_logloss: 1.7392\n",
      "[31]\tvalid_0's multi_logloss: 1.73893\n",
      "[32]\tvalid_0's multi_logloss: 1.73866\n",
      "[33]\tvalid_0's multi_logloss: 1.73843\n",
      "[34]\tvalid_0's multi_logloss: 1.73822\n",
      "[35]\tvalid_0's multi_logloss: 1.73802\n",
      "[36]\tvalid_0's multi_logloss: 1.73783\n",
      "[37]\tvalid_0's multi_logloss: 1.73766\n",
      "[38]\tvalid_0's multi_logloss: 1.73751\n",
      "[39]\tvalid_0's multi_logloss: 1.73736\n",
      "[40]\tvalid_0's multi_logloss: 1.73722\n",
      "[41]\tvalid_0's multi_logloss: 1.73709\n",
      "[42]\tvalid_0's multi_logloss: 1.73697\n",
      "[43]\tvalid_0's multi_logloss: 1.73684\n",
      "[44]\tvalid_0's multi_logloss: 1.73672\n",
      "[45]\tvalid_0's multi_logloss: 1.73661\n",
      "[46]\tvalid_0's multi_logloss: 1.7365\n",
      "[47]\tvalid_0's multi_logloss: 1.7364\n",
      "[48]\tvalid_0's multi_logloss: 1.7363\n",
      "[49]\tvalid_0's multi_logloss: 1.73621\n",
      "[50]\tvalid_0's multi_logloss: 1.73612\n",
      "[51]\tvalid_0's multi_logloss: 1.73603\n",
      "[52]\tvalid_0's multi_logloss: 1.73594\n",
      "[53]\tvalid_0's multi_logloss: 1.73584\n",
      "[54]\tvalid_0's multi_logloss: 1.73576\n",
      "[55]\tvalid_0's multi_logloss: 1.73567\n",
      "[56]\tvalid_0's multi_logloss: 1.7356\n",
      "[57]\tvalid_0's multi_logloss: 1.73552\n",
      "[58]\tvalid_0's multi_logloss: 1.73544\n",
      "[59]\tvalid_0's multi_logloss: 1.73535\n",
      "[60]\tvalid_0's multi_logloss: 1.73525\n",
      "[61]\tvalid_0's multi_logloss: 1.73518\n",
      "[62]\tvalid_0's multi_logloss: 1.73511\n",
      "[63]\tvalid_0's multi_logloss: 1.73503\n",
      "[64]\tvalid_0's multi_logloss: 1.73497\n",
      "[65]\tvalid_0's multi_logloss: 1.7349\n",
      "[66]\tvalid_0's multi_logloss: 1.73483\n",
      "[67]\tvalid_0's multi_logloss: 1.73476\n",
      "[68]\tvalid_0's multi_logloss: 1.73468\n",
      "[69]\tvalid_0's multi_logloss: 1.73463\n",
      "[70]\tvalid_0's multi_logloss: 1.73457\n",
      "[71]\tvalid_0's multi_logloss: 1.73449\n",
      "[72]\tvalid_0's multi_logloss: 1.73444\n",
      "[73]\tvalid_0's multi_logloss: 1.73438\n",
      "[74]\tvalid_0's multi_logloss: 1.73432\n",
      "[75]\tvalid_0's multi_logloss: 1.73425\n",
      "[76]\tvalid_0's multi_logloss: 1.7342\n",
      "[77]\tvalid_0's multi_logloss: 1.73414\n",
      "[78]\tvalid_0's multi_logloss: 1.7341\n",
      "[79]\tvalid_0's multi_logloss: 1.73403\n",
      "[80]\tvalid_0's multi_logloss: 1.73396\n",
      "[81]\tvalid_0's multi_logloss: 1.7339\n",
      "[82]\tvalid_0's multi_logloss: 1.73385\n",
      "[83]\tvalid_0's multi_logloss: 1.73379\n",
      "[84]\tvalid_0's multi_logloss: 1.73372\n",
      "[85]\tvalid_0's multi_logloss: 1.73365\n",
      "[86]\tvalid_0's multi_logloss: 1.73359\n",
      "[87]\tvalid_0's multi_logloss: 1.73353\n",
      "[88]\tvalid_0's multi_logloss: 1.73347\n",
      "[89]\tvalid_0's multi_logloss: 1.7334\n",
      "[90]\tvalid_0's multi_logloss: 1.73335\n",
      "[91]\tvalid_0's multi_logloss: 1.73328\n",
      "[92]\tvalid_0's multi_logloss: 1.73321\n",
      "[93]\tvalid_0's multi_logloss: 1.73315\n",
      "[94]\tvalid_0's multi_logloss: 1.73309\n",
      "[95]\tvalid_0's multi_logloss: 1.73304\n",
      "[96]\tvalid_0's multi_logloss: 1.73298\n",
      "[97]\tvalid_0's multi_logloss: 1.73292\n",
      "[98]\tvalid_0's multi_logloss: 1.73287\n",
      "[99]\tvalid_0's multi_logloss: 1.73281\n",
      "[100]\tvalid_0's multi_logloss: 1.73276\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001041 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 820733, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -0.683185\n",
      "[LightGBM] [Info] Start training from score -2.382997\n",
      "[LightGBM] [Info] Start training from score -2.734975\n",
      "[LightGBM] [Info] Start training from score -3.826068\n",
      "[LightGBM] [Info] Start training from score -1.583719\n",
      "[LightGBM] [Info] Start training from score -2.199855\n",
      "[1]\tvalid_0's multi_logloss: 1.24305\n",
      "[2]\tvalid_0's multi_logloss: 1.14409\n",
      "[3]\tvalid_0's multi_logloss: 1.06838\n",
      "[4]\tvalid_0's multi_logloss: 1.00857\n",
      "[5]\tvalid_0's multi_logloss: 0.960197\n",
      "[6]\tvalid_0's multi_logloss: 0.920247\n",
      "[7]\tvalid_0's multi_logloss: 0.887164\n",
      "[8]\tvalid_0's multi_logloss: 0.859455\n",
      "[9]\tvalid_0's multi_logloss: 0.835897\n",
      "[10]\tvalid_0's multi_logloss: 0.815648\n",
      "[11]\tvalid_0's multi_logloss: 0.798484\n",
      "[12]\tvalid_0's multi_logloss: 0.783607\n",
      "[13]\tvalid_0's multi_logloss: 0.770656\n",
      "[14]\tvalid_0's multi_logloss: 0.759439\n",
      "[15]\tvalid_0's multi_logloss: 0.749538\n",
      "[16]\tvalid_0's multi_logloss: 0.740827\n",
      "[17]\tvalid_0's multi_logloss: 0.733067\n",
      "[18]\tvalid_0's multi_logloss: 0.726222\n",
      "[19]\tvalid_0's multi_logloss: 0.720164\n",
      "[20]\tvalid_0's multi_logloss: 0.714631\n",
      "[21]\tvalid_0's multi_logloss: 0.709688\n",
      "[22]\tvalid_0's multi_logloss: 0.705293\n",
      "[23]\tvalid_0's multi_logloss: 0.70127\n",
      "[24]\tvalid_0's multi_logloss: 0.697687\n",
      "[25]\tvalid_0's multi_logloss: 0.694419\n",
      "[26]\tvalid_0's multi_logloss: 0.691437\n",
      "[27]\tvalid_0's multi_logloss: 0.688727\n",
      "[28]\tvalid_0's multi_logloss: 0.686265\n",
      "[29]\tvalid_0's multi_logloss: 0.683998\n",
      "[30]\tvalid_0's multi_logloss: 0.681928\n",
      "[31]\tvalid_0's multi_logloss: 0.680046\n",
      "[32]\tvalid_0's multi_logloss: 0.678351\n",
      "[33]\tvalid_0's multi_logloss: 0.676815\n",
      "[34]\tvalid_0's multi_logloss: 0.675378\n",
      "[35]\tvalid_0's multi_logloss: 0.674064\n",
      "[36]\tvalid_0's multi_logloss: 0.67278\n",
      "[37]\tvalid_0's multi_logloss: 0.671622\n",
      "[38]\tvalid_0's multi_logloss: 0.670547\n",
      "[39]\tvalid_0's multi_logloss: 0.66954\n",
      "[40]\tvalid_0's multi_logloss: 0.66858\n",
      "[41]\tvalid_0's multi_logloss: 0.667726\n",
      "[42]\tvalid_0's multi_logloss: 0.666901\n",
      "[43]\tvalid_0's multi_logloss: 0.666214\n",
      "[44]\tvalid_0's multi_logloss: 0.665505\n",
      "[45]\tvalid_0's multi_logloss: 0.664879\n",
      "[46]\tvalid_0's multi_logloss: 0.664279\n",
      "[47]\tvalid_0's multi_logloss: 0.663747\n",
      "[48]\tvalid_0's multi_logloss: 0.663245\n",
      "[49]\tvalid_0's multi_logloss: 0.662733\n",
      "[50]\tvalid_0's multi_logloss: 0.662288\n",
      "[51]\tvalid_0's multi_logloss: 0.661864\n",
      "[52]\tvalid_0's multi_logloss: 0.661437\n",
      "[53]\tvalid_0's multi_logloss: 0.661062\n",
      "[54]\tvalid_0's multi_logloss: 0.66073\n",
      "[55]\tvalid_0's multi_logloss: 0.660481\n",
      "[56]\tvalid_0's multi_logloss: 0.660128\n",
      "[57]\tvalid_0's multi_logloss: 0.659825\n",
      "[58]\tvalid_0's multi_logloss: 0.659631\n",
      "[59]\tvalid_0's multi_logloss: 0.659326\n",
      "[60]\tvalid_0's multi_logloss: 0.659055\n",
      "[61]\tvalid_0's multi_logloss: 0.658834\n",
      "[62]\tvalid_0's multi_logloss: 0.658609\n",
      "[63]\tvalid_0's multi_logloss: 0.658387\n",
      "[64]\tvalid_0's multi_logloss: 0.658174\n",
      "[65]\tvalid_0's multi_logloss: 0.657992\n",
      "[66]\tvalid_0's multi_logloss: 0.657825\n",
      "[67]\tvalid_0's multi_logloss: 0.657592\n",
      "[68]\tvalid_0's multi_logloss: 0.657384\n",
      "[69]\tvalid_0's multi_logloss: 0.657192\n",
      "[70]\tvalid_0's multi_logloss: 0.657032\n",
      "[71]\tvalid_0's multi_logloss: 0.656866\n",
      "[72]\tvalid_0's multi_logloss: 0.656698\n",
      "[73]\tvalid_0's multi_logloss: 0.65652\n",
      "[74]\tvalid_0's multi_logloss: 0.65638\n",
      "[75]\tvalid_0's multi_logloss: 0.656284\n",
      "[76]\tvalid_0's multi_logloss: 0.656113\n",
      "[77]\tvalid_0's multi_logloss: 0.655987\n",
      "[78]\tvalid_0's multi_logloss: 0.655832\n",
      "[79]\tvalid_0's multi_logloss: 0.655691\n",
      "[80]\tvalid_0's multi_logloss: 0.655546\n",
      "[81]\tvalid_0's multi_logloss: 0.655431\n",
      "[82]\tvalid_0's multi_logloss: 0.655258\n",
      "[83]\tvalid_0's multi_logloss: 0.655065\n",
      "[84]\tvalid_0's multi_logloss: 0.656092\n",
      "[85]\tvalid_0's multi_logloss: 0.654872\n",
      "[86]\tvalid_0's multi_logloss: 0.654768\n",
      "[87]\tvalid_0's multi_logloss: 0.654647\n",
      "[88]\tvalid_0's multi_logloss: 0.655251\n",
      "[89]\tvalid_0's multi_logloss: 0.65515\n",
      "[90]\tvalid_0's multi_logloss: 0.656058\n",
      "[91]\tvalid_0's multi_logloss: 0.654835\n",
      "[92]\tvalid_0's multi_logloss: 0.655331\n",
      "[93]\tvalid_0's multi_logloss: 0.654159\n",
      "[94]\tvalid_0's multi_logloss: 0.654073\n",
      "[95]\tvalid_0's multi_logloss: 0.654461\n",
      "[96]\tvalid_0's multi_logloss: 0.656342\n",
      "[97]\tvalid_0's multi_logloss: 0.65521\n",
      "[98]\tvalid_0's multi_logloss: 0.65365\n",
      "[99]\tvalid_0's multi_logloss: 0.653528\n",
      "[100]\tvalid_0's multi_logloss: 0.653443\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001023 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 820733, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -2.163833\n",
      "[LightGBM] [Info] Start training from score -1.796397\n",
      "[LightGBM] [Info] Start training from score -1.843741\n",
      "[LightGBM] [Info] Start training from score -1.989576\n",
      "[LightGBM] [Info] Start training from score -1.941218\n",
      "[LightGBM] [Info] Start training from score -1.949016\n",
      "[LightGBM] [Info] Start training from score -1.978333\n",
      "[1]\tvalid_0's multi_logloss: 1.89914\n",
      "[2]\tvalid_0's multi_logloss: 1.86699\n",
      "[3]\tvalid_0's multi_logloss: 1.84129\n",
      "[4]\tvalid_0's multi_logloss: 1.8204\n",
      "[5]\tvalid_0's multi_logloss: 1.80318\n",
      "[6]\tvalid_0's multi_logloss: 1.78892\n",
      "[7]\tvalid_0's multi_logloss: 1.77697\n",
      "[8]\tvalid_0's multi_logloss: 1.76696\n",
      "[9]\tvalid_0's multi_logloss: 1.75854\n",
      "[10]\tvalid_0's multi_logloss: 1.75124\n",
      "[11]\tvalid_0's multi_logloss: 1.74507\n",
      "[12]\tvalid_0's multi_logloss: 1.73988\n",
      "[13]\tvalid_0's multi_logloss: 1.73529\n",
      "[14]\tvalid_0's multi_logloss: 1.73136\n",
      "[15]\tvalid_0's multi_logloss: 1.72793\n",
      "[16]\tvalid_0's multi_logloss: 1.72496\n",
      "[17]\tvalid_0's multi_logloss: 1.72237\n",
      "[18]\tvalid_0's multi_logloss: 1.72011\n",
      "[19]\tvalid_0's multi_logloss: 1.71812\n",
      "[20]\tvalid_0's multi_logloss: 1.71635\n",
      "[21]\tvalid_0's multi_logloss: 1.71473\n",
      "[22]\tvalid_0's multi_logloss: 1.71335\n",
      "[23]\tvalid_0's multi_logloss: 1.71209\n",
      "[24]\tvalid_0's multi_logloss: 1.71097\n",
      "[25]\tvalid_0's multi_logloss: 1.70994\n",
      "[26]\tvalid_0's multi_logloss: 1.70903\n",
      "[27]\tvalid_0's multi_logloss: 1.70821\n",
      "[28]\tvalid_0's multi_logloss: 1.70748\n",
      "[29]\tvalid_0's multi_logloss: 1.70676\n",
      "[30]\tvalid_0's multi_logloss: 1.7061\n",
      "[31]\tvalid_0's multi_logloss: 1.70552\n",
      "[32]\tvalid_0's multi_logloss: 1.70499\n",
      "[33]\tvalid_0's multi_logloss: 1.7045\n",
      "[34]\tvalid_0's multi_logloss: 1.70404\n",
      "[35]\tvalid_0's multi_logloss: 1.70361\n",
      "[36]\tvalid_0's multi_logloss: 1.70321\n",
      "[37]\tvalid_0's multi_logloss: 1.70283\n",
      "[38]\tvalid_0's multi_logloss: 1.70247\n",
      "[39]\tvalid_0's multi_logloss: 1.70216\n",
      "[40]\tvalid_0's multi_logloss: 1.70185\n",
      "[41]\tvalid_0's multi_logloss: 1.70155\n",
      "[42]\tvalid_0's multi_logloss: 1.70126\n",
      "[43]\tvalid_0's multi_logloss: 1.70101\n",
      "[44]\tvalid_0's multi_logloss: 1.70075\n",
      "[45]\tvalid_0's multi_logloss: 1.70048\n",
      "[46]\tvalid_0's multi_logloss: 1.70025\n",
      "[47]\tvalid_0's multi_logloss: 1.7\n",
      "[48]\tvalid_0's multi_logloss: 1.69979\n",
      "[49]\tvalid_0's multi_logloss: 1.69958\n",
      "[50]\tvalid_0's multi_logloss: 1.69936\n",
      "[51]\tvalid_0's multi_logloss: 1.69918\n",
      "[52]\tvalid_0's multi_logloss: 1.69899\n",
      "[53]\tvalid_0's multi_logloss: 1.69881\n",
      "[54]\tvalid_0's multi_logloss: 1.69864\n",
      "[55]\tvalid_0's multi_logloss: 1.69847\n",
      "[56]\tvalid_0's multi_logloss: 1.6983\n",
      "[57]\tvalid_0's multi_logloss: 1.69814\n",
      "[58]\tvalid_0's multi_logloss: 1.69799\n",
      "[59]\tvalid_0's multi_logloss: 1.69785\n",
      "[60]\tvalid_0's multi_logloss: 1.69771\n",
      "[61]\tvalid_0's multi_logloss: 1.69759\n",
      "[62]\tvalid_0's multi_logloss: 1.69746\n",
      "[63]\tvalid_0's multi_logloss: 1.69733\n",
      "[64]\tvalid_0's multi_logloss: 1.69717\n",
      "[65]\tvalid_0's multi_logloss: 1.69703\n",
      "[66]\tvalid_0's multi_logloss: 1.6969\n",
      "[67]\tvalid_0's multi_logloss: 1.69675\n",
      "[68]\tvalid_0's multi_logloss: 1.69659\n",
      "[69]\tvalid_0's multi_logloss: 1.69647\n",
      "[70]\tvalid_0's multi_logloss: 1.69636\n",
      "[71]\tvalid_0's multi_logloss: 1.69623\n",
      "[72]\tvalid_0's multi_logloss: 1.69609\n",
      "[73]\tvalid_0's multi_logloss: 1.69595\n",
      "[74]\tvalid_0's multi_logloss: 1.69585\n",
      "[75]\tvalid_0's multi_logloss: 1.69574\n",
      "[76]\tvalid_0's multi_logloss: 1.69562\n",
      "[77]\tvalid_0's multi_logloss: 1.69551\n",
      "[78]\tvalid_0's multi_logloss: 1.69538\n",
      "[79]\tvalid_0's multi_logloss: 1.69527\n",
      "[80]\tvalid_0's multi_logloss: 1.69517\n",
      "[81]\tvalid_0's multi_logloss: 1.69504\n",
      "[82]\tvalid_0's multi_logloss: 1.69494\n",
      "[83]\tvalid_0's multi_logloss: 1.69483\n",
      "[84]\tvalid_0's multi_logloss: 1.69471\n",
      "[85]\tvalid_0's multi_logloss: 1.69461\n",
      "[86]\tvalid_0's multi_logloss: 1.6945\n",
      "[87]\tvalid_0's multi_logloss: 1.69439\n",
      "[88]\tvalid_0's multi_logloss: 1.69426\n",
      "[89]\tvalid_0's multi_logloss: 1.69414\n",
      "[90]\tvalid_0's multi_logloss: 1.69404\n",
      "[91]\tvalid_0's multi_logloss: 1.6939\n",
      "[92]\tvalid_0's multi_logloss: 1.69377\n",
      "[93]\tvalid_0's multi_logloss: 1.69366\n",
      "[94]\tvalid_0's multi_logloss: 1.69357\n",
      "[95]\tvalid_0's multi_logloss: 1.69348\n",
      "[96]\tvalid_0's multi_logloss: 1.69337\n",
      "[97]\tvalid_0's multi_logloss: 1.69327\n",
      "[98]\tvalid_0's multi_logloss: 1.69315\n",
      "[99]\tvalid_0's multi_logloss: 1.69302\n",
      "[100]\tvalid_0's multi_logloss: 1.6929\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001634 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 820733, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -0.683185\n",
      "[LightGBM] [Info] Start training from score -2.382997\n",
      "[LightGBM] [Info] Start training from score -2.734975\n",
      "[LightGBM] [Info] Start training from score -3.826068\n",
      "[LightGBM] [Info] Start training from score -1.583719\n",
      "[LightGBM] [Info] Start training from score -2.199855\n",
      "[1]\tvalid_0's multi_logloss: 1.22511\n",
      "[2]\tvalid_0's multi_logloss: 1.12022\n",
      "[3]\tvalid_0's multi_logloss: 1.04063\n",
      "[4]\tvalid_0's multi_logloss: 0.977925\n",
      "[5]\tvalid_0's multi_logloss: 0.927169\n",
      "[6]\tvalid_0's multi_logloss: 0.88569\n",
      "[7]\tvalid_0's multi_logloss: 0.851202\n",
      "[8]\tvalid_0's multi_logloss: 0.822099\n",
      "[9]\tvalid_0's multi_logloss: 0.797425\n",
      "[10]\tvalid_0's multi_logloss: 0.776503\n",
      "[11]\tvalid_0's multi_logloss: 0.758548\n",
      "[12]\tvalid_0's multi_logloss: 0.742817\n",
      "[13]\tvalid_0's multi_logloss: 0.72918\n",
      "[14]\tvalid_0's multi_logloss: 0.717449\n",
      "[15]\tvalid_0's multi_logloss: 0.707023\n",
      "[16]\tvalid_0's multi_logloss: 0.697778\n",
      "[17]\tvalid_0's multi_logloss: 0.689617\n",
      "[18]\tvalid_0's multi_logloss: 0.682482\n",
      "[19]\tvalid_0's multi_logloss: 0.676163\n",
      "[20]\tvalid_0's multi_logloss: 0.67027\n",
      "[21]\tvalid_0's multi_logloss: 0.665124\n",
      "[22]\tvalid_0's multi_logloss: 0.660467\n",
      "[23]\tvalid_0's multi_logloss: 0.656281\n",
      "[24]\tvalid_0's multi_logloss: 0.652401\n",
      "[25]\tvalid_0's multi_logloss: 0.648856\n",
      "[26]\tvalid_0's multi_logloss: 0.645665\n",
      "[27]\tvalid_0's multi_logloss: 0.642842\n",
      "[28]\tvalid_0's multi_logloss: 0.640206\n",
      "[29]\tvalid_0's multi_logloss: 0.637758\n",
      "[30]\tvalid_0's multi_logloss: 0.635591\n",
      "[31]\tvalid_0's multi_logloss: 0.633538\n",
      "[32]\tvalid_0's multi_logloss: 0.631668\n",
      "[33]\tvalid_0's multi_logloss: 0.63001\n",
      "[34]\tvalid_0's multi_logloss: 0.628436\n",
      "[35]\tvalid_0's multi_logloss: 0.626938\n",
      "[36]\tvalid_0's multi_logloss: 0.625556\n",
      "[37]\tvalid_0's multi_logloss: 0.624234\n",
      "[38]\tvalid_0's multi_logloss: 0.623048\n",
      "[39]\tvalid_0's multi_logloss: 0.621937\n",
      "[40]\tvalid_0's multi_logloss: 0.620969\n",
      "[41]\tvalid_0's multi_logloss: 0.619991\n",
      "[42]\tvalid_0's multi_logloss: 0.619121\n",
      "[43]\tvalid_0's multi_logloss: 0.618321\n",
      "[44]\tvalid_0's multi_logloss: 0.617521\n",
      "[45]\tvalid_0's multi_logloss: 0.616775\n",
      "[46]\tvalid_0's multi_logloss: 0.616113\n",
      "[47]\tvalid_0's multi_logloss: 0.615396\n",
      "[48]\tvalid_0's multi_logloss: 0.61475\n",
      "[49]\tvalid_0's multi_logloss: 0.614139\n",
      "[50]\tvalid_0's multi_logloss: 0.613547\n",
      "[51]\tvalid_0's multi_logloss: 0.613028\n",
      "[52]\tvalid_0's multi_logloss: 0.612526\n",
      "[53]\tvalid_0's multi_logloss: 0.612104\n",
      "[54]\tvalid_0's multi_logloss: 0.611636\n",
      "[55]\tvalid_0's multi_logloss: 0.611212\n",
      "[56]\tvalid_0's multi_logloss: 0.610813\n",
      "[57]\tvalid_0's multi_logloss: 0.610416\n",
      "[58]\tvalid_0's multi_logloss: 0.610026\n",
      "[59]\tvalid_0's multi_logloss: 0.609625\n",
      "[60]\tvalid_0's multi_logloss: 0.609272\n",
      "[61]\tvalid_0's multi_logloss: 0.608963\n",
      "[62]\tvalid_0's multi_logloss: 0.608682\n",
      "[63]\tvalid_0's multi_logloss: 0.608363\n",
      "[64]\tvalid_0's multi_logloss: 0.608068\n",
      "[65]\tvalid_0's multi_logloss: 0.607729\n",
      "[66]\tvalid_0's multi_logloss: 0.607429\n",
      "[67]\tvalid_0's multi_logloss: 0.60716\n",
      "[68]\tvalid_0's multi_logloss: 0.606892\n",
      "[69]\tvalid_0's multi_logloss: 0.606637\n",
      "[70]\tvalid_0's multi_logloss: 0.606373\n",
      "[71]\tvalid_0's multi_logloss: 0.606054\n",
      "[72]\tvalid_0's multi_logloss: 0.605822\n",
      "[73]\tvalid_0's multi_logloss: 0.605575\n",
      "[74]\tvalid_0's multi_logloss: 0.605311\n",
      "[75]\tvalid_0's multi_logloss: 0.605045\n",
      "[76]\tvalid_0's multi_logloss: 0.604854\n",
      "[77]\tvalid_0's multi_logloss: 0.604614\n",
      "[78]\tvalid_0's multi_logloss: 0.604397\n",
      "[79]\tvalid_0's multi_logloss: 0.604213\n",
      "[80]\tvalid_0's multi_logloss: 0.604031\n",
      "[81]\tvalid_0's multi_logloss: 0.603813\n",
      "[82]\tvalid_0's multi_logloss: 0.603973\n",
      "[83]\tvalid_0's multi_logloss: 0.603565\n",
      "[84]\tvalid_0's multi_logloss: 0.603388\n",
      "[85]\tvalid_0's multi_logloss: 0.603197\n",
      "[86]\tvalid_0's multi_logloss: 0.602975\n",
      "[87]\tvalid_0's multi_logloss: 0.602778\n",
      "[88]\tvalid_0's multi_logloss: 0.602623\n",
      "[89]\tvalid_0's multi_logloss: 0.602419\n",
      "[90]\tvalid_0's multi_logloss: 0.602558\n",
      "[91]\tvalid_0's multi_logloss: 0.602098\n",
      "[92]\tvalid_0's multi_logloss: 0.602709\n",
      "[93]\tvalid_0's multi_logloss: 0.602337\n",
      "[94]\tvalid_0's multi_logloss: 0.602663\n",
      "[95]\tvalid_0's multi_logloss: 0.602323\n",
      "[96]\tvalid_0's multi_logloss: 0.602704\n",
      "[97]\tvalid_0's multi_logloss: 0.60268\n",
      "[98]\tvalid_0's multi_logloss: 0.603772\n",
      "[99]\tvalid_0's multi_logloss: 0.603264\n",
      "[100]\tvalid_0's multi_logloss: 0.603189\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001460 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 820733, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -2.163833\n",
      "[LightGBM] [Info] Start training from score -1.796397\n",
      "[LightGBM] [Info] Start training from score -1.843741\n",
      "[LightGBM] [Info] Start training from score -1.989576\n",
      "[LightGBM] [Info] Start training from score -1.941218\n",
      "[LightGBM] [Info] Start training from score -1.949016\n",
      "[LightGBM] [Info] Start training from score -1.978333\n",
      "[1]\tvalid_0's multi_logloss: 1.89623\n",
      "[2]\tvalid_0's multi_logloss: 1.86204\n",
      "[3]\tvalid_0's multi_logloss: 1.83477\n",
      "[4]\tvalid_0's multi_logloss: 1.81247\n",
      "[5]\tvalid_0's multi_logloss: 1.79414\n",
      "[6]\tvalid_0's multi_logloss: 1.77881\n",
      "[7]\tvalid_0's multi_logloss: 1.76582\n",
      "[8]\tvalid_0's multi_logloss: 1.75495\n",
      "[9]\tvalid_0's multi_logloss: 1.74569\n",
      "[10]\tvalid_0's multi_logloss: 1.7377\n",
      "[11]\tvalid_0's multi_logloss: 1.73088\n",
      "[12]\tvalid_0's multi_logloss: 1.72496\n",
      "[13]\tvalid_0's multi_logloss: 1.71978\n",
      "[14]\tvalid_0's multi_logloss: 1.71538\n",
      "[15]\tvalid_0's multi_logloss: 1.71149\n",
      "[16]\tvalid_0's multi_logloss: 1.70797\n",
      "[17]\tvalid_0's multi_logloss: 1.70487\n",
      "[18]\tvalid_0's multi_logloss: 1.70213\n",
      "[19]\tvalid_0's multi_logloss: 1.69977\n",
      "[20]\tvalid_0's multi_logloss: 1.69759\n",
      "[21]\tvalid_0's multi_logloss: 1.69568\n",
      "[22]\tvalid_0's multi_logloss: 1.69388\n",
      "[23]\tvalid_0's multi_logloss: 1.69228\n",
      "[24]\tvalid_0's multi_logloss: 1.69083\n",
      "[25]\tvalid_0's multi_logloss: 1.68949\n",
      "[26]\tvalid_0's multi_logloss: 1.6883\n",
      "[27]\tvalid_0's multi_logloss: 1.68714\n",
      "[28]\tvalid_0's multi_logloss: 1.68609\n",
      "[29]\tvalid_0's multi_logloss: 1.68513\n",
      "[30]\tvalid_0's multi_logloss: 1.68422\n",
      "[31]\tvalid_0's multi_logloss: 1.68338\n",
      "[32]\tvalid_0's multi_logloss: 1.68264\n",
      "[33]\tvalid_0's multi_logloss: 1.68194\n",
      "[34]\tvalid_0's multi_logloss: 1.68125\n",
      "[35]\tvalid_0's multi_logloss: 1.68063\n",
      "[36]\tvalid_0's multi_logloss: 1.68006\n",
      "[37]\tvalid_0's multi_logloss: 1.67952\n",
      "[38]\tvalid_0's multi_logloss: 1.67899\n",
      "[39]\tvalid_0's multi_logloss: 1.67849\n",
      "[40]\tvalid_0's multi_logloss: 1.67802\n",
      "[41]\tvalid_0's multi_logloss: 1.67754\n",
      "[42]\tvalid_0's multi_logloss: 1.67708\n",
      "[43]\tvalid_0's multi_logloss: 1.67667\n",
      "[44]\tvalid_0's multi_logloss: 1.67625\n",
      "[45]\tvalid_0's multi_logloss: 1.67589\n",
      "[46]\tvalid_0's multi_logloss: 1.67554\n",
      "[47]\tvalid_0's multi_logloss: 1.6752\n",
      "[48]\tvalid_0's multi_logloss: 1.67488\n",
      "[49]\tvalid_0's multi_logloss: 1.67457\n",
      "[50]\tvalid_0's multi_logloss: 1.67425\n",
      "[51]\tvalid_0's multi_logloss: 1.67389\n",
      "[52]\tvalid_0's multi_logloss: 1.67358\n",
      "[53]\tvalid_0's multi_logloss: 1.67333\n",
      "[54]\tvalid_0's multi_logloss: 1.67304\n",
      "[55]\tvalid_0's multi_logloss: 1.67279\n",
      "[56]\tvalid_0's multi_logloss: 1.67252\n",
      "[57]\tvalid_0's multi_logloss: 1.67227\n",
      "[58]\tvalid_0's multi_logloss: 1.67201\n",
      "[59]\tvalid_0's multi_logloss: 1.67176\n",
      "[60]\tvalid_0's multi_logloss: 1.6715\n",
      "[61]\tvalid_0's multi_logloss: 1.67124\n",
      "[62]\tvalid_0's multi_logloss: 1.67103\n",
      "[63]\tvalid_0's multi_logloss: 1.67082\n",
      "[64]\tvalid_0's multi_logloss: 1.67056\n",
      "[65]\tvalid_0's multi_logloss: 1.67031\n",
      "[66]\tvalid_0's multi_logloss: 1.67006\n",
      "[67]\tvalid_0's multi_logloss: 1.66984\n",
      "[68]\tvalid_0's multi_logloss: 1.6696\n",
      "[69]\tvalid_0's multi_logloss: 1.66941\n",
      "[70]\tvalid_0's multi_logloss: 1.66919\n",
      "[71]\tvalid_0's multi_logloss: 1.66899\n",
      "[72]\tvalid_0's multi_logloss: 1.66877\n",
      "[73]\tvalid_0's multi_logloss: 1.66855\n",
      "[74]\tvalid_0's multi_logloss: 1.66835\n",
      "[75]\tvalid_0's multi_logloss: 1.66816\n",
      "[76]\tvalid_0's multi_logloss: 1.66797\n",
      "[77]\tvalid_0's multi_logloss: 1.66779\n",
      "[78]\tvalid_0's multi_logloss: 1.66756\n",
      "[79]\tvalid_0's multi_logloss: 1.66738\n",
      "[80]\tvalid_0's multi_logloss: 1.66716\n",
      "[81]\tvalid_0's multi_logloss: 1.66698\n",
      "[82]\tvalid_0's multi_logloss: 1.66678\n",
      "[83]\tvalid_0's multi_logloss: 1.66659\n",
      "[84]\tvalid_0's multi_logloss: 1.66639\n",
      "[85]\tvalid_0's multi_logloss: 1.66624\n",
      "[86]\tvalid_0's multi_logloss: 1.66607\n",
      "[87]\tvalid_0's multi_logloss: 1.66593\n",
      "[88]\tvalid_0's multi_logloss: 1.66578\n",
      "[89]\tvalid_0's multi_logloss: 1.66558\n",
      "[90]\tvalid_0's multi_logloss: 1.66537\n",
      "[91]\tvalid_0's multi_logloss: 1.66522\n",
      "[92]\tvalid_0's multi_logloss: 1.66504\n",
      "[93]\tvalid_0's multi_logloss: 1.66489\n",
      "[94]\tvalid_0's multi_logloss: 1.66469\n",
      "[95]\tvalid_0's multi_logloss: 1.66449\n",
      "[96]\tvalid_0's multi_logloss: 1.66433\n",
      "[97]\tvalid_0's multi_logloss: 1.66414\n",
      "[98]\tvalid_0's multi_logloss: 1.66396\n",
      "[99]\tvalid_0's multi_logloss: 1.66377\n",
      "[100]\tvalid_0's multi_logloss: 1.66362\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072559 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11220\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 44\n",
      "[LightGBM] [Info] Start training from score -1.853404\n",
      "[LightGBM] [Info] Start training from score -2.123202\n",
      "[LightGBM] [Info] Start training from score -2.391862\n",
      "[LightGBM] [Info] Start training from score -2.719639\n",
      "[LightGBM] [Info] Start training from score -2.078311\n",
      "[LightGBM] [Info] Start training from score -2.161447\n",
      "[LightGBM] [Info] Start training from score -2.497610\n",
      "[LightGBM] [Info] Start training from score -2.232530\n",
      "[LightGBM] [Info] Start training from score -2.689447\n",
      "[LightGBM] [Info] Start training from score -2.680407\n",
      "[1]\tvalid_0's multi_logloss: 1.86119\n",
      "[2]\tvalid_0's multi_logloss: 1.64821\n",
      "[3]\tvalid_0's multi_logloss: 1.49095\n",
      "[4]\tvalid_0's multi_logloss: 1.368\n",
      "[5]\tvalid_0's multi_logloss: 1.26907\n",
      "[6]\tvalid_0's multi_logloss: 1.1855\n",
      "[7]\tvalid_0's multi_logloss: 1.11508\n",
      "[8]\tvalid_0's multi_logloss: 1.05472\n",
      "[9]\tvalid_0's multi_logloss: 1.00153\n",
      "[10]\tvalid_0's multi_logloss: 0.955238\n",
      "[11]\tvalid_0's multi_logloss: 0.913568\n",
      "[12]\tvalid_0's multi_logloss: 0.877173\n",
      "[13]\tvalid_0's multi_logloss: 0.844828\n",
      "[14]\tvalid_0's multi_logloss: 0.814527\n",
      "[15]\tvalid_0's multi_logloss: 0.787977\n",
      "[16]\tvalid_0's multi_logloss: 0.763322\n",
      "[17]\tvalid_0's multi_logloss: 0.740942\n",
      "[18]\tvalid_0's multi_logloss: 0.720842\n",
      "[19]\tvalid_0's multi_logloss: 0.702073\n",
      "[20]\tvalid_0's multi_logloss: 0.684975\n",
      "[21]\tvalid_0's multi_logloss: 0.668894\n",
      "[22]\tvalid_0's multi_logloss: 0.654327\n",
      "[23]\tvalid_0's multi_logloss: 0.640694\n",
      "[24]\tvalid_0's multi_logloss: 0.628089\n",
      "[25]\tvalid_0's multi_logloss: 0.615546\n",
      "[26]\tvalid_0's multi_logloss: 0.604472\n",
      "[27]\tvalid_0's multi_logloss: 0.593856\n",
      "[28]\tvalid_0's multi_logloss: 0.584124\n",
      "[29]\tvalid_0's multi_logloss: 0.574863\n",
      "[30]\tvalid_0's multi_logloss: 0.566091\n",
      "[31]\tvalid_0's multi_logloss: 0.55777\n",
      "[32]\tvalid_0's multi_logloss: 0.550024\n",
      "[33]\tvalid_0's multi_logloss: 0.542651\n",
      "[34]\tvalid_0's multi_logloss: 0.535437\n",
      "[35]\tvalid_0's multi_logloss: 0.52887\n",
      "[36]\tvalid_0's multi_logloss: 0.522435\n",
      "[37]\tvalid_0's multi_logloss: 0.516437\n",
      "[38]\tvalid_0's multi_logloss: 0.510602\n",
      "[39]\tvalid_0's multi_logloss: 0.504849\n",
      "[40]\tvalid_0's multi_logloss: 0.49967\n",
      "[41]\tvalid_0's multi_logloss: 0.494598\n",
      "[42]\tvalid_0's multi_logloss: 0.48965\n",
      "[43]\tvalid_0's multi_logloss: 0.484946\n",
      "[44]\tvalid_0's multi_logloss: 0.480103\n",
      "[45]\tvalid_0's multi_logloss: 0.475458\n",
      "[46]\tvalid_0's multi_logloss: 0.471215\n",
      "[47]\tvalid_0's multi_logloss: 0.467059\n",
      "[48]\tvalid_0's multi_logloss: 0.463264\n",
      "[49]\tvalid_0's multi_logloss: 0.459218\n",
      "[50]\tvalid_0's multi_logloss: 0.455484\n",
      "[51]\tvalid_0's multi_logloss: 0.45196\n",
      "[52]\tvalid_0's multi_logloss: 0.448431\n",
      "[53]\tvalid_0's multi_logloss: 0.445078\n",
      "[54]\tvalid_0's multi_logloss: 0.441501\n",
      "[55]\tvalid_0's multi_logloss: 0.43819\n",
      "[56]\tvalid_0's multi_logloss: 0.434865\n",
      "[57]\tvalid_0's multi_logloss: 0.431653\n",
      "[58]\tvalid_0's multi_logloss: 0.428732\n",
      "[59]\tvalid_0's multi_logloss: 0.425954\n",
      "[60]\tvalid_0's multi_logloss: 0.423231\n",
      "[61]\tvalid_0's multi_logloss: 0.42019\n",
      "[62]\tvalid_0's multi_logloss: 0.417477\n",
      "[63]\tvalid_0's multi_logloss: 0.41479\n",
      "[64]\tvalid_0's multi_logloss: 0.412217\n",
      "[65]\tvalid_0's multi_logloss: 0.409784\n",
      "[66]\tvalid_0's multi_logloss: 0.407157\n",
      "[67]\tvalid_0's multi_logloss: 0.404743\n",
      "[68]\tvalid_0's multi_logloss: 0.402395\n",
      "[69]\tvalid_0's multi_logloss: 0.40031\n",
      "[70]\tvalid_0's multi_logloss: 0.398025\n",
      "[71]\tvalid_0's multi_logloss: 0.395989\n",
      "[72]\tvalid_0's multi_logloss: 0.393722\n",
      "[73]\tvalid_0's multi_logloss: 0.391509\n",
      "[74]\tvalid_0's multi_logloss: 0.389367\n",
      "[75]\tvalid_0's multi_logloss: 0.387487\n",
      "[76]\tvalid_0's multi_logloss: 0.385465\n",
      "[77]\tvalid_0's multi_logloss: 0.383593\n",
      "[78]\tvalid_0's multi_logloss: 0.381806\n",
      "[79]\tvalid_0's multi_logloss: 0.379895\n",
      "[80]\tvalid_0's multi_logloss: 0.378324\n",
      "[81]\tvalid_0's multi_logloss: 0.376441\n",
      "[82]\tvalid_0's multi_logloss: 0.374695\n",
      "[83]\tvalid_0's multi_logloss: 0.373027\n",
      "[84]\tvalid_0's multi_logloss: 0.371405\n",
      "[85]\tvalid_0's multi_logloss: 0.369932\n",
      "[86]\tvalid_0's multi_logloss: 0.368255\n",
      "[87]\tvalid_0's multi_logloss: 0.366595\n",
      "[88]\tvalid_0's multi_logloss: 0.36503\n",
      "[89]\tvalid_0's multi_logloss: 0.363522\n",
      "[90]\tvalid_0's multi_logloss: 0.362073\n",
      "[91]\tvalid_0's multi_logloss: 0.360626\n",
      "[92]\tvalid_0's multi_logloss: 0.359177\n",
      "[93]\tvalid_0's multi_logloss: 0.357793\n",
      "[94]\tvalid_0's multi_logloss: 0.356363\n",
      "[95]\tvalid_0's multi_logloss: 0.35499\n",
      "[96]\tvalid_0's multi_logloss: 0.353641\n",
      "[97]\tvalid_0's multi_logloss: 0.352264\n",
      "[98]\tvalid_0's multi_logloss: 0.350893\n",
      "[99]\tvalid_0's multi_logloss: 0.349764\n",
      "[100]\tvalid_0's multi_logloss: 0.348534\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076827 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11220\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 44\n",
      "[LightGBM] [Info] Start training from score -1.047228\n",
      "[LightGBM] [Info] Start training from score -1.516216\n",
      "[LightGBM] [Info] Start training from score -0.845018\n",
      "[1]\tvalid_0's multi_logloss: 1.00358\n",
      "[2]\tvalid_0's multi_logloss: 0.955189\n",
      "[3]\tvalid_0's multi_logloss: 0.915167\n",
      "[4]\tvalid_0's multi_logloss: 0.881191\n",
      "[5]\tvalid_0's multi_logloss: 0.852315\n",
      "[6]\tvalid_0's multi_logloss: 0.827583\n",
      "[7]\tvalid_0's multi_logloss: 0.806151\n",
      "[8]\tvalid_0's multi_logloss: 0.787463\n",
      "[9]\tvalid_0's multi_logloss: 0.770961\n",
      "[10]\tvalid_0's multi_logloss: 0.756425\n",
      "[11]\tvalid_0's multi_logloss: 0.743481\n",
      "[12]\tvalid_0's multi_logloss: 0.731826\n",
      "[13]\tvalid_0's multi_logloss: 0.721308\n",
      "[14]\tvalid_0's multi_logloss: 0.711848\n",
      "[15]\tvalid_0's multi_logloss: 0.703355\n",
      "[16]\tvalid_0's multi_logloss: 0.69553\n",
      "[17]\tvalid_0's multi_logloss: 0.688387\n",
      "[18]\tvalid_0's multi_logloss: 0.681816\n",
      "[19]\tvalid_0's multi_logloss: 0.675869\n",
      "[20]\tvalid_0's multi_logloss: 0.670333\n",
      "[21]\tvalid_0's multi_logloss: 0.665026\n",
      "[22]\tvalid_0's multi_logloss: 0.660361\n",
      "[23]\tvalid_0's multi_logloss: 0.655966\n",
      "[24]\tvalid_0's multi_logloss: 0.651865\n",
      "[25]\tvalid_0's multi_logloss: 0.647933\n",
      "[26]\tvalid_0's multi_logloss: 0.644381\n",
      "[27]\tvalid_0's multi_logloss: 0.641049\n",
      "[28]\tvalid_0's multi_logloss: 0.637923\n",
      "[29]\tvalid_0's multi_logloss: 0.634958\n",
      "[30]\tvalid_0's multi_logloss: 0.63217\n",
      "[31]\tvalid_0's multi_logloss: 0.629505\n",
      "[32]\tvalid_0's multi_logloss: 0.627019\n",
      "[33]\tvalid_0's multi_logloss: 0.624721\n",
      "[34]\tvalid_0's multi_logloss: 0.622656\n",
      "[35]\tvalid_0's multi_logloss: 0.620682\n",
      "[36]\tvalid_0's multi_logloss: 0.618818\n",
      "[37]\tvalid_0's multi_logloss: 0.616872\n",
      "[38]\tvalid_0's multi_logloss: 0.615117\n",
      "[39]\tvalid_0's multi_logloss: 0.613518\n",
      "[40]\tvalid_0's multi_logloss: 0.611944\n",
      "[41]\tvalid_0's multi_logloss: 0.610547\n",
      "[42]\tvalid_0's multi_logloss: 0.609119\n",
      "[43]\tvalid_0's multi_logloss: 0.607742\n",
      "[44]\tvalid_0's multi_logloss: 0.606398\n",
      "[45]\tvalid_0's multi_logloss: 0.605164\n",
      "[46]\tvalid_0's multi_logloss: 0.60406\n",
      "[47]\tvalid_0's multi_logloss: 0.602971\n",
      "[48]\tvalid_0's multi_logloss: 0.601951\n",
      "[49]\tvalid_0's multi_logloss: 0.601018\n",
      "[50]\tvalid_0's multi_logloss: 0.599975\n",
      "[51]\tvalid_0's multi_logloss: 0.599067\n",
      "[52]\tvalid_0's multi_logloss: 0.598201\n",
      "[53]\tvalid_0's multi_logloss: 0.597315\n",
      "[54]\tvalid_0's multi_logloss: 0.596536\n",
      "[55]\tvalid_0's multi_logloss: 0.59578\n",
      "[56]\tvalid_0's multi_logloss: 0.595044\n",
      "[57]\tvalid_0's multi_logloss: 0.59434\n",
      "[58]\tvalid_0's multi_logloss: 0.593622\n",
      "[59]\tvalid_0's multi_logloss: 0.592929\n",
      "[60]\tvalid_0's multi_logloss: 0.592238\n",
      "[61]\tvalid_0's multi_logloss: 0.591602\n",
      "[62]\tvalid_0's multi_logloss: 0.591045\n",
      "[63]\tvalid_0's multi_logloss: 0.590406\n",
      "[64]\tvalid_0's multi_logloss: 0.589819\n",
      "[65]\tvalid_0's multi_logloss: 0.589261\n",
      "[66]\tvalid_0's multi_logloss: 0.588743\n",
      "[67]\tvalid_0's multi_logloss: 0.588162\n",
      "[68]\tvalid_0's multi_logloss: 0.587604\n",
      "[69]\tvalid_0's multi_logloss: 0.587084\n",
      "[70]\tvalid_0's multi_logloss: 0.586583\n",
      "[71]\tvalid_0's multi_logloss: 0.586114\n",
      "[72]\tvalid_0's multi_logloss: 0.58573\n",
      "[73]\tvalid_0's multi_logloss: 0.585258\n",
      "[74]\tvalid_0's multi_logloss: 0.584792\n",
      "[75]\tvalid_0's multi_logloss: 0.584356\n",
      "[76]\tvalid_0's multi_logloss: 0.583862\n",
      "[77]\tvalid_0's multi_logloss: 0.583466\n",
      "[78]\tvalid_0's multi_logloss: 0.583066\n",
      "[79]\tvalid_0's multi_logloss: 0.582705\n",
      "[80]\tvalid_0's multi_logloss: 0.582294\n",
      "[81]\tvalid_0's multi_logloss: 0.58197\n",
      "[82]\tvalid_0's multi_logloss: 0.581606\n",
      "[83]\tvalid_0's multi_logloss: 0.581235\n",
      "[84]\tvalid_0's multi_logloss: 0.58094\n",
      "[85]\tvalid_0's multi_logloss: 0.58062\n",
      "[86]\tvalid_0's multi_logloss: 0.580204\n",
      "[87]\tvalid_0's multi_logloss: 0.579853\n",
      "[88]\tvalid_0's multi_logloss: 0.57953\n",
      "[89]\tvalid_0's multi_logloss: 0.579173\n",
      "[90]\tvalid_0's multi_logloss: 0.578869\n",
      "[91]\tvalid_0's multi_logloss: 0.578559\n",
      "[92]\tvalid_0's multi_logloss: 0.578306\n",
      "[93]\tvalid_0's multi_logloss: 0.577983\n",
      "[94]\tvalid_0's multi_logloss: 0.577665\n",
      "[95]\tvalid_0's multi_logloss: 0.577437\n",
      "[96]\tvalid_0's multi_logloss: 0.577155\n",
      "[97]\tvalid_0's multi_logloss: 0.576879\n",
      "[98]\tvalid_0's multi_logloss: 0.576597\n",
      "[99]\tvalid_0's multi_logloss: 0.576349\n",
      "[100]\tvalid_0's multi_logloss: 0.57609\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071407 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11220\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 44\n",
      "[LightGBM] [Info] Start training from score -3.244539\n",
      "[LightGBM] [Info] Start training from score -3.224920\n",
      "[LightGBM] [Info] Start training from score -3.369880\n",
      "[LightGBM] [Info] Start training from score -3.326941\n",
      "[LightGBM] [Info] Start training from score -3.378266\n",
      "[LightGBM] [Info] Start training from score -2.568017\n",
      "[LightGBM] [Info] Start training from score -1.914747\n",
      "[LightGBM] [Info] Start training from score -3.469579\n",
      "[LightGBM] [Info] Start training from score -1.919436\n",
      "[LightGBM] [Info] Start training from score -2.291576\n",
      "[LightGBM] [Info] Start training from score -2.007538\n",
      "[LightGBM] [Info] Start training from score -3.402200\n",
      "[LightGBM] [Info] Start training from score -3.212376\n",
      "[LightGBM] [Info] Start training from score -2.244521\n",
      "[1]\tvalid_0's multi_logloss: 2.38417\n",
      "[2]\tvalid_0's multi_logloss: 2.33488\n",
      "[3]\tvalid_0's multi_logloss: 2.29577\n",
      "[4]\tvalid_0's multi_logloss: 2.26386\n",
      "[5]\tvalid_0's multi_logloss: 2.23664\n",
      "[6]\tvalid_0's multi_logloss: 2.21322\n",
      "[7]\tvalid_0's multi_logloss: 2.19292\n",
      "[8]\tvalid_0's multi_logloss: 2.17535\n",
      "[9]\tvalid_0's multi_logloss: 2.15899\n",
      "[10]\tvalid_0's multi_logloss: 2.1445\n",
      "[11]\tvalid_0's multi_logloss: 2.13113\n",
      "[12]\tvalid_0's multi_logloss: 2.11915\n",
      "[13]\tvalid_0's multi_logloss: 2.10763\n",
      "[14]\tvalid_0's multi_logloss: 2.0971\n",
      "[15]\tvalid_0's multi_logloss: 2.08734\n",
      "[16]\tvalid_0's multi_logloss: 2.07817\n",
      "[17]\tvalid_0's multi_logloss: 2.06982\n",
      "[18]\tvalid_0's multi_logloss: 2.06206\n",
      "[19]\tvalid_0's multi_logloss: 2.05476\n",
      "[20]\tvalid_0's multi_logloss: 2.04793\n",
      "[21]\tvalid_0's multi_logloss: 2.04146\n",
      "[22]\tvalid_0's multi_logloss: 2.0354\n",
      "[23]\tvalid_0's multi_logloss: 2.02973\n",
      "[24]\tvalid_0's multi_logloss: 2.02442\n",
      "[25]\tvalid_0's multi_logloss: 2.0194\n",
      "[26]\tvalid_0's multi_logloss: 2.01452\n",
      "[27]\tvalid_0's multi_logloss: 2.00998\n",
      "[28]\tvalid_0's multi_logloss: 2.00555\n",
      "[29]\tvalid_0's multi_logloss: 2.00142\n",
      "[30]\tvalid_0's multi_logloss: 1.99744\n",
      "[31]\tvalid_0's multi_logloss: 1.99323\n",
      "[32]\tvalid_0's multi_logloss: 1.98958\n",
      "[33]\tvalid_0's multi_logloss: 1.9861\n",
      "[34]\tvalid_0's multi_logloss: 1.98256\n",
      "[35]\tvalid_0's multi_logloss: 1.97907\n",
      "[36]\tvalid_0's multi_logloss: 1.97596\n",
      "[37]\tvalid_0's multi_logloss: 1.97279\n",
      "[38]\tvalid_0's multi_logloss: 1.96997\n",
      "[39]\tvalid_0's multi_logloss: 1.96721\n",
      "[40]\tvalid_0's multi_logloss: 1.9645\n",
      "[41]\tvalid_0's multi_logloss: 1.9619\n",
      "[42]\tvalid_0's multi_logloss: 1.9591\n",
      "[43]\tvalid_0's multi_logloss: 1.95664\n",
      "[44]\tvalid_0's multi_logloss: 1.95431\n",
      "[45]\tvalid_0's multi_logloss: 1.95203\n",
      "[46]\tvalid_0's multi_logloss: 1.94973\n",
      "[47]\tvalid_0's multi_logloss: 1.94765\n",
      "[48]\tvalid_0's multi_logloss: 1.94546\n",
      "[49]\tvalid_0's multi_logloss: 1.94334\n",
      "[50]\tvalid_0's multi_logloss: 1.94133\n",
      "[51]\tvalid_0's multi_logloss: 1.93935\n",
      "[52]\tvalid_0's multi_logloss: 1.93746\n",
      "[53]\tvalid_0's multi_logloss: 1.93555\n",
      "[54]\tvalid_0's multi_logloss: 1.93381\n",
      "[55]\tvalid_0's multi_logloss: 1.93194\n",
      "[56]\tvalid_0's multi_logloss: 1.93024\n",
      "[57]\tvalid_0's multi_logloss: 1.92842\n",
      "[58]\tvalid_0's multi_logloss: 1.92682\n",
      "[59]\tvalid_0's multi_logloss: 1.92522\n",
      "[60]\tvalid_0's multi_logloss: 1.92359\n",
      "[61]\tvalid_0's multi_logloss: 1.92193\n",
      "[62]\tvalid_0's multi_logloss: 1.92033\n",
      "[63]\tvalid_0's multi_logloss: 1.91886\n",
      "[64]\tvalid_0's multi_logloss: 1.91728\n",
      "[65]\tvalid_0's multi_logloss: 1.91583\n",
      "[66]\tvalid_0's multi_logloss: 1.91442\n",
      "[67]\tvalid_0's multi_logloss: 1.91305\n",
      "[68]\tvalid_0's multi_logloss: 1.91166\n",
      "[69]\tvalid_0's multi_logloss: 1.91037\n",
      "[70]\tvalid_0's multi_logloss: 1.90911\n",
      "[71]\tvalid_0's multi_logloss: 1.90785\n",
      "[72]\tvalid_0's multi_logloss: 1.9066\n",
      "[73]\tvalid_0's multi_logloss: 1.90543\n",
      "[74]\tvalid_0's multi_logloss: 1.90419\n",
      "[75]\tvalid_0's multi_logloss: 1.90298\n",
      "[76]\tvalid_0's multi_logloss: 1.90173\n",
      "[77]\tvalid_0's multi_logloss: 1.90054\n",
      "[78]\tvalid_0's multi_logloss: 1.89949\n",
      "[79]\tvalid_0's multi_logloss: 1.89839\n",
      "[80]\tvalid_0's multi_logloss: 1.89726\n",
      "[81]\tvalid_0's multi_logloss: 1.8962\n",
      "[82]\tvalid_0's multi_logloss: 1.89517\n",
      "[83]\tvalid_0's multi_logloss: 1.89411\n",
      "[84]\tvalid_0's multi_logloss: 1.89307\n",
      "[85]\tvalid_0's multi_logloss: 1.89207\n",
      "[86]\tvalid_0's multi_logloss: 1.89111\n",
      "[87]\tvalid_0's multi_logloss: 1.89017\n",
      "[88]\tvalid_0's multi_logloss: 1.8892\n",
      "[89]\tvalid_0's multi_logloss: 1.8882\n",
      "[90]\tvalid_0's multi_logloss: 1.88726\n",
      "[91]\tvalid_0's multi_logloss: 1.88634\n",
      "[92]\tvalid_0's multi_logloss: 1.88542\n",
      "[93]\tvalid_0's multi_logloss: 1.88449\n",
      "[94]\tvalid_0's multi_logloss: 1.88357\n",
      "[95]\tvalid_0's multi_logloss: 1.88267\n",
      "[96]\tvalid_0's multi_logloss: 1.88179\n",
      "[97]\tvalid_0's multi_logloss: 1.881\n",
      "[98]\tvalid_0's multi_logloss: 1.88009\n",
      "[99]\tvalid_0's multi_logloss: 1.87929\n",
      "[100]\tvalid_0's multi_logloss: 1.87841\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11220\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 44\n",
      "[LightGBM] [Info] Start training from score -0.501622\n",
      "[LightGBM] [Info] Start training from score -0.930257\n",
      "[1]\tvalid_0's multi_logloss: 0.575765\n",
      "[2]\tvalid_0's multi_logloss: 0.499361\n",
      "[3]\tvalid_0's multi_logloss: 0.436291\n",
      "[4]\tvalid_0's multi_logloss: 0.383328\n",
      "[5]\tvalid_0's multi_logloss: 0.338256\n",
      "[6]\tvalid_0's multi_logloss: 0.299533\n",
      "[7]\tvalid_0's multi_logloss: 0.266004\n",
      "[8]\tvalid_0's multi_logloss: 0.236799\n",
      "[9]\tvalid_0's multi_logloss: 0.211222\n",
      "[10]\tvalid_0's multi_logloss: 0.188731\n",
      "[11]\tvalid_0's multi_logloss: 0.168885\n",
      "[12]\tvalid_0's multi_logloss: 0.151323\n",
      "[13]\tvalid_0's multi_logloss: 0.135734\n",
      "[14]\tvalid_0's multi_logloss: 0.121868\n",
      "[15]\tvalid_0's multi_logloss: 0.109511\n",
      "[16]\tvalid_0's multi_logloss: 0.0984828\n",
      "[17]\tvalid_0's multi_logloss: 0.0886246\n",
      "[18]\tvalid_0's multi_logloss: 0.0798002\n",
      "[19]\tvalid_0's multi_logloss: 0.0718918\n",
      "[20]\tvalid_0's multi_logloss: 0.0647973\n",
      "[21]\tvalid_0's multi_logloss: 0.0584209\n",
      "[22]\tvalid_0's multi_logloss: 0.0526961\n",
      "[23]\tvalid_0's multi_logloss: 0.0475483\n",
      "[24]\tvalid_0's multi_logloss: 0.042917\n",
      "[25]\tvalid_0's multi_logloss: 0.0387471\n",
      "[26]\tvalid_0's multi_logloss: 0.0349915\n",
      "[27]\tvalid_0's multi_logloss: 0.0316072\n",
      "[28]\tvalid_0's multi_logloss: 0.0285564\n",
      "[29]\tvalid_0's multi_logloss: 0.0258038\n",
      "[30]\tvalid_0's multi_logloss: 0.0233206\n",
      "[31]\tvalid_0's multi_logloss: 0.0210798\n",
      "[32]\tvalid_0's multi_logloss: 0.0190571\n",
      "[33]\tvalid_0's multi_logloss: 0.0172308\n",
      "[34]\tvalid_0's multi_logloss: 0.0155807\n",
      "[35]\tvalid_0's multi_logloss: 0.0140902\n",
      "[36]\tvalid_0's multi_logloss: 0.0127434\n",
      "[37]\tvalid_0's multi_logloss: 0.0115265\n",
      "[38]\tvalid_0's multi_logloss: 0.0104268\n",
      "[39]\tvalid_0's multi_logloss: 0.0094328\n",
      "[40]\tvalid_0's multi_logloss: 0.00853417\n",
      "[41]\tvalid_0's multi_logloss: 0.00772179\n",
      "[42]\tvalid_0's multi_logloss: 0.00698718\n",
      "[43]\tvalid_0's multi_logloss: 0.00632282\n",
      "[44]\tvalid_0's multi_logloss: 0.00572238\n",
      "[45]\tvalid_0's multi_logloss: 0.00517898\n",
      "[46]\tvalid_0's multi_logloss: 0.00468636\n",
      "[47]\tvalid_0's multi_logloss: 0.00424171\n",
      "[48]\tvalid_0's multi_logloss: 0.00383956\n",
      "[49]\tvalid_0's multi_logloss: 0.00347573\n",
      "[50]\tvalid_0's multi_logloss: 0.00314641\n",
      "[51]\tvalid_0's multi_logloss: 0.00284862\n",
      "[52]\tvalid_0's multi_logloss: 0.00257919\n",
      "[53]\tvalid_0's multi_logloss: 0.00233536\n",
      "[54]\tvalid_0's multi_logloss: 0.00211489\n",
      "[55]\tvalid_0's multi_logloss: 0.00191523\n",
      "[56]\tvalid_0's multi_logloss: 0.00173458\n",
      "[57]\tvalid_0's multi_logloss: 0.00157107\n",
      "[58]\tvalid_0's multi_logloss: 0.00142319\n",
      "[59]\tvalid_0's multi_logloss: 0.00128937\n",
      "[60]\tvalid_0's multi_logloss: 0.00116825\n",
      "[61]\tvalid_0's multi_logloss: 0.00105849\n",
      "[62]\tvalid_0's multi_logloss: 0.000959152\n",
      "[63]\tvalid_0's multi_logloss: 0.000869374\n",
      "[64]\tvalid_0's multi_logloss: 0.000787845\n",
      "[65]\tvalid_0's multi_logloss: 0.000714189\n",
      "[66]\tvalid_0's multi_logloss: 0.000647455\n",
      "[67]\tvalid_0's multi_logloss: 0.000587089\n",
      "[68]\tvalid_0's multi_logloss: 0.000532428\n",
      "[69]\tvalid_0's multi_logloss: 0.000482901\n",
      "[70]\tvalid_0's multi_logloss: 0.000438084\n",
      "[71]\tvalid_0's multi_logloss: 0.000397566\n",
      "[72]\tvalid_0's multi_logloss: 0.000360817\n",
      "[73]\tvalid_0's multi_logloss: 0.0003275\n",
      "[74]\tvalid_0's multi_logloss: 0.000297281\n",
      "[75]\tvalid_0's multi_logloss: 0.000269982\n",
      "[76]\tvalid_0's multi_logloss: 0.000245206\n",
      "[77]\tvalid_0's multi_logloss: 0.000222773\n",
      "[78]\tvalid_0's multi_logloss: 0.00020244\n",
      "[79]\tvalid_0's multi_logloss: 0.000184009\n",
      "[80]\tvalid_0's multi_logloss: 0.000167303\n",
      "[81]\tvalid_0's multi_logloss: 0.000152187\n",
      "[82]\tvalid_0's multi_logloss: 0.000138401\n",
      "[83]\tvalid_0's multi_logloss: 0.000125939\n",
      "[84]\tvalid_0's multi_logloss: 0.000114654\n",
      "[85]\tvalid_0's multi_logloss: 0.000104328\n",
      "[86]\tvalid_0's multi_logloss: 9.50208e-05\n",
      "[87]\tvalid_0's multi_logloss: 8.6585e-05\n",
      "[88]\tvalid_0's multi_logloss: 7.89115e-05\n",
      "[89]\tvalid_0's multi_logloss: 7.19652e-05\n",
      "[90]\tvalid_0's multi_logloss: 6.56406e-05\n",
      "[91]\tvalid_0's multi_logloss: 5.99152e-05\n",
      "[92]\tvalid_0's multi_logloss: 5.47186e-05\n",
      "[93]\tvalid_0's multi_logloss: 4.99961e-05\n",
      "[94]\tvalid_0's multi_logloss: 4.57366e-05\n",
      "[95]\tvalid_0's multi_logloss: 4.18548e-05\n",
      "[96]\tvalid_0's multi_logloss: 3.83383e-05\n",
      "[97]\tvalid_0's multi_logloss: 3.51177e-05\n",
      "[98]\tvalid_0's multi_logloss: 3.22141e-05\n",
      "[99]\tvalid_0's multi_logloss: 2.9573e-05\n",
      "[100]\tvalid_0's multi_logloss: 2.71546e-05\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11220\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 44\n",
      "[LightGBM] [Info] Start training from score -0.141837\n",
      "[LightGBM] [Info] Start training from score -2.023158\n",
      "[1]\tvalid_0's multi_logloss: 0.345777\n",
      "[2]\tvalid_0's multi_logloss: 0.316878\n",
      "[3]\tvalid_0's multi_logloss: 0.295104\n",
      "[4]\tvalid_0's multi_logloss: 0.276925\n",
      "[5]\tvalid_0's multi_logloss: 0.262176\n",
      "[6]\tvalid_0's multi_logloss: 0.249164\n",
      "[7]\tvalid_0's multi_logloss: 0.238076\n",
      "[8]\tvalid_0's multi_logloss: 0.227376\n",
      "[9]\tvalid_0's multi_logloss: 0.217958\n",
      "[10]\tvalid_0's multi_logloss: 0.209165\n",
      "[11]\tvalid_0's multi_logloss: 0.200643\n",
      "[12]\tvalid_0's multi_logloss: 0.192941\n",
      "[13]\tvalid_0's multi_logloss: 0.186844\n",
      "[14]\tvalid_0's multi_logloss: 0.179906\n",
      "[15]\tvalid_0's multi_logloss: 0.174152\n",
      "[16]\tvalid_0's multi_logloss: 0.168682\n",
      "[17]\tvalid_0's multi_logloss: 0.163537\n",
      "[18]\tvalid_0's multi_logloss: 0.159038\n",
      "[19]\tvalid_0's multi_logloss: 0.154738\n",
      "[20]\tvalid_0's multi_logloss: 0.15061\n",
      "[21]\tvalid_0's multi_logloss: 0.146785\n",
      "[22]\tvalid_0's multi_logloss: 0.143196\n",
      "[23]\tvalid_0's multi_logloss: 0.139794\n",
      "[24]\tvalid_0's multi_logloss: 0.136587\n",
      "[25]\tvalid_0's multi_logloss: 0.133818\n",
      "[26]\tvalid_0's multi_logloss: 0.13115\n",
      "[27]\tvalid_0's multi_logloss: 0.128808\n",
      "[28]\tvalid_0's multi_logloss: 0.12621\n",
      "[29]\tvalid_0's multi_logloss: 0.123831\n",
      "[30]\tvalid_0's multi_logloss: 0.121658\n",
      "[31]\tvalid_0's multi_logloss: 0.119358\n",
      "[32]\tvalid_0's multi_logloss: 0.117284\n",
      "[33]\tvalid_0's multi_logloss: 0.115381\n",
      "[34]\tvalid_0's multi_logloss: 0.113245\n",
      "[35]\tvalid_0's multi_logloss: 0.11128\n",
      "[36]\tvalid_0's multi_logloss: 0.109532\n",
      "[37]\tvalid_0's multi_logloss: 0.107904\n",
      "[38]\tvalid_0's multi_logloss: 0.106397\n",
      "[39]\tvalid_0's multi_logloss: 0.105054\n",
      "[40]\tvalid_0's multi_logloss: 0.103624\n",
      "[41]\tvalid_0's multi_logloss: 0.102174\n",
      "[42]\tvalid_0's multi_logloss: 0.100868\n",
      "[43]\tvalid_0's multi_logloss: 0.0996402\n",
      "[44]\tvalid_0's multi_logloss: 0.0983374\n",
      "[45]\tvalid_0's multi_logloss: 0.0970958\n",
      "[46]\tvalid_0's multi_logloss: 0.0959418\n",
      "[47]\tvalid_0's multi_logloss: 0.0949491\n",
      "[48]\tvalid_0's multi_logloss: 0.0939644\n",
      "[49]\tvalid_0's multi_logloss: 0.0929562\n",
      "[50]\tvalid_0's multi_logloss: 0.0920706\n",
      "[51]\tvalid_0's multi_logloss: 0.0911003\n",
      "[52]\tvalid_0's multi_logloss: 0.0901902\n",
      "[53]\tvalid_0's multi_logloss: 0.0891309\n",
      "[54]\tvalid_0's multi_logloss: 0.088317\n",
      "[55]\tvalid_0's multi_logloss: 0.0873875\n",
      "[56]\tvalid_0's multi_logloss: 0.0867211\n",
      "[57]\tvalid_0's multi_logloss: 0.0859714\n",
      "[58]\tvalid_0's multi_logloss: 0.0852322\n",
      "[59]\tvalid_0's multi_logloss: 0.0844394\n",
      "[60]\tvalid_0's multi_logloss: 0.0837114\n",
      "[61]\tvalid_0's multi_logloss: 0.0829429\n",
      "[62]\tvalid_0's multi_logloss: 0.0823307\n",
      "[63]\tvalid_0's multi_logloss: 0.0816448\n",
      "[64]\tvalid_0's multi_logloss: 0.080926\n",
      "[65]\tvalid_0's multi_logloss: 0.0801923\n",
      "[66]\tvalid_0's multi_logloss: 0.0795174\n",
      "[67]\tvalid_0's multi_logloss: 0.0789388\n",
      "[68]\tvalid_0's multi_logloss: 0.0783566\n",
      "[69]\tvalid_0's multi_logloss: 0.0779243\n",
      "[70]\tvalid_0's multi_logloss: 0.0773618\n",
      "[71]\tvalid_0's multi_logloss: 0.0768582\n",
      "[72]\tvalid_0's multi_logloss: 0.076309\n",
      "[73]\tvalid_0's multi_logloss: 0.0756829\n",
      "[74]\tvalid_0's multi_logloss: 0.0752291\n",
      "[75]\tvalid_0's multi_logloss: 0.0746786\n",
      "[76]\tvalid_0's multi_logloss: 0.0741137\n",
      "[77]\tvalid_0's multi_logloss: 0.0735557\n",
      "[78]\tvalid_0's multi_logloss: 0.0731324\n",
      "[79]\tvalid_0's multi_logloss: 0.0726234\n",
      "[80]\tvalid_0's multi_logloss: 0.072164\n",
      "[81]\tvalid_0's multi_logloss: 0.0717771\n",
      "[82]\tvalid_0's multi_logloss: 0.0713048\n",
      "[83]\tvalid_0's multi_logloss: 0.0709077\n",
      "[84]\tvalid_0's multi_logloss: 0.07055\n",
      "[85]\tvalid_0's multi_logloss: 0.0701387\n",
      "[86]\tvalid_0's multi_logloss: 0.0696662\n",
      "[87]\tvalid_0's multi_logloss: 0.0693181\n",
      "[88]\tvalid_0's multi_logloss: 0.0688934\n",
      "[89]\tvalid_0's multi_logloss: 0.0685288\n",
      "[90]\tvalid_0's multi_logloss: 0.0681816\n",
      "[91]\tvalid_0's multi_logloss: 0.0677949\n",
      "[92]\tvalid_0's multi_logloss: 0.0674602\n",
      "[93]\tvalid_0's multi_logloss: 0.0671741\n",
      "[94]\tvalid_0's multi_logloss: 0.0667504\n",
      "[95]\tvalid_0's multi_logloss: 0.0664698\n",
      "[96]\tvalid_0's multi_logloss: 0.0661959\n",
      "[97]\tvalid_0's multi_logloss: 0.0658763\n",
      "[98]\tvalid_0's multi_logloss: 0.0655439\n",
      "[99]\tvalid_0's multi_logloss: 0.0651411\n",
      "[100]\tvalid_0's multi_logloss: 0.064839\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017302 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.853404\n",
      "[LightGBM] [Info] Start training from score -2.123202\n",
      "[LightGBM] [Info] Start training from score -2.391862\n",
      "[LightGBM] [Info] Start training from score -2.719639\n",
      "[LightGBM] [Info] Start training from score -2.078311\n",
      "[LightGBM] [Info] Start training from score -2.161447\n",
      "[LightGBM] [Info] Start training from score -2.497610\n",
      "[LightGBM] [Info] Start training from score -2.232530\n",
      "[LightGBM] [Info] Start training from score -2.689447\n",
      "[LightGBM] [Info] Start training from score -2.680407\n",
      "[1]\tvalid_0's multi_logloss: 2.21529\n",
      "[2]\tvalid_0's multi_logloss: 2.17999\n",
      "[3]\tvalid_0's multi_logloss: 2.15234\n",
      "[4]\tvalid_0's multi_logloss: 2.13012\n",
      "[5]\tvalid_0's multi_logloss: 2.11197\n",
      "[6]\tvalid_0's multi_logloss: 2.09688\n",
      "[7]\tvalid_0's multi_logloss: 2.08441\n",
      "[8]\tvalid_0's multi_logloss: 2.07388\n",
      "[9]\tvalid_0's multi_logloss: 2.065\n",
      "[10]\tvalid_0's multi_logloss: 2.05747\n",
      "[11]\tvalid_0's multi_logloss: 2.05108\n",
      "[12]\tvalid_0's multi_logloss: 2.04558\n",
      "[13]\tvalid_0's multi_logloss: 2.04089\n",
      "[14]\tvalid_0's multi_logloss: 2.03687\n",
      "[15]\tvalid_0's multi_logloss: 2.03338\n",
      "[16]\tvalid_0's multi_logloss: 2.03029\n",
      "[17]\tvalid_0's multi_logloss: 2.02761\n",
      "[18]\tvalid_0's multi_logloss: 2.02532\n",
      "[19]\tvalid_0's multi_logloss: 2.02337\n",
      "[20]\tvalid_0's multi_logloss: 2.02155\n",
      "[21]\tvalid_0's multi_logloss: 2.02002\n",
      "[22]\tvalid_0's multi_logloss: 2.01862\n",
      "[23]\tvalid_0's multi_logloss: 2.01741\n",
      "[24]\tvalid_0's multi_logloss: 2.01633\n",
      "[25]\tvalid_0's multi_logloss: 2.01536\n",
      "[26]\tvalid_0's multi_logloss: 2.01451\n",
      "[27]\tvalid_0's multi_logloss: 2.01377\n",
      "[28]\tvalid_0's multi_logloss: 2.01309\n",
      "[29]\tvalid_0's multi_logloss: 2.01251\n",
      "[30]\tvalid_0's multi_logloss: 2.01197\n",
      "[31]\tvalid_0's multi_logloss: 2.01151\n",
      "[32]\tvalid_0's multi_logloss: 2.0111\n",
      "[33]\tvalid_0's multi_logloss: 2.01072\n",
      "[34]\tvalid_0's multi_logloss: 2.01036\n",
      "[35]\tvalid_0's multi_logloss: 2.01004\n",
      "[36]\tvalid_0's multi_logloss: 2.00978\n",
      "[37]\tvalid_0's multi_logloss: 2.00949\n",
      "[38]\tvalid_0's multi_logloss: 2.00924\n",
      "[39]\tvalid_0's multi_logloss: 2.00902\n",
      "[40]\tvalid_0's multi_logloss: 2.00881\n",
      "[41]\tvalid_0's multi_logloss: 2.00865\n",
      "[42]\tvalid_0's multi_logloss: 2.00847\n",
      "[43]\tvalid_0's multi_logloss: 2.00831\n",
      "[44]\tvalid_0's multi_logloss: 2.00816\n",
      "[45]\tvalid_0's multi_logloss: 2.00802\n",
      "[46]\tvalid_0's multi_logloss: 2.00788\n",
      "[47]\tvalid_0's multi_logloss: 2.00776\n",
      "[48]\tvalid_0's multi_logloss: 2.00764\n",
      "[49]\tvalid_0's multi_logloss: 2.00755\n",
      "[50]\tvalid_0's multi_logloss: 2.00746\n",
      "[51]\tvalid_0's multi_logloss: 2.00736\n",
      "[52]\tvalid_0's multi_logloss: 2.00725\n",
      "[53]\tvalid_0's multi_logloss: 2.00717\n",
      "[54]\tvalid_0's multi_logloss: 2.00709\n",
      "[55]\tvalid_0's multi_logloss: 2.00702\n",
      "[56]\tvalid_0's multi_logloss: 2.00695\n",
      "[57]\tvalid_0's multi_logloss: 2.00687\n",
      "[58]\tvalid_0's multi_logloss: 2.00682\n",
      "[59]\tvalid_0's multi_logloss: 2.00677\n",
      "[60]\tvalid_0's multi_logloss: 2.00671\n",
      "[61]\tvalid_0's multi_logloss: 2.00666\n",
      "[62]\tvalid_0's multi_logloss: 2.0066\n",
      "[63]\tvalid_0's multi_logloss: 2.00655\n",
      "[64]\tvalid_0's multi_logloss: 2.0065\n",
      "[65]\tvalid_0's multi_logloss: 2.00645\n",
      "[66]\tvalid_0's multi_logloss: 2.00639\n",
      "[67]\tvalid_0's multi_logloss: 2.00635\n",
      "[68]\tvalid_0's multi_logloss: 2.00631\n",
      "[69]\tvalid_0's multi_logloss: 2.00627\n",
      "[70]\tvalid_0's multi_logloss: 2.00623\n",
      "[71]\tvalid_0's multi_logloss: 2.00619\n",
      "[72]\tvalid_0's multi_logloss: 2.00615\n",
      "[73]\tvalid_0's multi_logloss: 2.00611\n",
      "[74]\tvalid_0's multi_logloss: 2.00608\n",
      "[75]\tvalid_0's multi_logloss: 2.00604\n",
      "[76]\tvalid_0's multi_logloss: 2.00601\n",
      "[77]\tvalid_0's multi_logloss: 2.00596\n",
      "[78]\tvalid_0's multi_logloss: 2.00594\n",
      "[79]\tvalid_0's multi_logloss: 2.0059\n",
      "[80]\tvalid_0's multi_logloss: 2.00588\n",
      "[81]\tvalid_0's multi_logloss: 2.00585\n",
      "[82]\tvalid_0's multi_logloss: 2.00582\n",
      "[83]\tvalid_0's multi_logloss: 2.0058\n",
      "[84]\tvalid_0's multi_logloss: 2.00577\n",
      "[85]\tvalid_0's multi_logloss: 2.00574\n",
      "[86]\tvalid_0's multi_logloss: 2.00571\n",
      "[87]\tvalid_0's multi_logloss: 2.0057\n",
      "[88]\tvalid_0's multi_logloss: 2.00568\n",
      "[89]\tvalid_0's multi_logloss: 2.00565\n",
      "[90]\tvalid_0's multi_logloss: 2.00563\n",
      "[91]\tvalid_0's multi_logloss: 2.0056\n",
      "[92]\tvalid_0's multi_logloss: 2.00558\n",
      "[93]\tvalid_0's multi_logloss: 2.00557\n",
      "[94]\tvalid_0's multi_logloss: 2.00554\n",
      "[95]\tvalid_0's multi_logloss: 2.00553\n",
      "[96]\tvalid_0's multi_logloss: 2.00551\n",
      "[97]\tvalid_0's multi_logloss: 2.0055\n",
      "[98]\tvalid_0's multi_logloss: 2.00549\n",
      "[99]\tvalid_0's multi_logloss: 2.00547\n",
      "[100]\tvalid_0's multi_logloss: 2.00545\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017744 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.047228\n",
      "[LightGBM] [Info] Start training from score -1.516216\n",
      "[LightGBM] [Info] Start training from score -0.845018\n",
      "[1]\tvalid_0's multi_logloss: 1.01394\n",
      "[2]\tvalid_0's multi_logloss: 0.973512\n",
      "[3]\tvalid_0's multi_logloss: 0.939879\n",
      "[4]\tvalid_0's multi_logloss: 0.911551\n",
      "[5]\tvalid_0's multi_logloss: 0.887457\n",
      "[6]\tvalid_0's multi_logloss: 0.866712\n",
      "[7]\tvalid_0's multi_logloss: 0.848817\n",
      "[8]\tvalid_0's multi_logloss: 0.833269\n",
      "[9]\tvalid_0's multi_logloss: 0.819636\n",
      "[10]\tvalid_0's multi_logloss: 0.807639\n",
      "[11]\tvalid_0's multi_logloss: 0.79702\n",
      "[12]\tvalid_0's multi_logloss: 0.787581\n",
      "[13]\tvalid_0's multi_logloss: 0.779151\n",
      "[14]\tvalid_0's multi_logloss: 0.771595\n",
      "[15]\tvalid_0's multi_logloss: 0.764786\n",
      "[16]\tvalid_0's multi_logloss: 0.758642\n",
      "[17]\tvalid_0's multi_logloss: 0.753076\n",
      "[18]\tvalid_0's multi_logloss: 0.748023\n",
      "[19]\tvalid_0's multi_logloss: 0.743388\n",
      "[20]\tvalid_0's multi_logloss: 0.739164\n",
      "[21]\tvalid_0's multi_logloss: 0.735304\n",
      "[22]\tvalid_0's multi_logloss: 0.731781\n",
      "[23]\tvalid_0's multi_logloss: 0.728533\n",
      "[24]\tvalid_0's multi_logloss: 0.725547\n",
      "[25]\tvalid_0's multi_logloss: 0.722804\n",
      "[26]\tvalid_0's multi_logloss: 0.720275\n",
      "[27]\tvalid_0's multi_logloss: 0.717933\n",
      "[28]\tvalid_0's multi_logloss: 0.715777\n",
      "[29]\tvalid_0's multi_logloss: 0.713783\n",
      "[30]\tvalid_0's multi_logloss: 0.711939\n",
      "[31]\tvalid_0's multi_logloss: 0.71023\n",
      "[32]\tvalid_0's multi_logloss: 0.708646\n",
      "[33]\tvalid_0's multi_logloss: 0.707176\n",
      "[34]\tvalid_0's multi_logloss: 0.705815\n",
      "[35]\tvalid_0's multi_logloss: 0.70455\n",
      "[36]\tvalid_0's multi_logloss: 0.703375\n",
      "[37]\tvalid_0's multi_logloss: 0.702282\n",
      "[38]\tvalid_0's multi_logloss: 0.701268\n",
      "[39]\tvalid_0's multi_logloss: 0.700325\n",
      "[40]\tvalid_0's multi_logloss: 0.699452\n",
      "[41]\tvalid_0's multi_logloss: 0.698632\n",
      "[42]\tvalid_0's multi_logloss: 0.69787\n",
      "[43]\tvalid_0's multi_logloss: 0.697161\n",
      "[44]\tvalid_0's multi_logloss: 0.696499\n",
      "[45]\tvalid_0's multi_logloss: 0.695881\n",
      "[46]\tvalid_0's multi_logloss: 0.695303\n",
      "[47]\tvalid_0's multi_logloss: 0.694767\n",
      "[48]\tvalid_0's multi_logloss: 0.694266\n",
      "[49]\tvalid_0's multi_logloss: 0.693798\n",
      "[50]\tvalid_0's multi_logloss: 0.693366\n",
      "[51]\tvalid_0's multi_logloss: 0.692961\n",
      "[52]\tvalid_0's multi_logloss: 0.692583\n",
      "[53]\tvalid_0's multi_logloss: 0.692227\n",
      "[54]\tvalid_0's multi_logloss: 0.6919\n",
      "[55]\tvalid_0's multi_logloss: 0.691593\n",
      "[56]\tvalid_0's multi_logloss: 0.691306\n",
      "[57]\tvalid_0's multi_logloss: 0.691039\n",
      "[58]\tvalid_0's multi_logloss: 0.69079\n",
      "[59]\tvalid_0's multi_logloss: 0.690557\n",
      "[60]\tvalid_0's multi_logloss: 0.690338\n",
      "[61]\tvalid_0's multi_logloss: 0.690134\n",
      "[62]\tvalid_0's multi_logloss: 0.689939\n",
      "[63]\tvalid_0's multi_logloss: 0.689757\n",
      "[64]\tvalid_0's multi_logloss: 0.689589\n",
      "[65]\tvalid_0's multi_logloss: 0.689429\n",
      "[66]\tvalid_0's multi_logloss: 0.689283\n",
      "[67]\tvalid_0's multi_logloss: 0.689145\n",
      "[68]\tvalid_0's multi_logloss: 0.689017\n",
      "[69]\tvalid_0's multi_logloss: 0.688897\n",
      "[70]\tvalid_0's multi_logloss: 0.688782\n",
      "[71]\tvalid_0's multi_logloss: 0.688676\n",
      "[72]\tvalid_0's multi_logloss: 0.688575\n",
      "[73]\tvalid_0's multi_logloss: 0.688482\n",
      "[74]\tvalid_0's multi_logloss: 0.688395\n",
      "[75]\tvalid_0's multi_logloss: 0.688314\n",
      "[76]\tvalid_0's multi_logloss: 0.688238\n",
      "[77]\tvalid_0's multi_logloss: 0.688167\n",
      "[78]\tvalid_0's multi_logloss: 0.688101\n",
      "[79]\tvalid_0's multi_logloss: 0.688039\n",
      "[80]\tvalid_0's multi_logloss: 0.687982\n",
      "[81]\tvalid_0's multi_logloss: 0.68793\n",
      "[82]\tvalid_0's multi_logloss: 0.68788\n",
      "[83]\tvalid_0's multi_logloss: 0.687834\n",
      "[84]\tvalid_0's multi_logloss: 0.687789\n",
      "[85]\tvalid_0's multi_logloss: 0.687747\n",
      "[86]\tvalid_0's multi_logloss: 0.687708\n",
      "[87]\tvalid_0's multi_logloss: 0.687673\n",
      "[88]\tvalid_0's multi_logloss: 0.687638\n",
      "[89]\tvalid_0's multi_logloss: 0.687604\n",
      "[90]\tvalid_0's multi_logloss: 0.687574\n",
      "[91]\tvalid_0's multi_logloss: 0.687546\n",
      "[92]\tvalid_0's multi_logloss: 0.687519\n",
      "[93]\tvalid_0's multi_logloss: 0.687495\n",
      "[94]\tvalid_0's multi_logloss: 0.687472\n",
      "[95]\tvalid_0's multi_logloss: 0.687451\n",
      "[96]\tvalid_0's multi_logloss: 0.687431\n",
      "[97]\tvalid_0's multi_logloss: 0.68741\n",
      "[98]\tvalid_0's multi_logloss: 0.687392\n",
      "[99]\tvalid_0's multi_logloss: 0.687374\n",
      "[100]\tvalid_0's multi_logloss: 0.687358\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017056 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -3.244539\n",
      "[LightGBM] [Info] Start training from score -3.224920\n",
      "[LightGBM] [Info] Start training from score -3.369880\n",
      "[LightGBM] [Info] Start training from score -3.326941\n",
      "[LightGBM] [Info] Start training from score -3.378266\n",
      "[LightGBM] [Info] Start training from score -2.568017\n",
      "[LightGBM] [Info] Start training from score -1.914747\n",
      "[LightGBM] [Info] Start training from score -3.469579\n",
      "[LightGBM] [Info] Start training from score -1.919436\n",
      "[LightGBM] [Info] Start training from score -2.291576\n",
      "[LightGBM] [Info] Start training from score -2.007538\n",
      "[LightGBM] [Info] Start training from score -3.402200\n",
      "[LightGBM] [Info] Start training from score -3.212376\n",
      "[LightGBM] [Info] Start training from score -2.244521\n",
      "[1]\tvalid_0's multi_logloss: 2.44665\n",
      "[2]\tvalid_0's multi_logloss: 2.43941\n",
      "[3]\tvalid_0's multi_logloss: 2.43359\n",
      "[4]\tvalid_0's multi_logloss: 2.42881\n",
      "[5]\tvalid_0's multi_logloss: 2.42485\n",
      "[6]\tvalid_0's multi_logloss: 2.42159\n",
      "[7]\tvalid_0's multi_logloss: 2.41885\n",
      "[8]\tvalid_0's multi_logloss: 2.41655\n",
      "[9]\tvalid_0's multi_logloss: 2.4146\n",
      "[10]\tvalid_0's multi_logloss: 2.41296\n",
      "[11]\tvalid_0's multi_logloss: 2.41155\n",
      "[12]\tvalid_0's multi_logloss: 2.41036\n",
      "[13]\tvalid_0's multi_logloss: 2.40933\n",
      "[14]\tvalid_0's multi_logloss: 2.40845\n",
      "[15]\tvalid_0's multi_logloss: 2.40769\n",
      "[16]\tvalid_0's multi_logloss: 2.40704\n",
      "[17]\tvalid_0's multi_logloss: 2.40647\n",
      "[18]\tvalid_0's multi_logloss: 2.40596\n",
      "[19]\tvalid_0's multi_logloss: 2.40553\n",
      "[20]\tvalid_0's multi_logloss: 2.40515\n",
      "[21]\tvalid_0's multi_logloss: 2.4048\n",
      "[22]\tvalid_0's multi_logloss: 2.4045\n",
      "[23]\tvalid_0's multi_logloss: 2.40424\n",
      "[24]\tvalid_0's multi_logloss: 2.40401\n",
      "[25]\tvalid_0's multi_logloss: 2.4038\n",
      "[26]\tvalid_0's multi_logloss: 2.40362\n",
      "[27]\tvalid_0's multi_logloss: 2.40346\n",
      "[28]\tvalid_0's multi_logloss: 2.40331\n",
      "[29]\tvalid_0's multi_logloss: 2.40317\n",
      "[30]\tvalid_0's multi_logloss: 2.40305\n",
      "[31]\tvalid_0's multi_logloss: 2.40293\n",
      "[32]\tvalid_0's multi_logloss: 2.40283\n",
      "[33]\tvalid_0's multi_logloss: 2.40275\n",
      "[34]\tvalid_0's multi_logloss: 2.40266\n",
      "[35]\tvalid_0's multi_logloss: 2.40258\n",
      "[36]\tvalid_0's multi_logloss: 2.40251\n",
      "[37]\tvalid_0's multi_logloss: 2.40244\n",
      "[38]\tvalid_0's multi_logloss: 2.40237\n",
      "[39]\tvalid_0's multi_logloss: 2.40231\n",
      "[40]\tvalid_0's multi_logloss: 2.40226\n",
      "[41]\tvalid_0's multi_logloss: 2.40221\n",
      "[42]\tvalid_0's multi_logloss: 2.40217\n",
      "[43]\tvalid_0's multi_logloss: 2.40212\n",
      "[44]\tvalid_0's multi_logloss: 2.40208\n",
      "[45]\tvalid_0's multi_logloss: 2.40204\n",
      "[46]\tvalid_0's multi_logloss: 2.402\n",
      "[47]\tvalid_0's multi_logloss: 2.40197\n",
      "[48]\tvalid_0's multi_logloss: 2.40194\n",
      "[49]\tvalid_0's multi_logloss: 2.40191\n",
      "[50]\tvalid_0's multi_logloss: 2.40188\n",
      "[51]\tvalid_0's multi_logloss: 2.40185\n",
      "[52]\tvalid_0's multi_logloss: 2.40182\n",
      "[53]\tvalid_0's multi_logloss: 2.40179\n",
      "[54]\tvalid_0's multi_logloss: 2.40177\n",
      "[55]\tvalid_0's multi_logloss: 2.40174\n",
      "[56]\tvalid_0's multi_logloss: 2.40172\n",
      "[57]\tvalid_0's multi_logloss: 2.4017\n",
      "[58]\tvalid_0's multi_logloss: 2.40168\n",
      "[59]\tvalid_0's multi_logloss: 2.40166\n",
      "[60]\tvalid_0's multi_logloss: 2.40164\n",
      "[61]\tvalid_0's multi_logloss: 2.40162\n",
      "[62]\tvalid_0's multi_logloss: 2.4016\n",
      "[63]\tvalid_0's multi_logloss: 2.40158\n",
      "[64]\tvalid_0's multi_logloss: 2.40156\n",
      "[65]\tvalid_0's multi_logloss: 2.40155\n",
      "[66]\tvalid_0's multi_logloss: 2.40153\n",
      "[67]\tvalid_0's multi_logloss: 2.40152\n",
      "[68]\tvalid_0's multi_logloss: 2.4015\n",
      "[69]\tvalid_0's multi_logloss: 2.40149\n",
      "[70]\tvalid_0's multi_logloss: 2.40147\n",
      "[71]\tvalid_0's multi_logloss: 2.40146\n",
      "[72]\tvalid_0's multi_logloss: 2.40144\n",
      "[73]\tvalid_0's multi_logloss: 2.40143\n",
      "[74]\tvalid_0's multi_logloss: 2.40142\n",
      "[75]\tvalid_0's multi_logloss: 2.4014\n",
      "[76]\tvalid_0's multi_logloss: 2.40138\n",
      "[77]\tvalid_0's multi_logloss: 2.40136\n",
      "[78]\tvalid_0's multi_logloss: 2.40134\n",
      "[79]\tvalid_0's multi_logloss: 2.40133\n",
      "[80]\tvalid_0's multi_logloss: 2.40132\n",
      "[81]\tvalid_0's multi_logloss: 2.40131\n",
      "[82]\tvalid_0's multi_logloss: 2.40129\n",
      "[83]\tvalid_0's multi_logloss: 2.40128\n",
      "[84]\tvalid_0's multi_logloss: 2.40127\n",
      "[85]\tvalid_0's multi_logloss: 2.40126\n",
      "[86]\tvalid_0's multi_logloss: 2.40124\n",
      "[87]\tvalid_0's multi_logloss: 2.40123\n",
      "[88]\tvalid_0's multi_logloss: 2.40122\n",
      "[89]\tvalid_0's multi_logloss: 2.40121\n",
      "[90]\tvalid_0's multi_logloss: 2.4012\n",
      "[91]\tvalid_0's multi_logloss: 2.40119\n",
      "[92]\tvalid_0's multi_logloss: 2.40118\n",
      "[93]\tvalid_0's multi_logloss: 2.40117\n",
      "[94]\tvalid_0's multi_logloss: 2.40116\n",
      "[95]\tvalid_0's multi_logloss: 2.40115\n",
      "[96]\tvalid_0's multi_logloss: 2.40114\n",
      "[97]\tvalid_0's multi_logloss: 2.40113\n",
      "[98]\tvalid_0's multi_logloss: 2.40111\n",
      "[99]\tvalid_0's multi_logloss: 2.4011\n",
      "[100]\tvalid_0's multi_logloss: 2.40109\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017071 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -0.501622\n",
      "[LightGBM] [Info] Start training from score -0.930257\n",
      "[1]\tvalid_0's multi_logloss: 0.578147\n",
      "[2]\tvalid_0's multi_logloss: 0.503663\n",
      "[3]\tvalid_0's multi_logloss: 0.442061\n",
      "[4]\tvalid_0's multi_logloss: 0.390342\n",
      "[5]\tvalid_0's multi_logloss: 0.346254\n",
      "[6]\tvalid_0's multi_logloss: 0.3084\n",
      "[7]\tvalid_0's multi_logloss: 0.275664\n",
      "[8]\tvalid_0's multi_logloss: 0.247243\n",
      "[9]\tvalid_0's multi_logloss: 0.222254\n",
      "[10]\tvalid_0's multi_logloss: 0.200404\n",
      "[11]\tvalid_0's multi_logloss: 0.181155\n",
      "[12]\tvalid_0's multi_logloss: 0.163956\n",
      "[13]\tvalid_0's multi_logloss: 0.148739\n",
      "[14]\tvalid_0's multi_logloss: 0.135203\n",
      "[15]\tvalid_0's multi_logloss: 0.123126\n",
      "[16]\tvalid_0's multi_logloss: 0.112364\n",
      "[17]\tvalid_0's multi_logloss: 0.102753\n",
      "[18]\tvalid_0's multi_logloss: 0.0941563\n",
      "[19]\tvalid_0's multi_logloss: 0.0864547\n",
      "[20]\tvalid_0's multi_logloss: 0.0795558\n",
      "[21]\tvalid_0's multi_logloss: 0.0733642\n",
      "[22]\tvalid_0's multi_logloss: 0.0678105\n",
      "[23]\tvalid_0's multi_logloss: 0.0628195\n",
      "[24]\tvalid_0's multi_logloss: 0.0583249\n",
      "[25]\tvalid_0's multi_logloss: 0.0542832\n",
      "[26]\tvalid_0's multi_logloss: 0.0506558\n",
      "[27]\tvalid_0's multi_logloss: 0.0473873\n",
      "[28]\tvalid_0's multi_logloss: 0.0444437\n",
      "[29]\tvalid_0's multi_logloss: 0.0417866\n",
      "[30]\tvalid_0's multi_logloss: 0.0393955\n",
      "[31]\tvalid_0's multi_logloss: 0.0372324\n",
      "[32]\tvalid_0's multi_logloss: 0.0352745\n",
      "[33]\tvalid_0's multi_logloss: 0.0335156\n",
      "[34]\tvalid_0's multi_logloss: 0.0319287\n",
      "[35]\tvalid_0's multi_logloss: 0.0304941\n",
      "[36]\tvalid_0's multi_logloss: 0.0291975\n",
      "[37]\tvalid_0's multi_logloss: 0.0280302\n",
      "[38]\tvalid_0's multi_logloss: 0.026974\n",
      "[39]\tvalid_0's multi_logloss: 0.0260176\n",
      "[40]\tvalid_0's multi_logloss: 0.0251504\n",
      "[41]\tvalid_0's multi_logloss: 0.0243668\n",
      "[42]\tvalid_0's multi_logloss: 0.023662\n",
      "[43]\tvalid_0's multi_logloss: 0.0230252\n",
      "[44]\tvalid_0's multi_logloss: 0.0224496\n",
      "[45]\tvalid_0's multi_logloss: 0.0219289\n",
      "[46]\tvalid_0's multi_logloss: 0.0214563\n",
      "[47]\tvalid_0's multi_logloss: 0.0210297\n",
      "[48]\tvalid_0's multi_logloss: 0.0206438\n",
      "[49]\tvalid_0's multi_logloss: 0.0202921\n",
      "[50]\tvalid_0's multi_logloss: 0.0199747\n",
      "[51]\tvalid_0's multi_logloss: 0.0196874\n",
      "[52]\tvalid_0's multi_logloss: 0.0194287\n",
      "[53]\tvalid_0's multi_logloss: 0.0191955\n",
      "[54]\tvalid_0's multi_logloss: 0.0189837\n",
      "[55]\tvalid_0's multi_logloss: 0.0187898\n",
      "[56]\tvalid_0's multi_logloss: 0.0186153\n",
      "[57]\tvalid_0's multi_logloss: 0.0184581\n",
      "[58]\tvalid_0's multi_logloss: 0.0183159\n",
      "[59]\tvalid_0's multi_logloss: 0.0181855\n",
      "[60]\tvalid_0's multi_logloss: 0.0180697\n",
      "[61]\tvalid_0's multi_logloss: 0.017965\n",
      "[62]\tvalid_0's multi_logloss: 0.0178693\n",
      "[63]\tvalid_0's multi_logloss: 0.0177828\n",
      "[64]\tvalid_0's multi_logloss: 0.0177043\n",
      "[65]\tvalid_0's multi_logloss: 0.0176336\n",
      "[66]\tvalid_0's multi_logloss: 0.0175671\n",
      "[67]\tvalid_0's multi_logloss: 0.0175089\n",
      "[68]\tvalid_0's multi_logloss: 0.0174529\n",
      "[69]\tvalid_0's multi_logloss: 0.0174029\n",
      "[70]\tvalid_0's multi_logloss: 0.0173579\n",
      "[71]\tvalid_0's multi_logloss: 0.0173161\n",
      "[72]\tvalid_0's multi_logloss: 0.0172792\n",
      "[73]\tvalid_0's multi_logloss: 0.0172455\n",
      "[74]\tvalid_0's multi_logloss: 0.0172162\n",
      "[75]\tvalid_0's multi_logloss: 0.0171866\n",
      "[76]\tvalid_0's multi_logloss: 0.0171616\n",
      "[77]\tvalid_0's multi_logloss: 0.0171396\n",
      "[78]\tvalid_0's multi_logloss: 0.017118\n",
      "[79]\tvalid_0's multi_logloss: 0.0170988\n",
      "[80]\tvalid_0's multi_logloss: 0.0170801\n",
      "[81]\tvalid_0's multi_logloss: 0.0170636\n",
      "[82]\tvalid_0's multi_logloss: 0.0170489\n",
      "[83]\tvalid_0's multi_logloss: 0.017035\n",
      "[84]\tvalid_0's multi_logloss: 0.0170241\n",
      "[85]\tvalid_0's multi_logloss: 0.0170235\n",
      "[86]\tvalid_0's multi_logloss: 0.0170037\n",
      "[87]\tvalid_0's multi_logloss: 0.0169926\n",
      "[88]\tvalid_0's multi_logloss: 0.0169829\n",
      "[89]\tvalid_0's multi_logloss: 0.0169742\n",
      "[90]\tvalid_0's multi_logloss: 0.0169667\n",
      "[91]\tvalid_0's multi_logloss: 0.0169596\n",
      "[92]\tvalid_0's multi_logloss: 0.0169541\n",
      "[93]\tvalid_0's multi_logloss: 0.0169488\n",
      "[94]\tvalid_0's multi_logloss: 0.0169416\n",
      "[95]\tvalid_0's multi_logloss: 0.0169366\n",
      "[96]\tvalid_0's multi_logloss: 0.0169323\n",
      "[97]\tvalid_0's multi_logloss: 0.0169285\n",
      "[98]\tvalid_0's multi_logloss: 0.0169243\n",
      "[99]\tvalid_0's multi_logloss: 0.0169219\n",
      "[100]\tvalid_0's multi_logloss: 0.0169174\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016611 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -0.141837\n",
      "[LightGBM] [Info] Start training from score -2.023158\n",
      "[1]\tvalid_0's multi_logloss: 0.385143\n",
      "[2]\tvalid_0's multi_logloss: 0.380835\n",
      "[3]\tvalid_0's multi_logloss: 0.377389\n",
      "[4]\tvalid_0's multi_logloss: 0.374514\n",
      "[5]\tvalid_0's multi_logloss: 0.372135\n",
      "[6]\tvalid_0's multi_logloss: 0.370163\n",
      "[7]\tvalid_0's multi_logloss: 0.36852\n",
      "[8]\tvalid_0's multi_logloss: 0.367084\n",
      "[9]\tvalid_0's multi_logloss: 0.36588\n",
      "[10]\tvalid_0's multi_logloss: 0.364822\n",
      "[11]\tvalid_0's multi_logloss: 0.363924\n",
      "[12]\tvalid_0's multi_logloss: 0.363154\n",
      "[13]\tvalid_0's multi_logloss: 0.362484\n",
      "[14]\tvalid_0's multi_logloss: 0.36193\n",
      "[15]\tvalid_0's multi_logloss: 0.361425\n",
      "[16]\tvalid_0's multi_logloss: 0.360988\n",
      "[17]\tvalid_0's multi_logloss: 0.360619\n",
      "[18]\tvalid_0's multi_logloss: 0.360286\n",
      "[19]\tvalid_0's multi_logloss: 0.359986\n",
      "[20]\tvalid_0's multi_logloss: 0.359711\n",
      "[21]\tvalid_0's multi_logloss: 0.359473\n",
      "[22]\tvalid_0's multi_logloss: 0.359267\n",
      "[23]\tvalid_0's multi_logloss: 0.359089\n",
      "[24]\tvalid_0's multi_logloss: 0.358925\n",
      "[25]\tvalid_0's multi_logloss: 0.358777\n",
      "[26]\tvalid_0's multi_logloss: 0.358653\n",
      "[27]\tvalid_0's multi_logloss: 0.358549\n",
      "[28]\tvalid_0's multi_logloss: 0.358444\n",
      "[29]\tvalid_0's multi_logloss: 0.358355\n",
      "[30]\tvalid_0's multi_logloss: 0.358276\n",
      "[31]\tvalid_0's multi_logloss: 0.358199\n",
      "[32]\tvalid_0's multi_logloss: 0.35814\n",
      "[33]\tvalid_0's multi_logloss: 0.358076\n",
      "[34]\tvalid_0's multi_logloss: 0.358032\n",
      "[35]\tvalid_0's multi_logloss: 0.357976\n",
      "[36]\tvalid_0's multi_logloss: 0.357931\n",
      "[37]\tvalid_0's multi_logloss: 0.35789\n",
      "[38]\tvalid_0's multi_logloss: 0.357856\n",
      "[39]\tvalid_0's multi_logloss: 0.357824\n",
      "[40]\tvalid_0's multi_logloss: 0.357794\n",
      "[41]\tvalid_0's multi_logloss: 0.357755\n",
      "[42]\tvalid_0's multi_logloss: 0.357731\n",
      "[43]\tvalid_0's multi_logloss: 0.357708\n",
      "[44]\tvalid_0's multi_logloss: 0.357687\n",
      "[45]\tvalid_0's multi_logloss: 0.357653\n",
      "[46]\tvalid_0's multi_logloss: 0.357634\n",
      "[47]\tvalid_0's multi_logloss: 0.35761\n",
      "[48]\tvalid_0's multi_logloss: 0.357596\n",
      "[49]\tvalid_0's multi_logloss: 0.357583\n",
      "[50]\tvalid_0's multi_logloss: 0.35756\n",
      "[51]\tvalid_0's multi_logloss: 0.357549\n",
      "[52]\tvalid_0's multi_logloss: 0.357535\n",
      "[53]\tvalid_0's multi_logloss: 0.35752\n",
      "[54]\tvalid_0's multi_logloss: 0.357502\n",
      "[55]\tvalid_0's multi_logloss: 0.357487\n",
      "[56]\tvalid_0's multi_logloss: 0.357475\n",
      "[57]\tvalid_0's multi_logloss: 0.357463\n",
      "[58]\tvalid_0's multi_logloss: 0.357449\n",
      "[59]\tvalid_0's multi_logloss: 0.35744\n",
      "[60]\tvalid_0's multi_logloss: 0.357434\n",
      "[61]\tvalid_0's multi_logloss: 0.357426\n",
      "[62]\tvalid_0's multi_logloss: 0.357416\n",
      "[63]\tvalid_0's multi_logloss: 0.357407\n",
      "[64]\tvalid_0's multi_logloss: 0.357397\n",
      "[65]\tvalid_0's multi_logloss: 0.357388\n",
      "[66]\tvalid_0's multi_logloss: 0.357381\n",
      "[67]\tvalid_0's multi_logloss: 0.357373\n",
      "[68]\tvalid_0's multi_logloss: 0.357368\n",
      "[69]\tvalid_0's multi_logloss: 0.357362\n",
      "[70]\tvalid_0's multi_logloss: 0.357352\n",
      "[71]\tvalid_0's multi_logloss: 0.357348\n",
      "[72]\tvalid_0's multi_logloss: 0.357342\n",
      "[73]\tvalid_0's multi_logloss: 0.357339\n",
      "[74]\tvalid_0's multi_logloss: 0.357329\n",
      "[75]\tvalid_0's multi_logloss: 0.357324\n",
      "[76]\tvalid_0's multi_logloss: 0.357321\n",
      "[77]\tvalid_0's multi_logloss: 0.357313\n",
      "[78]\tvalid_0's multi_logloss: 0.357307\n",
      "[79]\tvalid_0's multi_logloss: 0.3573\n",
      "[80]\tvalid_0's multi_logloss: 0.357296\n",
      "[81]\tvalid_0's multi_logloss: 0.357292\n",
      "[82]\tvalid_0's multi_logloss: 0.357286\n",
      "[83]\tvalid_0's multi_logloss: 0.357283\n",
      "[84]\tvalid_0's multi_logloss: 0.357278\n",
      "[85]\tvalid_0's multi_logloss: 0.357274\n",
      "[86]\tvalid_0's multi_logloss: 0.357269\n",
      "[87]\tvalid_0's multi_logloss: 0.357266\n",
      "[88]\tvalid_0's multi_logloss: 0.357263\n",
      "[89]\tvalid_0's multi_logloss: 0.35726\n",
      "[90]\tvalid_0's multi_logloss: 0.357253\n",
      "[91]\tvalid_0's multi_logloss: 0.357252\n",
      "[92]\tvalid_0's multi_logloss: 0.35725\n",
      "[93]\tvalid_0's multi_logloss: 0.357247\n",
      "[94]\tvalid_0's multi_logloss: 0.357243\n",
      "[95]\tvalid_0's multi_logloss: 0.357241\n",
      "[96]\tvalid_0's multi_logloss: 0.35724\n",
      "[97]\tvalid_0's multi_logloss: 0.357236\n",
      "[98]\tvalid_0's multi_logloss: 0.357234\n",
      "[99]\tvalid_0's multi_logloss: 0.357231\n",
      "[100]\tvalid_0's multi_logloss: 0.357228\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -1.853404\n",
      "[LightGBM] [Info] Start training from score -2.123202\n",
      "[LightGBM] [Info] Start training from score -2.391862\n",
      "[LightGBM] [Info] Start training from score -2.719639\n",
      "[LightGBM] [Info] Start training from score -2.078311\n",
      "[LightGBM] [Info] Start training from score -2.161447\n",
      "[LightGBM] [Info] Start training from score -2.497610\n",
      "[LightGBM] [Info] Start training from score -2.232530\n",
      "[LightGBM] [Info] Start training from score -2.689447\n",
      "[LightGBM] [Info] Start training from score -2.680407\n",
      "[1]\tvalid_0's multi_logloss: 2.16028\n",
      "[2]\tvalid_0's multi_logloss: 2.08944\n",
      "[3]\tvalid_0's multi_logloss: 2.03563\n",
      "[4]\tvalid_0's multi_logloss: 1.99294\n",
      "[5]\tvalid_0's multi_logloss: 1.95818\n",
      "[6]\tvalid_0's multi_logloss: 1.9293\n",
      "[7]\tvalid_0's multi_logloss: 1.90497\n",
      "[8]\tvalid_0's multi_logloss: 1.8844\n",
      "[9]\tvalid_0's multi_logloss: 1.86688\n",
      "[10]\tvalid_0's multi_logloss: 1.85181\n",
      "[11]\tvalid_0's multi_logloss: 1.83865\n",
      "[12]\tvalid_0's multi_logloss: 1.82732\n",
      "[13]\tvalid_0's multi_logloss: 1.81718\n",
      "[14]\tvalid_0's multi_logloss: 1.80836\n",
      "[15]\tvalid_0's multi_logloss: 1.80066\n",
      "[16]\tvalid_0's multi_logloss: 1.79399\n",
      "[17]\tvalid_0's multi_logloss: 1.788\n",
      "[18]\tvalid_0's multi_logloss: 1.78249\n",
      "[19]\tvalid_0's multi_logloss: 1.77759\n",
      "[20]\tvalid_0's multi_logloss: 1.77309\n",
      "[21]\tvalid_0's multi_logloss: 1.76906\n",
      "[22]\tvalid_0's multi_logloss: 1.76555\n",
      "[23]\tvalid_0's multi_logloss: 1.76238\n",
      "[24]\tvalid_0's multi_logloss: 1.75951\n",
      "[25]\tvalid_0's multi_logloss: 1.75686\n",
      "[26]\tvalid_0's multi_logloss: 1.75434\n",
      "[27]\tvalid_0's multi_logloss: 1.75212\n",
      "[28]\tvalid_0's multi_logloss: 1.75014\n",
      "[29]\tvalid_0's multi_logloss: 1.74825\n",
      "[30]\tvalid_0's multi_logloss: 1.74656\n",
      "[31]\tvalid_0's multi_logloss: 1.74498\n",
      "[32]\tvalid_0's multi_logloss: 1.74366\n",
      "[33]\tvalid_0's multi_logloss: 1.74221\n",
      "[34]\tvalid_0's multi_logloss: 1.74092\n",
      "[35]\tvalid_0's multi_logloss: 1.73982\n",
      "[36]\tvalid_0's multi_logloss: 1.73878\n",
      "[37]\tvalid_0's multi_logloss: 1.73775\n",
      "[38]\tvalid_0's multi_logloss: 1.73677\n",
      "[39]\tvalid_0's multi_logloss: 1.73588\n",
      "[40]\tvalid_0's multi_logloss: 1.73502\n",
      "[41]\tvalid_0's multi_logloss: 1.73415\n",
      "[42]\tvalid_0's multi_logloss: 1.73333\n",
      "[43]\tvalid_0's multi_logloss: 1.73255\n",
      "[44]\tvalid_0's multi_logloss: 1.73191\n",
      "[45]\tvalid_0's multi_logloss: 1.73121\n",
      "[46]\tvalid_0's multi_logloss: 1.7306\n",
      "[47]\tvalid_0's multi_logloss: 1.73003\n",
      "[48]\tvalid_0's multi_logloss: 1.72949\n",
      "[49]\tvalid_0's multi_logloss: 1.72896\n",
      "[50]\tvalid_0's multi_logloss: 1.72849\n",
      "[51]\tvalid_0's multi_logloss: 1.72801\n",
      "[52]\tvalid_0's multi_logloss: 1.7275\n",
      "[53]\tvalid_0's multi_logloss: 1.72702\n",
      "[54]\tvalid_0's multi_logloss: 1.72663\n",
      "[55]\tvalid_0's multi_logloss: 1.72622\n",
      "[56]\tvalid_0's multi_logloss: 1.72586\n",
      "[57]\tvalid_0's multi_logloss: 1.72555\n",
      "[58]\tvalid_0's multi_logloss: 1.72521\n",
      "[59]\tvalid_0's multi_logloss: 1.72491\n",
      "[60]\tvalid_0's multi_logloss: 1.72462\n",
      "[61]\tvalid_0's multi_logloss: 1.72433\n",
      "[62]\tvalid_0's multi_logloss: 1.72404\n",
      "[63]\tvalid_0's multi_logloss: 1.72373\n",
      "[64]\tvalid_0's multi_logloss: 1.7235\n",
      "[65]\tvalid_0's multi_logloss: 1.72324\n",
      "[66]\tvalid_0's multi_logloss: 1.72296\n",
      "[67]\tvalid_0's multi_logloss: 1.72273\n",
      "[68]\tvalid_0's multi_logloss: 1.72249\n",
      "[69]\tvalid_0's multi_logloss: 1.72225\n",
      "[70]\tvalid_0's multi_logloss: 1.72198\n",
      "[71]\tvalid_0's multi_logloss: 1.72178\n",
      "[72]\tvalid_0's multi_logloss: 1.72158\n",
      "[73]\tvalid_0's multi_logloss: 1.72137\n",
      "[74]\tvalid_0's multi_logloss: 1.72121\n",
      "[75]\tvalid_0's multi_logloss: 1.72101\n",
      "[76]\tvalid_0's multi_logloss: 1.72084\n",
      "[77]\tvalid_0's multi_logloss: 1.72067\n",
      "[78]\tvalid_0's multi_logloss: 1.72048\n",
      "[79]\tvalid_0's multi_logloss: 1.72028\n",
      "[80]\tvalid_0's multi_logloss: 1.72012\n",
      "[81]\tvalid_0's multi_logloss: 1.71998\n",
      "[82]\tvalid_0's multi_logloss: 1.71989\n",
      "[83]\tvalid_0's multi_logloss: 1.71973\n",
      "[84]\tvalid_0's multi_logloss: 1.71958\n",
      "[85]\tvalid_0's multi_logloss: 1.71946\n",
      "[86]\tvalid_0's multi_logloss: 1.71936\n",
      "[87]\tvalid_0's multi_logloss: 1.71922\n",
      "[88]\tvalid_0's multi_logloss: 1.71906\n",
      "[89]\tvalid_0's multi_logloss: 1.71894\n",
      "[90]\tvalid_0's multi_logloss: 1.71881\n",
      "[91]\tvalid_0's multi_logloss: 1.71871\n",
      "[92]\tvalid_0's multi_logloss: 1.71857\n",
      "[93]\tvalid_0's multi_logloss: 1.71843\n",
      "[94]\tvalid_0's multi_logloss: 1.7183\n",
      "[95]\tvalid_0's multi_logloss: 1.7182\n",
      "[96]\tvalid_0's multi_logloss: 1.71809\n",
      "[97]\tvalid_0's multi_logloss: 1.71798\n",
      "[98]\tvalid_0's multi_logloss: 1.71787\n",
      "[99]\tvalid_0's multi_logloss: 1.71775\n",
      "[100]\tvalid_0's multi_logloss: 1.71766\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023254 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -1.047228\n",
      "[LightGBM] [Info] Start training from score -1.516216\n",
      "[LightGBM] [Info] Start training from score -0.845018\n",
      "[1]\tvalid_0's multi_logloss: 1.01344\n",
      "[2]\tvalid_0's multi_logloss: 0.972657\n",
      "[3]\tvalid_0's multi_logloss: 0.938674\n",
      "[4]\tvalid_0's multi_logloss: 0.909958\n",
      "[5]\tvalid_0's multi_logloss: 0.885513\n",
      "[6]\tvalid_0's multi_logloss: 0.864499\n",
      "[7]\tvalid_0's multi_logloss: 0.846329\n",
      "[8]\tvalid_0's multi_logloss: 0.83045\n",
      "[9]\tvalid_0's multi_logloss: 0.81657\n",
      "[10]\tvalid_0's multi_logloss: 0.804289\n",
      "[11]\tvalid_0's multi_logloss: 0.793456\n",
      "[12]\tvalid_0's multi_logloss: 0.783807\n",
      "[13]\tvalid_0's multi_logloss: 0.775176\n",
      "[14]\tvalid_0's multi_logloss: 0.76741\n",
      "[15]\tvalid_0's multi_logloss: 0.760438\n",
      "[16]\tvalid_0's multi_logloss: 0.754137\n",
      "[17]\tvalid_0's multi_logloss: 0.748424\n",
      "[18]\tvalid_0's multi_logloss: 0.743243\n",
      "[19]\tvalid_0's multi_logloss: 0.738513\n",
      "[20]\tvalid_0's multi_logloss: 0.734177\n",
      "[21]\tvalid_0's multi_logloss: 0.730226\n",
      "[22]\tvalid_0's multi_logloss: 0.726582\n",
      "[23]\tvalid_0's multi_logloss: 0.723243\n",
      "[24]\tvalid_0's multi_logloss: 0.720168\n",
      "[25]\tvalid_0's multi_logloss: 0.717313\n",
      "[26]\tvalid_0's multi_logloss: 0.714685\n",
      "[27]\tvalid_0's multi_logloss: 0.712275\n",
      "[28]\tvalid_0's multi_logloss: 0.710051\n",
      "[29]\tvalid_0's multi_logloss: 0.707962\n",
      "[30]\tvalid_0's multi_logloss: 0.706047\n",
      "[31]\tvalid_0's multi_logloss: 0.704228\n",
      "[32]\tvalid_0's multi_logloss: 0.702572\n",
      "[33]\tvalid_0's multi_logloss: 0.701026\n",
      "[34]\tvalid_0's multi_logloss: 0.6996\n",
      "[35]\tvalid_0's multi_logloss: 0.698247\n",
      "[36]\tvalid_0's multi_logloss: 0.696998\n",
      "[37]\tvalid_0's multi_logloss: 0.69584\n",
      "[38]\tvalid_0's multi_logloss: 0.69475\n",
      "[39]\tvalid_0's multi_logloss: 0.693737\n",
      "[40]\tvalid_0's multi_logloss: 0.692787\n",
      "[41]\tvalid_0's multi_logloss: 0.691899\n",
      "[42]\tvalid_0's multi_logloss: 0.691068\n",
      "[43]\tvalid_0's multi_logloss: 0.690295\n",
      "[44]\tvalid_0's multi_logloss: 0.68957\n",
      "[45]\tvalid_0's multi_logloss: 0.688895\n",
      "[46]\tvalid_0's multi_logloss: 0.688266\n",
      "[47]\tvalid_0's multi_logloss: 0.68768\n",
      "[48]\tvalid_0's multi_logloss: 0.68714\n",
      "[49]\tvalid_0's multi_logloss: 0.686621\n",
      "[50]\tvalid_0's multi_logloss: 0.686127\n",
      "[51]\tvalid_0's multi_logloss: 0.685664\n",
      "[52]\tvalid_0's multi_logloss: 0.685242\n",
      "[53]\tvalid_0's multi_logloss: 0.684849\n",
      "[54]\tvalid_0's multi_logloss: 0.684486\n",
      "[55]\tvalid_0's multi_logloss: 0.684148\n",
      "[56]\tvalid_0's multi_logloss: 0.683797\n",
      "[57]\tvalid_0's multi_logloss: 0.683489\n",
      "[58]\tvalid_0's multi_logloss: 0.683197\n",
      "[59]\tvalid_0's multi_logloss: 0.682933\n",
      "[60]\tvalid_0's multi_logloss: 0.682675\n",
      "[61]\tvalid_0's multi_logloss: 0.682435\n",
      "[62]\tvalid_0's multi_logloss: 0.682217\n",
      "[63]\tvalid_0's multi_logloss: 0.681992\n",
      "[64]\tvalid_0's multi_logloss: 0.681799\n",
      "[65]\tvalid_0's multi_logloss: 0.681623\n",
      "[66]\tvalid_0's multi_logloss: 0.681458\n",
      "[67]\tvalid_0's multi_logloss: 0.68129\n",
      "[68]\tvalid_0's multi_logloss: 0.681143\n",
      "[69]\tvalid_0's multi_logloss: 0.680998\n",
      "[70]\tvalid_0's multi_logloss: 0.680861\n",
      "[71]\tvalid_0's multi_logloss: 0.680713\n",
      "[72]\tvalid_0's multi_logloss: 0.680598\n",
      "[73]\tvalid_0's multi_logloss: 0.680468\n",
      "[74]\tvalid_0's multi_logloss: 0.680356\n",
      "[75]\tvalid_0's multi_logloss: 0.680248\n",
      "[76]\tvalid_0's multi_logloss: 0.680143\n",
      "[77]\tvalid_0's multi_logloss: 0.680048\n",
      "[78]\tvalid_0's multi_logloss: 0.679963\n",
      "[79]\tvalid_0's multi_logloss: 0.679879\n",
      "[80]\tvalid_0's multi_logloss: 0.679798\n",
      "[81]\tvalid_0's multi_logloss: 0.679724\n",
      "[82]\tvalid_0's multi_logloss: 0.679659\n",
      "[83]\tvalid_0's multi_logloss: 0.679594\n",
      "[84]\tvalid_0's multi_logloss: 0.679539\n",
      "[85]\tvalid_0's multi_logloss: 0.679484\n",
      "[86]\tvalid_0's multi_logloss: 0.679432\n",
      "[87]\tvalid_0's multi_logloss: 0.679379\n",
      "[88]\tvalid_0's multi_logloss: 0.679325\n",
      "[89]\tvalid_0's multi_logloss: 0.679286\n",
      "[90]\tvalid_0's multi_logloss: 0.679226\n",
      "[91]\tvalid_0's multi_logloss: 0.679183\n",
      "[92]\tvalid_0's multi_logloss: 0.679144\n",
      "[93]\tvalid_0's multi_logloss: 0.679093\n",
      "[94]\tvalid_0's multi_logloss: 0.679054\n",
      "[95]\tvalid_0's multi_logloss: 0.679028\n",
      "[96]\tvalid_0's multi_logloss: 0.678993\n",
      "[97]\tvalid_0's multi_logloss: 0.678962\n",
      "[98]\tvalid_0's multi_logloss: 0.678931\n",
      "[99]\tvalid_0's multi_logloss: 0.678906\n",
      "[100]\tvalid_0's multi_logloss: 0.678865\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025137 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -3.244539\n",
      "[LightGBM] [Info] Start training from score -3.224920\n",
      "[LightGBM] [Info] Start training from score -3.369880\n",
      "[LightGBM] [Info] Start training from score -3.326941\n",
      "[LightGBM] [Info] Start training from score -3.378266\n",
      "[LightGBM] [Info] Start training from score -2.568017\n",
      "[LightGBM] [Info] Start training from score -1.914747\n",
      "[LightGBM] [Info] Start training from score -3.469579\n",
      "[LightGBM] [Info] Start training from score -1.919436\n",
      "[LightGBM] [Info] Start training from score -2.291576\n",
      "[LightGBM] [Info] Start training from score -2.007538\n",
      "[LightGBM] [Info] Start training from score -3.402200\n",
      "[LightGBM] [Info] Start training from score -3.212376\n",
      "[LightGBM] [Info] Start training from score -2.244521\n",
      "[1]\tvalid_0's multi_logloss: 2.44224\n",
      "[2]\tvalid_0's multi_logloss: 2.43152\n",
      "[3]\tvalid_0's multi_logloss: 2.42287\n",
      "[4]\tvalid_0's multi_logloss: 2.41577\n",
      "[5]\tvalid_0's multi_logloss: 2.40982\n",
      "[6]\tvalid_0's multi_logloss: 2.4047\n",
      "[7]\tvalid_0's multi_logloss: 2.40025\n",
      "[8]\tvalid_0's multi_logloss: 2.39656\n",
      "[9]\tvalid_0's multi_logloss: 2.39335\n",
      "[10]\tvalid_0's multi_logloss: 2.39058\n",
      "[11]\tvalid_0's multi_logloss: 2.38816\n",
      "[12]\tvalid_0's multi_logloss: 2.38607\n",
      "[13]\tvalid_0's multi_logloss: 2.38421\n",
      "[14]\tvalid_0's multi_logloss: 2.38256\n",
      "[15]\tvalid_0's multi_logloss: 2.38103\n",
      "[16]\tvalid_0's multi_logloss: 2.37969\n",
      "[17]\tvalid_0's multi_logloss: 2.3785\n",
      "[18]\tvalid_0's multi_logloss: 2.3774\n",
      "[19]\tvalid_0's multi_logloss: 2.37645\n",
      "[20]\tvalid_0's multi_logloss: 2.37561\n",
      "[21]\tvalid_0's multi_logloss: 2.37482\n",
      "[22]\tvalid_0's multi_logloss: 2.37407\n",
      "[23]\tvalid_0's multi_logloss: 2.37341\n",
      "[24]\tvalid_0's multi_logloss: 2.3728\n",
      "[25]\tvalid_0's multi_logloss: 2.3722\n",
      "[26]\tvalid_0's multi_logloss: 2.37166\n",
      "[27]\tvalid_0's multi_logloss: 2.37117\n",
      "[28]\tvalid_0's multi_logloss: 2.37073\n",
      "[29]\tvalid_0's multi_logloss: 2.37029\n",
      "[30]\tvalid_0's multi_logloss: 2.36988\n",
      "[31]\tvalid_0's multi_logloss: 2.36954\n",
      "[32]\tvalid_0's multi_logloss: 2.3692\n",
      "[33]\tvalid_0's multi_logloss: 2.36882\n",
      "[34]\tvalid_0's multi_logloss: 2.36851\n",
      "[35]\tvalid_0's multi_logloss: 2.36818\n",
      "[36]\tvalid_0's multi_logloss: 2.36786\n",
      "[37]\tvalid_0's multi_logloss: 2.36758\n",
      "[38]\tvalid_0's multi_logloss: 2.36732\n",
      "[39]\tvalid_0's multi_logloss: 2.3671\n",
      "[40]\tvalid_0's multi_logloss: 2.36687\n",
      "[41]\tvalid_0's multi_logloss: 2.36663\n",
      "[42]\tvalid_0's multi_logloss: 2.36642\n",
      "[43]\tvalid_0's multi_logloss: 2.36623\n",
      "[44]\tvalid_0's multi_logloss: 2.36606\n",
      "[45]\tvalid_0's multi_logloss: 2.36587\n",
      "[46]\tvalid_0's multi_logloss: 2.36571\n",
      "[47]\tvalid_0's multi_logloss: 2.36554\n",
      "[48]\tvalid_0's multi_logloss: 2.3654\n",
      "[49]\tvalid_0's multi_logloss: 2.36527\n",
      "[50]\tvalid_0's multi_logloss: 2.36513\n",
      "[51]\tvalid_0's multi_logloss: 2.365\n",
      "[52]\tvalid_0's multi_logloss: 2.36485\n",
      "[53]\tvalid_0's multi_logloss: 2.36472\n",
      "[54]\tvalid_0's multi_logloss: 2.36461\n",
      "[55]\tvalid_0's multi_logloss: 2.36449\n",
      "[56]\tvalid_0's multi_logloss: 2.36439\n",
      "[57]\tvalid_0's multi_logloss: 2.36429\n",
      "[58]\tvalid_0's multi_logloss: 2.3642\n",
      "[59]\tvalid_0's multi_logloss: 2.3641\n",
      "[60]\tvalid_0's multi_logloss: 2.364\n",
      "[61]\tvalid_0's multi_logloss: 2.3639\n",
      "[62]\tvalid_0's multi_logloss: 2.3638\n",
      "[63]\tvalid_0's multi_logloss: 2.36373\n",
      "[64]\tvalid_0's multi_logloss: 2.36365\n",
      "[65]\tvalid_0's multi_logloss: 2.36358\n",
      "[66]\tvalid_0's multi_logloss: 2.3635\n",
      "[67]\tvalid_0's multi_logloss: 2.36341\n",
      "[68]\tvalid_0's multi_logloss: 2.36335\n",
      "[69]\tvalid_0's multi_logloss: 2.36329\n",
      "[70]\tvalid_0's multi_logloss: 2.3632\n",
      "[71]\tvalid_0's multi_logloss: 2.36313\n",
      "[72]\tvalid_0's multi_logloss: 2.36305\n",
      "[73]\tvalid_0's multi_logloss: 2.36296\n",
      "[74]\tvalid_0's multi_logloss: 2.36291\n",
      "[75]\tvalid_0's multi_logloss: 2.36283\n",
      "[76]\tvalid_0's multi_logloss: 2.36276\n",
      "[77]\tvalid_0's multi_logloss: 2.36268\n",
      "[78]\tvalid_0's multi_logloss: 2.36259\n",
      "[79]\tvalid_0's multi_logloss: 2.36253\n",
      "[80]\tvalid_0's multi_logloss: 2.36245\n",
      "[81]\tvalid_0's multi_logloss: 2.36239\n",
      "[82]\tvalid_0's multi_logloss: 2.36232\n",
      "[83]\tvalid_0's multi_logloss: 2.36226\n",
      "[84]\tvalid_0's multi_logloss: 2.36221\n",
      "[85]\tvalid_0's multi_logloss: 2.36216\n",
      "[86]\tvalid_0's multi_logloss: 2.3621\n",
      "[87]\tvalid_0's multi_logloss: 2.36206\n",
      "[88]\tvalid_0's multi_logloss: 2.362\n",
      "[89]\tvalid_0's multi_logloss: 2.36194\n",
      "[90]\tvalid_0's multi_logloss: 2.3619\n",
      "[91]\tvalid_0's multi_logloss: 2.36185\n",
      "[92]\tvalid_0's multi_logloss: 2.36182\n",
      "[93]\tvalid_0's multi_logloss: 2.36177\n",
      "[94]\tvalid_0's multi_logloss: 2.36171\n",
      "[95]\tvalid_0's multi_logloss: 2.36167\n",
      "[96]\tvalid_0's multi_logloss: 2.36163\n",
      "[97]\tvalid_0's multi_logloss: 2.36157\n",
      "[98]\tvalid_0's multi_logloss: 2.36152\n",
      "[99]\tvalid_0's multi_logloss: 2.36148\n",
      "[100]\tvalid_0's multi_logloss: 2.36145\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025884 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -0.501622\n",
      "[LightGBM] [Info] Start training from score -0.930257\n",
      "[1]\tvalid_0's multi_logloss: 0.577905\n",
      "[2]\tvalid_0's multi_logloss: 0.5033\n",
      "[3]\tvalid_0's multi_logloss: 0.441442\n",
      "[4]\tvalid_0's multi_logloss: 0.389476\n",
      "[5]\tvalid_0's multi_logloss: 0.345211\n",
      "[6]\tvalid_0's multi_logloss: 0.307207\n",
      "[7]\tvalid_0's multi_logloss: 0.274303\n",
      "[8]\tvalid_0's multi_logloss: 0.245595\n",
      "[9]\tvalid_0's multi_logloss: 0.220542\n",
      "[10]\tvalid_0's multi_logloss: 0.198479\n",
      "[11]\tvalid_0's multi_logloss: 0.178893\n",
      "[12]\tvalid_0's multi_logloss: 0.161544\n",
      "[13]\tvalid_0's multi_logloss: 0.146232\n",
      "[14]\tvalid_0's multi_logloss: 0.132579\n",
      "[15]\tvalid_0's multi_logloss: 0.120342\n",
      "[16]\tvalid_0's multi_logloss: 0.109366\n",
      "[17]\tvalid_0's multi_logloss: 0.0995517\n",
      "[18]\tvalid_0's multi_logloss: 0.090745\n",
      "[19]\tvalid_0's multi_logloss: 0.0828592\n",
      "[20]\tvalid_0's multi_logloss: 0.0757834\n",
      "[21]\tvalid_0's multi_logloss: 0.0694159\n",
      "[22]\tvalid_0's multi_logloss: 0.0636746\n",
      "[23]\tvalid_0's multi_logloss: 0.0585094\n",
      "[24]\tvalid_0's multi_logloss: 0.0538485\n",
      "[25]\tvalid_0's multi_logloss: 0.0496555\n",
      "[26]\tvalid_0's multi_logloss: 0.045861\n",
      "[27]\tvalid_0's multi_logloss: 0.042449\n",
      "[28]\tvalid_0's multi_logloss: 0.0393818\n",
      "[29]\tvalid_0's multi_logloss: 0.0366088\n",
      "[30]\tvalid_0's multi_logloss: 0.0341277\n",
      "[31]\tvalid_0's multi_logloss: 0.0318623\n",
      "[32]\tvalid_0's multi_logloss: 0.0297989\n",
      "[33]\tvalid_0's multi_logloss: 0.0279356\n",
      "[34]\tvalid_0's multi_logloss: 0.026248\n",
      "[35]\tvalid_0's multi_logloss: 0.0247276\n",
      "[36]\tvalid_0's multi_logloss: 0.0233627\n",
      "[37]\tvalid_0's multi_logloss: 0.0221169\n",
      "[38]\tvalid_0's multi_logloss: 0.0209838\n",
      "[39]\tvalid_0's multi_logloss: 0.0199642\n",
      "[40]\tvalid_0's multi_logloss: 0.0190308\n",
      "[41]\tvalid_0's multi_logloss: 0.0181897\n",
      "[42]\tvalid_0's multi_logloss: 0.0174264\n",
      "[43]\tvalid_0's multi_logloss: 0.0167256\n",
      "[44]\tvalid_0's multi_logloss: 0.0160897\n",
      "[45]\tvalid_0's multi_logloss: 0.0155125\n",
      "[46]\tvalid_0's multi_logloss: 0.014986\n",
      "[47]\tvalid_0's multi_logloss: 0.0145087\n",
      "[48]\tvalid_0's multi_logloss: 0.0140763\n",
      "[49]\tvalid_0's multi_logloss: 0.0136811\n",
      "[50]\tvalid_0's multi_logloss: 0.0133206\n",
      "[51]\tvalid_0's multi_logloss: 0.0129912\n",
      "[52]\tvalid_0's multi_logloss: 0.0126989\n",
      "[53]\tvalid_0's multi_logloss: 0.012427\n",
      "[54]\tvalid_0's multi_logloss: 0.0121803\n",
      "[55]\tvalid_0's multi_logloss: 0.0119561\n",
      "[56]\tvalid_0's multi_logloss: 0.0117446\n",
      "[57]\tvalid_0's multi_logloss: 0.0115542\n",
      "[58]\tvalid_0's multi_logloss: 0.0113837\n",
      "[59]\tvalid_0's multi_logloss: 0.011226\n",
      "[60]\tvalid_0's multi_logloss: 0.011081\n",
      "[61]\tvalid_0's multi_logloss: 0.010954\n",
      "[62]\tvalid_0's multi_logloss: 0.0108365\n",
      "[63]\tvalid_0's multi_logloss: 0.0107303\n",
      "[64]\tvalid_0's multi_logloss: 0.0106312\n",
      "[65]\tvalid_0's multi_logloss: 0.0105415\n",
      "[66]\tvalid_0's multi_logloss: 0.0104559\n",
      "[67]\tvalid_0's multi_logloss: 0.01038\n",
      "[68]\tvalid_0's multi_logloss: 0.0103101\n",
      "[69]\tvalid_0's multi_logloss: 0.0102438\n",
      "[70]\tvalid_0's multi_logloss: 0.0101824\n",
      "[71]\tvalid_0's multi_logloss: 0.0101293\n",
      "[72]\tvalid_0's multi_logloss: 0.0100801\n",
      "[73]\tvalid_0's multi_logloss: 0.0100284\n",
      "[74]\tvalid_0's multi_logloss: 0.00998324\n",
      "[75]\tvalid_0's multi_logloss: 0.00993941\n",
      "[76]\tvalid_0's multi_logloss: 0.00990392\n",
      "[77]\tvalid_0's multi_logloss: 0.00987041\n",
      "[78]\tvalid_0's multi_logloss: 0.00984401\n",
      "[79]\tvalid_0's multi_logloss: 0.00981425\n",
      "[80]\tvalid_0's multi_logloss: 0.00978692\n",
      "[81]\tvalid_0's multi_logloss: 0.00976357\n",
      "[82]\tvalid_0's multi_logloss: 0.00973979\n",
      "[83]\tvalid_0's multi_logloss: 0.00971933\n",
      "[84]\tvalid_0's multi_logloss: 0.0097001\n",
      "[85]\tvalid_0's multi_logloss: 0.00967975\n",
      "[86]\tvalid_0's multi_logloss: 0.00966451\n",
      "[87]\tvalid_0's multi_logloss: 0.00963785\n",
      "[88]\tvalid_0's multi_logloss: 0.00962616\n",
      "[89]\tvalid_0's multi_logloss: 0.0096051\n",
      "[90]\tvalid_0's multi_logloss: 0.00958837\n",
      "[91]\tvalid_0's multi_logloss: 0.00957654\n",
      "[92]\tvalid_0's multi_logloss: 0.00956678\n",
      "[93]\tvalid_0's multi_logloss: 0.00955505\n",
      "[94]\tvalid_0's multi_logloss: 0.00954692\n",
      "[95]\tvalid_0's multi_logloss: 0.00953924\n",
      "[96]\tvalid_0's multi_logloss: 0.00953084\n",
      "[97]\tvalid_0's multi_logloss: 0.0095223\n",
      "[98]\tvalid_0's multi_logloss: 0.00951643\n",
      "[99]\tvalid_0's multi_logloss: 0.00950628\n",
      "[100]\tvalid_0's multi_logloss: 0.00950172\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024923 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -0.141837\n",
      "[LightGBM] [Info] Start training from score -2.023158\n",
      "[1]\tvalid_0's multi_logloss: 0.383512\n",
      "[2]\tvalid_0's multi_logloss: 0.37799\n",
      "[3]\tvalid_0's multi_logloss: 0.373582\n",
      "[4]\tvalid_0's multi_logloss: 0.370085\n",
      "[5]\tvalid_0's multi_logloss: 0.367175\n",
      "[6]\tvalid_0's multi_logloss: 0.364796\n",
      "[7]\tvalid_0's multi_logloss: 0.362511\n",
      "[8]\tvalid_0's multi_logloss: 0.360694\n",
      "[9]\tvalid_0's multi_logloss: 0.359048\n",
      "[10]\tvalid_0's multi_logloss: 0.357554\n",
      "[11]\tvalid_0's multi_logloss: 0.356299\n",
      "[12]\tvalid_0's multi_logloss: 0.355182\n",
      "[13]\tvalid_0's multi_logloss: 0.354196\n",
      "[14]\tvalid_0's multi_logloss: 0.353362\n",
      "[15]\tvalid_0's multi_logloss: 0.3526\n",
      "[16]\tvalid_0's multi_logloss: 0.351938\n",
      "[17]\tvalid_0's multi_logloss: 0.351313\n",
      "[18]\tvalid_0's multi_logloss: 0.35073\n",
      "[19]\tvalid_0's multi_logloss: 0.350221\n",
      "[20]\tvalid_0's multi_logloss: 0.349795\n",
      "[21]\tvalid_0's multi_logloss: 0.349386\n",
      "[22]\tvalid_0's multi_logloss: 0.349031\n",
      "[23]\tvalid_0's multi_logloss: 0.348684\n",
      "[24]\tvalid_0's multi_logloss: 0.348381\n",
      "[25]\tvalid_0's multi_logloss: 0.348096\n",
      "[26]\tvalid_0's multi_logloss: 0.347836\n",
      "[27]\tvalid_0's multi_logloss: 0.347572\n",
      "[28]\tvalid_0's multi_logloss: 0.347351\n",
      "[29]\tvalid_0's multi_logloss: 0.347135\n",
      "[30]\tvalid_0's multi_logloss: 0.346844\n",
      "[31]\tvalid_0's multi_logloss: 0.346608\n",
      "[32]\tvalid_0's multi_logloss: 0.346368\n",
      "[33]\tvalid_0's multi_logloss: 0.346229\n",
      "[34]\tvalid_0's multi_logloss: 0.346039\n",
      "[35]\tvalid_0's multi_logloss: 0.345859\n",
      "[36]\tvalid_0's multi_logloss: 0.345705\n",
      "[37]\tvalid_0's multi_logloss: 0.345574\n",
      "[38]\tvalid_0's multi_logloss: 0.345445\n",
      "[39]\tvalid_0's multi_logloss: 0.345314\n",
      "[40]\tvalid_0's multi_logloss: 0.345161\n",
      "[41]\tvalid_0's multi_logloss: 0.34504\n",
      "[42]\tvalid_0's multi_logloss: 0.344945\n",
      "[43]\tvalid_0's multi_logloss: 0.344847\n",
      "[44]\tvalid_0's multi_logloss: 0.344748\n",
      "[45]\tvalid_0's multi_logloss: 0.344678\n",
      "[46]\tvalid_0's multi_logloss: 0.344586\n",
      "[47]\tvalid_0's multi_logloss: 0.34452\n",
      "[48]\tvalid_0's multi_logloss: 0.344448\n",
      "[49]\tvalid_0's multi_logloss: 0.344374\n",
      "[50]\tvalid_0's multi_logloss: 0.344312\n",
      "[51]\tvalid_0's multi_logloss: 0.344238\n",
      "[52]\tvalid_0's multi_logloss: 0.344185\n",
      "[53]\tvalid_0's multi_logloss: 0.34414\n",
      "[54]\tvalid_0's multi_logloss: 0.344062\n",
      "[55]\tvalid_0's multi_logloss: 0.344001\n",
      "[56]\tvalid_0's multi_logloss: 0.343967\n",
      "[57]\tvalid_0's multi_logloss: 0.343926\n",
      "[58]\tvalid_0's multi_logloss: 0.343868\n",
      "[59]\tvalid_0's multi_logloss: 0.343832\n",
      "[60]\tvalid_0's multi_logloss: 0.343795\n",
      "[61]\tvalid_0's multi_logloss: 0.343757\n",
      "[62]\tvalid_0's multi_logloss: 0.343714\n",
      "[63]\tvalid_0's multi_logloss: 0.34369\n",
      "[64]\tvalid_0's multi_logloss: 0.343661\n",
      "[65]\tvalid_0's multi_logloss: 0.343625\n",
      "[66]\tvalid_0's multi_logloss: 0.343566\n",
      "[67]\tvalid_0's multi_logloss: 0.343542\n",
      "[68]\tvalid_0's multi_logloss: 0.343521\n",
      "[69]\tvalid_0's multi_logloss: 0.343498\n",
      "[70]\tvalid_0's multi_logloss: 0.343464\n",
      "[71]\tvalid_0's multi_logloss: 0.343428\n",
      "[72]\tvalid_0's multi_logloss: 0.343374\n",
      "[73]\tvalid_0's multi_logloss: 0.343344\n",
      "[74]\tvalid_0's multi_logloss: 0.34332\n",
      "[75]\tvalid_0's multi_logloss: 0.343297\n",
      "[76]\tvalid_0's multi_logloss: 0.343281\n",
      "[77]\tvalid_0's multi_logloss: 0.343263\n",
      "[78]\tvalid_0's multi_logloss: 0.343237\n",
      "[79]\tvalid_0's multi_logloss: 0.343207\n",
      "[80]\tvalid_0's multi_logloss: 0.343187\n",
      "[81]\tvalid_0's multi_logloss: 0.343173\n",
      "[82]\tvalid_0's multi_logloss: 0.343159\n",
      "[83]\tvalid_0's multi_logloss: 0.343146\n",
      "[84]\tvalid_0's multi_logloss: 0.343124\n",
      "[85]\tvalid_0's multi_logloss: 0.343107\n",
      "[86]\tvalid_0's multi_logloss: 0.343064\n",
      "[87]\tvalid_0's multi_logloss: 0.343053\n",
      "[88]\tvalid_0's multi_logloss: 0.343037\n",
      "[89]\tvalid_0's multi_logloss: 0.34302\n",
      "[90]\tvalid_0's multi_logloss: 0.343005\n",
      "[91]\tvalid_0's multi_logloss: 0.342994\n",
      "[92]\tvalid_0's multi_logloss: 0.34298\n",
      "[93]\tvalid_0's multi_logloss: 0.342933\n",
      "[94]\tvalid_0's multi_logloss: 0.342916\n",
      "[95]\tvalid_0's multi_logloss: 0.342891\n",
      "[96]\tvalid_0's multi_logloss: 0.342884\n",
      "[97]\tvalid_0's multi_logloss: 0.34286\n",
      "[98]\tvalid_0's multi_logloss: 0.34283\n",
      "[99]\tvalid_0's multi_logloss: 0.342822\n",
      "[100]\tvalid_0's multi_logloss: 0.342792\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018487 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -1.853404\n",
      "[LightGBM] [Info] Start training from score -2.123202\n",
      "[LightGBM] [Info] Start training from score -2.391862\n",
      "[LightGBM] [Info] Start training from score -2.719639\n",
      "[LightGBM] [Info] Start training from score -2.078311\n",
      "[LightGBM] [Info] Start training from score -2.161447\n",
      "[LightGBM] [Info] Start training from score -2.497610\n",
      "[LightGBM] [Info] Start training from score -2.232530\n",
      "[LightGBM] [Info] Start training from score -2.689447\n",
      "[LightGBM] [Info] Start training from score -2.680407\n",
      "[1]\tvalid_0's multi_logloss: 2.12041\n",
      "[2]\tvalid_0's multi_logloss: 2.0253\n",
      "[3]\tvalid_0's multi_logloss: 1.95347\n",
      "[4]\tvalid_0's multi_logloss: 1.89525\n",
      "[5]\tvalid_0's multi_logloss: 1.84756\n",
      "[6]\tvalid_0's multi_logloss: 1.8084\n",
      "[7]\tvalid_0's multi_logloss: 1.77482\n",
      "[8]\tvalid_0's multi_logloss: 1.74596\n",
      "[9]\tvalid_0's multi_logloss: 1.72141\n",
      "[10]\tvalid_0's multi_logloss: 1.69949\n",
      "[11]\tvalid_0's multi_logloss: 1.68034\n",
      "[12]\tvalid_0's multi_logloss: 1.66319\n",
      "[13]\tvalid_0's multi_logloss: 1.64878\n",
      "[14]\tvalid_0's multi_logloss: 1.63532\n",
      "[15]\tvalid_0's multi_logloss: 1.6233\n",
      "[16]\tvalid_0's multi_logloss: 1.61242\n",
      "[17]\tvalid_0's multi_logloss: 1.60243\n",
      "[18]\tvalid_0's multi_logloss: 1.59361\n",
      "[19]\tvalid_0's multi_logloss: 1.58541\n",
      "[20]\tvalid_0's multi_logloss: 1.578\n",
      "[21]\tvalid_0's multi_logloss: 1.57124\n",
      "[22]\tvalid_0's multi_logloss: 1.56502\n",
      "[23]\tvalid_0's multi_logloss: 1.55922\n",
      "[24]\tvalid_0's multi_logloss: 1.55372\n",
      "[25]\tvalid_0's multi_logloss: 1.54892\n",
      "[26]\tvalid_0's multi_logloss: 1.54435\n",
      "[27]\tvalid_0's multi_logloss: 1.54006\n",
      "[28]\tvalid_0's multi_logloss: 1.53608\n",
      "[29]\tvalid_0's multi_logloss: 1.53244\n",
      "[30]\tvalid_0's multi_logloss: 1.529\n",
      "[31]\tvalid_0's multi_logloss: 1.52561\n",
      "[32]\tvalid_0's multi_logloss: 1.52256\n",
      "[33]\tvalid_0's multi_logloss: 1.5196\n",
      "[34]\tvalid_0's multi_logloss: 1.51696\n",
      "[35]\tvalid_0's multi_logloss: 1.51441\n",
      "[36]\tvalid_0's multi_logloss: 1.51201\n",
      "[37]\tvalid_0's multi_logloss: 1.5096\n",
      "[38]\tvalid_0's multi_logloss: 1.50739\n",
      "[39]\tvalid_0's multi_logloss: 1.50543\n",
      "[40]\tvalid_0's multi_logloss: 1.50352\n",
      "[41]\tvalid_0's multi_logloss: 1.50166\n",
      "[42]\tvalid_0's multi_logloss: 1.49983\n",
      "[43]\tvalid_0's multi_logloss: 1.4983\n",
      "[44]\tvalid_0's multi_logloss: 1.49652\n",
      "[45]\tvalid_0's multi_logloss: 1.49498\n",
      "[46]\tvalid_0's multi_logloss: 1.49361\n",
      "[47]\tvalid_0's multi_logloss: 1.49201\n",
      "[48]\tvalid_0's multi_logloss: 1.49081\n",
      "[49]\tvalid_0's multi_logloss: 1.48963\n",
      "[50]\tvalid_0's multi_logloss: 1.48843\n",
      "[51]\tvalid_0's multi_logloss: 1.48717\n",
      "[52]\tvalid_0's multi_logloss: 1.48596\n",
      "[53]\tvalid_0's multi_logloss: 1.48473\n",
      "[54]\tvalid_0's multi_logloss: 1.48364\n",
      "[55]\tvalid_0's multi_logloss: 1.48269\n",
      "[56]\tvalid_0's multi_logloss: 1.48174\n",
      "[57]\tvalid_0's multi_logloss: 1.48078\n",
      "[58]\tvalid_0's multi_logloss: 1.47986\n",
      "[59]\tvalid_0's multi_logloss: 1.47898\n",
      "[60]\tvalid_0's multi_logloss: 1.47811\n",
      "[61]\tvalid_0's multi_logloss: 1.47737\n",
      "[62]\tvalid_0's multi_logloss: 1.47655\n",
      "[63]\tvalid_0's multi_logloss: 1.47579\n",
      "[64]\tvalid_0's multi_logloss: 1.47516\n",
      "[65]\tvalid_0's multi_logloss: 1.47454\n",
      "[66]\tvalid_0's multi_logloss: 1.47383\n",
      "[67]\tvalid_0's multi_logloss: 1.47305\n",
      "[68]\tvalid_0's multi_logloss: 1.47239\n",
      "[69]\tvalid_0's multi_logloss: 1.47177\n",
      "[70]\tvalid_0's multi_logloss: 1.47118\n",
      "[71]\tvalid_0's multi_logloss: 1.47054\n",
      "[72]\tvalid_0's multi_logloss: 1.46996\n",
      "[73]\tvalid_0's multi_logloss: 1.46935\n",
      "[74]\tvalid_0's multi_logloss: 1.4688\n",
      "[75]\tvalid_0's multi_logloss: 1.46834\n",
      "[76]\tvalid_0's multi_logloss: 1.46791\n",
      "[77]\tvalid_0's multi_logloss: 1.46741\n",
      "[78]\tvalid_0's multi_logloss: 1.46685\n",
      "[79]\tvalid_0's multi_logloss: 1.46642\n",
      "[80]\tvalid_0's multi_logloss: 1.46585\n",
      "[81]\tvalid_0's multi_logloss: 1.46543\n",
      "[82]\tvalid_0's multi_logloss: 1.46496\n",
      "[83]\tvalid_0's multi_logloss: 1.46439\n",
      "[84]\tvalid_0's multi_logloss: 1.46394\n",
      "[85]\tvalid_0's multi_logloss: 1.46358\n",
      "[86]\tvalid_0's multi_logloss: 1.46323\n",
      "[87]\tvalid_0's multi_logloss: 1.46279\n",
      "[88]\tvalid_0's multi_logloss: 1.46242\n",
      "[89]\tvalid_0's multi_logloss: 1.4621\n",
      "[90]\tvalid_0's multi_logloss: 1.46177\n",
      "[91]\tvalid_0's multi_logloss: 1.46145\n",
      "[92]\tvalid_0's multi_logloss: 1.46106\n",
      "[93]\tvalid_0's multi_logloss: 1.46075\n",
      "[94]\tvalid_0's multi_logloss: 1.46039\n",
      "[95]\tvalid_0's multi_logloss: 1.46008\n",
      "[96]\tvalid_0's multi_logloss: 1.45969\n",
      "[97]\tvalid_0's multi_logloss: 1.45933\n",
      "[98]\tvalid_0's multi_logloss: 1.45898\n",
      "[99]\tvalid_0's multi_logloss: 1.45858\n",
      "[100]\tvalid_0's multi_logloss: 1.45828\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028163 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -1.047228\n",
      "[LightGBM] [Info] Start training from score -1.516216\n",
      "[LightGBM] [Info] Start training from score -0.845018\n",
      "[1]\tvalid_0's multi_logloss: 1.01302\n",
      "[2]\tvalid_0's multi_logloss: 0.971797\n",
      "[3]\tvalid_0's multi_logloss: 0.937457\n",
      "[4]\tvalid_0's multi_logloss: 0.908452\n",
      "[5]\tvalid_0's multi_logloss: 0.883749\n",
      "[6]\tvalid_0's multi_logloss: 0.862489\n",
      "[7]\tvalid_0's multi_logloss: 0.844068\n",
      "[8]\tvalid_0's multi_logloss: 0.828013\n",
      "[9]\tvalid_0's multi_logloss: 0.813985\n",
      "[10]\tvalid_0's multi_logloss: 0.801531\n",
      "[11]\tvalid_0's multi_logloss: 0.790483\n",
      "[12]\tvalid_0's multi_logloss: 0.780615\n",
      "[13]\tvalid_0's multi_logloss: 0.771758\n",
      "[14]\tvalid_0's multi_logloss: 0.763854\n",
      "[15]\tvalid_0's multi_logloss: 0.756723\n",
      "[16]\tvalid_0's multi_logloss: 0.750263\n",
      "[17]\tvalid_0's multi_logloss: 0.744386\n",
      "[18]\tvalid_0's multi_logloss: 0.73907\n",
      "[19]\tvalid_0's multi_logloss: 0.734209\n",
      "[20]\tvalid_0's multi_logloss: 0.729779\n",
      "[21]\tvalid_0's multi_logloss: 0.725703\n",
      "[22]\tvalid_0's multi_logloss: 0.721957\n",
      "[23]\tvalid_0's multi_logloss: 0.718529\n",
      "[24]\tvalid_0's multi_logloss: 0.71534\n",
      "[25]\tvalid_0's multi_logloss: 0.712431\n",
      "[26]\tvalid_0's multi_logloss: 0.709744\n",
      "[27]\tvalid_0's multi_logloss: 0.707216\n",
      "[28]\tvalid_0's multi_logloss: 0.704915\n",
      "[29]\tvalid_0's multi_logloss: 0.702774\n",
      "[30]\tvalid_0's multi_logloss: 0.700793\n",
      "[31]\tvalid_0's multi_logloss: 0.698948\n",
      "[32]\tvalid_0's multi_logloss: 0.697223\n",
      "[33]\tvalid_0's multi_logloss: 0.695641\n",
      "[34]\tvalid_0's multi_logloss: 0.694168\n",
      "[35]\tvalid_0's multi_logloss: 0.6928\n",
      "[36]\tvalid_0's multi_logloss: 0.691513\n",
      "[37]\tvalid_0's multi_logloss: 0.690318\n",
      "[38]\tvalid_0's multi_logloss: 0.689206\n",
      "[39]\tvalid_0's multi_logloss: 0.688166\n",
      "[40]\tvalid_0's multi_logloss: 0.687149\n",
      "[41]\tvalid_0's multi_logloss: 0.686225\n",
      "[42]\tvalid_0's multi_logloss: 0.685361\n",
      "[43]\tvalid_0's multi_logloss: 0.68455\n",
      "[44]\tvalid_0's multi_logloss: 0.683803\n",
      "[45]\tvalid_0's multi_logloss: 0.683099\n",
      "[46]\tvalid_0's multi_logloss: 0.682437\n",
      "[47]\tvalid_0's multi_logloss: 0.681821\n",
      "[48]\tvalid_0's multi_logloss: 0.681246\n",
      "[49]\tvalid_0's multi_logloss: 0.6807\n",
      "[50]\tvalid_0's multi_logloss: 0.680193\n",
      "[51]\tvalid_0's multi_logloss: 0.679719\n",
      "[52]\tvalid_0's multi_logloss: 0.679272\n",
      "[53]\tvalid_0's multi_logloss: 0.678854\n",
      "[54]\tvalid_0's multi_logloss: 0.678451\n",
      "[55]\tvalid_0's multi_logloss: 0.678084\n",
      "[56]\tvalid_0's multi_logloss: 0.677739\n",
      "[57]\tvalid_0's multi_logloss: 0.677397\n",
      "[58]\tvalid_0's multi_logloss: 0.677093\n",
      "[59]\tvalid_0's multi_logloss: 0.676803\n",
      "[60]\tvalid_0's multi_logloss: 0.676533\n",
      "[61]\tvalid_0's multi_logloss: 0.676272\n",
      "[62]\tvalid_0's multi_logloss: 0.676016\n",
      "[63]\tvalid_0's multi_logloss: 0.675779\n",
      "[64]\tvalid_0's multi_logloss: 0.675551\n",
      "[65]\tvalid_0's multi_logloss: 0.675328\n",
      "[66]\tvalid_0's multi_logloss: 0.675124\n",
      "[67]\tvalid_0's multi_logloss: 0.674954\n",
      "[68]\tvalid_0's multi_logloss: 0.674784\n",
      "[69]\tvalid_0's multi_logloss: 0.674632\n",
      "[70]\tvalid_0's multi_logloss: 0.674479\n",
      "[71]\tvalid_0's multi_logloss: 0.674327\n",
      "[72]\tvalid_0's multi_logloss: 0.674193\n",
      "[73]\tvalid_0's multi_logloss: 0.674052\n",
      "[74]\tvalid_0's multi_logloss: 0.673932\n",
      "[75]\tvalid_0's multi_logloss: 0.673801\n",
      "[76]\tvalid_0's multi_logloss: 0.673681\n",
      "[77]\tvalid_0's multi_logloss: 0.673582\n",
      "[78]\tvalid_0's multi_logloss: 0.673474\n",
      "[79]\tvalid_0's multi_logloss: 0.673366\n",
      "[80]\tvalid_0's multi_logloss: 0.673273\n",
      "[81]\tvalid_0's multi_logloss: 0.673176\n",
      "[82]\tvalid_0's multi_logloss: 0.673089\n",
      "[83]\tvalid_0's multi_logloss: 0.673017\n",
      "[84]\tvalid_0's multi_logloss: 0.67293\n",
      "[85]\tvalid_0's multi_logloss: 0.672856\n",
      "[86]\tvalid_0's multi_logloss: 0.672789\n",
      "[87]\tvalid_0's multi_logloss: 0.672713\n",
      "[88]\tvalid_0's multi_logloss: 0.672651\n",
      "[89]\tvalid_0's multi_logloss: 0.672594\n",
      "[90]\tvalid_0's multi_logloss: 0.672529\n",
      "[91]\tvalid_0's multi_logloss: 0.672475\n",
      "[92]\tvalid_0's multi_logloss: 0.672414\n",
      "[93]\tvalid_0's multi_logloss: 0.67234\n",
      "[94]\tvalid_0's multi_logloss: 0.67229\n",
      "[95]\tvalid_0's multi_logloss: 0.672241\n",
      "[96]\tvalid_0's multi_logloss: 0.672187\n",
      "[97]\tvalid_0's multi_logloss: 0.672127\n",
      "[98]\tvalid_0's multi_logloss: 0.672077\n",
      "[99]\tvalid_0's multi_logloss: 0.672022\n",
      "[100]\tvalid_0's multi_logloss: 0.67198\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027460 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -3.244539\n",
      "[LightGBM] [Info] Start training from score -3.224920\n",
      "[LightGBM] [Info] Start training from score -3.369880\n",
      "[LightGBM] [Info] Start training from score -3.326941\n",
      "[LightGBM] [Info] Start training from score -3.378266\n",
      "[LightGBM] [Info] Start training from score -2.568017\n",
      "[LightGBM] [Info] Start training from score -1.914747\n",
      "[LightGBM] [Info] Start training from score -3.469579\n",
      "[LightGBM] [Info] Start training from score -1.919436\n",
      "[LightGBM] [Info] Start training from score -2.291576\n",
      "[LightGBM] [Info] Start training from score -2.007538\n",
      "[LightGBM] [Info] Start training from score -3.402200\n",
      "[LightGBM] [Info] Start training from score -3.212376\n",
      "[LightGBM] [Info] Start training from score -2.244521\n",
      "[1]\tvalid_0's multi_logloss: 2.43032\n",
      "[2]\tvalid_0's multi_logloss: 2.41121\n",
      "[3]\tvalid_0's multi_logloss: 2.39581\n",
      "[4]\tvalid_0's multi_logloss: 2.38307\n",
      "[5]\tvalid_0's multi_logloss: 2.37225\n",
      "[6]\tvalid_0's multi_logloss: 2.36307\n",
      "[7]\tvalid_0's multi_logloss: 2.35517\n",
      "[8]\tvalid_0's multi_logloss: 2.34828\n",
      "[9]\tvalid_0's multi_logloss: 2.34228\n",
      "[10]\tvalid_0's multi_logloss: 2.33687\n",
      "[11]\tvalid_0's multi_logloss: 2.33202\n",
      "[12]\tvalid_0's multi_logloss: 2.32785\n",
      "[13]\tvalid_0's multi_logloss: 2.32403\n",
      "[14]\tvalid_0's multi_logloss: 2.32066\n",
      "[15]\tvalid_0's multi_logloss: 2.31745\n",
      "[16]\tvalid_0's multi_logloss: 2.3146\n",
      "[17]\tvalid_0's multi_logloss: 2.31199\n",
      "[18]\tvalid_0's multi_logloss: 2.30959\n",
      "[19]\tvalid_0's multi_logloss: 2.30719\n",
      "[20]\tvalid_0's multi_logloss: 2.30507\n",
      "[21]\tvalid_0's multi_logloss: 2.3031\n",
      "[22]\tvalid_0's multi_logloss: 2.30122\n",
      "[23]\tvalid_0's multi_logloss: 2.29959\n",
      "[24]\tvalid_0's multi_logloss: 2.29801\n",
      "[25]\tvalid_0's multi_logloss: 2.29655\n",
      "[26]\tvalid_0's multi_logloss: 2.29512\n",
      "[27]\tvalid_0's multi_logloss: 2.29382\n",
      "[28]\tvalid_0's multi_logloss: 2.29256\n",
      "[29]\tvalid_0's multi_logloss: 2.29141\n",
      "[30]\tvalid_0's multi_logloss: 2.29026\n",
      "[31]\tvalid_0's multi_logloss: 2.2893\n",
      "[32]\tvalid_0's multi_logloss: 2.28835\n",
      "[33]\tvalid_0's multi_logloss: 2.28743\n",
      "[34]\tvalid_0's multi_logloss: 2.28661\n",
      "[35]\tvalid_0's multi_logloss: 2.28583\n",
      "[36]\tvalid_0's multi_logloss: 2.2851\n",
      "[37]\tvalid_0's multi_logloss: 2.28435\n",
      "[38]\tvalid_0's multi_logloss: 2.28368\n",
      "[39]\tvalid_0's multi_logloss: 2.283\n",
      "[40]\tvalid_0's multi_logloss: 2.28236\n",
      "[41]\tvalid_0's multi_logloss: 2.28179\n",
      "[42]\tvalid_0's multi_logloss: 2.28113\n",
      "[43]\tvalid_0's multi_logloss: 2.28053\n",
      "[44]\tvalid_0's multi_logloss: 2.27995\n",
      "[45]\tvalid_0's multi_logloss: 2.27944\n",
      "[46]\tvalid_0's multi_logloss: 2.27897\n",
      "[47]\tvalid_0's multi_logloss: 2.27857\n",
      "[48]\tvalid_0's multi_logloss: 2.27809\n",
      "[49]\tvalid_0's multi_logloss: 2.27769\n",
      "[50]\tvalid_0's multi_logloss: 2.27727\n",
      "[51]\tvalid_0's multi_logloss: 2.27693\n",
      "[52]\tvalid_0's multi_logloss: 2.2765\n",
      "[53]\tvalid_0's multi_logloss: 2.27612\n",
      "[54]\tvalid_0's multi_logloss: 2.27573\n",
      "[55]\tvalid_0's multi_logloss: 2.27535\n",
      "[56]\tvalid_0's multi_logloss: 2.275\n",
      "[57]\tvalid_0's multi_logloss: 2.27467\n",
      "[58]\tvalid_0's multi_logloss: 2.27428\n",
      "[59]\tvalid_0's multi_logloss: 2.27397\n",
      "[60]\tvalid_0's multi_logloss: 2.27366\n",
      "[61]\tvalid_0's multi_logloss: 2.27339\n",
      "[62]\tvalid_0's multi_logloss: 2.27311\n",
      "[63]\tvalid_0's multi_logloss: 2.27287\n",
      "[64]\tvalid_0's multi_logloss: 2.2726\n",
      "[65]\tvalid_0's multi_logloss: 2.27237\n",
      "[66]\tvalid_0's multi_logloss: 2.27212\n",
      "[67]\tvalid_0's multi_logloss: 2.27189\n",
      "[68]\tvalid_0's multi_logloss: 2.27162\n",
      "[69]\tvalid_0's multi_logloss: 2.27143\n",
      "[70]\tvalid_0's multi_logloss: 2.2712\n",
      "[71]\tvalid_0's multi_logloss: 2.27097\n",
      "[72]\tvalid_0's multi_logloss: 2.2707\n",
      "[73]\tvalid_0's multi_logloss: 2.27047\n",
      "[74]\tvalid_0's multi_logloss: 2.27022\n",
      "[75]\tvalid_0's multi_logloss: 2.26998\n",
      "[76]\tvalid_0's multi_logloss: 2.26974\n",
      "[77]\tvalid_0's multi_logloss: 2.26949\n",
      "[78]\tvalid_0's multi_logloss: 2.26931\n",
      "[79]\tvalid_0's multi_logloss: 2.26911\n",
      "[80]\tvalid_0's multi_logloss: 2.26892\n",
      "[81]\tvalid_0's multi_logloss: 2.26871\n",
      "[82]\tvalid_0's multi_logloss: 2.2685\n",
      "[83]\tvalid_0's multi_logloss: 2.26832\n",
      "[84]\tvalid_0's multi_logloss: 2.26816\n",
      "[85]\tvalid_0's multi_logloss: 2.26801\n",
      "[86]\tvalid_0's multi_logloss: 2.26781\n",
      "[87]\tvalid_0's multi_logloss: 2.26764\n",
      "[88]\tvalid_0's multi_logloss: 2.26746\n",
      "[89]\tvalid_0's multi_logloss: 2.2673\n",
      "[90]\tvalid_0's multi_logloss: 2.26706\n",
      "[91]\tvalid_0's multi_logloss: 2.26688\n",
      "[92]\tvalid_0's multi_logloss: 2.26674\n",
      "[93]\tvalid_0's multi_logloss: 2.26658\n",
      "[94]\tvalid_0's multi_logloss: 2.26641\n",
      "[95]\tvalid_0's multi_logloss: 2.26628\n",
      "[96]\tvalid_0's multi_logloss: 2.26612\n",
      "[97]\tvalid_0's multi_logloss: 2.26599\n",
      "[98]\tvalid_0's multi_logloss: 2.26584\n",
      "[99]\tvalid_0's multi_logloss: 2.26567\n",
      "[100]\tvalid_0's multi_logloss: 2.26551\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018647 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -0.501622\n",
      "[LightGBM] [Info] Start training from score -0.930257\n",
      "[1]\tvalid_0's multi_logloss: 0.57788\n",
      "[2]\tvalid_0's multi_logloss: 0.503243\n",
      "[3]\tvalid_0's multi_logloss: 0.44139\n",
      "[4]\tvalid_0's multi_logloss: 0.389644\n",
      "[5]\tvalid_0's multi_logloss: 0.345488\n",
      "[6]\tvalid_0's multi_logloss: 0.307584\n",
      "[7]\tvalid_0's multi_logloss: 0.274783\n",
      "[8]\tvalid_0's multi_logloss: 0.246118\n",
      "[9]\tvalid_0's multi_logloss: 0.22097\n",
      "[10]\tvalid_0's multi_logloss: 0.198834\n",
      "[11]\tvalid_0's multi_logloss: 0.179392\n",
      "[12]\tvalid_0's multi_logloss: 0.162049\n",
      "[13]\tvalid_0's multi_logloss: 0.146517\n",
      "[14]\tvalid_0's multi_logloss: 0.132801\n",
      "[15]\tvalid_0's multi_logloss: 0.120471\n",
      "[16]\tvalid_0's multi_logloss: 0.109525\n",
      "[17]\tvalid_0's multi_logloss: 0.0997461\n",
      "[18]\tvalid_0's multi_logloss: 0.0909475\n",
      "[19]\tvalid_0's multi_logloss: 0.083035\n",
      "[20]\tvalid_0's multi_logloss: 0.0759467\n",
      "[21]\tvalid_0's multi_logloss: 0.0695635\n",
      "[22]\tvalid_0's multi_logloss: 0.0637999\n",
      "[23]\tvalid_0's multi_logloss: 0.0585586\n",
      "[24]\tvalid_0's multi_logloss: 0.0538354\n",
      "[25]\tvalid_0's multi_logloss: 0.0495721\n",
      "[26]\tvalid_0's multi_logloss: 0.0457819\n",
      "[27]\tvalid_0's multi_logloss: 0.0423432\n",
      "[28]\tvalid_0's multi_logloss: 0.0392478\n",
      "[29]\tvalid_0's multi_logloss: 0.036453\n",
      "[30]\tvalid_0's multi_logloss: 0.033911\n",
      "[31]\tvalid_0's multi_logloss: 0.0316002\n",
      "[32]\tvalid_0's multi_logloss: 0.0295111\n",
      "[33]\tvalid_0's multi_logloss: 0.0276309\n",
      "[34]\tvalid_0's multi_logloss: 0.0259203\n",
      "[35]\tvalid_0's multi_logloss: 0.0243721\n",
      "[36]\tvalid_0's multi_logloss: 0.0228996\n",
      "[37]\tvalid_0's multi_logloss: 0.0216101\n",
      "[38]\tvalid_0's multi_logloss: 0.0204198\n",
      "[39]\tvalid_0's multi_logloss: 0.0193469\n",
      "[40]\tvalid_0's multi_logloss: 0.0183759\n",
      "[41]\tvalid_0's multi_logloss: 0.0174915\n",
      "[42]\tvalid_0's multi_logloss: 0.0166844\n",
      "[43]\tvalid_0's multi_logloss: 0.0159592\n",
      "[44]\tvalid_0's multi_logloss: 0.0152991\n",
      "[45]\tvalid_0's multi_logloss: 0.0146984\n",
      "[46]\tvalid_0's multi_logloss: 0.0141525\n",
      "[47]\tvalid_0's multi_logloss: 0.0136581\n",
      "[48]\tvalid_0's multi_logloss: 0.013206\n",
      "[49]\tvalid_0's multi_logloss: 0.0127655\n",
      "[50]\tvalid_0's multi_logloss: 0.0123826\n",
      "[51]\tvalid_0's multi_logloss: 0.0120322\n",
      "[52]\tvalid_0's multi_logloss: 0.0117061\n",
      "[53]\tvalid_0's multi_logloss: 0.0114184\n",
      "[54]\tvalid_0's multi_logloss: 0.0111458\n",
      "[55]\tvalid_0's multi_logloss: 0.0108854\n",
      "[56]\tvalid_0's multi_logloss: 0.0106555\n",
      "[57]\tvalid_0's multi_logloss: 0.010444\n",
      "[58]\tvalid_0's multi_logloss: 0.0102414\n",
      "[59]\tvalid_0's multi_logloss: 0.0100561\n",
      "[60]\tvalid_0's multi_logloss: 0.00989388\n",
      "[61]\tvalid_0's multi_logloss: 0.00972904\n",
      "[62]\tvalid_0's multi_logloss: 0.00958505\n",
      "[63]\tvalid_0's multi_logloss: 0.0094543\n",
      "[64]\tvalid_0's multi_logloss: 0.00933042\n",
      "[65]\tvalid_0's multi_logloss: 0.00921922\n",
      "[66]\tvalid_0's multi_logloss: 0.00911951\n",
      "[67]\tvalid_0's multi_logloss: 0.00902798\n",
      "[68]\tvalid_0's multi_logloss: 0.00893424\n",
      "[69]\tvalid_0's multi_logloss: 0.00883881\n",
      "[70]\tvalid_0's multi_logloss: 0.00875626\n",
      "[71]\tvalid_0's multi_logloss: 0.00867321\n",
      "[72]\tvalid_0's multi_logloss: 0.0086015\n",
      "[73]\tvalid_0's multi_logloss: 0.00853356\n",
      "[74]\tvalid_0's multi_logloss: 0.00846863\n",
      "[75]\tvalid_0's multi_logloss: 0.00841206\n",
      "[76]\tvalid_0's multi_logloss: 0.00836226\n",
      "[77]\tvalid_0's multi_logloss: 0.00830803\n",
      "[78]\tvalid_0's multi_logloss: 0.00825707\n",
      "[79]\tvalid_0's multi_logloss: 0.00821087\n",
      "[80]\tvalid_0's multi_logloss: 0.00816357\n",
      "[81]\tvalid_0's multi_logloss: 0.00812187\n",
      "[82]\tvalid_0's multi_logloss: 0.00808441\n",
      "[83]\tvalid_0's multi_logloss: 0.0080553\n",
      "[84]\tvalid_0's multi_logloss: 0.00802013\n",
      "[85]\tvalid_0's multi_logloss: 0.0079872\n",
      "[86]\tvalid_0's multi_logloss: 0.00795578\n",
      "[87]\tvalid_0's multi_logloss: 0.00792451\n",
      "[88]\tvalid_0's multi_logloss: 0.00790013\n",
      "[89]\tvalid_0's multi_logloss: 0.00787478\n",
      "[90]\tvalid_0's multi_logloss: 0.00785452\n",
      "[91]\tvalid_0's multi_logloss: 0.00783549\n",
      "[92]\tvalid_0's multi_logloss: 0.00781976\n",
      "[93]\tvalid_0's multi_logloss: 0.0077931\n",
      "[94]\tvalid_0's multi_logloss: 0.00777799\n",
      "[95]\tvalid_0's multi_logloss: 0.00776386\n",
      "[96]\tvalid_0's multi_logloss: 0.00774403\n",
      "[97]\tvalid_0's multi_logloss: 0.00772888\n",
      "[98]\tvalid_0's multi_logloss: 0.00770864\n",
      "[99]\tvalid_0's multi_logloss: 0.00769455\n",
      "[100]\tvalid_0's multi_logloss: 0.00767865\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018750 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 17329221, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -0.141837\n",
      "[LightGBM] [Info] Start training from score -2.023158\n",
      "[1]\tvalid_0's multi_logloss: 0.37282\n",
      "[2]\tvalid_0's multi_logloss: 0.359933\n",
      "[3]\tvalid_0's multi_logloss: 0.34957\n",
      "[4]\tvalid_0's multi_logloss: 0.341146\n",
      "[5]\tvalid_0's multi_logloss: 0.334098\n",
      "[6]\tvalid_0's multi_logloss: 0.328198\n",
      "[7]\tvalid_0's multi_logloss: 0.323334\n",
      "[8]\tvalid_0's multi_logloss: 0.318924\n",
      "[9]\tvalid_0's multi_logloss: 0.315181\n",
      "[10]\tvalid_0's multi_logloss: 0.311798\n",
      "[11]\tvalid_0's multi_logloss: 0.308779\n",
      "[12]\tvalid_0's multi_logloss: 0.306201\n",
      "[13]\tvalid_0's multi_logloss: 0.303739\n",
      "[14]\tvalid_0's multi_logloss: 0.301629\n",
      "[15]\tvalid_0's multi_logloss: 0.299639\n",
      "[16]\tvalid_0's multi_logloss: 0.297654\n",
      "[17]\tvalid_0's multi_logloss: 0.295897\n",
      "[18]\tvalid_0's multi_logloss: 0.294204\n",
      "[19]\tvalid_0's multi_logloss: 0.292656\n",
      "[20]\tvalid_0's multi_logloss: 0.291379\n",
      "[21]\tvalid_0's multi_logloss: 0.290248\n",
      "[22]\tvalid_0's multi_logloss: 0.289182\n",
      "[23]\tvalid_0's multi_logloss: 0.288113\n",
      "[24]\tvalid_0's multi_logloss: 0.287081\n",
      "[25]\tvalid_0's multi_logloss: 0.286092\n",
      "[26]\tvalid_0's multi_logloss: 0.285162\n",
      "[27]\tvalid_0's multi_logloss: 0.284388\n",
      "[28]\tvalid_0's multi_logloss: 0.28358\n",
      "[29]\tvalid_0's multi_logloss: 0.282994\n",
      "[30]\tvalid_0's multi_logloss: 0.282386\n",
      "[31]\tvalid_0's multi_logloss: 0.281779\n",
      "[32]\tvalid_0's multi_logloss: 0.281207\n",
      "[33]\tvalid_0's multi_logloss: 0.280646\n",
      "[34]\tvalid_0's multi_logloss: 0.280205\n",
      "[35]\tvalid_0's multi_logloss: 0.27969\n",
      "[36]\tvalid_0's multi_logloss: 0.279272\n",
      "[37]\tvalid_0's multi_logloss: 0.278897\n",
      "[38]\tvalid_0's multi_logloss: 0.278583\n",
      "[39]\tvalid_0's multi_logloss: 0.278209\n",
      "[40]\tvalid_0's multi_logloss: 0.277891\n",
      "[41]\tvalid_0's multi_logloss: 0.277547\n",
      "[42]\tvalid_0's multi_logloss: 0.277258\n",
      "[43]\tvalid_0's multi_logloss: 0.27701\n",
      "[44]\tvalid_0's multi_logloss: 0.276646\n",
      "[45]\tvalid_0's multi_logloss: 0.276351\n",
      "[46]\tvalid_0's multi_logloss: 0.276134\n",
      "[47]\tvalid_0's multi_logloss: 0.275768\n",
      "[48]\tvalid_0's multi_logloss: 0.275422\n",
      "[49]\tvalid_0's multi_logloss: 0.275151\n",
      "[50]\tvalid_0's multi_logloss: 0.274881\n",
      "[51]\tvalid_0's multi_logloss: 0.274616\n",
      "[52]\tvalid_0's multi_logloss: 0.274387\n",
      "[53]\tvalid_0's multi_logloss: 0.274186\n",
      "[54]\tvalid_0's multi_logloss: 0.273968\n",
      "[55]\tvalid_0's multi_logloss: 0.273752\n",
      "[56]\tvalid_0's multi_logloss: 0.273519\n",
      "[57]\tvalid_0's multi_logloss: 0.273286\n",
      "[58]\tvalid_0's multi_logloss: 0.273115\n",
      "[59]\tvalid_0's multi_logloss: 0.273021\n",
      "[60]\tvalid_0's multi_logloss: 0.272889\n",
      "[61]\tvalid_0's multi_logloss: 0.272721\n",
      "[62]\tvalid_0's multi_logloss: 0.272557\n",
      "[63]\tvalid_0's multi_logloss: 0.272394\n",
      "[64]\tvalid_0's multi_logloss: 0.272225\n",
      "[65]\tvalid_0's multi_logloss: 0.272107\n",
      "[66]\tvalid_0's multi_logloss: 0.271917\n",
      "[67]\tvalid_0's multi_logloss: 0.271756\n",
      "[68]\tvalid_0's multi_logloss: 0.271553\n",
      "[69]\tvalid_0's multi_logloss: 0.271397\n",
      "[70]\tvalid_0's multi_logloss: 0.27124\n",
      "[71]\tvalid_0's multi_logloss: 0.271128\n",
      "[72]\tvalid_0's multi_logloss: 0.271025\n",
      "[73]\tvalid_0's multi_logloss: 0.270942\n",
      "[74]\tvalid_0's multi_logloss: 0.270865\n",
      "[75]\tvalid_0's multi_logloss: 0.270735\n",
      "[76]\tvalid_0's multi_logloss: 0.270619\n",
      "[77]\tvalid_0's multi_logloss: 0.270491\n",
      "[78]\tvalid_0's multi_logloss: 0.270398\n",
      "[79]\tvalid_0's multi_logloss: 0.27029\n",
      "[80]\tvalid_0's multi_logloss: 0.270176\n",
      "[81]\tvalid_0's multi_logloss: 0.270035\n",
      "[82]\tvalid_0's multi_logloss: 0.269945\n",
      "[83]\tvalid_0's multi_logloss: 0.269835\n",
      "[84]\tvalid_0's multi_logloss: 0.269754\n",
      "[85]\tvalid_0's multi_logloss: 0.269639\n",
      "[86]\tvalid_0's multi_logloss: 0.269549\n",
      "[87]\tvalid_0's multi_logloss: 0.269479\n",
      "[88]\tvalid_0's multi_logloss: 0.269401\n",
      "[89]\tvalid_0's multi_logloss: 0.269328\n",
      "[90]\tvalid_0's multi_logloss: 0.269224\n",
      "[91]\tvalid_0's multi_logloss: 0.26914\n",
      "[92]\tvalid_0's multi_logloss: 0.269075\n",
      "[93]\tvalid_0's multi_logloss: 0.268949\n",
      "[94]\tvalid_0's multi_logloss: 0.268909\n",
      "[95]\tvalid_0's multi_logloss: 0.268834\n",
      "[96]\tvalid_0's multi_logloss: 0.268794\n",
      "[97]\tvalid_0's multi_logloss: 0.268747\n",
      "[98]\tvalid_0's multi_logloss: 0.268706\n",
      "[99]\tvalid_0's multi_logloss: 0.268606\n",
      "[100]\tvalid_0's multi_logloss: 0.268561\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023959 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9435\n",
      "[LightGBM] [Info] Number of data points in the train set: 7715638, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -1.249550\n",
      "[LightGBM] [Info] Start training from score -3.165534\n",
      "[LightGBM] [Info] Start training from score -1.726403\n",
      "[LightGBM] [Info] Start training from score -1.902421\n",
      "[LightGBM] [Info] Start training from score -1.667720\n",
      "[LightGBM] [Info] Start training from score -1.861961\n",
      "[1]\tvalid_0's multi_logloss: 1.64292\n",
      "[2]\tvalid_0's multi_logloss: 1.6096\n",
      "[3]\tvalid_0's multi_logloss: 1.58233\n",
      "[4]\tvalid_0's multi_logloss: 1.55996\n",
      "[5]\tvalid_0's multi_logloss: 1.54069\n",
      "[6]\tvalid_0's multi_logloss: 1.52395\n",
      "[7]\tvalid_0's multi_logloss: 1.50941\n",
      "[8]\tvalid_0's multi_logloss: 1.49671\n",
      "[9]\tvalid_0's multi_logloss: 1.48555\n",
      "[10]\tvalid_0's multi_logloss: 1.47551\n",
      "[11]\tvalid_0's multi_logloss: 1.46636\n",
      "[12]\tvalid_0's multi_logloss: 1.45801\n",
      "[13]\tvalid_0's multi_logloss: 1.45039\n",
      "[14]\tvalid_0's multi_logloss: 1.44327\n",
      "[15]\tvalid_0's multi_logloss: 1.43675\n",
      "[16]\tvalid_0's multi_logloss: 1.43092\n",
      "[17]\tvalid_0's multi_logloss: 1.42538\n",
      "[18]\tvalid_0's multi_logloss: 1.42001\n",
      "[19]\tvalid_0's multi_logloss: 1.41532\n",
      "[20]\tvalid_0's multi_logloss: 1.41067\n",
      "[21]\tvalid_0's multi_logloss: 1.40625\n",
      "[22]\tvalid_0's multi_logloss: 1.40224\n",
      "[23]\tvalid_0's multi_logloss: 1.39838\n",
      "[24]\tvalid_0's multi_logloss: 1.39463\n",
      "[25]\tvalid_0's multi_logloss: 1.39123\n",
      "[26]\tvalid_0's multi_logloss: 1.38783\n",
      "[27]\tvalid_0's multi_logloss: 1.38466\n",
      "[28]\tvalid_0's multi_logloss: 1.38169\n",
      "[29]\tvalid_0's multi_logloss: 1.3788\n",
      "[30]\tvalid_0's multi_logloss: 1.3761\n",
      "[31]\tvalid_0's multi_logloss: 1.37347\n",
      "[32]\tvalid_0's multi_logloss: 1.37073\n",
      "[33]\tvalid_0's multi_logloss: 1.36824\n",
      "[34]\tvalid_0's multi_logloss: 1.36575\n",
      "[35]\tvalid_0's multi_logloss: 1.36338\n",
      "[36]\tvalid_0's multi_logloss: 1.36107\n",
      "[37]\tvalid_0's multi_logloss: 1.35897\n",
      "[38]\tvalid_0's multi_logloss: 1.35673\n",
      "[39]\tvalid_0's multi_logloss: 1.35468\n",
      "[40]\tvalid_0's multi_logloss: 1.3528\n",
      "[41]\tvalid_0's multi_logloss: 1.35084\n",
      "[42]\tvalid_0's multi_logloss: 1.3488\n",
      "[43]\tvalid_0's multi_logloss: 1.3471\n",
      "[44]\tvalid_0's multi_logloss: 1.34541\n",
      "[45]\tvalid_0's multi_logloss: 1.34352\n",
      "[46]\tvalid_0's multi_logloss: 1.34181\n",
      "[47]\tvalid_0's multi_logloss: 1.34009\n",
      "[48]\tvalid_0's multi_logloss: 1.33843\n",
      "[49]\tvalid_0's multi_logloss: 1.33689\n",
      "[50]\tvalid_0's multi_logloss: 1.33543\n",
      "[51]\tvalid_0's multi_logloss: 1.33395\n",
      "[52]\tvalid_0's multi_logloss: 1.33244\n",
      "[53]\tvalid_0's multi_logloss: 1.33095\n",
      "[54]\tvalid_0's multi_logloss: 1.32957\n",
      "[55]\tvalid_0's multi_logloss: 1.32828\n",
      "[56]\tvalid_0's multi_logloss: 1.32697\n",
      "[57]\tvalid_0's multi_logloss: 1.32561\n",
      "[58]\tvalid_0's multi_logloss: 1.32443\n",
      "[59]\tvalid_0's multi_logloss: 1.32313\n",
      "[60]\tvalid_0's multi_logloss: 1.32195\n",
      "[61]\tvalid_0's multi_logloss: 1.32078\n",
      "[62]\tvalid_0's multi_logloss: 1.31962\n",
      "[63]\tvalid_0's multi_logloss: 1.31847\n",
      "[64]\tvalid_0's multi_logloss: 1.3173\n",
      "[65]\tvalid_0's multi_logloss: 1.3161\n",
      "[66]\tvalid_0's multi_logloss: 1.31497\n",
      "[67]\tvalid_0's multi_logloss: 1.314\n",
      "[68]\tvalid_0's multi_logloss: 1.31303\n",
      "[69]\tvalid_0's multi_logloss: 1.31198\n",
      "[70]\tvalid_0's multi_logloss: 1.31101\n",
      "[71]\tvalid_0's multi_logloss: 1.31008\n",
      "[72]\tvalid_0's multi_logloss: 1.30913\n",
      "[73]\tvalid_0's multi_logloss: 1.30812\n",
      "[74]\tvalid_0's multi_logloss: 1.30712\n",
      "[75]\tvalid_0's multi_logloss: 1.30621\n",
      "[76]\tvalid_0's multi_logloss: 1.30521\n",
      "[77]\tvalid_0's multi_logloss: 1.30427\n",
      "[78]\tvalid_0's multi_logloss: 1.30328\n",
      "[79]\tvalid_0's multi_logloss: 1.30242\n",
      "[80]\tvalid_0's multi_logloss: 1.30152\n",
      "[81]\tvalid_0's multi_logloss: 1.30063\n",
      "[82]\tvalid_0's multi_logloss: 1.29981\n",
      "[83]\tvalid_0's multi_logloss: 1.29895\n",
      "[84]\tvalid_0's multi_logloss: 1.29816\n",
      "[85]\tvalid_0's multi_logloss: 1.29734\n",
      "[86]\tvalid_0's multi_logloss: 1.29648\n",
      "[87]\tvalid_0's multi_logloss: 1.29572\n",
      "[88]\tvalid_0's multi_logloss: 1.29491\n",
      "[89]\tvalid_0's multi_logloss: 1.29407\n",
      "[90]\tvalid_0's multi_logloss: 1.29335\n",
      "[91]\tvalid_0's multi_logloss: 1.2926\n",
      "[92]\tvalid_0's multi_logloss: 1.2919\n",
      "[93]\tvalid_0's multi_logloss: 1.29118\n",
      "[94]\tvalid_0's multi_logloss: 1.29049\n",
      "[95]\tvalid_0's multi_logloss: 1.2898\n",
      "[96]\tvalid_0's multi_logloss: 1.28909\n",
      "[97]\tvalid_0's multi_logloss: 1.28839\n",
      "[98]\tvalid_0's multi_logloss: 1.28778\n",
      "[99]\tvalid_0's multi_logloss: 1.28707\n",
      "[100]\tvalid_0's multi_logloss: 1.28647\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025599 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9435\n",
      "[LightGBM] [Info] Number of data points in the train set: 7715638, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -3.388563\n",
      "[LightGBM] [Info] Start training from score -3.286043\n",
      "[LightGBM] [Info] Start training from score -3.265766\n",
      "[LightGBM] [Info] Start training from score -3.814547\n",
      "[LightGBM] [Info] Start training from score -3.310265\n",
      "[LightGBM] [Info] Start training from score -3.206426\n",
      "[LightGBM] [Info] Start training from score -4.264605\n",
      "[LightGBM] [Info] Start training from score -3.385622\n",
      "[LightGBM] [Info] Start training from score -3.678169\n",
      "[LightGBM] [Info] Start training from score -3.401590\n",
      "[LightGBM] [Info] Start training from score -4.879144\n",
      "[LightGBM] [Info] Start training from score -3.027581\n",
      "[LightGBM] [Info] Start training from score -2.985319\n",
      "[LightGBM] [Info] Start training from score -3.251856\n",
      "[LightGBM] [Info] Start training from score -3.294527\n",
      "[LightGBM] [Info] Start training from score -3.372086\n",
      "[LightGBM] [Info] Start training from score -2.973489\n",
      "[LightGBM] [Info] Start training from score -2.489644\n",
      "[LightGBM] [Info] Start training from score -3.403357\n",
      "[LightGBM] [Info] Start training from score -4.161407\n",
      "[LightGBM] [Info] Start training from score -4.219942\n",
      "[LightGBM] [Info] Start training from score -3.454308\n",
      "[LightGBM] [Info] Start training from score -3.414970\n",
      "[LightGBM] [Info] Start training from score -3.160243\n",
      "[LightGBM] [Info] Start training from score -3.113230\n",
      "[LightGBM] [Info] Start training from score -3.209175\n",
      "[LightGBM] [Info] Start training from score -3.282600\n",
      "[LightGBM] [Info] Start training from score -3.180636\n",
      "[1]\tvalid_0's multi_logloss: 2.53322\n",
      "[2]\tvalid_0's multi_logloss: 2.28757\n",
      "[3]\tvalid_0's multi_logloss: 2.11253\n",
      "[4]\tvalid_0's multi_logloss: 1.97332\n",
      "[5]\tvalid_0's multi_logloss: 1.85764\n",
      "[6]\tvalid_0's multi_logloss: 1.75847\n",
      "[7]\tvalid_0's multi_logloss: 1.67241\n",
      "[8]\tvalid_0's multi_logloss: 1.59678\n",
      "[9]\tvalid_0's multi_logloss: 1.52926\n",
      "[10]\tvalid_0's multi_logloss: 1.46914\n",
      "[11]\tvalid_0's multi_logloss: 1.41476\n",
      "[12]\tvalid_0's multi_logloss: 1.3657\n",
      "[13]\tvalid_0's multi_logloss: 1.32065\n",
      "[14]\tvalid_0's multi_logloss: 1.2795\n",
      "[15]\tvalid_0's multi_logloss: 1.24162\n",
      "[16]\tvalid_0's multi_logloss: 1.20685\n",
      "[17]\tvalid_0's multi_logloss: 1.1749\n",
      "[18]\tvalid_0's multi_logloss: 1.1444\n",
      "[19]\tvalid_0's multi_logloss: 1.11783\n",
      "[20]\tvalid_0's multi_logloss: 1.09148\n",
      "[21]\tvalid_0's multi_logloss: 1.06746\n",
      "[22]\tvalid_0's multi_logloss: 1.04501\n",
      "[23]\tvalid_0's multi_logloss: 1.02348\n",
      "[24]\tvalid_0's multi_logloss: 1.00304\n",
      "[25]\tvalid_0's multi_logloss: 0.984224\n",
      "[26]\tvalid_0's multi_logloss: 0.966099\n",
      "[27]\tvalid_0's multi_logloss: 0.948888\n",
      "[28]\tvalid_0's multi_logloss: 0.932473\n",
      "[29]\tvalid_0's multi_logloss: 0.917081\n",
      "[30]\tvalid_0's multi_logloss: 0.902662\n",
      "[31]\tvalid_0's multi_logloss: 0.888657\n",
      "[32]\tvalid_0's multi_logloss: 0.875162\n",
      "[33]\tvalid_0's multi_logloss: 0.862376\n",
      "[34]\tvalid_0's multi_logloss: 0.850306\n",
      "[35]\tvalid_0's multi_logloss: 0.838411\n",
      "[36]\tvalid_0's multi_logloss: 0.827183\n",
      "[37]\tvalid_0's multi_logloss: 0.816643\n",
      "[38]\tvalid_0's multi_logloss: 0.806484\n",
      "[39]\tvalid_0's multi_logloss: 0.796676\n",
      "[40]\tvalid_0's multi_logloss: 0.787156\n",
      "[41]\tvalid_0's multi_logloss: 0.778048\n",
      "[42]\tvalid_0's multi_logloss: 0.769492\n",
      "[43]\tvalid_0's multi_logloss: 0.761085\n",
      "[44]\tvalid_0's multi_logloss: 0.752957\n",
      "[45]\tvalid_0's multi_logloss: 0.745173\n",
      "[46]\tvalid_0's multi_logloss: 0.737657\n",
      "[47]\tvalid_0's multi_logloss: 0.730442\n",
      "[48]\tvalid_0's multi_logloss: 0.723563\n",
      "[49]\tvalid_0's multi_logloss: 0.716688\n",
      "[50]\tvalid_0's multi_logloss: 0.710097\n",
      "[51]\tvalid_0's multi_logloss: 0.703717\n",
      "[52]\tvalid_0's multi_logloss: 0.697572\n",
      "[53]\tvalid_0's multi_logloss: 0.691551\n",
      "[54]\tvalid_0's multi_logloss: 0.685353\n",
      "[55]\tvalid_0's multi_logloss: 0.679875\n",
      "[56]\tvalid_0's multi_logloss: 0.674379\n",
      "[57]\tvalid_0's multi_logloss: 0.669087\n",
      "[58]\tvalid_0's multi_logloss: 0.663821\n",
      "[59]\tvalid_0's multi_logloss: 0.658903\n",
      "[60]\tvalid_0's multi_logloss: 0.654214\n",
      "[61]\tvalid_0's multi_logloss: 0.649554\n",
      "[62]\tvalid_0's multi_logloss: 0.645011\n",
      "[63]\tvalid_0's multi_logloss: 0.640413\n",
      "[64]\tvalid_0's multi_logloss: 0.636004\n",
      "[65]\tvalid_0's multi_logloss: 0.631806\n",
      "[66]\tvalid_0's multi_logloss: 0.627808\n",
      "[67]\tvalid_0's multi_logloss: 0.623847\n",
      "[68]\tvalid_0's multi_logloss: 0.620003\n",
      "[69]\tvalid_0's multi_logloss: 0.6159\n",
      "[70]\tvalid_0's multi_logloss: 0.612201\n",
      "[71]\tvalid_0's multi_logloss: 0.608667\n",
      "[72]\tvalid_0's multi_logloss: 0.604983\n",
      "[73]\tvalid_0's multi_logloss: 0.601225\n",
      "[74]\tvalid_0's multi_logloss: 0.597843\n",
      "[75]\tvalid_0's multi_logloss: 0.594659\n",
      "[76]\tvalid_0's multi_logloss: 0.591239\n",
      "[77]\tvalid_0's multi_logloss: 0.588099\n",
      "[78]\tvalid_0's multi_logloss: 0.585094\n",
      "[79]\tvalid_0's multi_logloss: 0.582085\n",
      "[80]\tvalid_0's multi_logloss: 0.579199\n",
      "[81]\tvalid_0's multi_logloss: 0.57626\n",
      "[82]\tvalid_0's multi_logloss: 0.57324\n",
      "[83]\tvalid_0's multi_logloss: 0.570341\n",
      "[84]\tvalid_0's multi_logloss: 0.568073\n",
      "[85]\tvalid_0's multi_logloss: 0.565093\n",
      "[86]\tvalid_0's multi_logloss: 0.562469\n",
      "[87]\tvalid_0's multi_logloss: 0.559875\n",
      "[88]\tvalid_0's multi_logloss: 0.557259\n",
      "[89]\tvalid_0's multi_logloss: 0.554694\n",
      "[90]\tvalid_0's multi_logloss: 0.552249\n",
      "[91]\tvalid_0's multi_logloss: 0.549819\n",
      "[92]\tvalid_0's multi_logloss: 0.547443\n",
      "[93]\tvalid_0's multi_logloss: 0.545812\n",
      "[94]\tvalid_0's multi_logloss: 0.5461\n",
      "[95]\tvalid_0's multi_logloss: 0.543101\n",
      "[96]\tvalid_0's multi_logloss: 0.540045\n",
      "[97]\tvalid_0's multi_logloss: 0.537255\n",
      "[98]\tvalid_0's multi_logloss: 0.535168\n",
      "[99]\tvalid_0's multi_logloss: 0.533123\n",
      "[100]\tvalid_0's multi_logloss: 0.531438\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007917 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 7715638, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.249550\n",
      "[LightGBM] [Info] Start training from score -3.165534\n",
      "[LightGBM] [Info] Start training from score -1.726403\n",
      "[LightGBM] [Info] Start training from score -1.902421\n",
      "[LightGBM] [Info] Start training from score -1.667720\n",
      "[LightGBM] [Info] Start training from score -1.861961\n",
      "[1]\tvalid_0's multi_logloss: 1.68246\n",
      "[2]\tvalid_0's multi_logloss: 1.67933\n",
      "[3]\tvalid_0's multi_logloss: 1.67687\n",
      "[4]\tvalid_0's multi_logloss: 1.67489\n",
      "[5]\tvalid_0's multi_logloss: 1.67328\n",
      "[6]\tvalid_0's multi_logloss: 1.67197\n",
      "[7]\tvalid_0's multi_logloss: 1.67089\n",
      "[8]\tvalid_0's multi_logloss: 1.67\n",
      "[9]\tvalid_0's multi_logloss: 1.66926\n",
      "[10]\tvalid_0's multi_logloss: 1.66864\n",
      "[11]\tvalid_0's multi_logloss: 1.66813\n",
      "[12]\tvalid_0's multi_logloss: 1.6677\n",
      "[13]\tvalid_0's multi_logloss: 1.66734\n",
      "[14]\tvalid_0's multi_logloss: 1.66704\n",
      "[15]\tvalid_0's multi_logloss: 1.66679\n",
      "[16]\tvalid_0's multi_logloss: 1.66657\n",
      "[17]\tvalid_0's multi_logloss: 1.66639\n",
      "[18]\tvalid_0's multi_logloss: 1.66624\n",
      "[19]\tvalid_0's multi_logloss: 1.66611\n",
      "[20]\tvalid_0's multi_logloss: 1.666\n",
      "[21]\tvalid_0's multi_logloss: 1.66591\n",
      "[22]\tvalid_0's multi_logloss: 1.66582\n",
      "[23]\tvalid_0's multi_logloss: 1.66575\n",
      "[24]\tvalid_0's multi_logloss: 1.6657\n",
      "[25]\tvalid_0's multi_logloss: 1.66564\n",
      "[26]\tvalid_0's multi_logloss: 1.6656\n",
      "[27]\tvalid_0's multi_logloss: 1.66556\n",
      "[28]\tvalid_0's multi_logloss: 1.66553\n",
      "[29]\tvalid_0's multi_logloss: 1.6655\n",
      "[30]\tvalid_0's multi_logloss: 1.66547\n",
      "[31]\tvalid_0's multi_logloss: 1.66545\n",
      "[32]\tvalid_0's multi_logloss: 1.66543\n",
      "[33]\tvalid_0's multi_logloss: 1.66541\n",
      "[34]\tvalid_0's multi_logloss: 1.66539\n",
      "[35]\tvalid_0's multi_logloss: 1.66538\n",
      "[36]\tvalid_0's multi_logloss: 1.66536\n",
      "[37]\tvalid_0's multi_logloss: 1.66535\n",
      "[38]\tvalid_0's multi_logloss: 1.66534\n",
      "[39]\tvalid_0's multi_logloss: 1.66533\n",
      "[40]\tvalid_0's multi_logloss: 1.66532\n",
      "[41]\tvalid_0's multi_logloss: 1.66531\n",
      "[42]\tvalid_0's multi_logloss: 1.6653\n",
      "[43]\tvalid_0's multi_logloss: 1.66529\n",
      "[44]\tvalid_0's multi_logloss: 1.66528\n",
      "[45]\tvalid_0's multi_logloss: 1.66527\n",
      "[46]\tvalid_0's multi_logloss: 1.66526\n",
      "[47]\tvalid_0's multi_logloss: 1.66525\n",
      "[48]\tvalid_0's multi_logloss: 1.66525\n",
      "[49]\tvalid_0's multi_logloss: 1.66524\n",
      "[50]\tvalid_0's multi_logloss: 1.66523\n",
      "[51]\tvalid_0's multi_logloss: 1.66522\n",
      "[52]\tvalid_0's multi_logloss: 1.66522\n",
      "[53]\tvalid_0's multi_logloss: 1.66521\n",
      "[54]\tvalid_0's multi_logloss: 1.6652\n",
      "[55]\tvalid_0's multi_logloss: 1.6652\n",
      "[56]\tvalid_0's multi_logloss: 1.66519\n",
      "[57]\tvalid_0's multi_logloss: 1.66518\n",
      "[58]\tvalid_0's multi_logloss: 1.66518\n",
      "[59]\tvalid_0's multi_logloss: 1.66517\n",
      "[60]\tvalid_0's multi_logloss: 1.66517\n",
      "[61]\tvalid_0's multi_logloss: 1.66516\n",
      "[62]\tvalid_0's multi_logloss: 1.66515\n",
      "[63]\tvalid_0's multi_logloss: 1.66515\n",
      "[64]\tvalid_0's multi_logloss: 1.66514\n",
      "[65]\tvalid_0's multi_logloss: 1.66514\n",
      "[66]\tvalid_0's multi_logloss: 1.66513\n",
      "[67]\tvalid_0's multi_logloss: 1.66513\n",
      "[68]\tvalid_0's multi_logloss: 1.66512\n",
      "[69]\tvalid_0's multi_logloss: 1.66511\n",
      "[70]\tvalid_0's multi_logloss: 1.66511\n",
      "[71]\tvalid_0's multi_logloss: 1.6651\n",
      "[72]\tvalid_0's multi_logloss: 1.6651\n",
      "[73]\tvalid_0's multi_logloss: 1.66509\n",
      "[74]\tvalid_0's multi_logloss: 1.66509\n",
      "[75]\tvalid_0's multi_logloss: 1.66508\n",
      "[76]\tvalid_0's multi_logloss: 1.66508\n",
      "[77]\tvalid_0's multi_logloss: 1.66507\n",
      "[78]\tvalid_0's multi_logloss: 1.66507\n",
      "[79]\tvalid_0's multi_logloss: 1.66506\n",
      "[80]\tvalid_0's multi_logloss: 1.66506\n",
      "[81]\tvalid_0's multi_logloss: 1.66505\n",
      "[82]\tvalid_0's multi_logloss: 1.66504\n",
      "[83]\tvalid_0's multi_logloss: 1.66504\n",
      "[84]\tvalid_0's multi_logloss: 1.66503\n",
      "[85]\tvalid_0's multi_logloss: 1.66503\n",
      "[86]\tvalid_0's multi_logloss: 1.66502\n",
      "[87]\tvalid_0's multi_logloss: 1.66502\n",
      "[88]\tvalid_0's multi_logloss: 1.66501\n",
      "[89]\tvalid_0's multi_logloss: 1.66501\n",
      "[90]\tvalid_0's multi_logloss: 1.665\n",
      "[91]\tvalid_0's multi_logloss: 1.665\n",
      "[92]\tvalid_0's multi_logloss: 1.66499\n",
      "[93]\tvalid_0's multi_logloss: 1.66499\n",
      "[94]\tvalid_0's multi_logloss: 1.66498\n",
      "[95]\tvalid_0's multi_logloss: 1.66498\n",
      "[96]\tvalid_0's multi_logloss: 1.66497\n",
      "[97]\tvalid_0's multi_logloss: 1.66497\n",
      "[98]\tvalid_0's multi_logloss: 1.66496\n",
      "[99]\tvalid_0's multi_logloss: 1.66496\n",
      "[100]\tvalid_0's multi_logloss: 1.66495\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007287 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 7715638, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -3.388563\n",
      "[LightGBM] [Info] Start training from score -3.286043\n",
      "[LightGBM] [Info] Start training from score -3.265766\n",
      "[LightGBM] [Info] Start training from score -3.814547\n",
      "[LightGBM] [Info] Start training from score -3.310265\n",
      "[LightGBM] [Info] Start training from score -3.206426\n",
      "[LightGBM] [Info] Start training from score -4.264605\n",
      "[LightGBM] [Info] Start training from score -3.385622\n",
      "[LightGBM] [Info] Start training from score -3.678169\n",
      "[LightGBM] [Info] Start training from score -3.401590\n",
      "[LightGBM] [Info] Start training from score -4.879144\n",
      "[LightGBM] [Info] Start training from score -3.027581\n",
      "[LightGBM] [Info] Start training from score -2.985319\n",
      "[LightGBM] [Info] Start training from score -3.251856\n",
      "[LightGBM] [Info] Start training from score -3.294527\n",
      "[LightGBM] [Info] Start training from score -3.372086\n",
      "[LightGBM] [Info] Start training from score -2.973489\n",
      "[LightGBM] [Info] Start training from score -2.489644\n",
      "[LightGBM] [Info] Start training from score -3.403357\n",
      "[LightGBM] [Info] Start training from score -4.161407\n",
      "[LightGBM] [Info] Start training from score -4.219942\n",
      "[LightGBM] [Info] Start training from score -3.454308\n",
      "[LightGBM] [Info] Start training from score -3.414970\n",
      "[LightGBM] [Info] Start training from score -3.160243\n",
      "[LightGBM] [Info] Start training from score -3.113230\n",
      "[LightGBM] [Info] Start training from score -3.209175\n",
      "[LightGBM] [Info] Start training from score -3.282600\n",
      "[LightGBM] [Info] Start training from score -3.180636\n",
      "[1]\tvalid_0's multi_logloss: 3.18782\n",
      "[2]\tvalid_0's multi_logloss: 3.14594\n",
      "[3]\tvalid_0's multi_logloss: 3.11438\n",
      "[4]\tvalid_0's multi_logloss: 3.0896\n",
      "[5]\tvalid_0's multi_logloss: 3.06968\n",
      "[6]\tvalid_0's multi_logloss: 3.05346\n",
      "[7]\tvalid_0's multi_logloss: 3.04008\n",
      "[8]\tvalid_0's multi_logloss: 3.02895\n",
      "[9]\tvalid_0's multi_logloss: 3.01966\n",
      "[10]\tvalid_0's multi_logloss: 3.01185\n",
      "[11]\tvalid_0's multi_logloss: 3.00527\n",
      "[12]\tvalid_0's multi_logloss: 2.99969\n",
      "[13]\tvalid_0's multi_logloss: 2.99496\n",
      "[14]\tvalid_0's multi_logloss: 2.99091\n",
      "[15]\tvalid_0's multi_logloss: 2.98746\n",
      "[16]\tvalid_0's multi_logloss: 2.98451\n",
      "[17]\tvalid_0's multi_logloss: 2.98199\n",
      "[18]\tvalid_0's multi_logloss: 2.97981\n",
      "[19]\tvalid_0's multi_logloss: 2.97794\n",
      "[20]\tvalid_0's multi_logloss: 2.97634\n",
      "[21]\tvalid_0's multi_logloss: 2.97495\n",
      "[22]\tvalid_0's multi_logloss: 2.97375\n",
      "[23]\tvalid_0's multi_logloss: 2.97271\n",
      "[24]\tvalid_0's multi_logloss: 2.97181\n",
      "[25]\tvalid_0's multi_logloss: 2.97104\n",
      "[26]\tvalid_0's multi_logloss: 2.97037\n",
      "[27]\tvalid_0's multi_logloss: 2.96978\n",
      "[28]\tvalid_0's multi_logloss: 2.96926\n",
      "[29]\tvalid_0's multi_logloss: 2.96881\n",
      "[30]\tvalid_0's multi_logloss: 2.96842\n",
      "[31]\tvalid_0's multi_logloss: 2.96808\n",
      "[32]\tvalid_0's multi_logloss: 2.96778\n",
      "[33]\tvalid_0's multi_logloss: 2.96751\n",
      "[34]\tvalid_0's multi_logloss: 2.96727\n",
      "[35]\tvalid_0's multi_logloss: 2.96706\n",
      "[36]\tvalid_0's multi_logloss: 2.96688\n",
      "[37]\tvalid_0's multi_logloss: 2.96671\n",
      "[38]\tvalid_0's multi_logloss: 2.96656\n",
      "[39]\tvalid_0's multi_logloss: 2.96643\n",
      "[40]\tvalid_0's multi_logloss: 2.96631\n",
      "[41]\tvalid_0's multi_logloss: 2.9662\n",
      "[42]\tvalid_0's multi_logloss: 2.9661\n",
      "[43]\tvalid_0's multi_logloss: 2.96601\n",
      "[44]\tvalid_0's multi_logloss: 2.96593\n",
      "[45]\tvalid_0's multi_logloss: 2.96585\n",
      "[46]\tvalid_0's multi_logloss: 2.96578\n",
      "[47]\tvalid_0's multi_logloss: 2.96571\n",
      "[48]\tvalid_0's multi_logloss: 2.96565\n",
      "[49]\tvalid_0's multi_logloss: 2.96559\n",
      "[50]\tvalid_0's multi_logloss: 2.96553\n",
      "[51]\tvalid_0's multi_logloss: 2.96548\n",
      "[52]\tvalid_0's multi_logloss: 2.96543\n",
      "[53]\tvalid_0's multi_logloss: 2.96538\n",
      "[54]\tvalid_0's multi_logloss: 2.96533\n",
      "[55]\tvalid_0's multi_logloss: 2.96528\n",
      "[56]\tvalid_0's multi_logloss: 2.96524\n",
      "[57]\tvalid_0's multi_logloss: 2.96519\n",
      "[58]\tvalid_0's multi_logloss: 2.96515\n",
      "[59]\tvalid_0's multi_logloss: 2.96511\n",
      "[60]\tvalid_0's multi_logloss: 2.96507\n",
      "[61]\tvalid_0's multi_logloss: 2.96503\n",
      "[62]\tvalid_0's multi_logloss: 2.96499\n",
      "[63]\tvalid_0's multi_logloss: 2.96496\n",
      "[64]\tvalid_0's multi_logloss: 2.96492\n",
      "[65]\tvalid_0's multi_logloss: 2.96489\n",
      "[66]\tvalid_0's multi_logloss: 2.96485\n",
      "[67]\tvalid_0's multi_logloss: 2.96481\n",
      "[68]\tvalid_0's multi_logloss: 2.96492\n",
      "[69]\tvalid_0's multi_logloss: 2.96475\n",
      "[70]\tvalid_0's multi_logloss: 2.96515\n",
      "[71]\tvalid_0's multi_logloss: 2.9649\n",
      "[72]\tvalid_0's multi_logloss: 2.96491\n",
      "[73]\tvalid_0's multi_logloss: 2.96488\n",
      "[74]\tvalid_0's multi_logloss: 2.96504\n",
      "[75]\tvalid_0's multi_logloss: 2.96456\n",
      "[76]\tvalid_0's multi_logloss: 2.96454\n",
      "[77]\tvalid_0's multi_logloss: 2.96486\n",
      "[78]\tvalid_0's multi_logloss: 2.96482\n",
      "[79]\tvalid_0's multi_logloss: 2.96477\n",
      "[80]\tvalid_0's multi_logloss: 2.96489\n",
      "[81]\tvalid_0's multi_logloss: 2.96438\n",
      "[82]\tvalid_0's multi_logloss: 2.96449\n",
      "[83]\tvalid_0's multi_logloss: 2.96432\n",
      "[84]\tvalid_0's multi_logloss: 2.96449\n",
      "[85]\tvalid_0's multi_logloss: 2.96489\n",
      "[86]\tvalid_0's multi_logloss: 2.96487\n",
      "[87]\tvalid_0's multi_logloss: 2.96492\n",
      "[88]\tvalid_0's multi_logloss: 2.96497\n",
      "[89]\tvalid_0's multi_logloss: 2.96447\n",
      "[90]\tvalid_0's multi_logloss: 2.96454\n",
      "[91]\tvalid_0's multi_logloss: 2.96446\n",
      "[92]\tvalid_0's multi_logloss: 2.96443\n",
      "[93]\tvalid_0's multi_logloss: 2.96447\n",
      "[94]\tvalid_0's multi_logloss: 2.96441\n",
      "[95]\tvalid_0's multi_logloss: 2.96463\n",
      "[96]\tvalid_0's multi_logloss: 2.96432\n",
      "[97]\tvalid_0's multi_logloss: 2.96463\n",
      "[98]\tvalid_0's multi_logloss: 2.96389\n",
      "[99]\tvalid_0's multi_logloss: 2.96456\n",
      "[100]\tvalid_0's multi_logloss: 2.96383\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008669 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 7715638, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -1.249550\n",
      "[LightGBM] [Info] Start training from score -3.165534\n",
      "[LightGBM] [Info] Start training from score -1.726403\n",
      "[LightGBM] [Info] Start training from score -1.902421\n",
      "[LightGBM] [Info] Start training from score -1.667720\n",
      "[LightGBM] [Info] Start training from score -1.861961\n",
      "[1]\tvalid_0's multi_logloss: 1.68134\n",
      "[2]\tvalid_0's multi_logloss: 1.67738\n",
      "[3]\tvalid_0's multi_logloss: 1.67422\n",
      "[4]\tvalid_0's multi_logloss: 1.67166\n",
      "[5]\tvalid_0's multi_logloss: 1.66957\n",
      "[6]\tvalid_0's multi_logloss: 1.66784\n",
      "[7]\tvalid_0's multi_logloss: 1.66639\n",
      "[8]\tvalid_0's multi_logloss: 1.66518\n",
      "[9]\tvalid_0's multi_logloss: 1.66417\n",
      "[10]\tvalid_0's multi_logloss: 1.66332\n",
      "[11]\tvalid_0's multi_logloss: 1.66259\n",
      "[12]\tvalid_0's multi_logloss: 1.66197\n",
      "[13]\tvalid_0's multi_logloss: 1.66144\n",
      "[14]\tvalid_0's multi_logloss: 1.66098\n",
      "[15]\tvalid_0's multi_logloss: 1.66058\n",
      "[16]\tvalid_0's multi_logloss: 1.66024\n",
      "[17]\tvalid_0's multi_logloss: 1.65993\n",
      "[18]\tvalid_0's multi_logloss: 1.65966\n",
      "[19]\tvalid_0's multi_logloss: 1.65943\n",
      "[20]\tvalid_0's multi_logloss: 1.65923\n",
      "[21]\tvalid_0's multi_logloss: 1.65905\n",
      "[22]\tvalid_0's multi_logloss: 1.65889\n",
      "[23]\tvalid_0's multi_logloss: 1.65874\n",
      "[24]\tvalid_0's multi_logloss: 1.65861\n",
      "[25]\tvalid_0's multi_logloss: 1.65849\n",
      "[26]\tvalid_0's multi_logloss: 1.65839\n",
      "[27]\tvalid_0's multi_logloss: 1.65829\n",
      "[28]\tvalid_0's multi_logloss: 1.65821\n",
      "[29]\tvalid_0's multi_logloss: 1.65813\n",
      "[30]\tvalid_0's multi_logloss: 1.65805\n",
      "[31]\tvalid_0's multi_logloss: 1.65798\n",
      "[32]\tvalid_0's multi_logloss: 1.65792\n",
      "[33]\tvalid_0's multi_logloss: 1.65786\n",
      "[34]\tvalid_0's multi_logloss: 1.65781\n",
      "[35]\tvalid_0's multi_logloss: 1.65775\n",
      "[36]\tvalid_0's multi_logloss: 1.65771\n",
      "[37]\tvalid_0's multi_logloss: 1.65766\n",
      "[38]\tvalid_0's multi_logloss: 1.65762\n",
      "[39]\tvalid_0's multi_logloss: 1.65758\n",
      "[40]\tvalid_0's multi_logloss: 1.65754\n",
      "[41]\tvalid_0's multi_logloss: 1.65751\n",
      "[42]\tvalid_0's multi_logloss: 1.65748\n",
      "[43]\tvalid_0's multi_logloss: 1.65744\n",
      "[44]\tvalid_0's multi_logloss: 1.65741\n",
      "[45]\tvalid_0's multi_logloss: 1.65738\n",
      "[46]\tvalid_0's multi_logloss: 1.65735\n",
      "[47]\tvalid_0's multi_logloss: 1.65733\n",
      "[48]\tvalid_0's multi_logloss: 1.6573\n",
      "[49]\tvalid_0's multi_logloss: 1.65728\n",
      "[50]\tvalid_0's multi_logloss: 1.65725\n",
      "[51]\tvalid_0's multi_logloss: 1.65723\n",
      "[52]\tvalid_0's multi_logloss: 1.65721\n",
      "[53]\tvalid_0's multi_logloss: 1.65719\n",
      "[54]\tvalid_0's multi_logloss: 1.65717\n",
      "[55]\tvalid_0's multi_logloss: 1.65715\n",
      "[56]\tvalid_0's multi_logloss: 1.65713\n",
      "[57]\tvalid_0's multi_logloss: 1.65711\n",
      "[58]\tvalid_0's multi_logloss: 1.65709\n",
      "[59]\tvalid_0's multi_logloss: 1.65707\n",
      "[60]\tvalid_0's multi_logloss: 1.65705\n",
      "[61]\tvalid_0's multi_logloss: 1.65704\n",
      "[62]\tvalid_0's multi_logloss: 1.65702\n",
      "[63]\tvalid_0's multi_logloss: 1.65701\n",
      "[64]\tvalid_0's multi_logloss: 1.65699\n",
      "[65]\tvalid_0's multi_logloss: 1.65698\n",
      "[66]\tvalid_0's multi_logloss: 1.65696\n",
      "[67]\tvalid_0's multi_logloss: 1.65695\n",
      "[68]\tvalid_0's multi_logloss: 1.65693\n",
      "[69]\tvalid_0's multi_logloss: 1.65692\n",
      "[70]\tvalid_0's multi_logloss: 1.65691\n",
      "[71]\tvalid_0's multi_logloss: 1.65689\n",
      "[72]\tvalid_0's multi_logloss: 1.65688\n",
      "[73]\tvalid_0's multi_logloss: 1.65687\n",
      "[74]\tvalid_0's multi_logloss: 1.65685\n",
      "[75]\tvalid_0's multi_logloss: 1.65684\n",
      "[76]\tvalid_0's multi_logloss: 1.65683\n",
      "[77]\tvalid_0's multi_logloss: 1.65682\n",
      "[78]\tvalid_0's multi_logloss: 1.6568\n",
      "[79]\tvalid_0's multi_logloss: 1.65679\n",
      "[80]\tvalid_0's multi_logloss: 1.65678\n",
      "[81]\tvalid_0's multi_logloss: 1.65676\n",
      "[82]\tvalid_0's multi_logloss: 1.65675\n",
      "[83]\tvalid_0's multi_logloss: 1.65674\n",
      "[84]\tvalid_0's multi_logloss: 1.65673\n",
      "[85]\tvalid_0's multi_logloss: 1.65671\n",
      "[86]\tvalid_0's multi_logloss: 1.6567\n",
      "[87]\tvalid_0's multi_logloss: 1.65669\n",
      "[88]\tvalid_0's multi_logloss: 1.65667\n",
      "[89]\tvalid_0's multi_logloss: 1.65666\n",
      "[90]\tvalid_0's multi_logloss: 1.65665\n",
      "[91]\tvalid_0's multi_logloss: 1.65664\n",
      "[92]\tvalid_0's multi_logloss: 1.65662\n",
      "[93]\tvalid_0's multi_logloss: 1.65661\n",
      "[94]\tvalid_0's multi_logloss: 1.6566\n",
      "[95]\tvalid_0's multi_logloss: 1.65659\n",
      "[96]\tvalid_0's multi_logloss: 1.65658\n",
      "[97]\tvalid_0's multi_logloss: 1.65657\n",
      "[98]\tvalid_0's multi_logloss: 1.65656\n",
      "[99]\tvalid_0's multi_logloss: 1.65654\n",
      "[100]\tvalid_0's multi_logloss: 1.65653\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007718 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 7715638, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -3.388563\n",
      "[LightGBM] [Info] Start training from score -3.286043\n",
      "[LightGBM] [Info] Start training from score -3.265766\n",
      "[LightGBM] [Info] Start training from score -3.814547\n",
      "[LightGBM] [Info] Start training from score -3.310265\n",
      "[LightGBM] [Info] Start training from score -3.206426\n",
      "[LightGBM] [Info] Start training from score -4.264605\n",
      "[LightGBM] [Info] Start training from score -3.385622\n",
      "[LightGBM] [Info] Start training from score -3.678169\n",
      "[LightGBM] [Info] Start training from score -3.401590\n",
      "[LightGBM] [Info] Start training from score -4.879144\n",
      "[LightGBM] [Info] Start training from score -3.027581\n",
      "[LightGBM] [Info] Start training from score -2.985319\n",
      "[LightGBM] [Info] Start training from score -3.251856\n",
      "[LightGBM] [Info] Start training from score -3.294527\n",
      "[LightGBM] [Info] Start training from score -3.372086\n",
      "[LightGBM] [Info] Start training from score -2.973489\n",
      "[LightGBM] [Info] Start training from score -2.489644\n",
      "[LightGBM] [Info] Start training from score -3.403357\n",
      "[LightGBM] [Info] Start training from score -4.161407\n",
      "[LightGBM] [Info] Start training from score -4.219942\n",
      "[LightGBM] [Info] Start training from score -3.454308\n",
      "[LightGBM] [Info] Start training from score -3.414970\n",
      "[LightGBM] [Info] Start training from score -3.160243\n",
      "[LightGBM] [Info] Start training from score -3.113230\n",
      "[LightGBM] [Info] Start training from score -3.209175\n",
      "[LightGBM] [Info] Start training from score -3.282600\n",
      "[LightGBM] [Info] Start training from score -3.180636\n",
      "[1]\tvalid_0's multi_logloss: 3.1175\n",
      "[2]\tvalid_0's multi_logloss: 3.04502\n",
      "[3]\tvalid_0's multi_logloss: 2.99142\n",
      "[4]\tvalid_0's multi_logloss: 2.94954\n",
      "[5]\tvalid_0's multi_logloss: 2.91601\n",
      "[6]\tvalid_0's multi_logloss: 2.88851\n",
      "[7]\tvalid_0's multi_logloss: 2.86558\n",
      "[8]\tvalid_0's multi_logloss: 2.84636\n",
      "[9]\tvalid_0's multi_logloss: 2.83007\n",
      "[10]\tvalid_0's multi_logloss: 2.81617\n",
      "[11]\tvalid_0's multi_logloss: 2.80419\n",
      "[12]\tvalid_0's multi_logloss: 2.79386\n",
      "[13]\tvalid_0's multi_logloss: 2.78488\n",
      "[14]\tvalid_0's multi_logloss: 2.77702\n",
      "[15]\tvalid_0's multi_logloss: 2.77017\n",
      "[16]\tvalid_0's multi_logloss: 2.76418\n",
      "[17]\tvalid_0's multi_logloss: 2.75884\n",
      "[18]\tvalid_0's multi_logloss: 2.75416\n",
      "[19]\tvalid_0's multi_logloss: 2.75\n",
      "[20]\tvalid_0's multi_logloss: 2.74627\n",
      "[21]\tvalid_0's multi_logloss: 2.74295\n",
      "[22]\tvalid_0's multi_logloss: 2.73998\n",
      "[23]\tvalid_0's multi_logloss: 2.73737\n",
      "[24]\tvalid_0's multi_logloss: 2.73503\n",
      "[25]\tvalid_0's multi_logloss: 2.73291\n",
      "[26]\tvalid_0's multi_logloss: 2.731\n",
      "[27]\tvalid_0's multi_logloss: 2.72927\n",
      "[28]\tvalid_0's multi_logloss: 2.7277\n",
      "[29]\tvalid_0's multi_logloss: 2.7263\n",
      "[30]\tvalid_0's multi_logloss: 2.72499\n",
      "[31]\tvalid_0's multi_logloss: 2.7238\n",
      "[32]\tvalid_0's multi_logloss: 2.72271\n",
      "[33]\tvalid_0's multi_logloss: 2.72169\n",
      "[34]\tvalid_0's multi_logloss: 2.72078\n",
      "[35]\tvalid_0's multi_logloss: 2.71994\n",
      "[36]\tvalid_0's multi_logloss: 2.71918\n",
      "[37]\tvalid_0's multi_logloss: 2.71845\n",
      "[38]\tvalid_0's multi_logloss: 2.71783\n",
      "[39]\tvalid_0's multi_logloss: 2.7172\n",
      "[40]\tvalid_0's multi_logloss: 2.71664\n",
      "[41]\tvalid_0's multi_logloss: 2.71612\n",
      "[42]\tvalid_0's multi_logloss: 2.71564\n",
      "[43]\tvalid_0's multi_logloss: 2.7152\n",
      "[44]\tvalid_0's multi_logloss: 2.71476\n",
      "[45]\tvalid_0's multi_logloss: 2.71436\n",
      "[46]\tvalid_0's multi_logloss: 2.71399\n",
      "[47]\tvalid_0's multi_logloss: 2.71362\n",
      "[48]\tvalid_0's multi_logloss: 2.71328\n",
      "[49]\tvalid_0's multi_logloss: 2.71297\n",
      "[50]\tvalid_0's multi_logloss: 2.71269\n",
      "[51]\tvalid_0's multi_logloss: 2.71241\n",
      "[52]\tvalid_0's multi_logloss: 2.71216\n",
      "[53]\tvalid_0's multi_logloss: 2.71187\n",
      "[54]\tvalid_0's multi_logloss: 2.71161\n",
      "[55]\tvalid_0's multi_logloss: 2.71145\n",
      "[56]\tvalid_0's multi_logloss: 2.71122\n",
      "[57]\tvalid_0's multi_logloss: 2.71101\n",
      "[58]\tvalid_0's multi_logloss: 2.7108\n",
      "[59]\tvalid_0's multi_logloss: 2.71079\n",
      "[60]\tvalid_0's multi_logloss: 2.71048\n",
      "[61]\tvalid_0's multi_logloss: 2.71043\n",
      "[62]\tvalid_0's multi_logloss: 2.71031\n",
      "[63]\tvalid_0's multi_logloss: 2.71008\n",
      "[64]\tvalid_0's multi_logloss: 2.71\n",
      "[65]\tvalid_0's multi_logloss: 2.7098\n",
      "[66]\tvalid_0's multi_logloss: 2.70984\n",
      "[67]\tvalid_0's multi_logloss: 2.70984\n",
      "[68]\tvalid_0's multi_logloss: 2.70967\n",
      "[69]\tvalid_0's multi_logloss: 2.70959\n",
      "[70]\tvalid_0's multi_logloss: 2.70947\n",
      "[71]\tvalid_0's multi_logloss: 2.70958\n",
      "[72]\tvalid_0's multi_logloss: 2.70973\n",
      "[73]\tvalid_0's multi_logloss: 2.70944\n",
      "[74]\tvalid_0's multi_logloss: 2.70959\n",
      "[75]\tvalid_0's multi_logloss: 2.70947\n",
      "[76]\tvalid_0's multi_logloss: 2.70956\n",
      "[77]\tvalid_0's multi_logloss: 2.70958\n",
      "[78]\tvalid_0's multi_logloss: 2.70943\n",
      "[79]\tvalid_0's multi_logloss: 2.70915\n",
      "[80]\tvalid_0's multi_logloss: 2.70908\n",
      "[81]\tvalid_0's multi_logloss: 2.70958\n",
      "[82]\tvalid_0's multi_logloss: 2.70899\n",
      "[83]\tvalid_0's multi_logloss: 2.7092\n",
      "[84]\tvalid_0's multi_logloss: 2.70915\n",
      "[85]\tvalid_0's multi_logloss: 2.71\n",
      "[86]\tvalid_0's multi_logloss: 2.70971\n",
      "[87]\tvalid_0's multi_logloss: 2.71052\n",
      "[88]\tvalid_0's multi_logloss: 2.70984\n",
      "[89]\tvalid_0's multi_logloss: 2.71113\n",
      "[90]\tvalid_0's multi_logloss: 2.71066\n",
      "[91]\tvalid_0's multi_logloss: 2.70979\n",
      "[92]\tvalid_0's multi_logloss: 2.71073\n",
      "[93]\tvalid_0's multi_logloss: 2.71163\n",
      "[94]\tvalid_0's multi_logloss: 2.70998\n",
      "[95]\tvalid_0's multi_logloss: 2.71081\n",
      "[96]\tvalid_0's multi_logloss: 2.71131\n",
      "[97]\tvalid_0's multi_logloss: 2.71213\n",
      "[98]\tvalid_0's multi_logloss: 2.71117\n",
      "[99]\tvalid_0's multi_logloss: 2.7124\n",
      "[100]\tvalid_0's multi_logloss: 2.71191\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009090 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 7715638, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -1.249550\n",
      "[LightGBM] [Info] Start training from score -3.165534\n",
      "[LightGBM] [Info] Start training from score -1.726403\n",
      "[LightGBM] [Info] Start training from score -1.902421\n",
      "[LightGBM] [Info] Start training from score -1.667720\n",
      "[LightGBM] [Info] Start training from score -1.861961\n",
      "[1]\tvalid_0's multi_logloss: 1.67729\n",
      "[2]\tvalid_0's multi_logloss: 1.67007\n",
      "[3]\tvalid_0's multi_logloss: 1.66422\n",
      "[4]\tvalid_0's multi_logloss: 1.65936\n",
      "[5]\tvalid_0's multi_logloss: 1.65524\n",
      "[6]\tvalid_0's multi_logloss: 1.6517\n",
      "[7]\tvalid_0's multi_logloss: 1.6487\n",
      "[8]\tvalid_0's multi_logloss: 1.64611\n",
      "[9]\tvalid_0's multi_logloss: 1.64389\n",
      "[10]\tvalid_0's multi_logloss: 1.64193\n",
      "[11]\tvalid_0's multi_logloss: 1.64022\n",
      "[12]\tvalid_0's multi_logloss: 1.63872\n",
      "[13]\tvalid_0's multi_logloss: 1.63741\n",
      "[14]\tvalid_0's multi_logloss: 1.63623\n",
      "[15]\tvalid_0's multi_logloss: 1.63518\n",
      "[16]\tvalid_0's multi_logloss: 1.63424\n",
      "[17]\tvalid_0's multi_logloss: 1.63341\n",
      "[18]\tvalid_0's multi_logloss: 1.63264\n",
      "[19]\tvalid_0's multi_logloss: 1.63193\n",
      "[20]\tvalid_0's multi_logloss: 1.63133\n",
      "[21]\tvalid_0's multi_logloss: 1.63076\n",
      "[22]\tvalid_0's multi_logloss: 1.63025\n",
      "[23]\tvalid_0's multi_logloss: 1.62977\n",
      "[24]\tvalid_0's multi_logloss: 1.62932\n",
      "[25]\tvalid_0's multi_logloss: 1.62892\n",
      "[26]\tvalid_0's multi_logloss: 1.62854\n",
      "[27]\tvalid_0's multi_logloss: 1.62818\n",
      "[28]\tvalid_0's multi_logloss: 1.62784\n",
      "[29]\tvalid_0's multi_logloss: 1.62752\n",
      "[30]\tvalid_0's multi_logloss: 1.62721\n",
      "[31]\tvalid_0's multi_logloss: 1.62693\n",
      "[32]\tvalid_0's multi_logloss: 1.62667\n",
      "[33]\tvalid_0's multi_logloss: 1.62642\n",
      "[34]\tvalid_0's multi_logloss: 1.62618\n",
      "[35]\tvalid_0's multi_logloss: 1.62595\n",
      "[36]\tvalid_0's multi_logloss: 1.62574\n",
      "[37]\tvalid_0's multi_logloss: 1.62554\n",
      "[38]\tvalid_0's multi_logloss: 1.62536\n",
      "[39]\tvalid_0's multi_logloss: 1.62513\n",
      "[40]\tvalid_0's multi_logloss: 1.62497\n",
      "[41]\tvalid_0's multi_logloss: 1.62479\n",
      "[42]\tvalid_0's multi_logloss: 1.62463\n",
      "[43]\tvalid_0's multi_logloss: 1.62446\n",
      "[44]\tvalid_0's multi_logloss: 1.62432\n",
      "[45]\tvalid_0's multi_logloss: 1.62416\n",
      "[46]\tvalid_0's multi_logloss: 1.62403\n",
      "[47]\tvalid_0's multi_logloss: 1.6239\n",
      "[48]\tvalid_0's multi_logloss: 1.62379\n",
      "[49]\tvalid_0's multi_logloss: 1.62366\n",
      "[50]\tvalid_0's multi_logloss: 1.62354\n",
      "[51]\tvalid_0's multi_logloss: 1.62343\n",
      "[52]\tvalid_0's multi_logloss: 1.62331\n",
      "[53]\tvalid_0's multi_logloss: 1.62321\n",
      "[54]\tvalid_0's multi_logloss: 1.62311\n",
      "[55]\tvalid_0's multi_logloss: 1.623\n",
      "[56]\tvalid_0's multi_logloss: 1.62289\n",
      "[57]\tvalid_0's multi_logloss: 1.62279\n",
      "[58]\tvalid_0's multi_logloss: 1.6227\n",
      "[59]\tvalid_0's multi_logloss: 1.62262\n",
      "[60]\tvalid_0's multi_logloss: 1.62254\n",
      "[61]\tvalid_0's multi_logloss: 1.62244\n",
      "[62]\tvalid_0's multi_logloss: 1.62237\n",
      "[63]\tvalid_0's multi_logloss: 1.6223\n",
      "[64]\tvalid_0's multi_logloss: 1.62223\n",
      "[65]\tvalid_0's multi_logloss: 1.62216\n",
      "[66]\tvalid_0's multi_logloss: 1.62207\n",
      "[67]\tvalid_0's multi_logloss: 1.62198\n",
      "[68]\tvalid_0's multi_logloss: 1.62191\n",
      "[69]\tvalid_0's multi_logloss: 1.62184\n",
      "[70]\tvalid_0's multi_logloss: 1.62179\n",
      "[71]\tvalid_0's multi_logloss: 1.62172\n",
      "[72]\tvalid_0's multi_logloss: 1.62165\n",
      "[73]\tvalid_0's multi_logloss: 1.62158\n",
      "[74]\tvalid_0's multi_logloss: 1.6215\n",
      "[75]\tvalid_0's multi_logloss: 1.62145\n",
      "[76]\tvalid_0's multi_logloss: 1.62139\n",
      "[77]\tvalid_0's multi_logloss: 1.62134\n",
      "[78]\tvalid_0's multi_logloss: 1.62129\n",
      "[79]\tvalid_0's multi_logloss: 1.62122\n",
      "[80]\tvalid_0's multi_logloss: 1.62116\n",
      "[81]\tvalid_0's multi_logloss: 1.62112\n",
      "[82]\tvalid_0's multi_logloss: 1.62107\n",
      "[83]\tvalid_0's multi_logloss: 1.62102\n",
      "[84]\tvalid_0's multi_logloss: 1.62098\n",
      "[85]\tvalid_0's multi_logloss: 1.62093\n",
      "[86]\tvalid_0's multi_logloss: 1.62088\n",
      "[87]\tvalid_0's multi_logloss: 1.62085\n",
      "[88]\tvalid_0's multi_logloss: 1.6208\n",
      "[89]\tvalid_0's multi_logloss: 1.62077\n",
      "[90]\tvalid_0's multi_logloss: 1.62072\n",
      "[91]\tvalid_0's multi_logloss: 1.62067\n",
      "[92]\tvalid_0's multi_logloss: 1.62062\n",
      "[93]\tvalid_0's multi_logloss: 1.62055\n",
      "[94]\tvalid_0's multi_logloss: 1.62051\n",
      "[95]\tvalid_0's multi_logloss: 1.62043\n",
      "[96]\tvalid_0's multi_logloss: 1.62038\n",
      "[97]\tvalid_0's multi_logloss: 1.62033\n",
      "[98]\tvalid_0's multi_logloss: 1.62029\n",
      "[99]\tvalid_0's multi_logloss: 1.62025\n",
      "[100]\tvalid_0's multi_logloss: 1.62019\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011859 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 7715638, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -3.388563\n",
      "[LightGBM] [Info] Start training from score -3.286043\n",
      "[LightGBM] [Info] Start training from score -3.265766\n",
      "[LightGBM] [Info] Start training from score -3.814547\n",
      "[LightGBM] [Info] Start training from score -3.310265\n",
      "[LightGBM] [Info] Start training from score -3.206426\n",
      "[LightGBM] [Info] Start training from score -4.264605\n",
      "[LightGBM] [Info] Start training from score -3.385622\n",
      "[LightGBM] [Info] Start training from score -3.678169\n",
      "[LightGBM] [Info] Start training from score -3.401590\n",
      "[LightGBM] [Info] Start training from score -4.879144\n",
      "[LightGBM] [Info] Start training from score -3.027581\n",
      "[LightGBM] [Info] Start training from score -2.985319\n",
      "[LightGBM] [Info] Start training from score -3.251856\n",
      "[LightGBM] [Info] Start training from score -3.294527\n",
      "[LightGBM] [Info] Start training from score -3.372086\n",
      "[LightGBM] [Info] Start training from score -2.973489\n",
      "[LightGBM] [Info] Start training from score -2.489644\n",
      "[LightGBM] [Info] Start training from score -3.403357\n",
      "[LightGBM] [Info] Start training from score -4.161407\n",
      "[LightGBM] [Info] Start training from score -4.219942\n",
      "[LightGBM] [Info] Start training from score -3.454308\n",
      "[LightGBM] [Info] Start training from score -3.414970\n",
      "[LightGBM] [Info] Start training from score -3.160243\n",
      "[LightGBM] [Info] Start training from score -3.113230\n",
      "[LightGBM] [Info] Start training from score -3.209175\n",
      "[LightGBM] [Info] Start training from score -3.282600\n",
      "[LightGBM] [Info] Start training from score -3.180636\n",
      "[1]\tvalid_0's multi_logloss: 2.99452\n",
      "[2]\tvalid_0's multi_logloss: 2.87813\n",
      "[3]\tvalid_0's multi_logloss: 2.7936\n",
      "[4]\tvalid_0's multi_logloss: 2.72758\n",
      "[5]\tvalid_0's multi_logloss: 2.67417\n",
      "[6]\tvalid_0's multi_logloss: 2.63015\n",
      "[7]\tvalid_0's multi_logloss: 2.59255\n",
      "[8]\tvalid_0's multi_logloss: 2.56096\n",
      "[9]\tvalid_0's multi_logloss: 2.53351\n",
      "[10]\tvalid_0's multi_logloss: 2.50955\n",
      "[11]\tvalid_0's multi_logloss: 2.48852\n",
      "[12]\tvalid_0's multi_logloss: 2.46997\n",
      "[13]\tvalid_0's multi_logloss: 2.45364\n",
      "[14]\tvalid_0's multi_logloss: 2.43916\n",
      "[15]\tvalid_0's multi_logloss: 2.42628\n",
      "[16]\tvalid_0's multi_logloss: 2.4146\n",
      "[17]\tvalid_0's multi_logloss: 2.40412\n",
      "[18]\tvalid_0's multi_logloss: 2.3946\n",
      "[19]\tvalid_0's multi_logloss: 2.38596\n",
      "[20]\tvalid_0's multi_logloss: 2.37817\n",
      "[21]\tvalid_0's multi_logloss: 2.37106\n",
      "[22]\tvalid_0's multi_logloss: 2.36447\n",
      "[23]\tvalid_0's multi_logloss: 2.35839\n",
      "[24]\tvalid_0's multi_logloss: 2.35268\n",
      "[25]\tvalid_0's multi_logloss: 2.34749\n",
      "[26]\tvalid_0's multi_logloss: 2.34267\n",
      "[27]\tvalid_0's multi_logloss: 2.33817\n",
      "[28]\tvalid_0's multi_logloss: 2.33403\n",
      "[29]\tvalid_0's multi_logloss: 2.33022\n",
      "[30]\tvalid_0's multi_logloss: 2.32666\n",
      "[31]\tvalid_0's multi_logloss: 2.3234\n",
      "[32]\tvalid_0's multi_logloss: 2.32027\n",
      "[33]\tvalid_0's multi_logloss: 2.31734\n",
      "[34]\tvalid_0's multi_logloss: 2.31454\n",
      "[35]\tvalid_0's multi_logloss: 2.31199\n",
      "[36]\tvalid_0's multi_logloss: 2.30946\n",
      "[37]\tvalid_0's multi_logloss: 2.30718\n",
      "[38]\tvalid_0's multi_logloss: 2.30501\n",
      "[39]\tvalid_0's multi_logloss: 2.30294\n",
      "[40]\tvalid_0's multi_logloss: 2.30097\n",
      "[41]\tvalid_0's multi_logloss: 2.29913\n",
      "[42]\tvalid_0's multi_logloss: 2.29742\n",
      "[43]\tvalid_0's multi_logloss: 2.29576\n",
      "[44]\tvalid_0's multi_logloss: 2.2942\n",
      "[45]\tvalid_0's multi_logloss: 2.2927\n",
      "[46]\tvalid_0's multi_logloss: 2.29134\n",
      "[47]\tvalid_0's multi_logloss: 2.28997\n",
      "[48]\tvalid_0's multi_logloss: 2.28868\n",
      "[49]\tvalid_0's multi_logloss: 2.28744\n",
      "[50]\tvalid_0's multi_logloss: 2.28622\n",
      "[51]\tvalid_0's multi_logloss: 2.28508\n",
      "[52]\tvalid_0's multi_logloss: 2.28395\n",
      "[53]\tvalid_0's multi_logloss: 2.28289\n",
      "[54]\tvalid_0's multi_logloss: 2.28192\n",
      "[55]\tvalid_0's multi_logloss: 2.28093\n",
      "[56]\tvalid_0's multi_logloss: 2.27994\n",
      "[57]\tvalid_0's multi_logloss: 2.27904\n",
      "[58]\tvalid_0's multi_logloss: 2.27806\n",
      "[59]\tvalid_0's multi_logloss: 2.27729\n",
      "[60]\tvalid_0's multi_logloss: 2.27648\n",
      "[61]\tvalid_0's multi_logloss: 2.27572\n",
      "[62]\tvalid_0's multi_logloss: 2.27497\n",
      "[63]\tvalid_0's multi_logloss: 2.27427\n",
      "[64]\tvalid_0's multi_logloss: 2.27352\n",
      "[65]\tvalid_0's multi_logloss: 2.27281\n",
      "[66]\tvalid_0's multi_logloss: 2.27212\n",
      "[67]\tvalid_0's multi_logloss: 2.27142\n",
      "[68]\tvalid_0's multi_logloss: 2.2707\n",
      "[69]\tvalid_0's multi_logloss: 2.27012\n",
      "[70]\tvalid_0's multi_logloss: 2.26954\n",
      "[71]\tvalid_0's multi_logloss: 2.26896\n",
      "[72]\tvalid_0's multi_logloss: 2.26828\n",
      "[73]\tvalid_0's multi_logloss: 2.26783\n",
      "[74]\tvalid_0's multi_logloss: 2.26727\n",
      "[75]\tvalid_0's multi_logloss: 2.26692\n",
      "[76]\tvalid_0's multi_logloss: 2.26638\n",
      "[77]\tvalid_0's multi_logloss: 2.26571\n",
      "[78]\tvalid_0's multi_logloss: 2.26512\n",
      "[79]\tvalid_0's multi_logloss: 2.26464\n",
      "[80]\tvalid_0's multi_logloss: 2.26417\n",
      "[81]\tvalid_0's multi_logloss: 2.26384\n",
      "[82]\tvalid_0's multi_logloss: 2.2634\n",
      "[83]\tvalid_0's multi_logloss: 2.26297\n",
      "[84]\tvalid_0's multi_logloss: 2.26254\n",
      "[85]\tvalid_0's multi_logloss: 2.2622\n",
      "[86]\tvalid_0's multi_logloss: 2.26166\n",
      "[87]\tvalid_0's multi_logloss: 2.26146\n",
      "[88]\tvalid_0's multi_logloss: 2.26085\n",
      "[89]\tvalid_0's multi_logloss: 2.26122\n",
      "[90]\tvalid_0's multi_logloss: 2.2602\n",
      "[91]\tvalid_0's multi_logloss: 2.25972\n",
      "[92]\tvalid_0's multi_logloss: 2.25946\n",
      "[93]\tvalid_0's multi_logloss: 2.25912\n",
      "[94]\tvalid_0's multi_logloss: 2.25884\n",
      "[95]\tvalid_0's multi_logloss: 2.25839\n",
      "[96]\tvalid_0's multi_logloss: 2.25848\n",
      "[97]\tvalid_0's multi_logloss: 2.25874\n",
      "[98]\tvalid_0's multi_logloss: 2.25803\n",
      "[99]\tvalid_0's multi_logloss: 2.25759\n",
      "[100]\tvalid_0's multi_logloss: 2.25736\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_result_list = []\n",
    "baseline_result_list = []\n",
    "metadata_dict = dict()\n",
    "save_dir = Path('/data/PycharmProjects/cytof_benchmark/results/classifier_data')\n",
    "for dataset_name in variables.keys():\n",
    "    dataset_class = getattr(datasets, dataset_name)\n",
    "    dataset_dir = dataset_dirs[dataset_name]\n",
    "\n",
    "    dataset = dataset_class(data_dir=dataset_dir)\n",
    "    X_train,y_train = dataset.train\n",
    "    X_val,y_val = dataset.train\n",
    "    X_test,y_test = dataset.train\n",
    "\n",
    "    for variable in variables[dataset_name]:\n",
    "        baseline_top_class = y_test[variable].value_counts(normalize=True).max()\n",
    "\n",
    "        gbm = lightgbm.LGBMClassifier()\n",
    "        params = {'objective': 'multiclass','num_class': y_train[variable].nunique()}\n",
    "\n",
    "        lgb_train = lightgbm.Dataset(X_train, y_train[variable].astype('category').cat.codes)\n",
    "        lgb_eval = lightgbm.Dataset(X_val, y_val[variable].astype('category').cat.codes, reference=lgb_train)\n",
    "\n",
    "        classifier = lightgbm.train(params, train_set=lgb_train, valid_sets=lgb_eval)\n",
    "\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "        all_marker_acc = sklearn.metrics.accuracy_score(y_test[variable].astype('category').cat.codes, y_pred)\n",
    "        baseline_result_list.append((dataset_name,variable,baseline_top_class,all_marker_acc))\n",
    "\n",
    "    for dim in [2,3,5]:\n",
    "        pca = PCA(n_components=dim)\n",
    "        pca.fit(X_train)\n",
    "        lgb_X_train = pca.transform(X_train)\n",
    "        lgb_X_val = pca.transform(X_val)\n",
    "        lgb_X_test = pca.transform(X_test)\n",
    "        for variable in variables[dataset_name]:\n",
    "            gbm = lightgbm.LGBMClassifier()\n",
    "            params = {'objective': 'multiclass','num_class': y_train[variable].nunique()}\n",
    "\n",
    "            lgb_train = lightgbm.Dataset(lgb_X_train, y_train[variable].astype('category').cat.codes)\n",
    "            lgb_eval = lightgbm.Dataset(lgb_X_val, y_val[variable].astype('category').cat.codes, reference=lgb_train)\n",
    "\n",
    "            classifier = lightgbm.train(params, train_set=lgb_train, valid_sets=lgb_eval)\n",
    "\n",
    "            y_pred = classifier.predict(lgb_X_test)\n",
    "            y_pred = np.argmax(y_pred, axis=1)\n",
    "            acc = sklearn.metrics.accuracy_score(y_test[variable].astype('category').cat.codes, y_pred)\n",
    "\n",
    "            pca_result_list.append((dim,dataset_name,variable,acc))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "pd.DataFrame(pca_result_list, columns=['dim','dataset','variable','test_acc']).to_csv(save_dir / \"lgbm_pca.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "pd.DataFrame(baseline_result_list, columns=['dataset','variable','maj_class_acc','lgbm_all_vars_test_acc']).to_csv(save_dir / \"lgbm_baseline.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
