{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import sys\n",
    "if \"..\" not in sys.path:\n",
    "    sys.path.insert(0, \"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "from datasets import OrganoidDataset\n",
    "\n",
    "dataset = OrganoidDataset(data_dir='/data/PycharmProjects/cytof_benchmark/data/organoids')\n",
    "\n",
    "import torch\n",
    "\n",
    "X_val, y_val = dataset.val\n",
    "X_val_batches = torch.split(torch.Tensor(X_val).to('cuda'), split_size_or_sections=32*1024)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "          index        cell_type  day\n0        125964       Enterocyte    2\n1        573521       Enterocyte    7\n2       1112662             Tuft    5\n3       1058543             Tuft    2\n4       1031398             Stem    7\n...         ...              ...  ...\n234490   857805             Stem    4\n234491   167125       Enterocyte    2\n234492   680457  Enteroendocrine    6\n234493   139701       Enterocyte    2\n234494   412098       Enterocyte    4\n\n[234495 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>cell_type</th>\n      <th>day</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>125964</td>\n      <td>Enterocyte</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>573521</td>\n      <td>Enterocyte</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1112662</td>\n      <td>Tuft</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1058543</td>\n      <td>Tuft</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1031398</td>\n      <td>Stem</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>234490</th>\n      <td>857805</td>\n      <td>Stem</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>234491</th>\n      <td>167125</td>\n      <td>Enterocyte</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>234492</th>\n      <td>680457</td>\n      <td>Enteroendocrine</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>234493</th>\n      <td>139701</td>\n      <td>Enterocyte</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>234494</th>\n      <td>412098</td>\n      <td>Enterocyte</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>234495 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "from configs.pbt import beta_vae_pbt,dbeta_vae_pbt,wae_pbt,hs_vae_pbt\n",
    "\n",
    "model_names = [\"BetaVAE\", \"DBetaVAE\", \"WAE_MMD\", \"HyperSphericalVAE\"]\n",
    "configs = [beta_vae_pbt.get_config(),dbeta_vae_pbt.get_config(),wae_pbt.get_config(),hs_vae_pbt.get_config()]\n",
    "\n",
    "dataset_names = ['OrganoidDataset', 'CafDataset', 'ChallengeDataset']\n",
    "data_dirs = ['/data/PycharmProjects/cytof_benchmark/data/organoids',\n",
    "             '/data/PycharmProjects/cytof_benchmark/data/caf',\n",
    "             '/data/PycharmProjects/cytof_benchmark/data/breast_cancer_challenge']\n",
    "features = [41, 44, 37]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "['/home/egor/Desktop/ray_tune/pbt_bench/HyperSphericalVAE/ChallengeDataset/model.pth',\n '/home/egor/Desktop/ray_tune/pbt_bench/HyperSphericalVAE/CafDataset/model.pth',\n '/home/egor/Desktop/ray_tune/pbt_bench/HyperSphericalVAE/OrganoidDataset/model.pth',\n '/home/egor/Desktop/ray_tune/pbt_bench/DBetaVAE/ChallengeDataset/model.pth',\n '/home/egor/Desktop/ray_tune/pbt_bench/DBetaVAE/CafDataset/model.pth',\n '/home/egor/Desktop/ray_tune/pbt_bench/DBetaVAE/OrganoidDataset/model.pth',\n '/home/egor/Desktop/ray_tune/pbt_bench/BetaVAE/ChallengeDataset/model.pth',\n '/home/egor/Desktop/ray_tune/pbt_bench/BetaVAE/CafDataset/model.pth',\n '/home/egor/Desktop/ray_tune/pbt_bench/BetaVAE/OrganoidDataset/model.pth',\n '/home/egor/Desktop/ray_tune/pbt_bench/WAE_MMD/ChallengeDataset/model.pth',\n '/home/egor/Desktop/ray_tune/pbt_bench/WAE_MMD/CafDataset/model.pth',\n '/home/egor/Desktop/ray_tune/pbt_bench/WAE_MMD/OrganoidDataset/model.pth']"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "bench_dir = \"/home/egor/Desktop/ray_tune/pbt_bench/\"\n",
    "checkpoint_files = glob.glob(bench_dir + \"*/*/model.pth\")\n",
    "checkpoint_files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "{'ChallengeDataset': {'HyperSphericalVAE': '/home/egor/Desktop/ray_tune/pbt_bench/HyperSphericalVAE/ChallengeDataset/model.pth',\n  'DBetaVAE': '/home/egor/Desktop/ray_tune/pbt_bench/DBetaVAE/ChallengeDataset/model.pth',\n  'BetaVAE': '/home/egor/Desktop/ray_tune/pbt_bench/BetaVAE/ChallengeDataset/model.pth',\n  'WAE_MMD': '/home/egor/Desktop/ray_tune/pbt_bench/WAE_MMD/ChallengeDataset/model.pth'},\n 'CafDataset': {'HyperSphericalVAE': '/home/egor/Desktop/ray_tune/pbt_bench/HyperSphericalVAE/CafDataset/model.pth',\n  'DBetaVAE': '/home/egor/Desktop/ray_tune/pbt_bench/DBetaVAE/CafDataset/model.pth',\n  'BetaVAE': '/home/egor/Desktop/ray_tune/pbt_bench/BetaVAE/CafDataset/model.pth',\n  'WAE_MMD': '/home/egor/Desktop/ray_tune/pbt_bench/WAE_MMD/CafDataset/model.pth'},\n 'OrganoidDataset': {'HyperSphericalVAE': '/home/egor/Desktop/ray_tune/pbt_bench/HyperSphericalVAE/OrganoidDataset/model.pth',\n  'DBetaVAE': '/home/egor/Desktop/ray_tune/pbt_bench/DBetaVAE/OrganoidDataset/model.pth',\n  'BetaVAE': '/home/egor/Desktop/ray_tune/pbt_bench/BetaVAE/OrganoidDataset/model.pth',\n  'WAE_MMD': '/home/egor/Desktop/ray_tune/pbt_bench/WAE_MMD/OrganoidDataset/model.pth'}}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_dict = dict()\n",
    "for checkpoint_file in checkpoint_files:\n",
    "    dataset_name = checkpoint_file.split('/')[-2]\n",
    "    model = checkpoint_file.split('/')[-3]\n",
    "    if dataset_name not in checkpoint_dict:\n",
    "        checkpoint_dict[dataset_name]=dict()\n",
    "    checkpoint_dict[dataset_name][model]= checkpoint_file\n",
    "checkpoint_dict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/PycharmProjects/cytof_benchmark/venv/lib/python3.10/site-packages/torch/distributions/distribution.py:45: UserWarning: <class 'models.hyperspherical_vae_extra.distributions.hyperspherical_uniform.HypersphericalUniform'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n",
      "  warnings.warn(f'{self.__class__} does not define `arg_constraints`. ' +\n",
      "/data/PycharmProjects/cytof_benchmark/venv/lib/python3.10/site-packages/torch/distributions/distribution.py:45: UserWarning: <class 'models.hyperspherical_vae_extra.distributions.hyperspherical_uniform.HypersphericalUniform'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n",
      "  warnings.warn(f'{self.__class__} does not define `arg_constraints`. ' +\n",
      "/data/PycharmProjects/cytof_benchmark/venv/lib/python3.10/site-packages/torch/distributions/distribution.py:45: UserWarning: <class 'models.hyperspherical_vae_extra.distributions.hyperspherical_uniform.HypersphericalUniform'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n",
      "  warnings.warn(f'{self.__class__} does not define `arg_constraints`. ' +\n"
     ]
    }
   ],
   "source": [
    "import models\n",
    "import pandas as pd\n",
    "import datasets\n",
    "save_dir ='/data/PycharmProjects/cytof_benchmark/results/mse_data'\n",
    "\n",
    "for dataset_name,feature_count,data_dir in zip(dataset_names,features,data_dirs):\n",
    "\n",
    "    dataset_class = getattr(datasets, dataset_name)\n",
    "    dataset = dataset_class(data_dir=data_dir)\n",
    "    X_val, y_val = dataset.val\n",
    "    X_val_batches = torch.split(torch.Tensor(X_val).to('cuda'), split_size_or_sections=32*1024)\n",
    "\n",
    "    for config, model_name in zip(configs,model_names):\n",
    "        with config.unlocked():\n",
    "            config.in_features = feature_count\n",
    "\n",
    "        model_class = getattr(models, model_name)\n",
    "        model = model_class(config).to('cuda')\n",
    "\n",
    "        checkpoint = torch.load(checkpoint_dict[dataset_name][model_name])\n",
    "        model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "        decoded_batches = []\n",
    "        latent_batches = []\n",
    "        with torch.no_grad():\n",
    "            for X_batch in X_val_batches:\n",
    "                decoded_batch = model.forward(X_batch)[0].to('cpu')\n",
    "                decoded_batches.append(decoded_batch)\n",
    "\n",
    "                latent_batch = model.latent(X_batch).to('cpu')\n",
    "                latent_batches.append(latent_batch)\n",
    "\n",
    "        decoded = torch.cat(decoded_batches)\n",
    "        latent = torch.cat(latent_batches)\n",
    "\n",
    "        latent_df = pd.DataFrame(latent.numpy(), columns=[\"VAE{}\".format(i) for i in range(1, latent.shape[1] + 1)])\n",
    "        mse_df = pd.DataFrame(((decoded-torch.Tensor(X_val))**2).numpy(), columns=list(dataset.variables))\n",
    "\n",
    "        latent_df.to_csv(os.path.join(save_dir,f'{dataset_name}_{model_name}_latent.csv'))\n",
    "        mse_df.to_csv(os.path.join(save_dir,f'{dataset_name}_{model_name}_mse.csv'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/PycharmProjects/cytof_benchmark/venv/lib/python3.10/site-packages/torch/distributions/distribution.py:45: UserWarning: <class 'models.hyperspherical_vae_extra.distributions.hyperspherical_uniform.HypersphericalUniform'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n",
      "  warnings.warn(f'{self.__class__} does not define `arg_constraints`. ' +\n",
      "/data/PycharmProjects/cytof_benchmark/venv/lib/python3.10/site-packages/torch/distributions/distribution.py:45: UserWarning: <class 'models.hyperspherical_vae_extra.distributions.hyperspherical_uniform.HypersphericalUniform'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n",
      "  warnings.warn(f'{self.__class__} does not define `arg_constraints`. ' +\n",
      "/data/PycharmProjects/cytof_benchmark/venv/lib/python3.10/site-packages/torch/distributions/distribution.py:45: UserWarning: <class 'models.hyperspherical_vae_extra.distributions.hyperspherical_uniform.HypersphericalUniform'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n",
      "  warnings.warn(f'{self.__class__} does not define `arg_constraints`. ' +\n",
      "/data/PycharmProjects/cytof_benchmark/venv/lib/python3.10/site-packages/torch/distributions/distribution.py:45: UserWarning: <class 'models.hyperspherical_vae_extra.distributions.hyperspherical_uniform.HypersphericalUniform'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n",
      "  warnings.warn(f'{self.__class__} does not define `arg_constraints`. ' +\n",
      "/data/PycharmProjects/cytof_benchmark/venv/lib/python3.10/site-packages/torch/distributions/distribution.py:45: UserWarning: <class 'models.hyperspherical_vae_extra.distributions.hyperspherical_uniform.HypersphericalUniform'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n",
      "  warnings.warn(f'{self.__class__} does not define `arg_constraints`. ' +\n",
      "/data/PycharmProjects/cytof_benchmark/venv/lib/python3.10/site-packages/torch/distributions/distribution.py:45: UserWarning: <class 'models.hyperspherical_vae_extra.distributions.hyperspherical_uniform.HypersphericalUniform'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n",
      "  warnings.warn(f'{self.__class__} does not define `arg_constraints`. ' +\n"
     ]
    }
   ],
   "source": [
    "import models\n",
    "import pandas as pd\n",
    "import datasets\n",
    "save_dir ='/data/PycharmProjects/cytof_benchmark/results/latent_data'\n",
    "\n",
    "for dataset_name,feature_count,data_dir in zip(dataset_names,features,data_dirs):\n",
    "\n",
    "    dataset_class = getattr(datasets, dataset_name)\n",
    "    dataset = dataset_class(data_dir=data_dir)\n",
    "\n",
    "    X_train,y_train = dataset.train\n",
    "    X_val, y_val = dataset.val\n",
    "\n",
    "    X_train_batches = torch.split(torch.Tensor(X_train).to('cuda'), split_size_or_sections=32*1024)\n",
    "    X_val_batches = torch.split(torch.Tensor(X_val).to('cuda'), split_size_or_sections=32*1024)\n",
    "\n",
    "    for config, model_name in zip(configs,model_names):\n",
    "        with config.unlocked():\n",
    "            config.in_features = feature_count\n",
    "\n",
    "        model_class = getattr(models, model_name)\n",
    "        model = model_class(config).to('cuda')\n",
    "\n",
    "        checkpoint = torch.load(checkpoint_dict[dataset_name][model_name])\n",
    "        model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "        latent_batches = []\n",
    "        with torch.no_grad():\n",
    "            for X_batch in X_val_batches:\n",
    "                latent_batch = model.latent(X_batch).to('cpu')\n",
    "                latent_batches.append(latent_batch)\n",
    "\n",
    "        latent = torch.cat(latent_batches)\n",
    "\n",
    "        latent_df = pd.DataFrame(latent.numpy(), columns=[\"VAE{}\".format(i) for i in range(1, latent.shape[1] + 1)])\n",
    "        latent_df.to_csv(os.path.join(save_dir,f'{dataset_name}_{model_name}_val_latent.csv'))\n",
    "\n",
    "\n",
    "        latent_batches = []\n",
    "        with torch.no_grad():\n",
    "            for X_batch in X_train_batches:\n",
    "                latent_batch = model.latent(X_batch).to('cpu')\n",
    "                latent_batches.append(latent_batch)\n",
    "\n",
    "        latent = torch.cat(latent_batches)\n",
    "\n",
    "        latent_df = pd.DataFrame(latent.numpy(), columns=[\"VAE{}\".format(i) for i in range(1, latent.shape[1] + 1)])\n",
    "        latent_df.to_csv(os.path.join(save_dir,f'{dataset_name}_{model_name}_train_latent.csv'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
